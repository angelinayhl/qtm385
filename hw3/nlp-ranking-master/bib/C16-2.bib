@inproceedings{C16-2001,
 abstract = {We present an interactive system to provide effective and efficient search
capabilities in Community Question Answering (cQA) forums. The system
integrates state-of-the-art technology for answer search with a Web-based user
interface specifically tailored to support the cQA forum readers. The answer
search module automatically finds relevant answers for a new question by
exploring related questions and the comments within their threads. The
graphical user interface presents the search results and supports the
exploration of related information. The system is running live at
http://www.qatarliving.com/betasearch/.
Author{1}{Affiliation}},
 address = {Osaka, Japan},
 author = {Hoque, Enamul  and  Joty, Shafiq  and  M\`{a}rquez, Llu\'{i}s  and  Barr\'{o}n-Cede\~{n}o, Alberto  and  Da San Martino, Giovanni  and  Moschitti, Alessandro  and  Nakov, Preslav  and  Romeo, Salvatore  and  Carenini, Giuseppe},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {1--5},
 publisher = {The COLING 2016 Organizing Committee},
 title = {An Interactive System for Exploring Community Question Answering Forums},
 year = {2016}
}

@inproceedings{C16-2002,
 abstract = {We present a Natural Language Interface (nlmaps.cl.uni-heidelberg.de) to query
OpenStreetMap. Natural language questions about geographical facts are parsed
into database queries that can be executed against the OpenStreetMap (OSM)
database. After parsing the question, the system provides a text based answer
as well as an interactive map with all points of interest and their relevant
information marked. Additionally, we provide several options for users to give
feedback after a question has been parsed.},
 address = {Osaka, Japan},
 author = {Lawrence, Carolin  and  Riezler, Stefan},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {6--10},
 publisher = {The COLING 2016 Organizing Committee},
 title = {NLmaps: A Natural Language Interface to Query OpenStreetMap},
 year = {2016}
}

@inproceedings{C16-2003,
 abstract = {We present a mobile app that provides a reading environment for learners of
Chinese as a foreign language.              The app includes a text database that
offers
over 500K articles from Chinese Wikipedia.  These articles have been
word-segmented; each word is linked to its entry in a Chinese-English
dictionary, and to automatically-generated review exercises.  The app estimates
the reading proficiency of the user based on a ``to-learn'' list of vocabulary
items.              It automatically constructs and maintains this list by tracking
the
user's dictionary lookup behavior and performance in review exercises.
When a
user searches for articles to read, search results are filtered such that the
proportion of unknown words does not exceed a user-specified threshold.},
 address = {Osaka, Japan},
 author = {Lee, John  and  Lam, Chun Yin  and  Jiang, Shu},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {11--15},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Reading Environment for Learners of Chinese as a Foreign Language},
 year = {2016}
}

@inproceedings{C16-2004,
 abstract = {Adaptive machine translation (MT) systems are a promising approach for
improving the effectiveness of computer-aided translation (CAT) environments.
There is, however, virtually only theoretical work that examines how such a
system could be implemented. We present an open source post-editing interface
for adaptive statistical MT, which has in-depth monitoring capabilities and
excellent expandability, and can facilitate practical studies. To this end, we
designed text-based and graphical post-editing interfaces. The graphical
interface offers means for displaying and editing a rich view of the MT output.
Our translation systems may learn from post-edits using several weight, language model and novel translation model adaptation techniques, in part by
exploiting the output of the graphical interface. In a user study we show that
using the proposed interface and adaptation methods, reductions in technical
effort and time can be achieved.},
 address = {Osaka, Japan},
 author = {Simianer, Patrick  and  Karimova, Sariya  and  Riezler, Stefan},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {16--20},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Post-editing Interface for Immediate Adaptation in Statistical Machine Translation},
 year = {2016}
}

@inproceedings{C16-2005,
 abstract = {Adult second language learners face the daunting but underappreciated task of
mastering patterns of language use that are neither products of fully
productive grammar rules nor frozen items to be memorized. Word Midas, a web
browser extention, targets this uncharted territory of lexicogrammar by
detecting multiword tokens of lexicogrammatical patterning in real time in situ
within the noisy digital texts from the userâs unscripted web browsing or
other digital venues. The language model powering Word Midas is StringNet, a
densely cross-indexed navigable network of one billion lexicogrammatical
patterns of English. These resources are described and their functionality is
illustrated with a detailed scenario.},
 address = {Osaka, Japan},
 author = {Wible, David  and  Tsao, Nai-Lung},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {21--24},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Word Midas Powered by StringNet: Discovering Lexicogrammatical Constructions in Situ},
 year = {2016}
}

@inproceedings{C16-2006,
 abstract = {The National Institute for Japanese Language and Linguistics, Japan (NINJAL)
has undertaken
a corpus compilation project to construct a web corpus for linguistic research
comprising ten
billion words. The project is divided into four parts: page collection, linguistic analysis, development
of the corpus concordance system, and preservation. This article presents the
corpus
concordance system named âBonTenâ which enables the ten-billion-scaled
corpus to be queried
by string, a sequence of morphological information or a subtree of the
syntactic dependency
structure.},
 address = {Osaka, Japan},
 author = {Asahara, Masayuki  and  KAWAHARA, Kazuya  and  TAKEI, Yuya  and  MASUOKA, Hideto  and  OHBA, Yasuko  and  TORII, Yuki  and  MORII, Toru  and  TANAKA, Yuki  and  Maekawa, Kikuo  and  KATO, Sachi  and  KONISHI, Hikari},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {25--29},
 publisher = {The COLING 2016 Organizing Committee},
 title = {`BonTen' -- Corpus Concordance System for `NINJAL Web Japanese Corpus'},
 year = {2016}
}

@inproceedings{C16-2007,
 abstract = {Simultaneous interpretation allows people to communicate spontaneously across
language boundaries, but such services are prohibitively expensive for the
general public. This paper presents a fully automatic simultaneous
interpretation system to address this problem. Though the development is still
at an early stage, the system is capable of keeping up with the fastest of the
TED speakers while at the same time delivering high-quality translations. We
believe that the system will become an effective tool for facilitating
cross-lingual communication in the future.},
 address = {Osaka, Japan},
 author = {Wang, Xiaolin  and  Finch, Andrew  and  Utiyama, Masao  and  Sumita, Eiichiro},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {30--34},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Prototype Automatic Simultaneous Interpretation System},
 year = {2016}
}

@inproceedings{C16-2008,
 abstract = {The paper introduces a web-based authoring support system, MuTUAL, which aims
to help writers create multilingual texts. The highlighted feature of the
system is that it enables machine translation (MT) to generate outputs
appropriate to their functional context within the target document. Our system
is operational online, implementing core mechanisms for document structuring
and controlled writing. These include a topic template and a controlled
language authoring assistant, linked to our statistical MT system.},
 address = {Osaka, Japan},
 author = {Miyata, Rei  and  Hartley, Anthony  and  Kageura, Kyo  and  Paris, Cecile  and  Utiyama, Masao  and  Sumita, Eiichiro},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {35--39},
 publisher = {The COLING 2016 Organizing Committee},
 title = {MuTUAL: A Controlled Authoring Support System Enabling Contextual Machine Translation},
 year = {2016}
}

@inproceedings{C16-2009,
 abstract = {In this paper and the associated system demo, we present an advanced search
system that allows to perform a joint search over a (bilingual) valency lexicon
and a correspondingly annotated linked parallel corpus. This search tool has
been developed on the basis of the Prague Czech-English Dependency Treebank, but its ideas are applicable in principle to any bilingual parallel corpus that
is annotated for dependencies and valency (i.e., predicate-argument structure), and where verbs are linked to appropriate entries in an associated valency
lexicon.  Our online search tool consolidates more search interfaces into one, providing expanded structured search capability and a more efficient advanced
way to search, allowing users to search for verb pairs, verbal argument pairs, their surface realization as recorded in the lexicon, or for their surface form
actually appearing in the linked parallel corpus. The search system is
currently under development, and is replacing our current search tool available
at \url{http://lindat.mff.cuni.cz/services/CzEngVallex}, which could search the
lexicon but the queries cannot take advantage of the underlying corpus nor use
the additional surface form information from the lexicon(s). The system is
available as open source.},
 address = {Osaka, Japan},
 author = {Fu\v{c}\'{i}kov\'{a}, Eva  and  Hajic, Jan  and  Uresova, Zdenka},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {40--44},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Joint search in a bilingual valency lexicon and an annotated corpus},
 year = {2016}
}

@inproceedings{C16-2010,
 abstract = {In this study we develop a system that tags and extracts financial concepts
called financial named entities (FNE) along with corresponding numeric values
-- monetary and temporal. We employ machine learning and natural language
processing methods to identify financial concepts and dates, and link them to
numerical entities.},
 address = {Osaka, Japan},
 author = {Kumar, Aman  and  Alam, Hassan  and  Werner, Tina  and  Vyas, Manan},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {45--48},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Experiments in Candidate Phrase Selection for Financial Named Entity Extraction - A Demo},
 year = {2016}
}

@inproceedings{C16-2011,
 abstract = {ChaKi.NET is a corpus management system for dependency
structure annotated corpora.
After more than 10 years of continuous development, the system is now usable
not only for
corpus search, but also for visualization, annotation, labelling, and
formatting
for statistical analysis.
This paper describes the various functions included in the current ChaKi.NET
system.},
 address = {Osaka, Japan},
 author = {Asahara, Masayuki  and  Matsumoto, Yuji  and  MORITA, Toshio},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {49--53},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Demonstration of ChaKi.NET -- beyond the corpus search system},
 year = {2016}
}

@inproceedings{C16-2012,
 abstract = {Much existing work in text-to-scene generation focuses on generating static
scenes.  By introducing a focus on motion verbs, we integrate dynamic semantics
into a rich formal model of events to generate animations in real time that
correlate with human conceptions of the event described.  This paper presents a
working system that generates these animated scenes over a test set, discussing
challenges encountered and describing the solutions implemented.},
 address = {Osaka, Japan},
 author = {Krishnaswamy, Nikhil  and  Pustejovsky, James},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {54--58},
 publisher = {The COLING 2016 Organizing Committee},
 title = {VoxSim: A Visual Platform for Modeling Motion Language},
 year = {2016}
}

@inproceedings{C16-2013,
 abstract = {More and more disciplines require NLP tools for performing automatic text
analyses on various levels of linguistic resolution. However, the usage of
established NLP frameworks is often hampered for several reasons: in most
cases, they require basic to sophisticated programming skills, interfere with
interoperability due to using non-standard I/O-formats and often lack tools for
visualizing computational results. This makes it difficult especially for
humanities scholars to use such frameworks. In order to cope with these
challenges, we present TextImager, a UIMA-based framework that offers a range
of NLP and visualization tools by means of a user-friendly GUI. Using
TextImager requires no programming skills.},
 address = {Osaka, Japan},
 author = {Hemati, Wahed  and  Uslu, Tolga  and  Mehler, Alexander},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {59--63},
 publisher = {The COLING 2016 Organizing Committee},
 title = {TextImager: a Distributed UIMA-based System for NLP},
 year = {2016}
}

@inproceedings{C16-2014,
 abstract = {This paper presents Disco, a prototype for supporting knowledge workers in
exploring, reviewing and sorting collections of textual data. The goal is to
facilitate, accelerate and improve the discovery of information. To this end, it combines Semantic Relatedness techniques with a review workflow developed in
a tangible environment. Disco uses a semantic model that is leveraged on-line
in the course of search sessions, and accessed through natural hand-gesture, in
a simple and intuitive way.},
 address = {Osaka, Japan},
 author = {Vo, Ngoc Phuoc An  and  Guillot, Fabien  and  Privault, Caroline},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {64--68},
 publisher = {The COLING 2016 Organizing Committee},
 title = {DISCO: A System Leveraging Semantic Search in Document Review},
 year = {2016}
}

@inproceedings{C16-2015,
 abstract = {We describe pke, an open source python-based keyphrase extraction toolkit. It
provides an end-to-end keyphrase extraction pipeline in which each component
can be easily modified or extented to develop new approaches. pke also allows
for easy benchmarking of state-of-the-art keyphrase extraction approaches, and
ships with supervised models trained on the SemEval-2010 dataset.},
 address = {Osaka, Japan},
 author = {Boudin, Florian},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {69--73},
 publisher = {The COLING 2016 Organizing Committee},
 title = {pke: an open source python-based keyphrase extraction toolkit},
 year = {2016}
}

@inproceedings{C16-2016,
 abstract = {In this paper, we describe \textbf{Langforia}, a multilingual processing
pipeline to annotate texts with multiple layers: formatting, parts of speech, named entities, dependencies, semantic roles, and entity links. Langforia works
as a web service, where the server hosts the language processing components and
the client, the input and result visualization. To annotate a text or a
Wikipedia page, the user chooses an NLP pipeline and enters the text in the
interface or selects the page URL. Once processed, the results are returned to
the client, where the user can select the annotation layers s/he wants to
visualize.
We designed Langforia with a specific focus for Wikipedia, although it can
process any type of text. Wikipedia has become an essential encyclopedic corpus
used in many NLP projects. However, processing articles and visualizing the
annotations are nontrivial tasks that require dealing with multiple markup
variants, encodings issues, and tool incompatibilities across the language
versions. This motivated the development of a new architecture.
A demonstration of Langforia is available for six languages: English, French, German, Spanish, Russian, and Swedish at \url{http://vilde.cs.lth.se:9000/} as
well as a web API: \url{http://vilde.cs.lth.se:9000/api}. Langforia is also
provided as a standalone library and is compatible with cluster computing.},
 address = {Osaka, Japan},
 author = {Klang, Marcus  and  Nugues, Pierre},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {74--78},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Langforia: Language Pipelines for Annotating Large Collections of Documents},
 year = {2016}
}

@inproceedings{C16-2017,
 abstract = {We introduce Anita: a flexible and intelligent Text Adaptation tool for web
content that provides Text Simplification and Text Enhancement modules. Anita's
simplification module features a state-of-the-art system that adapts texts
according to the needs of individual users, and its enhancement module allows
the user to search for a word's definitions, synonyms, translations, and visual
cues through related images. These utilities are brought together in an
easy-to-use interface of a freely available web browser extension.},
 address = {Osaka, Japan},
 author = {Paetzold, Gustavo  and  Specia, Lucia},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {79--83},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Anita: An Intelligent Text Adaptation Tool},
 year = {2016}
}

@inproceedings{C16-2018,
 abstract = {Recent years have witnessed significant increase in the number of large scale
digital collections of archival documents such as news articles, books, etc.
Typically, users access these collections through searching or browsing. In
this paper we investigate another way of accessing temporal collections -
across-time comparison, i.e., comparing query-relevant information at different
periods in the past. We propose an interactive framework called
HistoryComparator for contrastively analyzing concepts in archival document
collections at different time periods.},
 address = {Osaka, Japan},
 author = {Jatowt, Adam  and  Bron, Marc},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {84--88},
 publisher = {The COLING 2016 Organizing Committee},
 title = {HistoryComparator: Interactive Across-Time Comparison in Document Archives},
 year = {2016}
}

@inproceedings{C16-2019,
 abstract = {In this demo, we present our free on-line multilingual linguistic services
which allow to analyze sentences or to extract collocations from a corpus
directly on-line, or by uploading a corpus. They are available for 8 European
languages (English, French, German, Greek, Italian, Portuguese, Romanian, Spanish) and can also be accessed as web services by programs.
While several open systems are available for POS-tagging and dependency parsing
or terminology extraction, their integration into an application requires some
computational competence. Furthermore, none of the parsers/taggers handles MWEs
very satisfactorily, in particular when the two terms of the collocation are
distant from each other or in reverse order. Our tools, on  the other hand, are
specifically designed for users with no particular computational literacy. They
do not require from the user any download, installation or adaptation if used
on-line, and their integration in an application, using one the scripts
described below is quite easy. Furthermore, by default, the parser handles
collocations and other MWEs, as well as anaphora resolution (limited to 3rd
person personal pronouns). When used in the tagger mode, it can be set to
display grammatical functions and collocations.},
 address = {Osaka, Japan},
 author = {Wehrli, Eric  and  Scherrer, Yves  and  Nerima, Luka},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {89--92},
 publisher = {The COLING 2016 Organizing Committee},
 title = {On-line Multilingual Linguistic Services},
 year = {2016}
}

@inproceedings{C16-2020,
 abstract = {We present a browser-based editor for simplifying English text.  Given an input
sentence, the editor performs both syntactic and lexical simplification.  It
splits a complex sentence into shorter ones, and suggests word substitutions in
drop-down lists.  The user can choose the best substitution from the list, undo
any inappropriate splitting, and further edit the sentence as necessary.  A
significant novelty is that the system accepts a customized vocabulary list for
a target reader population.  It identifies all words in the text that do not
belong to the list, and attempts to substitute them with words from the list, thus producing a text tailored for the targeted readers.},
 address = {Osaka, Japan},
 author = {Lee, John  and  Zhao, Wenlong  and  Xie, Wenxiu},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {93--97},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Customizable Editor for Text Simplification},
 year = {2016}
}

@inproceedings{C16-2021,
 abstract = {We present a free web-based CAT tool called CATaLog Online which provides a
novel and user-friendly online CAT environment for post-editors/translators.
The goal is to support distributed translation, reduce post-editing time and
effort, improve the post-editing experience and capture data for incremental
MT/APE (automatic post-editing) and translation process research. The tool
supports individual as well as batch mode file translation and provides
translations from three engines -- translation memory (TM), MT and APE. TM
suggestions are color coded to accelerate the post-editing task. The users can
integrate their personal TM/MT outputs. The tool remotely monitors and records
post-editing activities generating an extensive range of post-editing logs.},
 address = {Osaka, Japan},
 author = {Pal, Santanu  and  Naskar, Sudip Kumar  and  Zampieri, Marcos  and  Nayak, Tapas  and  van Genabith, Josef},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {98--102},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CATaLog Online: A Web-based CAT Tool for Distributed Translation with Data Capture for APE and Translation Process Research},
 year = {2016}
}

@inproceedings{C16-2022,
 abstract = {We present INDREX-MM, a main memory database system for interactively executing
two interwoven tasks, declarative relation extraction from text and their
exploitation with SQL. INDREX-MM simplifies these tasks for the user with
powerful SQL extensions for gathering statistical semantics, for executing open
information extraction and for integrating relation candidates with domain
specific data. We demonstrate these functions on 800k documents from Reuters
RCV1 with more than a billion linguistic annotations and report execution times
in the order of seconds.},
 address = {Osaka, Japan},
 author = {Schneider, Rudolf  and  Guder, Cordula  and  Kilias, Torsten  and  L\"{o}ser, Alexander  and  Graupmann, Jens  and  Kozachuk, Oleksandr},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {103--106},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Interactive Relation Extraction in Main Memory Database Systems},
 year = {2016}
}

@inproceedings{C16-2023,
 abstract = {In this paper, we introduce an original Python implementation of datetime
resolution in french, which we make available as open-source library. Our
approach is based on Frame Semantics and Corpus Pattern Analysis in order to
provide a precise semantic interpretation of datetime expressions. This
interpretation facilitates the contextual resolution of datetime expressions in
timestamp format.},
 address = {Osaka, Japan},
 author = {Merlo, Aur\'{e}lie  and  Pasin, Denis},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {107--110},
 publisher = {The COLING 2016 Organizing Committee},
 title = {An Open Source Library for Semantic-Based Datetime Resolution},
 year = {2016}
}

@inproceedings{C16-2024,
 abstract = {We introduce TASTY (Tag-as-you-type), a novel text editor for interactive
entity linking as part of the writing process. Tasty supports the author of a
text with complementary information about the mentioned entities shown in a
`live' exploration view. The system is automatically triggered by keystrokes, recognizes mention boundaries and disambiguates the mentioned entities to
Wikipedia articles. The author can use seven operators to interact with the
editor and refine the results according to his specific intention while
writing. Our implementation captures syntactic and semantic context using a
robust end-to-end LSTM sequence learner and word embeddings. We demonstrate the
applicability of our system in English and German language for encyclopedic or
medical text. Tasty is currently being tested in interactive applications for
text production, such as scientific research, news editorial, medical
anamnesis, help desks and product reviews.},
 address = {Osaka, Japan},
 author = {Arnold, Sebastian  and  Dziuba, Robert  and  L\"{o}ser, Alexander},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {111--115},
 publisher = {The COLING 2016 Organizing Committee},
 title = {TASTY: Interactive Entity Linking As-You-Type},
 year = {2016}
}

@inproceedings{C16-2025,
 abstract = {We demonstrate a bilingual robot application, WikiTalk, that can talk fluently
in both English and Japanese about almost any topic using information from
English and Japanese Wikipedias. The English version of the system has been
demonstrated previously, but we now present a live demo with a Nao robot that
speaks English and Japanese and switches language on request. The robot
supports the verbal interaction with face-tracking, nodding and communicative
gesturing. One of the key features of the WikiTalk system is that the robot can
switch from the current topic to related topics during the interaction in order
to navigate around Wikipedia following the userâs individual interests.},
 address = {Osaka, Japan},
 author = {Wilcock, Graham  and  Jokinen, Kristiina  and  Yamamoto, Seiichi},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {116--120},
 publisher = {The COLING 2016 Organizing Committee},
 title = {What topic do you want to hear about? A bilingual talking robot using English and Japanese Wikipedias},
 year = {2016}
}

@inproceedings{C16-2026,
 abstract = {The PDTB Annotator is a tool for annotating and adjudicating discourse
relations based on the annotation framework of the Penn Discourse TreeBank
(PDTB). This demo describes the benefits of using the PDTB Annotator, gives an
overview of the PDTB Framework and discusses the toolâs features, setup
requirements and how it can also be used for adjudication.
Author{4}{Affiliation}},
 address = {Osaka, Japan},
 author = {Lee, Alan  and  Prasad, Rashmi  and  Webber, Bonnie  and  Joshi, Aravind K.},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {121--125},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Annotating Discourse Relations with the PDTB Annotator},
 year = {2016}
}

@inproceedings{C16-2027,
 abstract = {Opinion mining is a natural language processing technique which extracts
subjective information from natural language text. To estimate an opinion about
a query in large data collection, an opinion retrieval system that retrieves
subjective and relevant information about the query can be useful. We present
an opinion retrieval system that retrieves subjective and query-relevant tweets
from Twitter, which is a useful source of obtaining real-time opinions. Our
system outperforms previous opinion retrieval systems, and it further provides
subjective information about Twitter authors and hashtags to describe their
subjective tendencies.},
 address = {Osaka, Japan},
 author = {Kim, Yoon-Sung  and  Song, Young-In  and  Rim, Hae-Chang},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {126--130},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Opinion Retrieval Systems using Tweet-external Factors},
 year = {2016}
}

@inproceedings{C16-2028,
 abstract = {This paper presents TextPro-AL (Active Learning for Text Processing), a
platform where human annotators can efficiently work to produce high quality
training data for new domains and new languages exploiting Active Learning
methodologies. TextPro-AL is a web-based application integrating four
components: a machine learning based NLP pipeline, an annotation editor for
task definition and text annotations,  an incremental re-training procedure
based on active learning selection from a large pool of unannotated data, and a
graphical visualization of the learning status of the system.},
 address = {Osaka, Japan},
 author = {Magnini, Bernardo  and  Minard, Anne-Lyse  and  Qwaider, Mohammed R. H.  and  Speranza, Manuela},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {131--135},
 publisher = {The COLING 2016 Organizing Committee},
 title = {TextPro-AL: An Active Learning Platform for Flexible and Efficient Production of Training Data for NLP Tasks},
 year = {2016}
}

@inproceedings{C16-2029,
 abstract = {In this paper, we discuss our ongoing efforts to construct a scientific paper
browsing system that helps users to read and understand advanced technical
content distributed in PDF. Since PDF is a format specifically designed for
printing, layout and logical structures of documents are indistinguishably
embedded in the file. It requires much effort to extract natural language text
from PDF files, and reversely, display semantic annotations produced by NLP
tools on the original page layout. In our browsing system, we tackle these
issues caused by the gap between printable document and plain text. Our system
provides ways to extract natural language sentences from PDF files together
with their logical structures, and also to map arbitrary textual spans to their
corresponding regions on page images. We setup a demonstration system using
papers published in ACL anthology and demonstrate the enhanced search and
refined recommendation functions which we plan to make widely available to NLP
researchers.},
 address = {Osaka, Japan},
 author = {Abekawa, Takeshi  and  Aizawa, Akiko},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {136--140},
 publisher = {The COLING 2016 Organizing Committee},
 title = {SideNoter: Scholarly Paper Browsing System based on PDF Restructuring and Text Annotation},
 year = {2016}
}

@inproceedings{C16-2030,
 abstract = {Instant messaging and push notifications play important roles in modern digital
life. To enable robust sense-making and rich context awareness in computer
mediated communications, we introduce EmotionPush, a system that automatically
conveys the emotion of received text with a colored push notification on mobile
devices. EmotionPush is powered by state-of-the-art emotion classifiers
and is deployed for Facebook Messenger clients on Android. The study showed
that the system is able to help users prioritize interactions.},
 address = {Osaka, Japan},
 author = {Wang, Shih-Ming  and  Lee, Chun-Hui Scott  and  Lo, Yu-Chun  and  Huang, Ting-Hao  and  Ku, Lun-Wei},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {141--145},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Sensing Emotions in Text Messages: An Application and Deployment Study of EmotionPush},
 year = {2016}
}

@inproceedings{C16-2031,
 abstract = {We release a cross-lingual wikification system for all languages in Wikipedia.
Given a piece of text in any supported language, the system identifies names of
people, locations, organizations, and grounds these names to the corresponding
English Wikipedia entries. The system is based on two components: a
cross-lingual named entity recognition (NER) model and a cross-lingual mention
grounding model. The cross-lingual NER model is a language-independent model
which can extract named entity mentions in the text of any language in
Wikipedia. The extracted mentions are then grounded to the English Wikipedia
using the cross-lingual mention grounding model. The only resources required to
train the proposed system are the multilingual Wikipedia dump and existing
training data for English NER. The system is online at
http://cogcomp.cs.illinois.edu/page/demo\_view/xl\_wikifier},
 address = {Osaka, Japan},
 author = {Tsai, Chen-Tse  and  Roth, Dan},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {146--150},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Illinois Cross-Lingual Wikifier: Grounding Entities in Many Languages to the English Wikipedia},
 year = {2016}
}

@inproceedings{C16-2032,
 abstract = {This paper presents a meaning-based statistical math word problem (MWP) solver
with understanding, reasoning and explanation. It comprises a web user
interface and pipelined modules for analysing the text, transforming both body
and question parts into their logic forms, and then performing inference on
them. The associated context of each quantity is represented with proposed
role-tags (e.g., nsubj, verb, etc.), which provides the flexibility for
annotating the extracted math quantity with its associated syntactic and
semantic information (which specifies the physical meaning of that quantity).
Those role-tags are then used to identify the desired operands and filter out
irrelevant quantities (so that the answer can be obtained precisely). Since the
physical meaning of each quantity is explicitly represented with those
role-tags and used in the inference process, the proposed approach could
explain how the answer is obtained in a human comprehensible way.},
 address = {Osaka, Japan},
 author = {Liang, Chao-Chun  and  Tsai, Shih-Hong  and  Chang, Ting-Yun  and  Lin, Yi-Chung  and  Su, Keh-Yih},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {151--155},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Meaning-based English Math Word Problem Solver with Understanding, Reasoning and Explanation},
 year = {2016}
}

@inproceedings{C16-2033,
 abstract = {This paper introduces Valencer: a RESTful API to search for annotated sentences
matching a given combination of syntactic realizations of the arguments of a
predicate -- also called 'valence pattern' -- in the FrameNet database. The API
takes as input an HTTP GET request specifying a valence pattern and outputs a
list of exemplifying annotated sentences in JSON format. The API is designed to
be modular and language-independent, and can therefore be easily integrated to
other (NLP) server-side or client-side applications, as well as non-English
FrameNet projects. Valencer is free, open-source, and licensed under the MIT
license.},
 address = {Osaka, Japan},
 author = {Kabbach, Alexandre  and  Ribeyre, Corentin},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {156--160},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Valencer: an API to Query Valence Patterns in FrameNet},
 year = {2016}
}

@inproceedings{C16-2034,
 abstract = {Developing a question answering (QA) system is a task of implementing and
integrating modules of different technologies and evaluating an integrated
whole system, which inevitably goes with a collaboration among experts of
different domains. For supporting a easy collaboration, this demonstration
presents the open framework that aims to support developing a QA system in
collaborative and intuitive ways. The demonstration also shows the QA system
developed by our novel framework.},
 address = {Osaka, Japan},
 author = {Kim, Jiseong  and  Choi, GyuHyeon  and  Kim, Jung-Uk  and  Kim, Eun-kyung  and  CHOI, KEY-SUN},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {161--165},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The Open Framework for Developing Knowledge Base And Question Answering System},
 year = {2016}
}

@inproceedings{C16-2035,
 abstract = {This paper shows the great potential of incorporating different approaches to
help writing. Not only did they solve different kinds of writing problems, but
also they complement and reinforce each other to be a complete and effective
solution. Despite the extensive and multifaceted feedback and suggestion, writing is not all about syntactically or lexically well-written. It involves
contents, structure, the certain understanding of the background, and many
other factors to compose a rich, organized and sophisticated text. (e.g., conventional structure and idioms in academic writing). There is still a long
way to go to accomplish the ultimate goal. We envision the future of writing to
be a joyful experience with the help of instantaneous suggestion and
constructive feedback.},
 address = {Osaka, Japan},
 author = {Chen, Jhih-Jie  and  Peng, Hao-Chun  and  Yeh, Mei-Cih  and  Chen, Peng-Yu  and  Chang, Jason},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {166--169},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Linggle Knows: A Search Engine Tells How People Write},
 year = {2016}
}

@inproceedings{C16-2036,
 abstract = {We present a text simplification approach that is directed
at improving the performance of state-of-the-art Open Relation Extraction (RE)
systems. As syntactically complex sentences often pose a challenge for current
Open RE approaches, we have developed a simplification framework that performs
a
pre-processing step by taking a single sentence as input and using a set of
syntactic-based transformation rules to create a textual input that is easier
to process for subsequently applied Open RE systems.},
 address = {Osaka, Japan},
 author = {Niklaus, Christina  and  Bermeitinger, Bernhard  and  Handschuh, Siegfried  and  Freitas, Andr\'{e}},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {170--174},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Sentence Simplification System for Improving Relation Extraction},
 year = {2016}
}

@inproceedings{C16-2037,
 abstract = {FrameNet project has begun from Berkeley in 1997, and is now supported in
several countries reflecting characteristics of each language. The work for
generating Korean FrameNet was already done by converting annotated English
sentences into Korean with trained translators. However, high cost of
frame-preservation and error revision was a huge burden on further expansion of
FrameNet. This study makes use of linguistic similarity between Japanese and
Korean to increase Korean FrameNet corpus with low cost. We also suggest
adapting PubAnnotation and Korean-friendly valence patterns to FrameNet for
increased accessibility.},
 address = {Osaka, Japan},
 author = {kim, jeonguk  and  hahm, younggyun  and  choi, key-sun},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {175--179},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Korean FrameNet Expansion Based on Projection of Japanese FrameNet},
 year = {2016}
}

@inproceedings{C16-2038,
 abstract = {Any real world events or trends that can affect the company's growth trajectory
can be considered as risk. There has been a growing need to automatically
identify, extract and analyze risk related statements from news events. In this
demonstration, we will present a risk analytics framework that processes
enterprise project management reports in the form of textual data and news
documents and classify them into valid and invalid risk categories. The
framework also extracts information from the text pertaining to the different
categories of risks like their possible cause and impacts. Accordingly, we have
used machine learning based techniques and studied different linguistic
features like n-gram, POS, dependency, future timing, uncertainty factors in
texts and their various combinations. A manual annotation study from management
experts using risk descriptions collected for a specific organization was
conducted to evaluate the framework. The evaluation showed promising results
for automated risk analysis and identification.},
 address = {Osaka, Japan},
 author = {Dasgupta, Tirthankar  and  Dey, Lipika  and  Dey, Prasenjit  and  Saha, Rupsa},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {180--184},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Framework for Mining Enterprise Risk and Risk Factors from News Documents},
 year = {2016}
}

@inproceedings{C16-2039,
 abstract = {In this paper, we introduce papago - a translator for mobile device which is
equipped with new features that can provide convenience for users. The first
feature is word sense disambiguation based on user feedback. By using the
feature, users can select one among multiple meanings of a homograph and obtain
the corrected translation with the user-selected sense. The second feature is
the instant currency conversion of money expressions contained in a translation
result with current exchange rate. Users can be quickly and precisely provided
the amount of money converted as local currency when they travel abroad.},
 address = {Osaka, Japan},
 author = {Lee, Hyoung-Gyu  and  Kim, Jun-Seok  and  Shin, Joong-Hwi  and  Lee, Jaesong  and  Quan, Ying-Xiu  and  Jeong, Young-Seob},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {185--188},
 publisher = {The COLING 2016 Organizing Committee},
 title = {papago: A Machine Translation Service with Word Sense Disambiguation and Currency Conversion},
 year = {2016}
}

@inproceedings{C16-2040,
 abstract = {We demonstrate TopoText, an interactive tool for digital mapping of literary
text. TopoText takes as input a literary piece of text such as a novel or a
biography article and automatically extracts all place names in the text. The
identified places are then geoparsed and displayed on an interactive map.
TopoText calculates the number of times a place was mentioned in the text, which is then reflected on the map allowing the end-user to grasp the
importance of the different places within the text. It also displays the most
frequent words mentioned within a specified proximity of a place name in
context or across the entire text. This can also be faceted according to part
of speech tags. Finally, TopoText keeps the human in the loop by allowing the
end-user to disambiguate places and to provide specific place annotations. All
extracted information such as geolocations, place frequencies, as well as all
user-provided annotations can be automatically exported as a CSV file that can
be imported later by the same user or other users.},
 address = {Osaka, Japan},
 author = {El Khatib, Randa  and  El Zini, Julia  and  Wrisley, David  and  Jaber, Mohamad  and  Elbassuoni, Shady},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {189--193},
 publisher = {The COLING 2016 Organizing Committee},
 title = {TopoText: Interactive Digital Mapping of Literary Text},
 year = {2016}
}

@inproceedings{C16-2041,
 abstract = {We present a system called ACE for Automatic Colloquialism and Errors detection
for written Chinese. ACE is based on the combination of N-gram model and
rule-base model. Although it focuses on detecting colloquial Cantonese (a
dialect of Chinese) at the current stage, it can be extended to detect other
dialects. We chose Cantonese becauase it has many interesting properties, such
as unique grammar system and huge colloquial terms, that turn the detection
task extremely challenging. We conducted experiments using real data and
synthetic data. The results indicated that ACE is highly reliable and
effective.},
 address = {Osaka, Japan},
 author = {Dong, Shichao  and  Fung, Gabriel Pui Cheong  and  Li, Binyang  and  Peng, Baolin  and  Liao, Ming  and  Zhu, Jia  and  Wong, Kam-Fai},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {194--197},
 publisher = {The COLING 2016 Organizing Committee},
 title = {ACE: Automatic Colloquialism, Typographical and Orthographic Errors Detection for Chinese Language},
 year = {2016}
}

@inproceedings{C16-2042,
 abstract = {We build a tool to assist in content creation by mining the web for information
relevant to a given topic. This tool imitates the process of essay writing by
humans: searching for topics on the web, selecting content frag-ments from the
found document,  and then compiling these fragments to obtain a coherent text.
The process of writing starts with automated building of a table of content by
obtaining the list of key entities for the given topic extracted from web
resources such as Wikipedia. Once a table of content is formed, each item forms
a seed for web mining. The tool builds a full-featured structured Word document
with table of content, section structure, images and captions and web
references for all mined text fragments.
Two linguistic technologies are employed: for relevance verification, we
use similarity computed as a tree similarity between parse trees for a seed and
candidate text fragment. For text coherence, we use a measure of agreement
between a given and consecutive paragraph by tree kernel learning of their
discourse trees.
The tool is available at http://animatronica.io/submit.html.},
 address = {Osaka, Japan},
 author = {Galitsky, Boris},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {198--202},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Tool for Efficient Content Compilation},
 year = {2016}
}

@inproceedings{C16-2043,
 abstract = {This demo presents MAGES (multilingual angle-integrated grouping-based entity
summarization), an entity summarization system for a large knowledge base such
as DBpedia based on a entity-group-bound ranking in a single integrated entity
space across multiple language-specific editions. MAGES offers a multilingual
angle-integrated space model, which has the advantage of overcoming missing
semantic tags (i.e., categories) caused by biases in different language
communities, and can contribute to the creation of entity groups that are
well-formed and more stable than the monolingual condition within it. MAGES can
help people quickly identify the essential points of the entities when they
search or browse a large volume of entity-centric data. Evaluation results on
the same experimental data demonstrate that our system produces a better
summary compared with other representative DBpedia entity summarization
methods.},
 address = {Osaka, Japan},
 author = {Kim, Eun-kyung  and  CHOI, KEY-SUN},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {203--207},
 publisher = {The COLING 2016 Organizing Committee},
 title = {MAGES: A Multilingual Angle-integrated Grouping-based Entity Summarization System},
 year = {2016}
}

@inproceedings{C16-2044,
 abstract = {This paper presents BOTTA, the first Arabic dialect chatbot. We explore the
challenges of creating a conversational agent that aims to simulate friendly
conversations using the Egyptian Arabic dialect. We present a number of
solutions and describe the different components of the BOTTA chatbot. The BOTTA
database files are publicly available for researchers working on Arabic chatbot
technologies. The BOTTA chatbot is also publicly available for any users who
want to chat with it online.},
 address = {Osaka, Japan},
 author = {Abu Ali, Dana  and  Habash, Nizar},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {208--212},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Botta: An Arabic Dialect Chatbot},
 year = {2016}
}

@inproceedings{C16-2045,
 abstract = {Event detection and analysis with respect to public opinions and sentiments in
social media is a broad and well-addressed research topic. However, the
characteristics and sheer volume of noisy Twitter messages make this a
difficult task.
This demonstration paper describes a TWItter event Summarizer and Trend
detector (TWIST) system for event detection, visualization, textual
description, and geo-sentiment analysis of real-life events reported in
Twitter.},
 address = {Osaka, Japan},
 author = {Litvak, Marina  and  Vanetik, Natalia  and  Levi, Efi  and  Roistacher, Michael},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {213--217},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Whatâs up on Twitter? Catch up with TWIST!},
 year = {2016}
}

@inproceedings{C16-2046,
 abstract = {This paper presents an implementation of the widely used speech analysis tool
Praat as a web application with an extended functionality for feature
annotation. In particular, Praat on the Web addresses some of the central
limitations of the original Praat tool and provides (i) enhanced visualization
of annotations in a dedicated window for feature annotation at interval and
point segments, (ii) a dynamic scripting composition exemplified with a modular
prosody tagger, and (iii) portability and an operational web interface. Speech
annotation tools with such a functionality are key for exploring large corpora
and designing modular pipelines.},
 address = {Osaka, Japan},
 author = {Dominguez, Monica  and  Latorre, Iv\'{a}n  and  Farr\'{u}s, Mireia  and  Codina-Filba, Joan  and  Wanner, Leo},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {218--222},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Praat on the Web: An Upgrade of Praat for Semi-Automatic Speech Annotation},
 year = {2016}
}

@inproceedings{C16-2047,
 abstract = {In this paper, we present YAMAMA, a multi-dialect Arabic morphological analyzer
and disambiguator. Our system is almost five times faster than the state-of-art
MADAMIRA system with a slightly lower quality. In addition to speed, YAMAMA
outputs a rich representation which allows for a wider spectrum of use. In this
regard, YAMAMA transcends other systems, such as FARASA, which is faster but
provides specific outputs catering to specific applications.},
 address = {Osaka, Japan},
 author = {Khalifa, Salam  and  Zalmout, Nasser  and  Habash, Nizar},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {223--227},
 publisher = {The COLING 2016 Organizing Committee},
 title = {YAMAMA: Yet Another Multi-Dialect Arabic Morphological Analyzer},
 year = {2016}
}

@inproceedings{C16-2048,
 abstract = {In this paper, we present CamelParser, a state-of-the-art system for Arabic
syntactic dependency analysis aligned with contextually disambiguated
morphological features. CamelParser uses a state-of-the-art morphological
disambiguator and improves its results using syntactically driven features. The
system offers a number of output formats that include basic dependency with
morphological features, two tree visualization modes, and traditional Arabic
grammatical analysis.
Author{1}{Affiliation}},
 address = {Osaka, Japan},
 author = {Shahrour, Anas  and  Khalifa, Salam  and  Taji, Dima  and  Habash, Nizar},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {228--232},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CamelParser: A system for Arabic Syntactic Analysis and Morphological Disambiguation},
 year = {2016}
}

@inproceedings{C16-2049,
 abstract = {In this demonstration paper we describe Ambient Search, a system that displays
and retrieves documents in real time based on speech input. The system operates
continuously in ambient mode, i.e. it generates speech transcriptions and
identifies main keywords and keyphrases, while also querying its index to
display relevant documents without explicit query. Without user intervention, the results are dynamically updated; users can choose to interact with the
system at any time, employing a conversation protocol that is enriched with the
ambient information gathered continuously. Our evaluation shows that Ambient
Search outperforms another implicit speech-based information retrieval system.
Ambient search is available as open source software.},
 address = {Osaka, Japan},
 author = {Milde, Benjamin  and  Wacker, Jonas  and  Radomski, Stefan  and  M\"{u}hlh\"{a}user, Max  and  Biemann, Chris},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {233--237},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Demonstrating Ambient Search: Implicit Document Retrieval for Speech Streams},
 year = {2016}
}

@inproceedings{C16-2050,
 abstract = {ConFarm is a web service dedicated to extraction of surface representations of
verb and noun constructions from dependency annotated corpora of Russian texts.
Currently, the extraction of constructions with a specific lemma from SynTagRus
and Russian National Corpus is available. The system provides flexible
interface that allows users to fine-tune the output. Extracted constructions
are grouped by their contents to allow for compact representation, and the
groups are visualised as a graph in order to help navigating the extraction
results. ConFarm differs from similar existing tools for Russian language in
that it offers full constructions, as opposed to extracting separate dependents
of search word or working with collocations, and allows users to discover
unexpected constructions as opposed to searching for examples of a user-defined
construction.},
 address = {Osaka, Japan},
 author = {Mediankin, Nikita},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {238--242},
 publisher = {The COLING 2016 Organizing Committee},
 title = {ConFarm: Extracting Surface Representations of Verb and Noun Constructions from Dependency Annotated Corpora of Russian},
 year = {2016}
}

@inproceedings{C16-2051,
 abstract = {This paper presents ENIAM, the first syntactic and semantic parser that
generates semantic representations for sentences in Polish.
The parser processes non-annotated data and performs tokenization, lemmatization, dependency recognition, word sense annotation, thematic role
annotation, partial disambiguation and computes the semantic representation.},
 address = {Osaka, Japan},
 author = {Jaworski, Wojciech  and  Kozakoszczak, Jakub},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {243--247},
 publisher = {The COLING 2016 Organizing Committee},
 title = {ENIAM: Categorial Syntactic-Semantic Parser for Polish},
 year = {2016}
}

@inproceedings{C16-2052,
 abstract = {This paper presents a novel high-order dependency parsing framework that
targets non-projective treebanks. It imitates how a human parses sentences in
an intuitive way. At every step of the parse, it determines which word is the
easiest to process among all the remaining words, identifies its head word and
then folds it under the head word. Further, this work is flexible enough to be
augmented with other parsing techniques.},
 address = {Osaka, Japan},
 author = {Fang, Wenjing  and  Zhu, Kenny  and  Wang, Yizhong  and  Tan, Jia},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {248--252},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Towards Non-projective High-Order Dependency Parser},
 year = {2016}
}

@inproceedings{C16-2053,
 abstract = {A script is a type of knowledge representation in artificial intelligence (AI).
This paper presents two methods for synthetically using collected scripts for
story generation. The first method recursively generates long sequences of
events and the second creates script networks. Although related studies
generally use one or more scripts for story generation, this research
synthetically uses many scripts to flexibly generate a diverse narrative.},
 address = {Osaka, Japan},
 author = {Ogata, Takashi  and  Arai, Tatsuya  and  ono, jumpei},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {253--257},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Using Synthetically Collected Scripts for Story Generation},
 year = {2016}
}

@inproceedings{C16-2054,
 abstract = {Attorneys, judges, and others in the justice system are constantly surrounded
by large amounts of legal text, which can be difficult to manage across many
cases. We present CaseSummarizer, a tool for automated text summarization of
legal documents which uses standard summary methods based on word frequency
augmented with additional domain-specific knowledge. Summaries are then
provided through an informative interface with abbreviations, significance heat
maps, and other flexible controls. It is evaluated using ROUGE and human
scoring against several other summarization systems, including summary text and
feedback provided by domain experts.},
 address = {Osaka, Japan},
 author = {Polsley, Seth  and  Jhunjhunwala, Pooja  and  Huang, Ruihong},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {258--262},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CaseSummarizer: A System for Automated Summarization of Legal Texts},
 year = {2016}
}

@inproceedings{C16-2055,
 abstract = {We demonstrate our large-scale NLP systems: WISDOM X, DISAANA, and D-SUMM.
WISDOM X provides numerous possible answers including unpredictable ones to
widely diverse natural language questions to provide deep insights about a
broad range of issues. DISAANA and D-SUMM enable us to assess the damage caused
by large-scale disasters in real time using Twitter as an information source.},
 address = {Osaka, Japan},
 author = {Mizuno, Junta  and  Tanaka, Masahiro  and  Ohtake, Kiyonori  and  Oh, Jong-Hoon  and  Kloetzer, Julien  and  Hashimoto, Chikara  and  Torisawa, Kentaro},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {263--267},
 publisher = {The COLING 2016 Organizing Committee},
 title = {WISDOM X, DISAANA and D-SUMM: Large-scale NLP Systems for Analyzing Textual Big Data},
 year = {2016}
}

@inproceedings{C16-2056,
 abstract = {We present PolyglotIE, a web-based tool for developing extractors that perform
Information Extraction (IE) over multilingual data. Our tool has two core
features: First, it allows users to develop extractors against a unified
abstraction that is shared across a large set of natural languages. This means
that an extractor needs only be created once for one language, but will then
run on multilingual data without any additional effort or language-specific
knowledge on part of the user. Second, it embeds this abstraction as a set of
views within a declarative IE system, allowing users to quickly create
extractors using a mature IE query language. We present PolyglotIE as a
hands-on demo in which users can experiment with creating extractors, execute
them on multilingual text and inspect extraction results. Using the UI, we
discuss the challenges and potential of using unified, crosslingual semantic
abstractions as basis for downstream applications. We demonstrate multilingual
IE for 9 languages from 4 different language groups: English, German, French, Spanish, Japanese, Chinese, Arabic, Russian and Hindi.},
 address = {Osaka, Japan},
 author = {Akbik, Alan  and  chiticariu, laura  and  Danilevsky, Marina  and  Kbrom, Yonas  and  Li, Yunyao  and  Zhu, Huaiyu},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {268--272},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Multilingual Information Extraction with PolyglotIE},
 year = {2016}
}

@inproceedings{C16-2057,
 abstract = {This paper presents WordForce, a system powered by the state of the art neural
network model to visualize the learned user-dependent word embeddings from each
post according to the post content and its engaged users. It generates the
scatter plots to show the force of a word, i.e., whether the semantics of word
embeddings from posts of different stances are clearly separated from the
aspect of this controversial word. In addition, WordForce provides the
dispersion and the distance of word embeddings from posts of different stance
groups, and proposes the most controversial words accordingly to show clues to
what people argue about in a debate.},
 address = {Osaka, Japan},
 author = {Chen, Wei-Fan  and  Lin, Fang-Yu  and  Ku, Lun-Wei},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {273--277},
 publisher = {The COLING 2016 Organizing Committee},
 title = {WordForce: Visualizing Controversial Words in Debates},
 year = {2016}
}

@inproceedings{C16-2058,
 abstract = {Zara, or âZara the Supergirlâ is a virtual robot, that can exhibit empathy
while interacting with an user, with the aid of its built in facial and emotion
recognition, sentiment analysis, and speech module. At the end of the 5-10
minute conversation, Zara can give a personality analysis of the user based on
all the user utterances. We have also implemented a real-time emotion
recognition, using a CNN model that detects emotion from raw audio without
feature extraction, and have achieved an average of 65.7% accuracy on six
different emotion classes, which is an impressive 4.5% improvement from the
conventional feature based SVM classification. Also, we have described a CNN
based sentiment analysis module trained using out-of-domain data, that
recognizes sentiment from the speech recognition transcript, which has a 74.8
F-measure when tested on human-machine dialogues.},
 address = {Osaka, Japan},
 author = {Fung, Pascale  and  Dey, Anik  and  Siddique, Farhad Bin  and  Lin, Ruixi  and  Yang, Yang  and  Bertero, Dario  and  Wan, Yan  and  Chan, Ricky Ho Yin  and  Wu, Chien-Sheng},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {278--281},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Zara: A Virtual Interactive Dialogue System Incorporating Emotion, Sentiment and Personality Recognition},
 year = {2016}
}

@inproceedings{C16-2059,
 abstract = {Words to express relations in natural language (NL) statements may be different
from those to represent properties in knowledge bases (KB). The vocabulary gap
becomes barriers for knowledge base construction and retrieval. With the demo
system called NL2KB in this paper, users can browse which properties in KB side
may be mapped to for a given relational pattern in NL side. Besides, they can
retrieve the sets of relational patterns in NL side for a given property in KB
side. We describe how the mapping is established in detail. Although the mined
patterns are used for Chinese knowledge base applications, the methodology can
be extended to other languages.},
 address = {Osaka, Japan},
 author = {Wei, Sheng-Lun  and  Chiu, Yen-Pin  and  Huang, Hen-Hsen  and  Chen, Hsin-Hsi},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {282--286},
 publisher = {The COLING 2016 Organizing Committee},
 title = {NL2KB: Resolving Vocabulary Gap between Natural Language and Knowledge Base in Knowledge Base Construction and Retrieval},
 year = {2016}
}

@inproceedings{C16-2060,
 abstract = {PKUSUMSUM is a Java platform for multilingual document summarization, and it
sup-ports multiple languages, integrates 10 automatic summarization methods, and tackles three typical  summarization tasks. The summarization platform has
been released and users can easily use and update it. In this paper, we make a
brief description of the char-acteristics, the summarization methods, and the
evaluation results of the platform, and al-so compare PKUSUMSUM with other
summarization toolkits.},
 address = {Osaka, Japan},
 author = {Zhang, Jianmin  and  Wang, Tianming  and  Wan, Xiaojun},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {287--291},
 publisher = {The COLING 2016 Organizing Committee},
 title = {PKUSUMSUM : A Java Platform for Multilingual Document Summarization},
 year = {2016}
}

@inproceedings{C16-2061,
 abstract = {Kotonush, a system that clarifies peopleâs values on various concepts on the
basis of what they write about on social media, is presented. The values are
represented by ordering sets of concepts (e.g., London, Berlin, and Rome) in
accordance with a common attribute intensity expressed by an adjective (e.g., entertaining). We exploit social media text written by different demographics
and at different times in order to induce specific orderings for comparison.
The system combines a text-to-ordering module with an interactive querying
interface enabled by massive hyponymy relations and provides mechanisms to
compare the induced orderings from various viewpoints. We empirically evaluate
Kotonush and present some case studies, featuring real-world concept orderings
with different domains on Twitter, to demonstrate the usefulness of our system.},
 address = {Osaka, Japan},
 author = {Iwanari, Tatsuya  and  Ohara, Kohei  and  Yoshinaga, Naoki  and  Kaji, Nobuhiro  and  Toyoda, Masashi  and  Kitsuregawa, Masaru},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {292--296},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Kotonush: Understanding Concepts Based on Values behind Social Media},
 year = {2016}
}

@inproceedings{C16-2062,
 abstract = {We aim at showing that lexical descriptions based on multifactorial and
continuous models can be used by linguists and lexicographers (and not only by
machines) so long as they are provided with a way to efficiently navigate data
collections. We propose to demonstrate such a system.},
 address = {Osaka, Japan},
 author = {Marchal, Pierre  and  Poibeau, Thierry},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {297--301},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Exploring a Continuous and Flexible Representation of the Lexicon},
 year = {2016}
}

@inproceedings{C16-2063,
 abstract = {In this paper, we propose GiveMeExample that ranks example sentences according
to
their capacity of demonstrating the differences among English and Chinese
near-synonyms for language learners. The difficulty of the example sentences is
automatically detected. Furthermore, the usage models of the near-synonyms are
built by the GMM and Bi-LSTM models to suggest the best elaborative sentences.
Experiments show the good performance both in the fill-in-the-blank test and on
the manually labeled gold data, that is, the built models can select the
appropriate words for the given context and vice versa.},
 address = {Osaka, Japan},
 author = {Huang, Chieh-Yang  and  Peinelt, Nicole  and  Ku, Lun-Wei},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {302--306},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Automatically Suggesting Example Sentences of Near-Synonyms for Language Learners},
 year = {2016}
}

@inproceedings{C16-2064,
 abstract = {We present Kyoto-NMT, an open-source
implementation of the Neural Machine Translation paradigm. This implementation
is done in Python and Chainer, an easy-to-use Deep Learning Framework.},
 address = {Osaka, Japan},
 author = {Cromieres, Fabien},
 booktitle = {Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations},
 month = {December},
 pages = {307--311},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Kyoto-NMT: a Neural Machine Translation implementation in Chainer},
 year = {2016}
}

