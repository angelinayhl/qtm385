@inproceedings{W17-0101,
 address = {Honolulu},
 author = {Bowers, Dustin and Arppe, Antti and Lachler, Jordan and Moshagen, Sjur and Trosterud, Trond},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0101},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {1--9},
 publisher = {Association for Computational Linguistics},
 title = {A Morphological Parser for Odawa},
 year = {2017}
}

@inproceedings{W17-0102,
 address = {Honolulu},
 author = {Kazeminejad, Ghazaleh and Cowell, Andrew and Hulden, Mans},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0102},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {10--18},
 publisher = {Association for Computational Linguistics},
 title = {Creating lexical resources for polysynthetic languages---the case of Arapaho},
 year = {2017}
}

@inproceedings{W17-0103,
 address = {Honolulu},
 author = {Thieberger, Nick and Tuohy, Conal},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0103},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {19--23},
 publisher = {Association for Computational Linguistics},
 title = {From Small to Big Data: paper manuscripts to RDF triples of Australian Indigenous Vocabularies},
 year = {2017}
}

@inproceedings{W17-0104,
 address = {Honolulu},
 author = {Um, Emmanuel Ngu\'e},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0104},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {24--32},
 publisher = {Association for Computational Linguistics},
 title = {Issues in digital text representation, on-line dissemination, sharing and re-use for African minority languages},
 year = {2017}
}

@inproceedings{W17-0105,
 address = {Honolulu},
 author = {Holton, Gary and Hooshiar, Kavon and Thieberger, Nick},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0105},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {33--38},
 publisher = {Association for Computational Linguistics},
 title = {Developing collection management tools to create more robust and reliable linguistic data},
 year = {2017}
}

@inproceedings{W17-0106,
 address = {Honolulu},
 author = {Levow, Gina-Anne and Bender, Emily M. and Littell, Patrick and Howell, Kristen and Chelliah, Shobhana and Crowgey, Joshua and Garrette, Dan and Good, Jeff and Hargus, Sharon and Inman, David and Maxwell, Michael and Tjalve, Michael and Xia, Fei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0106},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {39--47},
 publisher = {Association for Computational Linguistics},
 title = {STREAMLInED Challenges: Aligning Research Interests with Shared Tasks},
 year = {2017}
}

@inproceedings{W17-0107,
 address = {Honolulu},
 author = {Bell, Lucy and Bell, Lawrence},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0107},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {48--51},
 publisher = {Association for Computational Linguistics},
 title = {Work With What You've Got},
 year = {2017}
}

@inproceedings{W17-0108,
 address = {Honolulu},
 author = {Arppe, Antti and Junker, Marie-Odile and Torkornoo, Delasie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0108},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {52--56},
 publisher = {Association for Computational Linguistics},
 title = {Converting a comprehensive lexical database into a computational model: The case of East Cree verb inflection},
 year = {2017}
}

@inproceedings{W17-0109,
 address = {Honolulu},
 author = {Gerstenberger, Ciprian and Partanen, Niko and Rie{\ss}ler, Michael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0109},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {57--66},
 publisher = {Association for Computational Linguistics},
 title = {Instant annotations in ELAN corpora of spoken and written Komi, an endangered language of the Barents Sea region},
 year = {2017}
}

@inproceedings{W17-0110,
 address = {Honolulu},
 author = {Howell, Kristen and Bender, Emily M. and Lockwood, Michel and Xia, Fei and Zamaraeva, Olga},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0110},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {67--75},
 publisher = {Association for Computational Linguistics},
 title = {Inferring Case Systems from IGT: Enriching the Enrichment},
 year = {2017}
}

@inproceedings{W17-0111,
 address = {Honolulu},
 author = {Kodner, Jordan and Kaplan, Spencer and Xu, Hongzhi and Marcus, Mitchell P. and Yang, Charles},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0111},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {76--84},
 publisher = {Association for Computational Linguistics},
 title = {Case Studies in the Automatic Characterization of Grammars from Small Wordlists},
 year = {2017}
}

@inproceedings{W17-0112,
 address = {Honolulu},
 author = {Maxwell, Michael and Bills, Aric},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0112},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {85--91},
 publisher = {Association for Computational Linguistics},
 title = {Endangered Data for Endangered Languages: Digitizing Print dictionaries},
 year = {2017}
}

@inproceedings{W17-0113,
 address = {Honolulu},
 author = {Meyer, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0113},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {92--100},
 publisher = {Association for Computational Linguistics},
 title = {A computationally-assisted procedure for discovering poetic organization within oral tradition},
 year = {2017}
}

@inproceedings{W17-0114,
 address = {Honolulu},
 author = {Micher, Jeffrey},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0114},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {101--106},
 publisher = {Association for Computational Linguistics},
 title = {Improving Coverage of an Inuktitut Morphological Analyzer Using a Segmental Recurrent Neural Network},
 year = {2017}
}

@inproceedings{W17-0115,
 address = {Honolulu},
 author = {Miller, Amanda and Elsner, Micha},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0115},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {107--115},
 publisher = {Association for Computational Linguistics},
 title = {Click reduction in fluent speech: a semi-automated analysis of Mangetti Dune !Xung},
 year = {2017}
}

@inproceedings{W17-0116,
 address = {Honolulu},
 author = {Rytting, C. Anton and Yelle, Julie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0116},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {116--121},
 publisher = {Association for Computational Linguistics},
 title = {DECCA Repurposed: Detecting transcription inconsistencies without an orthographic standard},
 year = {2017}
}

@inproceedings{W17-0117,
 address = {Honolulu},
 author = {Saltzman, Moira},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0117},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {122--129},
 publisher = {Association for Computational Linguistics},
 title = {Jejueo talking dictionary: A collaborative online database for language revitalization},
 year = {2017}
}

@inproceedings{W17-0118,
 address = {Honolulu},
 author = {Zamaraeva, Olga and Kratochv\'il, Franti\v{s}ek and Bender, Emily M. and Xia, Fei and Howell, Kristen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0118},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {130--140},
 publisher = {Association for Computational Linguistics},
 title = {Computational Support for Finding Word Classes: A Case Study of Abui},
 year = {2017}
}

@inproceedings{W17-0119,
 address = {Honolulu},
 author = {Littell, Patrick and Pine, Aidan and Davis, Henry},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0119},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {141--150},
 publisher = {Association for Computational Linguistics},
 title = {Waldayu and Waldayu Mobile: Modern digital dictionary interfaces for endangered languages},
 year = {2017}
}

@inproceedings{W17-0120,
 address = {Honolulu},
 author = {Little, Alexa N.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0120},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {151--155},
 publisher = {Association for Computational Linguistics},
 title = {Connecting Documentation and Revitalization: A New Approach to Language Apps},
 year = {2017}
}

@inproceedings{W17-0121,
 address = {Honolulu},
 author = {Bettinson, Mat and Bird, Steven},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0121},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {156--164},
 publisher = {Association for Computational Linguistics},
 title = {Developing a Suite of Mobile Applications for Collaborative Language Documentation},
 year = {2017}
}

@inproceedings{W17-0122,
 address = {Honolulu},
 author = {Kempton, Timothy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0122},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {165--169},
 publisher = {Association for Computational Linguistics},
 title = {Cross-language forced alignment to assist community-based linguistics for low resource languages},
 year = {2017}
}

@inproceedings{W17-0123,
 address = {Honolulu},
 author = {Anastasopoulos, Antonios and Chiang, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0123},
 booktitle = {Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages},
 month = {March},
 pages = {170--178},
 publisher = {Association for Computational Linguistics},
 title = {A case study on using speech-to-translation alignments for language documentation},
 year = {2017}
}

@inproceedings{W17-0201,
 address = {Gothenburg, Sweden},
 author = {Velldal, Erik and {\O}vrelid, Lilja and Hohle, Petter},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0201},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Joint UD Parsing of Norwegian Bokm{\aa}l and Nynorsk},
 year = {2017}
}

@inproceedings{W17-0202,
 address = {Gothenburg, Sweden},
 author = {Kolachina, Prasanth and Riedl, Martin and Biemann, Chris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0202},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {11--19},
 publisher = {Association for Computational Linguistics},
 title = {Replacing OOV Words For Dependency Parsing With Distributional Semantics},
 year = {2017}
}

@inproceedings{W17-0203,
 address = {Gothenburg, Sweden},
 author = {Basirat, Ali and Nivre, Joakim},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0203},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {20--28},
 publisher = {Association for Computational Linguistics},
 title = {Real-valued Syntactic Word Vectors (RSV) for Greedy Neural Dependency Parsing},
 year = {2017}
}

@inproceedings{W17-0204,
 address = {Gothenburg, Sweden},
 author = {Kettunen, Kimmo and L\"{o}fberg, Laura},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0204},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {29--36},
 publisher = {Association for Computational Linguistics},
 title = {Tagging Named Entities in 19th Century and Modern Finnish Newspaper Material with a Finnish Semantic Tagger},
 year = {2017}
}

@inproceedings{W17-0205,
 address = {Gothenburg, Sweden},
 author = {Dubremetz, Marie and Nivre, Joakim},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0205},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {37--45},
 publisher = {Association for Computational Linguistics},
 title = {Machine Learning for Rhetorical Figure Detection: More Chiasmus with Less Annotation},
 year = {2017}
}

@inproceedings{W17-0206,
 address = {Gothenburg, Sweden},
 author = {Wallin, Alexander and Nugues, Pierre},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0206},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {46--55},
 publisher = {Association for Computational Linguistics},
 title = {Coreference Resolution for Swedish and German using Distant Supervision},
 year = {2017}
}

@inproceedings{W17-0207,
 address = {Gothenburg, Sweden},
 author = {Koskenniemi, Kimmo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0207},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {56--64},
 publisher = {Association for Computational Linguistics},
 title = {Aligning phonemes using finte-state methods},
 year = {2017}
}

@inproceedings{W17-0208,
 address = {Gothenburg, Sweden},
 author = {Leino, Katri and Kurimo, Mikko},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0208},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {65--69},
 publisher = {Association for Computational Linguistics},
 title = {Acoustic Model Compression with MAP adaptation},
 year = {2017}
}

@inproceedings{W17-0209,
 address = {Gothenburg, Sweden},
 author = {Drobac, Senka and Kauppinen, Pekka and Lind\'{e}n, Krister},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0209},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {70--76},
 publisher = {Association for Computational Linguistics},
 title = {OCR and post-correction of historical Finnish texts},
 year = {2017}
}

@inproceedings{W17-0210,
 address = {Gothenburg, Sweden},
 author = {Steinskog, Asbj{\o}rn and Therkelsen, Jonas and Gamb\"{a}ck, Bj\"{o}rn},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0210},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {77--86},
 publisher = {Association for Computational Linguistics},
 title = {Twitter Topic Modeling by Tweet Aggregation},
 year = {2017}
}

@inproceedings{W17-0211,
 address = {Gothenburg, Sweden},
 author = {S\"{o}dergren, Anton and Nugues, Pierre},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0211},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {87--95},
 publisher = {Association for Computational Linguistics},
 title = {A Multilingual Entity Linker Using PageRank and Semantic Graphs},
 year = {2017}
}

@inproceedings{W17-0212,
 address = {Gothenburg, Sweden},
 author = {Murom\"{a}gi, Avo and Sirts, Kairit and Laur, Sven},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0212},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {96--104},
 publisher = {Association for Computational Linguistics},
 title = {Linear Ensembles of Word Embedding Models},
 year = {2017}
}

@inproceedings{W17-0213,
 address = {Gothenburg, Sweden},
 author = {Massimiliano Cecchini, Flavio and Biemann, Chris and Riedl, Martin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0213},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {105--114},
 publisher = {Association for Computational Linguistics},
 title = {Using Pseudowords for Algorithm Comparison: An Evaluation Framework for Graph-based Word Sense Induction},
 year = {2017}
}

@inproceedings{W17-0214,
 address = {Gothenburg, Sweden},
 author = {Pirinen, Tommi and Tyers, Francis M. and Trosterud, Trond and Johnson, Ryan and Unhammer, Kevin and Puolakainen, Tiina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0214},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {115--122},
 publisher = {Association for Computational Linguistics},
 title = {North-S\'{a}mi to Finnish rule-based machine translation system},
 year = {2017}
}

@inproceedings{W17-0215,
 address = {Gothenburg, Sweden},
 author = {Antonsen, Lene and Gerstenberger, Ciprian and Kappfjell, Maja and Nyst{\o} R\'{a}hka, Sandra and Olthuis, Marja-Liisa and Trosterud, Trond and Tyers, Francis M.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0215},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {123--131},
 publisher = {Association for Computational Linguistics},
 title = {Machine translation with North Saami as a pivot language},
 year = {2017}
}

@inproceedings{W17-0216,
 address = {Gothenburg, Sweden},
 author = {N\"{a}sman, Jesper and Megyesi, Be{\'a}ta and Palm\'{e}r, Anne},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0216},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {132--141},
 publisher = {Association for Computational Linguistics},
 title = {SWEGRAM \textendash A Web-Based Tool for Automatic Annotation and Analysis of Swedish Texts},
 year = {2017}
}

@inproceedings{W17-0217,
 address = {Gothenburg, Sweden},
 author = {Hohle, Petter and {\O}vrelid, Lilja and Velldal, Erik},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0217},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {142--151},
 publisher = {Association for Computational Linguistics},
 title = {Optimizing a PoS Tagset for Norwegian Dependency Parsing},
 year = {2017}
}

@inproceedings{W17-0218,
 address = {Gothenburg, Sweden},
 author = {Laippala, Veronika and Luotolahti, Juhani and Kyr\"{o}l\"{a}inen, Aki-Juhani and Salakoski, Tapio and Ginter, Filip},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0218},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {152--161},
 publisher = {Association for Computational Linguistics},
 title = {Creating register sub-corpora for the Finnish Internet Parsebank},
 year = {2017}
}

@inproceedings{W17-0219,
 address = {Gothenburg, Sweden},
 author = {Dobnik, Simon and de Graaf, Erik},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0219},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {162--171},
 publisher = {Association for Computational Linguistics},
 title = {KILLE: a Framework for Situated Agents for Learning Language Through Interaction},
 year = {2017}
}

@inproceedings{W17-0220,
 address = {Gothenburg, Sweden},
 author = {Kokkinakis, Dimitrios and Lundholm Fors, Kristina and Bj\"{o}rkner, Eva and Nordlund, Arto},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0220},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {172--182},
 publisher = {Association for Computational Linguistics},
 title = {Data Collection from Persons with Mild Forms of Cognitive Impairment and Healthy Controls - Infrastructure for Classification and Prediction of Dementia},
 year = {2017}
}

@inproceedings{W17-0221,
 address = {Gothenburg, Sweden},
 author = {Jauhiainen, Tommi and Lind\'{e}n, Krister and Jauhiainen, Heidi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0221},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {183--191},
 publisher = {Association for Computational Linguistics},
 title = {Evaluation of language identification methods using 285 languages},
 year = {2017}
}

@inproceedings{W17-0222,
 address = {Gothenburg, Sweden},
 author = {Orasmaa, Siim and Kaalep, Heiki-Jaan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0222},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {192--201},
 publisher = {Association for Computational Linguistics},
 title = {Can We Create a Tool for General Domain Event Analysis?},
 year = {2017}
}

@inproceedings{W17-0223,
 address = {Gothenburg, Sweden},
 author = {Bick, Eckhard},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0223},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {202--210},
 publisher = {Association for Computational Linguistics},
 title = {From Treebank to Propbank: A Semantic-Role and VerbNet Corpus for Danish},
 year = {2017}
}

@inproceedings{W17-0224,
 address = {Gothenburg, Sweden},
 author = {Bjerva, Johannes and \"{O}stling, Robert},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0224},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {211--215},
 publisher = {Association for Computational Linguistics},
 title = {Cross-lingual Learning of Semantic Textual Similarity with Multilingual Word Representations},
 year = {2017}
}

@inproceedings{W17-0225,
 address = {Gothenburg, Sweden},
 author = {Bjerva, Johannes},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0225},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {216--220},
 publisher = {Association for Computational Linguistics},
 title = {Will my auxiliary tagging task help? Estimating Auxiliary Tasks Effectivity in Multi-Task Learning},
 year = {2017}
}

@inproceedings{W17-0226,
 address = {Gothenburg, Sweden},
 author = {B\"{o}rstell, Carl and \"{O}stling, Robert},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0226},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {221--225},
 publisher = {Association for Computational Linguistics},
 title = {Iconic Locations in Swedish Sign Language: Mapping Form to Meaning with Lexical Databases},
 year = {2017}
}

@inproceedings{W17-0227,
 address = {Gothenburg, Sweden},
 author = {Klang, Marcus and Nugues, Pierre},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0227},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {226--230},
 publisher = {Association for Computational Linguistics},
 title = {Docforia: A Multilayer Document Model},
 year = {2017}
}

@inproceedings{W17-0228,
 address = {Gothenburg, Sweden},
 author = {Venekoski, Viljami and Vankka, Jouko},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0228},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {231--236},
 publisher = {Association for Computational Linguistics},
 title = {Finnish resources for evaluating language model semantics},
 year = {2017}
}

@inproceedings{W17-0229,
 address = {Gothenburg, Sweden},
 author = {Steingr\'{\i}msson, Stein{\th}\'{o}r and Gu{\dh}nason, J\'{o}n and Helgad\'{o}ttir, Sigr\'{u}n and R\"{o}gnvaldsson, Eir\'{\i}kur},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0229},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {237--240},
 publisher = {Association for Computational Linguistics},
 title = {M\'{a}lr\'{o}mur: A Manually Verified Corpus of Recorded Icelandic Speech},
 year = {2017}
}

@inproceedings{W17-0230,
 address = {Gothenburg, Sweden},
 author = {Stymne, Sara},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0230},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {241--246},
 publisher = {Association for Computational Linguistics},
 title = {The Effect of Translationese on Tuning for Statistical Machine Translation},
 year = {2017}
}

@inproceedings{W17-0231,
 address = {Gothenburg, Sweden},
 author = {Gra\"{e}n, Johannes and Sandoz, Dominique and Volk, Martin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0231},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {247--250},
 publisher = {Association for Computational Linguistics},
 title = {Multilingwis2 \textendash Explore Your Parallel Corpus},
 year = {2017}
}

@inproceedings{W17-0232,
 address = {Gothenburg, Sweden},
 author = {N{\o}klestad, Anders and Hagen, Kristin and Bondi Johannessen, Janne and Kosek, Micha{\l} and Priestley, Joel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0232},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {251--254},
 publisher = {Association for Computational Linguistics},
 title = {A modernised version of the Glossa corpus search system},
 year = {2017}
}

@inproceedings{W17-0233,
 address = {Gothenburg, Sweden},
 author = {Luotolahti, Juhani and Kanerva, Jenna and Ginter, Filip},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0233},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {255--258},
 publisher = {Association for Computational Linguistics},
 title = {Dep\_search: Efficient Search Tool for Large Dependency Parsebanks},
 year = {2017}
}

@inproceedings{W17-0234,
 address = {Gothenburg, Sweden},
 author = {Pyysalo, Jouna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0234},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {259--262},
 publisher = {Association for Computational Linguistics},
 title = {Proto-Indo-European Lexicon: The Generative Etymological Dictionary of Indo-European Languages},
 year = {2017}
}

@inproceedings{W17-0235,
 address = {Gothenburg, Sweden},
 author = {Rozis, Roberts and Skadi\c{n}\v{s}, Raivis},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0235},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {263--265},
 publisher = {Association for Computational Linguistics},
 title = {Tilde MODEL - Multilingual Open Data for EU Languages},
 year = {2017}
}

@inproceedings{W17-0236,
 address = {Gothenburg, Sweden},
 author = {Ek, Adam and Knuutinen, Sofia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0236},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {266--270},
 publisher = {Association for Computational Linguistics},
 title = {Mainstreaming August Strindberg with Text Normalization},
 year = {2017}
}

@inproceedings{W17-0237,
 address = {Gothenburg, Sweden},
 author = {Fares, Murhaf and Kutuzov, Andrey and Oepen, Stephan and Velldal, Erik},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0237},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {271--276},
 publisher = {Association for Computational Linguistics},
 title = {Word vectors, reuse, and replicability: Towards a community repository of large-text resources},
 year = {2017}
}

@inproceedings{W17-0238,
 address = {Gothenburg, Sweden},
 author = {Koistinen, Mika and Kettunen, Kimmo and P\"{a}\"{a}kk\"{o}nen, Tuula},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0238},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {277--283},
 publisher = {Association for Computational Linguistics},
 title = {Improving Optical Character Recognition of Finnish Historical Newspapers with a Combination of Fraktur \& Antiqua Models and Image Preprocessing},
 year = {2017}
}

@inproceedings{W17-0239,
 address = {Gothenburg, Sweden},
 author = {Lison, Pierre and Kutuzov, Andrey},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0239},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {284--288},
 publisher = {Association for Computational Linguistics},
 title = {Redefining Context Windows for Word Embedding Models: An Experimental Study},
 year = {2017}
}

@inproceedings{W17-0240,
 address = {Gothenburg, Sweden},
 author = {Persson, Adam},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0240},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {289--292},
 publisher = {Association for Computational Linguistics},
 title = {The Effect of Excluding Out of Domain Training Data from Supervised Named-Entity Recognition},
 year = {2017}
}

@inproceedings{W17-0241,
 address = {Gothenburg, Sweden},
 author = {Salway, Andrew and Meurer, Paul and Hofland, Knut and Reigem, {\O}ystein},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0241},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {293--297},
 publisher = {Association for Computational Linguistics},
 title = {Quote Extraction and Attribution from Norwegian Newspapers},
 year = {2017}
}

@inproceedings{W17-0242,
 address = {Gothenburg, Sweden},
 author = {Sand, Heidi and Velldal, Erik and {\O}vrelid, Lilja},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0242},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {298--302},
 publisher = {Association for Computational Linguistics},
 title = {Wordnet extension via word embeddings: Experiments on the Norwegian Wordnet},
 year = {2017}
}

@inproceedings{W17-0243,
 address = {Gothenburg, Sweden},
 author = {\"{O}stling, Robert and B\"{o}rstell, Carl and G\"{a}rdenfors, Moa and Wir\'{e}n, Mats},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0243},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {303--308},
 publisher = {Association for Computational Linguistics},
 title = {Universal Dependencies for Swedish Sign Language},
 year = {2017}
}

@inproceedings{W17-0244,
 address = {Gothenburg, Sweden},
 author = {Falkenjack, Johan and Rennes, Evelina and Fahlborg, Daniel and Johansson, Vida and J\"{o}nsson, Arne},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0244},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {309--313},
 publisher = {Association for Computational Linguistics},
 title = {Services for text simplification and analysis},
 year = {2017}
}

@inproceedings{W17-0245,
 address = {Gothenburg, Sweden},
 author = {Gra\"{e}n, Johannes and Bless, Christof},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0245},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {314--317},
 publisher = {Association for Computational Linguistics},
 title = {Exploring Properties of Intralingual and Interlingual Association Measures Visually},
 year = {2017}
}

@inproceedings{W17-0246,
 address = {Gothenburg, Sweden},
 author = {Juel Henrichsen, Peter},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0246},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {318--321},
 publisher = {Association for Computational Linguistics},
 title = {TALERUM - Learning Danish by Doing Danish},
 year = {2017}
}

@inproceedings{W17-0247,
 address = {Gothenburg, Sweden},
 author = {Ranta, Aarne and Kolachina, Prasanth and Hallgren, Thomas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0247},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {322--325},
 publisher = {Association for Computational Linguistics},
 title = {Cross-Lingual Syntax: Relating Grammatical Framework with Universal Dependencies},
 year = {2017}
}

@inproceedings{W17-0248,
 address = {Gothenburg, Sweden},
 author = {Ros\'{e}n, Victoria and Dyvik, Helge and Meurer, Paul and De Smedt, Koenraad},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0248},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {326--329},
 publisher = {Association for Computational Linguistics},
 title = {Exploring Treebanks with INESS Search},
 year = {2017}
}

@inproceedings{W17-0249,
 address = {Gothenburg, Sweden},
 author = {Vesanto, Aleksi and Ginter, Filip and Salmi, Hannu and Nivala, Asko and Salakoski, Tapio},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0249},
 booktitle = {Proceedings of the 21st Nordic Conference on Computational Linguistics},
 month = {May},
 pages = {330--333},
 publisher = {Association for Computational Linguistics},
 title = {A System for Identifying and Exploring Text Repetition in Large Historical Document Corpora},
 year = {2017}
}

@inproceedings{W17-0401,
 address = {Gothenburg, Sweden},
 author = {Agi\'{c}, \v{Z}eljko},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0401},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Cross-Lingual Parser Selection for Low-Resource Languages},
 year = {2017}
}

@inproceedings{W17-0402,
 address = {Gothenburg, Sweden},
 author = {Ahrenberg, Lars},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0402},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {11--18},
 publisher = {Association for Computational Linguistics},
 title = {Swedish Prepositions are not Pure Function Words},
 year = {2017}
}

@inproceedings{W17-0403,
 address = {Gothenburg, Sweden},
 author = {Bouma, Gosse and Van Noord, Gertjan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0403},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {19--26},
 publisher = {Association for Computational Linguistics},
 title = {Increasing Return on Annotation Investment: The Automatic Construction of a Universal Dependency Treebank for Dutch},
 year = {2017}
}

@inproceedings{W17-0404,
 address = {Gothenburg, Sweden},
 author = {\c{C}\"{o}ltekin, \c{C}a\u{g}r{\i} and Campbell, Ben and Hinrichs, Erhard and Telljohann, Heike},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0404},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {27--37},
 publisher = {Association for Computational Linguistics},
 title = {Converting the T\"{u}Ba-D/Z Treebank of German to Universal Dependencies},
 year = {2017}
}

@inproceedings{W17-0405,
 address = {Gothenburg, Sweden},
 author = {Dirix, Peter and Augustinus, Liesbeth and van Niekerk, Daniel and Van Eynde, Frank},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0405},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {38--47},
 publisher = {Association for Computational Linguistics},
 title = {Universal Dependencies for Afrikaans},
 year = {2017}
}

@inproceedings{W17-0406,
 address = {Gothenburg, Sweden},
 author = {Droganova, Kira and Zeman, Daniel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0406},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {48--57},
 publisher = {Association for Computational Linguistics},
 title = {Elliptic Constructions: Spotting Patterns in UD Treebanks},
 year = {2017}
}

@inproceedings{W17-0407,
 address = {Gothenburg, Sweden},
 author = {Hennig, Felix and K\"{o}hn, Arne},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0407},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {58--66},
 publisher = {Association for Computational Linguistics},
 title = {Dependency Tree Transformation with Tree Transducers},
 year = {2017}
}

@inproceedings{W17-0408,
 address = {Gothenburg, Sweden},
 author = {Lee, John and Leung, Herman and Li, Keying},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0408},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {67--71},
 publisher = {Association for Computational Linguistics},
 title = {Towards Universal Dependencies for Learner Chinese},
 year = {2017}
}

@inproceedings{W17-0409,
 address = {Gothenburg, Sweden},
 author = {Levshina, Natalia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0409},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {72--78},
 publisher = {Association for Computational Linguistics},
 title = {Does Syntactic Informativity Predict Word Length? A Cross-Linguistic Study Based on the Universal Dependencies Corpora},
 year = {2017}
}

@inproceedings{W17-0410,
 address = {Gothenburg, Sweden},
 author = {Muischnek, Kadri and M\"{u}\"{u}risep, Kaili},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0410},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {79--85},
 publisher = {Association for Computational Linguistics},
 title = {Estonian Copular and Existential Constructions as an UD Annotation Problem},
 year = {2017}
}

@inproceedings{W17-0411,
 address = {Gothenburg, Sweden},
 author = {Nivre, Joakim and Fang, Chiao-Ting},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0411},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {86--95},
 publisher = {Association for Computational Linguistics},
 title = {Universal Dependency Evaluation},
 year = {2017}
}

@inproceedings{W17-0412,
 address = {Gothenburg, Sweden},
 author = {Popel, Martin and \v{Z}abokrtsk\'{y}, Zden\v{e}k and Vojtek, Martin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0412},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {96--101},
 publisher = {Association for Computational Linguistics},
 title = {Udapi: Universal API for Universal Dependencies},
 year = {2017}
}

@inproceedings{W17-0413,
 address = {Gothenburg, Sweden},
 author = {Prokopidis, Prokopis and Papageorgiou, Haris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0413},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {102--106},
 publisher = {Association for Computational Linguistics},
 title = {Universal Dependencies for Greek},
 year = {2017}
}

@inproceedings{W17-0414,
 address = {Gothenburg, Sweden},
 author = {Ranta, Aarne and Kolachina, Prasanth},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0414},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {107--116},
 publisher = {Association for Computational Linguistics},
 title = {From Universal Dependencies to Abstract Syntax},
 year = {2017}
}

@inproceedings{W17-0415,
 address = {Gothenburg, Sweden},
 author = {Schluter, Natalie and Agi\'{c}, \v{Z}eljko},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0415},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {117--122},
 publisher = {Association for Computational Linguistics},
 title = {Empirically Sampling Universal Dependencies},
 year = {2017}
}

@inproceedings{W17-0416,
 address = {Gothenburg, Sweden},
 author = {Schuster, Sebastian and Lamm, Matthew and Manning, Christopher D.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0416},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {123--132},
 publisher = {Association for Computational Linguistics},
 title = {Gapping Constructions in Universal Dependencies v2},
 year = {2017}
}

@inproceedings{W17-0417,
 address = {Gothenburg, Sweden},
 author = {Senuma, Hajime and Aizawa, Akiko},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0417},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {133--139},
 publisher = {Association for Computational Linguistics},
 title = {Toward Universal Dependencies for Ainu},
 year = {2017}
}

@inproceedings{W17-0418,
 address = {Gothenburg, Sweden},
 author = {Silfverberg, Miikka and Hulden, Mans},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0418},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {140--145},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Morpheme Segmentation and Labeling in Universal Dependencies Resources},
 year = {2017}
}

@inproceedings{W17-0419,
 address = {Gothenburg, Sweden},
 author = {Wisniewski, Guillaume and Lacroix, Oph\'{e}lie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0419},
 booktitle = {Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017)},
 month = {May},
 pages = {146--152},
 publisher = {Association for Computational Linguistics},
 title = {A Systematic Comparison of Syntactic Representations of Dependency Parsing},
 year = {2017}
}

@inproceedings{W17-0601,
 address = {St. Petersburg, Russia},
 author = {Rueter, Jack and H\"{a}m\"{a}l\"{a}inen, Mika},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0601},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics for Uralic Languages},
 month = {January},
 pages = {1--7},
 publisher = {Association for Computational Linguistics},
 title = {Synchronized Mediawiki based analyzer dictionary development},
 year = {2017}
}

@inproceedings{W17-0602,
 address = {St. Petersburg, Russia},
 author = {Rueter, Jack},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0602},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics for Uralic Languages},
 month = {January},
 pages = {8--9},
 publisher = {Association for Computational Linguistics},
 title = {DEMO: Giellatekno Open-source click-in-text dictionaries for bringing closely related languages into contact.},
 year = {2017}
}

@inproceedings{W17-0603,
 address = {St. Petersburg, Russia},
 author = {Simon, Eszter and Mus, Nikolett},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0603},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics for Uralic Languages},
 month = {January},
 pages = {10--24},
 publisher = {Association for Computational Linguistics},
 title = {Languages under the influence: Building a database of Uralic languages},
 year = {2017}
}

@inproceedings{W17-0604,
 address = {St. Petersburg, Russia},
 author = {Gerstenberger, Ciprian and Partanen, Niko and Rie{\ss}ler, Michael and Wilbur, Joshua},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0604},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics for Uralic Languages},
 month = {January},
 pages = {25--36},
 publisher = {Association for Computational Linguistics},
 title = {Instant Annotations \textendash Applying NLP Methods to the Annotation of Spoken Language Documentation Corpora},
 year = {2017}
}

@inproceedings{W17-0605,
 address = {St. Petersburg, Russia},
 author = {Chaminade, Guersande and Poibeau, Thierry},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0605},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics for Uralic Languages},
 month = {January},
 pages = {37--55},
 publisher = {Association for Computational Linguistics},
 title = {Preliminary Experiments concerning Verbal Predicative Structure Extraction from a Large Finnish Corpus},
 year = {2017}
}

@inproceedings{W17-0606,
 address = {St. Petersburg, Russia},
 author = {Horv\'{a}th, Csilla and Szil\'{a}gyi, Norbert and Vincze, Veronika and Nagy, \'{A}goston},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0606},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics for Uralic Languages},
 month = {January},
 pages = {56--65},
 publisher = {Association for Computational Linguistics},
 title = {Language technology resources and tools for Mansi: an overview},
 year = {2017}
}

@inproceedings{W17-0607,
 address = {St. Petersburg, Russia},
 author = {M. Tyers, Francis and Sheyanova, Mariya},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0607},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics for Uralic Languages},
 month = {January},
 pages = {66--75},
 publisher = {Association for Computational Linguistics},
 title = {Annotation schemes in North S\'{a}mi dependency parsing},
 year = {2017}
}

@inproceedings{W17-0608,
 address = {St. Petersburg, Russia},
 author = {Reino Trosterud, Sindre and Trosterud, Trond and R\"{a}is\"{a}nen, Anna-Kaisa and Niiranen, Leena and Haavisto, Mervi and Maliniemi, Kaisa},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0608},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics for Uralic Languages},
 month = {January},
 pages = {76--88},
 publisher = {Association for Computational Linguistics},
 title = {A morphological analyser for Kven},
 year = {2017}
}

@inproceedings{W17-0701,
 abstract = {Using the Entropy Reduction incremental complexity metric, we relate high gamma power signals from the brains of epileptic patients
to incremental stages of syntactic analysis in English and French.
We find that signals recorded intracranially from the anterior Inferior
Temporal Sulcus (aITS) and
the posterior Inferior Temporal Gyrus (pITG) correlate with word-by-word
Entropy Reduction values
derived from phrase structure grammars for those languages.
In the anterior region, this correlation persists even in combination with
surprisal co-predictors
from PCFG and ngram models.
The result confirms the idea that the brain's temporal lobe houses a parsing
function, one whose incremental processing difficulty profile reflects changes in
grammatical uncertainty.},
 address = {Valencia, Spain},
 author = {Nelson, Matthew and Dehaene, Stanislas and Pallier, Christophe and Hale, John},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0701},
 booktitle = {Proceedings of the 7th Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2017)},
 month = {April},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Entropy Reduction correlates with temporal lobe activity},
 year = {2017}
}

@inproceedings{W17-0702,
 abstract = {How do children learn a verb{\^a}s argument structure when their input contains
nonbasic clauses that obscure verb transitivity? Here we present a new model
that infers verb transitivity by learning to filter out non-basic clauses that
were likely parsed in error. In simulations with child-directed speech, we show
that this model accurately categorizes the majority of 50 frequent transitive, intransitive and alternating verbs, and jointly learns appropriate parameters
for filtering parsing errors. Our model is thus able to filter out problematic
data for verb learning without knowing in advance which data need to be
filtered.},
 address = {Valencia, Spain},
 author = {Perkins, Laurel and Feldman, Naomi and Lidz, Jeffrey},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0702},
 booktitle = {Proceedings of the 7th Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2017)},
 month = {April},
 pages = {11--19},
 publisher = {Association for Computational Linguistics},
 title = {Learning an Input Filter for Argument Structure Acquisition},
 year = {2017}
}

@inproceedings{W17-0703,
 abstract = {An important predictor of historical sound change, functional load, fails to
capture insights from speech perception. Building on ideal observer models of
word recognition, we devise a new definition of functional load that
incorporates both a priori predictability and perceptual information. We
explore this new measure with a simple model and find that it outperforms
traditional measures.},
 address = {Valencia, Spain},
 author = {Burchill, Zachary and Jaeger, T. Florian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0703},
 booktitle = {Proceedings of the 7th Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2017)},
 month = {April},
 pages = {20--28},
 publisher = {Association for Computational Linguistics},
 title = {Grounding sound change in ideal observer models of perception},
 year = {2017}
}

@inproceedings{W17-0704,
 abstract = {Human listeners are able to quickly and robustly adapt to new accents and do so
by using information about speaker's identities. This paper will present
experimental evidence that, even considering information about speaker's
identities, listeners retain a strong bias towards the acoustics of their own
dialect after dialect learning. Participants' behaviour was accurately mimicked
by a classifier which was trained on more cases from the base dialect and fewer
from the target dialect. This suggests that imbalanced training data may result
in automatic speech recognition errors consistent with those of speakers from
populations over-represented in the training data.},
 address = {Valencia, Spain},
 author = {Tatman, Rachael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0704},
 booktitle = {Proceedings of the 7th Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2017)},
 month = {April},
 pages = {29--34},
 publisher = {Association for Computational Linguistics},
 title = {``Oh, I've Heard That Before": Modelling Own-Dialect Bias After Perceptual Learning by Weighting Training Data},
 year = {2017}
}

@inproceedings{W17-0705,
 abstract = {A recurrent neural network model of phonological pattern learning is proposed.
The model is a relatively simple neural network with one recurrent layer, and
displays biases in learning that mimic observed biases in human learning.
Single-feature patterns are learned faster than two-feature patterns, and vowel
or consonant-only patterns are learned faster than patterns involving vowels
and consonants, mimicking the results of laboratory learning experiments. In
non-recurrent models, capturing these biases requires the use of alpha features
or some other representation of repeated features, but with a recurrent neural
network, these elaborations are not necessary.},
 address = {Valencia, Spain},
 author = {Doucette, Amanda},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0705},
 booktitle = {Proceedings of the 7th Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2017)},
 month = {April},
 pages = {35--40},
 publisher = {Association for Computational Linguistics},
 title = {Inherent Biases of Recurrent Neural Networks for Phonological Assimilation and Dissimilation},
 year = {2017}
}

@inproceedings{W17-0706,
 abstract = {Japanese speakers have a choice between canonical SOV and scrambled OSV word
order to express the same meaning. Although previous experiments examine the
influence of one or two factors for scrambling in a controlled setting, it is
not yet known what kinds of multiple effects contribute to scrambling. This
study uses naturally distributed data to test the multiple effects on
scrambling simultaneously. A regression analysis replicates the NP length
effect and suggests the influence of noun types, but it provides no evidence
for syntactic priming, given-new ordering, and the animacy effect. These
findings only show evidence for sentence-internal factors, but we find no
evidence that discourse level factors play a role.},
 address = {Valencia, Spain},
 author = {Orita, Naho},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0706},
 booktitle = {Proceedings of the 7th Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2017)},
 month = {April},
 pages = {41--45},
 publisher = {Association for Computational Linguistics},
 title = {Predicting Japanese scrambling in the wild},
 year = {2017}
}

@inproceedings{W17-0801,
 abstract = {We here examine how different perspectives of understanding written discourse, like the reader's, the writer's or the text's point of view, affect the quality
of emotion annotations. We conducted a series of annotation experiments on two
corpora, a popular movie review corpus and a genre- and domain-balanced corpus
of standard English. We found statistical evidence that the writer's
perspective yields superior annotation quality overall. However, the quality
one perspective yields compared to the other(s) seems to depend on the domain
the utterance originates from. Our data further suggest that the popular movie
review data set suffers from an atypical bimodal distribution which may
decrease model performance when used as a training resource.},
 address = {Valencia, Spain},
 author = {Buechel, Sven and Hahn, Udo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0801},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {1--12},
 publisher = {Association for Computational Linguistics},
 title = {Readers vs. Writers vs. Texts: Coping with Different Perspectives of Text Understanding in Emotion Annotation},
 year = {2017}
}

@inproceedings{W17-0802,
 abstract = {This work presents a dataset and annotation scheme for the new task of
identifying {\^a}good{\^a} conversations that occur online, which we call ERICs:
Engaging, Respectful, and/or Informative Conversations. We develop a taxonomy
to reflect features of entire threads and individual comments which we believe
contribute to identifying ERICs; code a novel dataset of Yahoo News comment
threads (2.4k threads and 10k comments) and 1k threads from the Internet
Argument Corpus; and analyze the features characteristic of ERICs. This is one
of the largest annotated corpora of online human dialogues, with the most
detailed set of annotations. It will be valuable for identifying ERICs and
other aspects of argumentation, dialogue, and discourse.},
 address = {Valencia, Spain},
 author = {Napoles, Courtney and Tetreault, Joel and Pappu, Aasish and Rosato, Enrica and Provenzale, Brian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0802},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {13--23},
 publisher = {Association for Computational Linguistics},
 title = {Finding Good Conversations Online: The Yahoo News Annotated Comments Corpus},
 year = {2017}
}

@inproceedings{W17-0803,
 abstract = {Traditional discourse annotation tasks are considered costly and
time-consuming, and the reliability and validity of these tasks is in question.
In this paper, we investigate whether crowdsourcing can be used to obtain
reliable discourse relation annotations. We also examine the influence of
context on the reliability of the data. The results of a crowdsourced
connective insertion task showed that the method can be used to obtain reliable
annotations: The majority of the inserted connectives converged with the
original label. Further, the method is sensitive to the fact that multiple
senses can often be inferred for a single relation. Regarding the presence of
context, the results show no significant difference in distributions of
insertions between conditions overall. However, a by-item comparison revealed
several characteristics of segments that determine whether the presence of
context makes a difference in annotations. The findings discussed in this paper
can be taken as evidence that crowdsourcing can be used as a valuable method to
obtain insights into the sense(s) of relations.},
 address = {Valencia, Spain},
 author = {Scholman, Merel and Demberg, Vera},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0803},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {24--33},
 publisher = {Association for Computational Linguistics},
 title = {Crowdsourcing discourse interpretations: On the influence of context and the reliability of a connective insertion task},
 year = {2017}
}

@inproceedings{W17-0804,
 abstract = {We present a code-switching corpus of Turkish-German that is collected by
recording
conversations of bilinguals. The recordings are then transcribed in two layers
following speech and orthography conventions, and annotated with sentence
boundaries and intersentential, intrasentential, and intra-word switch points.
The total amount of data is 5 hours of speech which corresponds to 3614
sentences.
The corpus aims at serving as a resource for speech or text analysis, as well
as a
collection for linguistic inquiries.},
 address = {Valencia, Spain},
 author = {\c{C}etino\u{g}lu, \"{O}zlem},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0804},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {34--40},
 publisher = {Association for Computational Linguistics},
 title = {A Code-Switching Corpus of Turkish-German Conversations},
 year = {2017}
}

@inproceedings{W17-0805,
 abstract = {We focus on the identification of omission in statement pairs. We compare three
annotation schemes, namely two different crowdsourcing schemes and manual
expert annotation. We show that the simplest of the two crowdsourcing
approaches yields a better annotation quality than the more complex one. We use
a dedicated classifier to assess whether the annotators' behavior can be
explained by straightforward linguistic features. The classifier benefits from
a modeling that uses lexical information beyond length and overlap measures.
However, for our  task, we argue that expert and not crowdsourcing-based
annotation is the best compromise between annotation cost and quality.},
 address = {Valencia, Spain},
 author = {Mart\'{i}nez Alonso, H\'{e}ctor and Delamaire, Amaury and Sagot, Beno\^{i}t},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0805},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {41--45},
 publisher = {Association for Computational Linguistics},
 title = {Annotating omission in statement pairs},
 year = {2017}
}

@inproceedings{W17-0806,
 abstract = {We present REPORTS, an annotation scheme for the annotation of speech, attitude
and perception reports. Such a scheme makes it possible to annotate the various
text elements involved in such reports (e.g. embedding entity, complement, complement head) and their relations in a uniform way, which in turn
facilitates the automatic extraction of information on, for example, complementation and vocabulary distribution. We also present the Ancient Greek
corpus RAG (Thucydides{\^a} History of the Peloponnesian War), to which we have
applied this scheme using the annotation tool BRAT. We discuss some of the
issues, both theoretical and practical, that we encountered, show how the
corpus helps in answering specific questions, and conclude that REPORTS fitted
in well with our needs.},
 address = {Valencia, Spain},
 author = {Bary, Corien and Hess, Leopold and Thijs, Kees and Berck, Peter and Hendrickx, Iris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0806},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {46--56},
 publisher = {Association for Computational Linguistics},
 title = {Annotating Speech, Attitude and Perception Reports},
 year = {2017}
}

@inproceedings{W17-0807,
 abstract = {Consistency is a crucial requirement in text annotation.  It is especially
important in educational applications, as lack of consistency directly affects
learners' motivation and learning performance.                          This paper
presents
a
quality
assessment scheme for English-to-Japanese translations produced by learner
translators at university.  We constructed a revision typology and a decision
tree manually through an application of the OntoNotes method, i.e., an
iteration of assessing learners' translations and hypothesizing the conditions
for consistent decision making, as well as re-organizing the typology.
Intrinsic evaluation of the created scheme confirmed its potential contribution
to the consistent classification of identified erroneous text spans, achieving
visibly higher Cohen's kappa values, up to 0.831, than previous work.  This
paper also describes an application of our scheme to an English-to-Japanese
translation exercise course for undergraduate students at a university in
Japan.},
 address = {Valencia, Spain},
 author = {Fujita, Atsushi and Tanabe, Kikuko and Toyoshima, Chiho and Yamamoto, Mayuka and Kageura, Kyo and Hartley, Anthony},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0807},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {57--66},
 publisher = {Association for Computational Linguistics},
 title = {Consistent Classification of Translation Revisions: A Case Study of English-Japanese Student Translations},
 year = {2017}
}

@inproceedings{W17-0808,
 abstract = {For decades, most self-respecting linguistic engineering initiatives have
designed and implemented custom representations for various layers of, for
example, morphological, syntactic, and semantic analysis. Despite occasional
efforts at harmonization or even standardization, our field today is blessed
with a multitude of ways of encoding and exchanging linguistic annotations of
these types, both at the levels of {\^a}abstract syntax{\^a}, naming choices, and
of
course file formats. To a large degree, it is possible to work within and
across design plurality by conversion, and often there may be good reasons for
divergent design reflecting differences in use. However, it is likely that some
abstract commonalities across choices of representation are obscured by more
superficial differences, and conversely there is no obvious procedure to tease
apart what actually constitute contentful vs. mere technical divergences. In
this study, we seek to conceptually align three representations for common
types of morpho-syntactic analysis, pinpoint what in our view constitute
contentful differences, and reflect on the underlying principles and specific
requirements that led to individual choices. We expect that a more in-depth
understanding of these choices across designs may led to increased
harmonization, or at least to more informed design of future representations.},
 address = {Valencia, Spain},
 author = {Eckart de Castilho, Richard and Ide, Nancy and Lapponi, Emanuele and Oepen, Stephan and Suderman, Keith and Velldal, Erik and Verhagen, Marc},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0808},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {67--75},
 publisher = {Association for Computational Linguistics},
 title = {Representation and Interchange of Linguistic Annotation. An In-Depth, Side-by-Side Comparison of Three Designs},
 year = {2017}
}

@inproceedings{W17-0809,
 abstract = {This paper presents the recent developments on Turkish Discourse Bank (TDB).
First, the resource is summarized and an evaluation is presented. Then, TDB
1.1, i.e. enrichments on 10% of the corpus are described (namely, senses for
explicit discourse connectives, and new annotations for three discourse
relation types - implicit relations, entity relations and alternative
lexicalizations). The method of annotation is explained and the data are
evaluated.},
 address = {Valencia, Spain},
 author = {Zeyrek, Deniz and Kurfal{\"A}$\pm$, Murathan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0809},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {76--81},
 publisher = {Association for Computational Linguistics},
 title = {TDB 1.1: Extensions on Turkish Discourse Bank},
 year = {2017}
}

@inproceedings{W17-0810,
 abstract = {In this paper, we describe our preliminary study on annotating event mention as
a part of our research on high-precision news event extraction models. To this
end, we propose a two-layer annotation scheme, designed to separately capture
the functional and conceptual aspects of event mentions. We hypothesize that
the precision of models can be improved by modeling and extracting separately
the different aspects of news events, and then combining the extracted
information by leveraging the complementarities of the models. In addition, we
carry out a preliminary annotation using the proposed scheme and analyze the
annotation quality in terms of inter-annotator agreement.},
 address = {Valencia, Spain},
 author = {di Buono, Maria Pia and Tutek, Martin and \v{S}najder, Jan and Glava\v{s}, Goran and Dalbelo Ba\v{s}i\'{c}, Bojana and Milic-Frayling, Natasa},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0810},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {82--90},
 publisher = {Association for Computational Linguistics},
 title = {Two Layers of Annotation for Representing Event Mentions in News Stories},
 year = {2017}
}

@inproceedings{W17-0811,
 abstract = {With the advent of word representations, word similarity tasks are becoming
increasing popular as an evaluation metric for the quality of the
representations. In this paper, we present manually annotated monolingual word
similarity datasets of six Indian languages - Urdu, Telugu, Marathi, Punjabi, Tamil and Gujarati. These languages are most spoken Indian languages worldwide
after Hindi and Bengali. For the construction of these datasets, our approach
relies on translation and re-annotation of word similarity datasets of English.
We also present baseline scores for word representation models using
state-of-the-art techniques for Urdu, Telugu and Marathi by evaluating them on
newly created word similarity datasets.},
 address = {Valencia, Spain},
 author = {Akhtar, Syed Sarfaraz and Gupta, Arihant and Vajpayee, Avijit and Srivastava, Arjit and Shrivastava, Manish},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0811},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {91--94},
 publisher = {Association for Computational Linguistics},
 title = {Word Similarity Datasets for Indian Languages: Annotation and Baseline Systems},
 year = {2017}
}

@inproceedings{W17-0812,
 abstract = {Language of cause and effect captures an essential component of the semantics
of a text. However, causal language is also intertwined with other semantic
relations, such as temporal precedence and correlation. This makes it difficult
to determine when causation is the primary intended meaning. This paper
presents BECauSE 2.0, a new version of the BECauSE corpus with exhaustively
annotated expressions of causal language, but also seven semantic relations
that are frequently co-present with causation. The new corpus shows high
inter-annotator agreement, and yields insights both about the linguistic
expressions of causation and about the process of annotating co-present
semantic relations.},
 address = {Valencia, Spain},
 author = {Dunietz, Jesse and Levin, Lori and Carbonell, Jaime},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0812},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {95--104},
 publisher = {Association for Computational Linguistics},
 title = {The BECauSE Corpus 2.0: Annotating Causality and Overlapping Relations},
 year = {2017}
}

@inproceedings{W17-0813,
 abstract = {In this paper, we present a simple, yet effective method for the automatic
identification and extraction of causal relations from text, based on a large
English-German parallel corpus. The goal of this effort is to create a lexical
resource for German causal relations. The resource will consist of a lexicon
that describes constructions that trigger causality as well as the participants
of the causal event, and will be augmented by a corpus with annotated instances
for each entry, that can be used as training data to develop a system for
automatic classification of causal relations. Focusing on verbs, our method
harvested a set of 100 different lexical triggers of causality, including
support verb constructions. At the moment, our corpus includes over 1,000
annotated instances. The lexicon and the annotated data will be made available
to the research community.},
 address = {Valencia, Spain},
 author = {Rehbein, Ines and Ruppenhofer, Josef},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0813},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {105--114},
 publisher = {Association for Computational Linguistics},
 title = {Catching the Common Cause: Extraction and Annotation of Causal Relations and their Participants},
 year = {2017}
}

@inproceedings{W17-0814,
 abstract = {We present the first experiment-based study that explicitly contrasts the three
major semantic role labeling frameworks.
As a prerequisite, we create a dataset labeled with parallel FrameNet-, PropBank-, and VerbNet-style labels for German.
We train a state-of-the-art SRL tool for German for the different annotation
styles and provide a comparative analysis across frameworks.
We further explore the behavior of the frameworks with automatic training data
generation.
VerbNet provides larger semantic expressivity than PropBank, and we find that
its generalization capacity approaches PropBank in SRL training, but it benefits less from training data expansion than the sparse-data affected
FrameNet.},
 address = {Valencia, Spain},
 author = {Hartmann, Silvana and M\'{u}jdricza-Maydt, \'{E}va and Kuznetsov, Ilia and Gurevych, Iryna and Frank, Anette},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-0814},
 booktitle = {Proceedings of the 11th Linguistic Annotation Workshop},
 month = {April},
 pages = {115--121},
 publisher = {Association for Computational Linguistics},
 title = {Assessing SRL Frameworks with Automatic Training Data Expansion},
 year = {2017}
}

@inproceedings{W17-0901,
 abstract = {We present a semi-supervised clustering approach to induce script structure
from crowdsourced descriptions of event sequences by grouping event
descriptions into paraphrase sets (representing event types) and inducing their
temporal order. Our approach exploits semantic and positional similarity and
allows for flexible event order, thus overcoming the rigidity of previous
approaches. We incorporate crowdsourced alignments as prior knowledge and show
that exploiting a small number of alignments results in a substantial
improvement in cluster quality over state-of-the-art models and provides an
appropriate basis for the induction of temporal order. We also show a coverage
study to demonstrate the scalability of our approach.},
 address = {Valencia, Spain},
 author = {Wanzare, Lilian and Zarcone, Alessandra and Thater, Stefan and Pinkal, Manfred},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0901},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {1--11},
 publisher = {Association for Computational Linguistics},
 title = {Inducing Script Structure from Crowdsourced Event Descriptions via Semi-Supervised Clustering},
 year = {2017}
}

@inproceedings{W17-0902,
 abstract = {We propose to move from Open Information Extraction (OIE) ahead to Open
Knowledge Representation (OKR), aiming to represent information conveyed
jointly in a set of texts in an open text- based manner. We do so by
consolidating OIE extractions using entity and predicate coreference, while
modeling information containment between coreferring elements via lexical
entailment. We suggest that generating OKR structures can be a useful step in
the NLP pipeline, to give semantic applications an easy handle on consolidated
information across multiple texts.},
 address = {Valencia, Spain},
 author = {Wities, Rachel and Shwartz, Vered and Stanovsky, Gabriel and Adler, Meni and Shapira, Ori and Upadhyay, Shyam and Roth, Dan and Mart\'{i}nez-C\'{a}mara, Eugenio and Gurevych, Iryna and Dagan, Ido},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0902},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {12--24},
 publisher = {Association for Computational Linguistics},
 title = {A Consolidated Open Knowledge Representation for Multiple Texts},
 year = {2017}
}

@inproceedings{W17-0903,
 abstract = {Causal relations play a key role in information extraction and reasoning. Most
of the times, their expression is ambiguous or implicit, i.e. without signals
in the text. This makes their identification challenging. We aim to improve
their identification by implementing a Feedforward Neural Network with a novel
set of features for this task. In particular, these are based on the position
of event mentions and the semantics of events and participants. The resulting
classifier outperforms strong baselines on two datasets (the Penn Discourse
Treebank and the CSTNews corpus) annotated with different schemes and
containing examples in two languages, English and Portuguese. This result
demonstrates the importance of events for identifying discourse relations.},
 address = {Valencia, Spain},
 author = {Ponti, Edoardo Maria and Korhonen, Anna},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0903},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {25--30},
 publisher = {Association for Computational Linguistics},
 title = {Event-Related Features in Feedforward Neural Networks Contribute to Identifying Causal Relations in Discourse},
 year = {2017}
}

@inproceedings{W17-0904,
 abstract = {We argue that in order to detect stance, not only the explicit attitudes
of the stance holder towards the targets are crucial. It is the whole narrative
the writer drafts that counts, including the way  he hypostasizes the discourse
referents: as benefactors or villains, as victims or beneficiaries.
We exemplify the ability of our system to identify targets and detect
the writer's stance towards them on the basis of about 100 000 Facebook posts
of a German right-wing party.
A reader and writer model on top of our verb-based attitude extraction
directly reveal stance conflicts.},
 address = {Valencia, Spain},
 author = {Klenner, Manfred and Tuggener, Don and Clematide, Simon},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0904},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {31--40},
 publisher = {Association for Computational Linguistics},
 title = {Stance Detection in Facebook Posts of a German Right-wing Party},
 year = {2017}
}

@inproceedings{W17-0905,
 abstract = {This paper analyzes the narrative event cloze test and its recent evolution.
The test removes one event from a document's chain of events, and systems
predict the missing event.
Originally proposed to evaluate learned knowledge of event scenarios (e.g., scripts and frames), most recent work now builds ngram-like language models
(LM) to beat the test.
This paper argues that the test has slowly/unknowingly been altered to
accommodate LMs.5
Most notably, tests are auto-generated rather than by hand, and no effort is
taken to include core script events.
Recent work is not clear on evaluation goals and contains contradictory
results.
We implement several models, and show that the test's bias to high-frequency
events explains the inconsistencies.
We conclude with recommendations on how to return to the test's original
intent, and offer brief suggestions on a path forward.},
 address = {Valencia, Spain},
 author = {Chambers, Nathanael},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0905},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {41--45},
 publisher = {Association for Computational Linguistics},
 title = {Behind the Scenes of an Evolving Event Cloze Test},
 year = {2017}
}

@inproceedings{W17-0906,
 abstract = {The LSDSem'17 shared task is the Story Cloze Test, a new evaluation for story
understanding and script learning. This test provides a system with a
four-sentence story and two possible endings, and the system must choose the
correct ending to the story. Successful narrative understanding (getting closer
to human performance of 100%) requires systems to link various levels of
semantics to commonsense knowledge. A total of eight systems participated in
the shared task, with a variety of approaches including.},
 address = {Valencia, Spain},
 author = {Mostafazadeh, Nasrin and Roth, Michael and Louis, Annie and Chambers, Nathanael and Allen, James},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0906},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {46--51},
 publisher = {Association for Computational Linguistics},
 title = {LSDSem 2017 Shared Task: The Story Cloze Test},
 year = {2017}
}

@inproceedings{W17-0907,
 abstract = {This paper describes University of Washington NLP{\^a}s submission for the
Linking Models of Lexical, Sentential and Discourse-level Semantics (LSDSem
2017) shared task{\^a}the Story Cloze Task. Our system is a linear classifier
with a variety of features, including both the scores of a neural language
model and style features. We report 75.2% accuracy on the task. A further
discussion of our results can be found in Schwartz et al. (2017).},
 address = {Valencia, Spain},
 author = {Schwartz, Roy and Sap, Maarten and Konstas, Ioannis and Zilles, Leila and Choi, Yejin and Smith, Noah A.},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0907},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {52--55},
 publisher = {Association for Computational Linguistics},
 title = {Story Cloze Task: UW NLP System},
 year = {2017}
}

@inproceedings{W17-0908,
 abstract = {The Story Cloze test is a recent effort in providing a common test scenario for
text understanding systems.
As part of the LSDSem 2017 shared task, we present a system based on a deep
learning architecture combined with a rich set of manually-crafted linguistic
features. The system outperforms all known baselines for the task, suggesting
that the chosen approach is promising. We additionally present two methods for
generating further training data based on stories from the ROCStories corpus.},
 address = {Valencia, Spain},
 author = {Bugert, Michael and Puzikov, Yevgeniy and R\"{u}ckl\'{e}, Andreas and Eckle-Kohler, Judith and Martin, Teresa and Mart\'{i}nez-C\'{a}mara, Eugenio and Sorokin, Daniil and Peyrard, Maxime and Gurevych, Iryna},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0908},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {56--61},
 publisher = {Association for Computational Linguistics},
 title = {LSDSem 2017: Exploring Data Generation Methods for the Story Cloze Test},
 year = {2017}
}

@inproceedings{W17-0909,
 abstract = {We present two NLP components for the Story Cloze Task -- dictionary-based
sentiment analysis and lexical cohesion. While previous research found no
contribution from sentiment analysis to the accuracy on this task, we
demonstrate that sentiment is an important aspect. We describe a new approach, using a rule that estimates sentiment congruence in a story. Our
sentiment-based system achieves strong results on this task. Our lexical
cohesion system achieves accuracy comparable to previously published baseline
results. A combination of the two systems achieves better accuracy than
published baselines. We argue that sentiment analysis should be considered an
integral part of narrative comprehension.},
 address = {Valencia, Spain},
 author = {Flor, Michael and Somasundaran, Swapna},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0909},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {62--67},
 publisher = {Association for Computational Linguistics},
 title = {Sentiment Analysis and Lexical Cohesion for the Story Cloze Task},
 year = {2017}
}

@inproceedings{W17-0910,
 abstract = {We present a resource-lean neural recognizer for modeling coherence in
commonsense stories. Our lightweight system is inspired by successful attempts
to modeling discourse relations and stands out due to its simplicity and easy
optimization compared to prior approaches to narrative script learning.
We evaluate our approach in the Story Cloze Test demonstrating an absolute
improvement in accuracy of 4.7% over state-of-the-art implementations.},
 address = {Valencia, Spain},
 author = {Schenk, Niko and Chiarcos, Christian},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0910},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {68--73},
 publisher = {Association for Computational Linguistics},
 title = {Resource-Lean Modeling of Coherence in Commonsense Stories},
 year = {2017}
}

@inproceedings{W17-0911,
 abstract = {The Story Cloze Test consists of choosing a sentence that best completes a
story given two choices. In this paper we present a system that performs this
task using a supervised binary classifier on top of a recurrent neural network
to predict the probability that a given story ending is correct. The classifier
is trained to distinguish correct story endings given in the training data from
incorrect ones that we artificially generate. Our experiments evaluate
different methods for generating these negative examples, as well as different
embedding-based representations of the stories. Our best result obtains 67.2%
accuracy on the test set, outperforming the existing top baseline of 58.5%.},
 address = {Valencia, Spain},
 author = {Roemmele, Melissa and Kobayashi, Sosuke and Inoue, Naoya and Gordon, Andrew},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0911},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {74--80},
 publisher = {Association for Computational Linguistics},
 title = {An RNN-based Binary Classifier for the Story Cloze Test},
 year = {2017}
}

@inproceedings{W17-0912,
 abstract = {This paper describes an ensemble system submitted as part of the LSDSem Shared
Task 2017 - the Story Cloze Test. The main conclusion from our results is that
an approach based on semantic similarity alone may not be enough for this task.
We test various approaches and compare them with two ensemble systems. One is
based on voting and the other on logistic regression based classifier. Our
final system is able to outperform the previous state of the art for the Story
Cloze test. Another very interesting observation is the performance of
sentiment based approach which works almost as well on its own as our final
ensemble system.},
 address = {Valencia, Spain},
 author = {Goel, Pranav and Singh, Anil Kumar},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0912},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {81--86},
 publisher = {Association for Computational Linguistics},
 title = {IIT (BHU): System Description for LSDSem'17 Shared Task},
 year = {2017}
}

@inproceedings{W17-0913,
 abstract = {This paper describes two supervised baseline systems for the Story Cloze Test
Shared Task (Mostafazadeh et al., 2016a). We first build a classifier using
features based on word embeddings and semantic similarity computation. We
further implement a neural LSTM system with different encoding strategies that
try to model the relation between the story and the
provided endings. Our experiments show that a model using representation
features based on average word embedding vectors over the given story words and
the candidate ending sentences words, joint with similarity features between
the story and candidate ending representations performed better than the neural
models. Our best model based on achieves an accuracy
of 72.42, ranking 3rd in the official evaluation.},
 address = {Valencia, Spain},
 author = {Mihaylov, Todor and Frank, Anette},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-0913},
 booktitle = {Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},
 month = {April},
 pages = {87--92},
 publisher = {Association for Computational Linguistics},
 title = {Story Cloze Ending Selection Baselines and Data Examination},
 year = {2017}
}

@inproceedings{W17-1001,
 abstract = {In this brief report we present an overview of the MultiLing 2017 effort and
workshop, as implemented within EACL 2017.
MultiLing is a community-driven initiative that pushes the state-of-the-art in
Automatic Summarization by providing data sets and fostering further research
and development of summarization systems.
This year the scope of the workshop was widened, bringing together researchers
that work on summarization across sources, languages and genres. We summarize
the main tasks planned and implemented this year, the contributions received, and we also provide insights on next steps.},
 address = {Valencia, Spain},
 author = {Giannakopoulos, George and Conroy, John and Kubina, Jeff and Rankel, Peter A. and Lloret, Elena and Steinberger, Josef and Litvak, Marina and Favre, Benoit},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1001},
 booktitle = {Proceedings of the MultiLing 2017 Workshop on Summarization and Summary Evaluation Across Source Types and Genres},
 month = {April},
 pages = {1--6},
 publisher = {Association for Computational Linguistics},
 title = {MultiLing 2017 Overview},
 year = {2017}
}

@inproceedings{W17-1002,
 abstract = {Abstractive document summarization seeks to automatically generate a summary
for a document, based on some abstract ''understanding'' of the original
document. State-of-the-art techniques traditionally use
attentive encoder--decoder architectures.  However, due to the large number of
parameters in these models, they require large training datasets and long
training times. In this paper, we propose decoupling the encoder and decoder
networks, and training them separately.  We encode documents using an
unsupervised document encoder, and then feed the document vector to a recurrent
neural network decoder. With this decoupled architecture, we decrease the
number of parameters in the decoder substantially, and shorten its training
time.  Experiments show that the decoupled model achieves comparable
performance with state-of-the-art models for in-domain documents, but less well
for out-of-domain documents.},
 address = {Valencia, Spain},
 author = {Xu, Ying and Lau, Jey Han and Baldwin, Timothy and Cohn, Trevor},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1002},
 booktitle = {Proceedings of the MultiLing 2017 Workshop on Summarization and Summary Evaluation Across Source Types and Genres},
 month = {April},
 pages = {7--11},
 publisher = {Association for Computational Linguistics},
 title = {Decoupling Encoder and Decoder Networks for Abstractive Document Summarization},
 year = {2017}
}

@inproceedings{W17-1003,
 abstract = {The textual similarity is a crucial aspect for many extractive text
summarization methods. A bag-of-words representation does not allow to grasp
the semantic relationships between concepts when comparing strongly related
sentences with no words in common. To overcome this issue, in this paper we
propose a centroid-based method for text summarization that exploits the
compositional capabilities of word embeddings. The evaluations on
multi-document and multilingual datasets prove the effectiveness of the
continuous vector representation of words compared to the bag-of-words model.
Despite its simplicity, our method achieves good performance even in comparison
to more complex deep learning models. Our method is unsupervised and it can be
adopted in other summarization tasks.},
 address = {Valencia, Spain},
 author = {Rossiello, Gaetano and Basile, Pierpaolo and Semeraro, Giovanni},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1003},
 booktitle = {Proceedings of the MultiLing 2017 Workshop on Summarization and Summary Evaluation Across Source Types and Genres},
 month = {April},
 pages = {12--21},
 publisher = {Association for Computational Linguistics},
 title = {Centroid-based Text Summarization through Compositionality of Word Embeddings},
 year = {2017}
}

@inproceedings{W17-1004,
 abstract = {Query-based text summarization is aimed at extracting essential information
that answers the query from original text. The answer is presented
in a minimal, often predefined, number of words. In this paper we introduce a
new unsupervised approach for query-based extractive summarization, based on
the minimum description length (MDL) principle that employs Krimp compression
algorithm (Vreeken et al., 2011). The key idea of our approach is to select
frequent word sets related to a given query that compress document sentences
better and therefore describe the document better.
A summary is extracted by selecting sentences that best cover query-related
frequent word sets.
The approach is evaluated based on the DUC 2005 and DUC 2006 datasets which are
specifically designed for query-based summarization (DUC, 2005 2006). It
competes with the best results.},
 address = {Valencia, Spain},
 author = {Litvak, Marina and Vanetik, Natalia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1004},
 booktitle = {Proceedings of the MultiLing 2017 Workshop on Summarization and Summary Evaluation Across Source Types and Genres},
 month = {April},
 pages = {22--31},
 publisher = {Association for Computational Linguistics},
 title = {Query-based summarization using MDL principle},
 year = {2017}
}

@inproceedings{W17-1005,
 abstract = {Multiple grammatical and semantic features are adopted in content linking and
argument/sentiment labeling for online forums in this paper. There are mainly
two different methods for content linking. First, we utilize the deep feature
obtained from Word Embedding Model in deep learning and compute sentence
similarity. Second, we use multiple traditional features to locate candidate
linking sentences, and then adopt a voting method to obtain the final result.
LDA topic modeling is used to mine latent semantic feature and K-means
clustering is implemented for argument labeling, while features from sentiment
dictionaries and rule-based sentiment analysis are integrated for sentiment
labeling. Experimental results have shown that our methods are valid.},
 address = {Valencia, Spain},
 author = {Li, Lei and Mao, Liyuan and Chen, Moye},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1005},
 booktitle = {Proceedings of the MultiLing 2017 Workshop on Summarization and Summary Evaluation Across Source Types and Genres},
 month = {April},
 pages = {32--36},
 publisher = {Association for Computational Linguistics},
 title = {Word Embedding and Topic Modeling Enhanced Multiple Features for Content Linking and Argument / Sentiment Labeling in Online Forums},
 year = {2017}
}

@inproceedings{W17-1006,
 abstract = {The electronic Word of Mouth has become the most powerful communication channel
thanks to the wide usage of the Social Media. Our research proposes an approach
towards the production of automatic ultra-concise summaries from multiple Web
2.0
sources. We exploit user-generated content from reviews and microblogs in dif-
ferent domains, and compile and analyse four types of ultra-concise summaries:
a)positive information, b) negative information; c) both or d) objective
information. The appropriateness and usefulness of our model is demonstrated by
its successful results and great potential in real-life applications, thus
meaning a relevant advancement of the state-of-the-art approaches.},
 address = {Valencia, Spain},
 author = {Lloret, Elena and Boldrini, Ester and Martinez-Barco, Patricio and Palomar, Manuel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1006},
 booktitle = {Proceedings of the MultiLing 2017 Workshop on Summarization and Summary Evaluation Across Source Types and Genres},
 month = {April},
 pages = {37--46},
 publisher = {Association for Computational Linguistics},
 title = {Ultra-Concise Multi-genre Summarisation of Web2.0: towards Intelligent Content Generation},
 year = {2017}
}

@inproceedings{W17-1007,
 abstract = {The present paper introduces a new MultiLing text summary evaluation method.
This method relies on machine learning approach which operates by combining
multiple features to build models that predict the human score (overall
responsiveness) of a new summary. We have tried several single and ``ensemble
learning'' classifiers to build the best model. We have experimented our
method
in summary level evaluation where we evaluate each text summary separately. The
correlation between built models and human score is better than the correlation
between baselines and manual score.},
 address = {Valencia, Spain},
 author = {Ellouze, Samira and Jaoua, Maher and Hadrich Belguith, Lamia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1007},
 booktitle = {Proceedings of the MultiLing 2017 Workshop on Summarization and Summary Evaluation Across Source Types and Genres},
 month = {April},
 pages = {47--54},
 publisher = {Association for Computational Linguistics},
 title = {Machine Learning Approach to Evaluate MultiLingual Summaries},
 year = {2017}
}

@inproceedings{W17-1101,
 abstract = {This paper presents a survey on hate speech detection. Given the steadily
growing body of social media content, the amount of online hate speech is also
increasing. Due to the massive scale of the web, methods that automatically
detect hate speech are required. Our survey describes key areas that have been
explored to automatically recognize these types of utterances using natural
language processing. We also discuss limits of those approaches.},
 address = {Valencia, Spain},
 author = {Schmidt, Anna and Wiegand, Michael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1101},
 booktitle = {Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media},
 month = {April},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {A Survey on Hate Speech Detection using Natural Language Processing},
 year = {2017}
}

@inproceedings{W17-1102,
 abstract = {Emojis are used frequently in social media. A widely assumed view is that
emojis express the emotional state of the user, which has led to research
focusing on the expressiveness of emojis independent from the linguistic
context. We argue that emojis and the linguistic texts can modify the meaning
of each other. The overall communicated meaning is not a simple sum of the two
channels.
In order to study the meaning interplay, we need data indicating the overall
sentiment of the entire message as well as the sentiment of the emojis
stand-alone. We propose that Facebook Reactions are a good data source for such
a purpose. FB reactions (e.g. ``Love'' and ``Angry'') indicate the readers'
overall sentiment, against which we can investigate the types of emojis used
the comments under different reaction profiles. We present a data set of 21,000
FB posts (57 million reactions and 8 million comments) from public media pages
across four countries.},
 address = {Valencia, Spain},
 author = {Tian, Ye and Galery, Thiago and Dulcinati, Giulio and Molimpakis, Emilia and Sun, Chao},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1102},
 booktitle = {Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media},
 month = {April},
 pages = {11--16},
 publisher = {Association for Computational Linguistics},
 title = {Facebook sentiment: Reactions and Emojis},
 year = {2017}
}

@inproceedings{W17-1103,
 abstract = {In this paper we investigate the cross-domain performance of a current
state-of-the-art sentiment analysis systems. For this purpose we train a
convolutional neural network (CNN) on data from different domains and evaluate
its performance on other domains. Furthermore, we evaluate the usefulness of
combining a large amount of different smaller annotated corpora to a large
corpus. Our results show that more sophisticated approaches are required to
train a system that works equally well on various domains.},
 address = {Valencia, Spain},
 author = {Deriu, Jan Milan and Weilenmann, Martin and Von Gruenigen, Dirk and Cieliebak, Mark},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1103},
 booktitle = {Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media},
 month = {April},
 pages = {17--24},
 publisher = {Association for Computational Linguistics},
 title = {Potential and Limitations of Cross-Domain Sentiment Classification},
 year = {2017}
}

@inproceedings{W17-1104,
 abstract = {This paper presents new models that automatically align online aliases with
their real entity names. Many research applications rely on identifying entity
names in text, but people often refer to entities with unexpected nicknames and
aliases. For example, The King and King James are aliases for Lebron James, a
professional basketball player. Recent work on entity linking attempts to
resolve mentions to knowledge base entries, like a wikipedia page, but linking
is unfortunately limited to well-known entities with pre-built pages. This
paper asks a more basic question: can aliases be aligned without background
knowledge of the entity? Further, can the semantics surrounding alias mentions
be used to inform alignments? We describe statistical models that make
decisions based on the lexicographic properties of the aliases with their
semantic context in a large corpus of tweets. We experiment on a database of
Twitter users and their usernames, and present the first human evaluation for
this task. Alignment accuracy approaches human performance at 81%, and we show
that while lexicographic features are most important, the semantic context of
an alias further improves classification accuracy.},
 address = {Valencia, Spain},
 author = {McKelvey, Kevin and Goutzounis, Peter and da Cruz, Stephen and Chambers, Nathanael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1104},
 booktitle = {Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media},
 month = {April},
 pages = {25--35},
 publisher = {Association for Computational Linguistics},
 title = {Aligning Entity Names with Online Aliases on Twitter},
 year = {2017}
}

@inproceedings{W17-1105,
 abstract = {In this paper we show how the performance of tweet clustering can be improved
by leveraging character-based neural networks. The proposed approach overcomes
the limitations related to the vocabulary explosion in the word-based models
and allows for the seamless processing of the multilingual content. Our
evaluation results and code are available on-line:
https://github.com/vendi12/tweet2vec\_clustering.},
 address = {Valencia, Spain},
 author = {Vakulenko, Svitlana and Nixon, Lyndon and Lupu, Mihai},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1105},
 booktitle = {Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media},
 month = {April},
 pages = {36--44},
 publisher = {Association for Computational Linguistics},
 title = {Character-based Neural Embeddings for Tweet Clustering},
 year = {2017}
}

@inproceedings{W17-1106,
 abstract = {In this paper we present SB10k, a new corpus for sentiment analysis with
approx. 10,000 German tweets.
We use this new corpus and two existing corpora to provide state-of-the-art
benchmarks for sentiment analysis in German: we implemented a CNN (based on the
winning system of SemEval-2016) and a feature-based SVM and compare their
performance on all three corpora.
For the CNN, we also created German word embeddings trained on 300M tweets.
These word embeddings were then optimized for sentiment analysis using
distant-supervised
learning.
The new corpus, the German word embeddings (plain and optimized), and
source code to re-run the benchmarks are publicly available.},
 address = {Valencia, Spain},
 author = {Cieliebak, Mark and Deriu, Jan Milan and Egger, Dominic and Uzdilli, Fatih},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1106},
 booktitle = {Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media},
 month = {April},
 pages = {45--51},
 publisher = {Association for Computational Linguistics},
 title = {A Twitter Corpus and Benchmark Resources for German Sentiment Analysis},
 year = {2017}
}

@inproceedings{W17-1201,
 abstract = {We present the results of the VarDial Evaluation Campaign on Natural Language
Processing (NLP) for Similar Languages, Varieties and Dialects, which we
organized as part of the fourth edition of the VarDial workshop at EACL'2017.
This year, we included four shared tasks: Discriminating between Similar
Languages (DSL), Arabic Dialect Identification (ADI), German Dialect
Identification (GDI), and Cross-lingual Dependency Parsing (CLP). A total of 19
teams submitted runs across the four tasks, and 15 of them wrote system
description papers.},
 address = {Valencia, Spain},
 author = {Zampieri, Marcos and Malmasi, Shervin and Ljube\v{s}i\'{c}, Nikola and Nakov, Preslav and Ali, Ahmed and Tiedemann, J\"{o}rg and Scherrer, Yves and Aepli, No\"{e}mi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1201},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {1--15},
 publisher = {Association for Computational Linguistics},
 title = {Findings of the VarDial Evaluation Campaign 2017},
 year = {2017}
}

@inproceedings{W17-1202,
 abstract = {In the last few years, microblogging platforms such as Twitter have given rise
to a deluge of textual data that can be used for the analysis of informal
communication between millions of individuals. In this work, we propose an
information-theoretic approach to geographic language variation using a corpus
based on Twitter. We test our models with tens of concepts and their associated
keywords detected in Spanish tweets geolocated in Spain. We employ
dialectometric measures (cosine similarity and Jensen-Shannon divergence) to
quantify the linguistic distance on the lexical level between cells created in
a uniform grid over the map. This can be done for a single concept or in the
general case taking into account an average of the considered variants. The
latter permits an analysis of the dialects that naturally emerge from the data.
Interestingly, our results reveal the existence of two dialect macrovarieties.
The first group includes a region-specific speech spoken in small towns and
rural areas whereas the second cluster encompasses cities that tend to use a
more uniform variety. Since the results obtained with the two different metrics
qualitatively agree, our work suggests that social media corpora can be
efficiently used for dialectometric analyses.},
 address = {Valencia, Spain},
 author = {Donoso, Gonzalo and Sanchez, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1202},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {16--25},
 publisher = {Association for Computational Linguistics},
 title = {Dialectometric analysis of language variation in Twitter},
 year = {2017}
}

@inproceedings{W17-1203,
 abstract = {This paper presents a computational analysis of Gondi dialects spoken in
central India. We present a digitized data set of the dialect area, and analyze
the data using different techniques from dialectometry, deep learning, and
computational biology. We show that the methods largely agree with each other
and with the earlier non-computational analyses of the language group.},
 address = {Valencia, Spain},
 author = {Rama, Taraka and \c{C}\"{o}ltekin, \c{C}a\u{g}r{\"A}$\pm$ and Sofroniev, Pavel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1203},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {26--35},
 publisher = {Association for Computational Linguistics},
 title = {Computational analysis of Gondi dialects},
 year = {2017}
}

@inproceedings{W17-1204,
 abstract = {This paper investigates diatopic variation in a historical corpus of German.
Based on equivalent word forms from different language areas, replacement rules
and mappings are derived which describe the relations between these word forms.
These rules and mappings are then interpreted as reflections of morphological, phonological or graphemic variation. Based on sample rules and mappings, we
show that our approach can replicate results from historical linguistics. While
previous studies were restricted to predefined word lists, or confined to
single authors or texts, our approach uses a much wider range of data available
in historical corpora.},
 address = {Valencia, Spain},
 author = {Dipper, Stefanie and Waldenberger, Sandra},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1204},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {36--45},
 publisher = {Association for Computational Linguistics},
 title = {Investigating Diatopic Variation in a Historical Corpus},
 year = {2017}
}

@inproceedings{W17-1205,
 abstract = {Author profiling is the study of how language is shared by people, a problem of
growing importance in applications dealing with security, in order to
understand who could be behind an anonymous threat message, and marketing, where companies may be interested in knowing the demographics of people that in
online reviews liked or disliked their products. In this talk we will give an
overview of the PAN\footnote{\url{http://pan.webis.de/}} shared tasks that
since 2013 have been organised at CLEF and FIRE evaluation forums, mainly on
age and gender identification in social media, although also personality
recognition in Twitter as well as in code sources was also addressed.
In 2017 the PAN author profiling shared task addresses jointly gender and
language variety identification in Twitter where tweets have been annotated
with authors' gender and their specific variation of their native language:
English (Australia, Canada, Great Britain, Ireland, New  Zealand, United
States), Spanish (Argentina, Chile, Colombia, Mexico,  Peru, Spain, Venezuela), Portuguese (Brazil, Portugal), and Arabic  (Egypt, Gulf, Levantine, Maghrebi).},
 address = {Valencia, Spain},
 author = {Rosso, Paolo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1205},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {46},
 publisher = {Association for Computational Linguistics},
 title = {Author Profiling at PAN: from Age and Gender Identification to Language Variety Identification (invited talk)},
 year = {2017}
}

@inproceedings{W17-1206,
 abstract = {The present study has examined the similarity and the mutual intelligibility
between Amharic and Tigrigna using three tools namely Levenshtein distance, intelligibility test  and questionnaires. The study has shown that both
Tigrigna varieties have almost equal phonetic and lexical distances from
Amharic. The study also indicated that Amharic speakers understand less than
50% of the two varieties. Furthermore, the study showed that Amharic speakers
are more positive about the Ethiopian Tigrigna variety than the Eritrean
Variety. However, their attitude towards the two varieties does not have an
impact on their intelligibility. The Amharic speakers{\^a} familiarity to the
Tigrigna varieties is largely dependent on the genealogical relation between
Amharic and the two Tigrigna varieties.},
 address = {Valencia, Spain},
 author = {Feleke, Tekabe Legesse},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1206},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {47--54},
 publisher = {Association for Computational Linguistics},
 title = {The similarity and Mutual Intelligibility between Amharic and Tigrigna Varieties},
 year = {2017}
}

@inproceedings{W17-1207,
 abstract = {Catalan and Spanish are two related languages given that both derive from
Latin.
They share similarities in several linguistic levels including morphology, syntax and semantics. This makes them particularly interesting for the MT task.
Given the recent appearance and popularity of neural MT, this paper analyzes
the
performance of this new approach compared to the well-established rule-based
and phrase-based MT systems.
Experiments are reported on a large database of 180 million words. Results, in terms of standard automatic measures, show that neural MT clearly
outperforms
the rule-based and phrase-based MT system on in-domain test set, but it is
worst in the out-of-domain test set. A naive system combination specially works
for the latter.
In-domain manual analysis shows that neural MT tends to improve both adequacy
and fluency, for example, by being able to generate more natural translations
instead of literal ones, choosing to the adequate target word when the source
word has several translations and improving gender agreement. However, out-of-domain manual analysis shows how neural MT is more affected by unknown
words or contexts.},
 address = {Valencia, Spain},
 author = {Costa-juss\`{a}, Marta R.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1207},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {55--62},
 publisher = {Association for Computational Linguistics},
 title = {Why Catalan-Spanish Neural Machine Translation? Analysis, comparison and combination with standard Rule and Phrase-based technologies},
 year = {2017}
}

@inproceedings{W17-1208,
 abstract = {This research suggests a method for machine translation among two Kurdish
dialects. We chose the two widely spoken dialects, Kurmanji and Sorani, which
are considered to be mutually unintelligible. Also, despite being spoken by
about 30 million people in different countries, Kurdish is among less-resourced
languages. The research used bi-dialectal dictionaries and showed that the lack
of parallel corpora is not a major obstacle in machine translation between the
two dialects. The experiments showed that the machine translated texts are
comprehensible to those who do not speak the dialect. The research is the first
attempt for inter-dialect machine translation in Kurdish and particularly could
help in making online texts in one dialect comprehensible to those who only
speak the target dialect. The results showed that the translated texts are in
71%  and 79% cases rated as understandable for Kurmanji and Sorani
respectively. They are rated as slightly-understandable in 29% cases for
Kurmanji and 21% for Sorani.},
 address = {Valencia, Spain},
 author = {Hassani, Hossein},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1208},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {63--72},
 publisher = {Association for Computational Linguistics},
 title = {Kurdish Interdialect Machine Translation},
 year = {2017}
}

@inproceedings{W17-1209,
 abstract = {We present a new method to bootstrap filter Twitter language ID labels in our
dataset for automatic language identification (LID). Our method combines
geo-location, original Twitter LID labels, and Amazon Mechanical Turk to
resolve missing and unreliable labels. We are the first to compare LID
classification performance using the MIRA algorithm and langid.py. We show
classifier performance on different versions of our dataset with high accuracy
using only Twitter data, without ground truth, and very few training examples.
We also show how Platt Scaling can be use to calibrate MIRA classifier output
values into a probability distribution over candidate classes, making the
output more intuitive. Our method allows for fine-grained distinctions between
similar languages and dialects and allows us to rediscover the language
composition of our Twitter dataset.},
 address = {Valencia, Spain},
 author = {Williams, Jennifer and Dagli, Charlie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1209},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {73--83},
 publisher = {Association for Computational Linguistics},
 title = {Twitter Language Identification Of Similar Languages And Dialects Without Ground Truth},
 year = {2017}
}

@inproceedings{W17-1210,
 abstract = {This paper deals with the development of morphosyntactic taggers for spoken
varieties of the Slavic minority language Rusyn. As neither annotated corpora
nor parallel corpora are electronically available for Rusyn, we propose to
combine existing resources from the etymologically close Slavic languages
Russian, Ukrainian, Slovak, and Polish and adapt them to Rusyn. Using MarMoT as
tagging toolkit, we show that a tagger trained on a balanced set of the four
source languages outperforms single language taggers by about 9%, and that
additional automatically induced morphosyntactic lexicons lead to further
improvements. The best observed accuracies for Rusyn are 82.4% for
part-of-speech tagging and 75.5% for full morphological tagging.},
 address = {Valencia, Spain},
 author = {Scherrer, Yves and Rabus, Achim},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1210},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {84--92},
 publisher = {Association for Computational Linguistics},
 title = {Multi-source morphosyntactic tagging for spoken Rusyn},
 year = {2017}
}

@inproceedings{W17-1211,
 abstract = {We describe several systems for identifying short samples of Arabic or
Swiss-German dialects, which were prepared for the shared task of the 2017 DSL
Workshop
\cite{vardial2017report}.  The Arabic data comprises both text and
acoustic files, and our best run combined both.  The Swiss-German data
is text-only.  Coincidently, our best runs  achieved a
accuracy of nearly 63\% on both the Swiss-German and Arabic dialects tasks.},
 address = {Valencia, Spain},
 author = {Hanani, Abualsoud and Qaroush, Aziz and Taylor, Stephen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1211},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {93--101},
 publisher = {Association for Computational Linguistics},
 title = {Identifying dialects with textual and acoustic cues},
 year = {2017}
}

@inproceedings{W17-1212,
 abstract = {In this paper we describe the non-linear mappings we used with the Helsinki
language identification method, HeLI, in the 4th edition of the Discriminating
between Similar Languages (DSL) shared task, which was organized as part of the
VarDial 2017 workshop. Our SUKI team participated on the closed track together
with 10 other teams. Our system reached the 7th position in the track. We
describe the HeLI method and the non-linear mappings in mathematical notation.
The HeLI method uses a probabilistic model with character n-grams and
word-based backoff. We also describe our trials using the non-linear mappings
instead of relative frequencies and we present statistics about the back-off
function of the HeLI method.},
 address = {Valencia, Spain},
 author = {Jauhiainen, Tommi and Lind\'{e}n, Krister and Jauhiainen, Heidi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1212},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {102--108},
 publisher = {Association for Computational Linguistics},
 title = {Evaluating HeLI with Non-Linear Mappings},
 year = {2017}
}

@inproceedings{W17-1213,
 abstract = {This article describes the system submitted by the Citius\_Ixa\_Imaxin team to
the VarDial 2017 (DSL and GDI tasks). The strategy underlying our system is
based on a language distance computed by means of model perplexity. The best
model configuration we have tested is a voting system making use of several
$n$-grams models of both words and characters, even if word unigrams turned out
to be a very competitive model with reasonable results in the tasks we have
participated. An error analysis has been performed in which we identified many
test examples with no linguistic evidences to distinguish among the variants.},
 address = {Valencia, Spain},
 author = {Gamallo, Pablo and Pichel, Jose Ramom and Alegria, I\~{n}aki},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1213},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {109--114},
 publisher = {Association for Computational Linguistics},
 title = {A Perplexity-Based Method for Similar Languages Discrimination},
 year = {2017}
}

@inproceedings{W17-1214,
 abstract = {This paper describes the system developed by the Centre for English Corpus
Linguistics (CECL) to discriminating similar languages, language varieties and
dialects. Based on a SVM with character and POStag n-grams as features and the
BM25 weighting scheme, it achieved 92.7\% accuracy in the Discriminating
between Similar Languages (DSL) task, ranking first among eleven systems but
with a lead over the next three teams of only 0.2\%. A simpler version of the
system ranked second in the German Dialect Identification (GDI) task thanks to
several ad hoc postprocessing steps. Complementary analyses carried out by a
cross-validation procedure suggest that the BM25 weighting scheme could be
competitive in this type of tasks, at least in comparison with the sublinear
TF-IDF. POStag n-grams also improved the system performance.},
 address = {Valencia, Spain},
 author = {Bestgen, Yves},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1214},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {115--123},
 publisher = {Association for Computational Linguistics},
 title = {Improving the Character Ngram Model for the DSL Task with BM25 Weighting and Less Frequently Used Feature Sets},
 year = {2017}
}

@inproceedings{W17-1215,
 abstract = {Discriminating between Similar Languages (DSL) is a challenging task addressed
at the VarDial Workshop series. We report on our participation in the DSL
shared task with a two-stage system. In the first stage, character n-grams are
used to separate language groups, then specialized classifiers distinguish
similar language varieties. We have conducted experiments with three system
configurations and submitted one run for each. Our main approach is a
word-level convolutional neural network (CNN) that learns task-specific vectors
with minimal text preprocessing. We also experiment with multi-layer perceptron
(MLP) networks and another hybrid configuration. Our best run achieved an
accuracy of 90.76%, ranking 8th among 11 participants and getting very close to
the system that ranked first (less than 2 points). Even though the CNN model
could not achieve the best results, it still makes a viable approach to
discriminating between similar languages.},
 address = {Valencia, Spain},
 author = {Criscuolo, Marcelo and Aluisio, Sandra Maria},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1215},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {124--130},
 publisher = {Association for Computational Linguistics},
 title = {Discriminating between Similar Languages with Word-level Convolutional Neural Networks},
 year = {2017}
}

@inproceedings{W17-1216,
 abstract = {This paper describes the submission from the University of Helsinki to the
shared task on cross-lingual dependency parsing at VarDial 2017. We present
work on annotation projection and treebank translation that gave good results
for all three target languages in the test set. In particular, Slovak seems to
work well with information coming from the Czech treebank, which is in line
with related work. The attachment scores for cross-lingual models even surpass
the fully supervised models trained on the target language treebank. Croatian
is the most difficult language in the test set and the improvements over the
baseline are rather modest. Norwegian works best with information coming from
Swedish whereas Danish contributes surprisingly little.},
 address = {Valencia, Spain},
 author = {Tiedemann, J\"{o}rg},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1216},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {131--136},
 publisher = {Association for Computational Linguistics},
 title = {Cross-lingual dependency parsing for closely related languages - Helsinki's submission to VarDial 2017},
 year = {2017}
}

@inproceedings{W17-1217,
 abstract = {This paper presents the cic\_ualg's system that took part in the Discriminating
between Similar Languages (DSL) shared task, held at the VarDial 2017 Workshop.
This year's task aims at identifying 14 languages across 6 language groups
using a corpus of excerpts of journalistic texts. Two classification approaches
were compared: a single-step (all languages) approach and a two-step (language
group and then languages within the group) approach. Features exploited include
lexical features (unigrams of words) and character n-grams. Besides traditional
(untyped) character n-grams, we introduce typed character n-grams in the DSL
task. Experiments were carried out with different feature representation
methods (binary and raw term frequency), frequency threshold values, and
machine-learning algorithms -- Support Vector Machines (SVM) and Multinomial
Naive Bayes (MNB). Our best run in the DSL task achieved 91.46% accuracy.},
 address = {Valencia, Spain},
 author = {Gomez, Helena and Markov, Ilia and Baptista, Jorge and Sidorov, Grigori and Pinto, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1217},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {137--145},
 publisher = {Association for Computational Linguistics},
 title = {Discriminating between Similar Languages Using a Combination of Typed and Untyped Character N-grams and Words},
 year = {2017}
}

@inproceedings{W17-1218,
 abstract = {This paper describes our systems and results on VarDial 2017 shared
tasks.                    Besides three language/dialect discrimination tasks, we
also
participated in the cross-lingual dependency parsing (CLP) task using
a simple methodology which we also briefly describe in this paper.
For all the discrimination tasks, we used linear SVMs with character
and word features.  The system achieves competitive results among
other systems in the shared task.  We also report additional
experiments with neural network models. The performance of neural
network models was close but always below the corresponding SVM
classifiers in the discrimination tasks.
For the cross-lingual parsing task, we experimented with an approach
based on automatically translating the source treebank to the target
language, and training a parser on the translated treebank.  We used
off-the-shelf tools for both translation and parsing.  Despite
achieving better-than-baseline results, our scores in CLP tasks were
substantially lower than the scores of the other participants.},
 address = {Valencia, Spain},
 author = {\c{C}\"{o}ltekin, \c{C}a\u{g}r{\"A}$\pm$ and Rama, Taraka},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1218},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {146--155},
 publisher = {Association for Computational Linguistics},
 title = {T\"{u}bingen system in VarDial 2017 shared task: experiments with language identification and cross-lingual parsing},
 year = {2017}
}

@inproceedings{W17-1219,
 abstract = {We present the results of our participation in the VarDial 4 shared task on
discriminating closely related languages. Our submission includes simple
traditional models using linear support vector machines (SVMs) and a neural
network (NN). The main idea was to leverage language group information. We did
so with a two-layer approach in the traditional model and a multi-task
objective in the neural network case. Our results confirm earlier findings:
simple traditional models outperform neural networks consistently for this
task, at least given the amount of systems we could examine in the available
time. Our two-layer linear SVM ranked 2nd in the shared task.},
 address = {Valencia, Spain},
 author = {Medvedeva, Maria and Kroon, Martin and Plank, Barbara},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1219},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {156--163},
 publisher = {Association for Computational Linguistics},
 title = {When Sparse Traditional Models Outperform Dense Neural Networks: the Curious Case of Discriminating between Similar Languages},
 year = {2017}
}

@inproceedings{W17-1220,
 abstract = {This paper presents three systems submitted to the German Dialect
Identification (GDI) task at the VarDial Evaluation Campaign 2017. The task
consists of training models to identify the dialect of Swiss- German speech
transcripts. The dialects included in the GDI dataset are Basel, Bern, Lucerne, and Zurich. The three systems we submitted are based on: a plurality ensemble, a mean probability ensemble, and a meta-classifier trained on character and
word n-grams. The best results were obtained by the meta-classifier achieving
68.1% accuracy and 66.2% F1-score, ranking first among the 10 teams which
participated in the GDI shared task.},
 address = {Valencia, Spain},
 author = {Malmasi, Shervin and Zampieri, Marcos},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1220},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {164--169},
 publisher = {Association for Computational Linguistics},
 title = {German Dialect Identification in Interview Transcriptions},
 year = {2017}
}

@inproceedings{W17-1221,
 abstract = {Our submissions for the GDI 2017 Shared Task are the results from three
different types of classifiers: Na{\"A}$\pm${\`I}ve Bayes, Conditional Random Fields
(CRF), and Support Vector Machine (SVM). Our CRF-based run achieves a weighted
F1 score of 65% (third rank) being beaten by the best system by 0.9%. Measured
by classification accuracy, our ensemble run (Na{\"A}$\pm${\`I}ve Bayes, CRF, SVM) reaches
67% (second rank) being 1% lower than the best system. We also describe our
experiments with Recurrent Neural Network (RNN) architectures. Since they
performed worse than our non-neural approaches we did not include them in the
submission.},
 address = {Valencia, Spain},
 author = {Clematide, Simon and Makarov, Peter},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1221},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {170--177},
 publisher = {Association for Computational Linguistics},
 title = {CLUZH at VarDial GDI 2017: Testing a Variety of Machine Learning Tools for the Classification of Swiss German Dialects},
 year = {2017}
}

@inproceedings{W17-1222,
 abstract = {This paper presents the systems submitted by the MAZA team to the Arabic
Dialect Identification (ADI) shared task at the VarDial Evaluation Campaign
2017. The goal of the task is to evaluate computational models to identify the
dialect of Arabic utterances using both audio and text transcriptions. The ADI
shared task dataset included Modern Standard Arabic (MSA) and four Arabic
dialects: Egyptian, Gulf, Levantine, and North-African. The three systems
submitted by MAZA are based on combinations of multiple machine learning
classifiers arranged as (1) voting ensemble; (2) mean probability ensemble; (3)
meta-classifier. The best results were obtained by the meta-classifier
achieving 71.7% accuracy, ranking second among the six teams which participated
in the ADI shared task.},
 address = {Valencia, Spain},
 author = {Malmasi, Shervin and Zampieri, Marcos},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1222},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {178--183},
 publisher = {Association for Computational Linguistics},
 title = {Arabic Dialect Identification Using iVectors and ASR Transcripts},
 year = {2017}
}

@inproceedings{W17-1223,
 abstract = {The present contribution revolves around a contrastive subword n-gram model
which has been tested in the Discriminating between Similar Languages shared
task. I present and discuss the method used in this 14-way language
identification task comprising varieties of 6 main language groups. It features
the following characteristics: (1) the preprocessing and conversion of a
collection of documents to sparse features; (2) weighted character n-gram
profiles; (3) a multinomial Bayesian classifier. Meaningful bag-of-n-grams
features can be used as a system in a straightforward way, my approach
outperforms most of the systems used in the DSL shared task (3rd rank).},
 address = {Valencia, Spain},
 author = {Barbaresi, Adrien},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1223},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {184--189},
 publisher = {Association for Computational Linguistics},
 title = {Discriminating between Similar Languages using Weighted Subword Features},
 year = {2017}
}

@inproceedings{W17-1224,
 abstract = {We present a method to discriminate between texts written in either the
Netherlandic or the Flemish variant of the Dutch language. The method draws on
a feature bundle representing text statistics, syntactic features, and word
$n$-grams. Text statistics include average word length and sentence length, while syntactic features include ratios of function words and part-of-speech
$n$-grams.
The effectiveness of the classifier was measured by classifying Dutch
subtitles developed for either Dutch or Flemish television. Several machine
learning algorithms were compared as well as feature combination methods in
order to find the optimal generalization performance. A machine-learning meta
classifier based on AdaBoost attained the best F-score of 0.92.},
 address = {Valencia, Spain},
 author = {van der Lee, Chris and van den Bosch, Antal},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1224},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {190--199},
 publisher = {Association for Computational Linguistics},
 title = {Exploring Lexical and Syntactic Features for Language Variety Identification},
 year = {2017}
}

@inproceedings{W17-1225,
 abstract = {We present a machine learning approach for the Arabic Dialect Identification
(ADI) and the German Dialect Identification (GDI) Closed Shared Tasks of the
DSL 2017 Challenge. The proposed approach combines several kernels using
multiple kernel learning. While most of our kernels are based on character
p-grams (also known as n-grams) extracted from speech transcripts, we also use
a kernel based on i-vectors, a low-dimensional representation of audio
recordings, provided only for the Arabic data. In the learning stage, we
independently employ Kernel Discriminant Analysis (KDA) and Kernel Ridge
Regression (KRR). Our approach is shallow and simple, but the empirical results
obtained in the shared tasks prove that it achieves very good results. Indeed, we ranked on the first place in the ADI Shared Task with a weighted F1 score of
76.32% (4.62% above the second place) and on the fifth place in the GDI Shared
Task with a weighted F1 score of 63.67% (2.57% below the first place).},
 address = {Valencia, Spain},
 author = {Ionescu, Radu Tudor and Butnaru, Andrei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1225},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {200--209},
 publisher = {Association for Computational Linguistics},
 title = {Learning to Identify Arabic and German Dialects using Multiple Kernels},
 year = {2017}
}

@inproceedings{W17-1226,
 abstract = {We once had a corp, or should we say, it once had us
They showed us its tags, isn't it great, unified tags
They asked us to parse
and they told us to use everything
So we looked around
and we noticed there was near nothing
We took other langs, bitext aligned: words one-to-one
We played for two weeks, and then they said, here is the test
The parser kept training till morning, just until deadline
So we had to wait and hope what we get
would be just fine
And, when we awoke, the results were done, we saw we'd won
So, we wrote this paper, isn't it good, Norwegian wood.},
 address = {Valencia, Spain},
 author = {Rosa, Rudolf and Zeman, Daniel and Mare\v{c}ek, David and \v{Z}abokrtsk\'{y}, Zden{\"A}k},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1226},
 booktitle = {Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)},
 month = {April},
 pages = {210--219},
 publisher = {Association for Computational Linguistics},
 title = {Slavic Forest, Norwegian Wood},
 year = {2017}
}

@inproceedings{W17-1301,
 abstract = {This paper presents a language identification system designed to detect the
language of each word, in its context, in a multilingual documents as generated
in social media by bilingual/multilingual communities, in our case speakers of
Algerian Arabic. We frame the task as a sequence tagging problem and use
supervised machine learning with standard methods like HMM and Ngram
classification tagging. We also experiment with a lexicon-based method.
Combining all the methods in a fall-back mechanism and introducing some
linguistic rules, to deal with unseen tokens and ambiguous words, gives an
overall accuracy of 93.14%. Finally, we introduced rules for language
identification from sequences of recognised words.},
 address = {Valencia, Spain},
 author = {Adouane, Wafia and Dobnik, Simon},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1301},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {1--8},
 publisher = {Association for Computational Linguistics},
 title = {Identification of Languages in Algerian Arabic Multilingual Documents},
 year = {2017}
}

@inproceedings{W17-1302,
 abstract = {In this paper, we present a new and fast state-of-the-art Arabic diacritizer
that guesses the diacritics of words and then their case endings.  We employ a
Viterbi decoder at word-level with back-off to stem, morphological patterns, and transliteration and sequence labeling based diacritization of named
entities.  For case endings, we use Support Vector Machine (SVM) based ranking
coupled with morphological patterns and linguistic rules to properly guess case
endings. We achieve a low word level diacritization error of 3.29% and 12.77%
without and with case endings respectively on a new multi-genre free of
copyright test set. We are making the diacritizer available for free for
research purposes.},
 address = {Valencia, Spain},
 author = {Darwish, Kareem and Mubarak, Hamdy and Abdelali, Ahmed},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1302},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {9--17},
 publisher = {Association for Computational Linguistics},
 title = {Arabic Diacritization: Stats, Rules, and Hacks},
 year = {2017}
}

@inproceedings{W17-1303,
 abstract = {Semantic textual similarity is the basis of
countless applications and plays an important
role in diverse areas, such as information
retrieval, plagiarism detection, information
extraction and machine translation.
This article proposes an innovative
word embedding-based system devoted to
calculate the semantic similarity in Arabic
sentences. The main idea is to exploit vectors
as word representations in a multidimensional
space in order to capture the semantic
and syntactic properties of words.
IDF weighting and Part-of-Speech tagging
are applied on the examined sentences to
support the identification of words that are
highly descriptive in each sentence. The
performance of our proposed system is
confirmed through the Pearson correlation
between our assigned semantic similarity
scores and human judgments.},
 address = {Valencia, Spain},
 author = {Nagoudi, El Moatez Billah and Schwab, Didier},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1303},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {18--24},
 publisher = {Association for Computational Linguistics},
 title = {Semantic Similarity of Arabic Sentences with Word Embeddings},
 year = {2017}
}

@inproceedings{W17-1304,
 abstract = {Maltese is a morphologically rich language with a hybrid morphological system
which features both concatenative and non-concatenative processes. This paper
analyses the impact of this hybridity on the performance of machine learning
techniques for morphological labelling and clustering. In particular, we
analyse a dataset of morphologically related word clusters to evaluate the
difference in results for concatenative and non-concatenative clusters. We also
describe research carried out in morphological labelling, with a particular
focus on the verb category. Two evaluations were carried out, one using an
unseen dataset, and another one using a gold standard dataset which was
manually labelled. The gold standard dataset was split into concatenative and
non-concatenative to analyse the difference in results between the two
morphological systems.},
 address = {Valencia, Spain},
 author = {Borg, Claudia and Gatt, Albert},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1304},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {25--34},
 publisher = {Association for Computational Linguistics},
 title = {Morphological Analysis for the Maltese Language: The challenges of a hybrid system},
 year = {2017}
}

@inproceedings{W17-1305,
 abstract = {We present CALIMAGLF, a Gulf Arabic morphological analyzer currently covering
over 2,600 verbal lemmas. We describe in detail the process of building the
analyzer starting from phonetic dictionary entries to fully inflected
orthographic paradigms and associated lexicon and orthographic variants. We
evaluate the coverage of CALIMA-GLF against Modern Standard Arabic and Egyptian
Arabic analyzers on part of a Gulf Arabic novel. CALIMA-GLF verb analysis token
recall for identifying correct POS tag outperforms both the Modern Standard
Arabic and Egyptian Arabic analyzers by over 27.4% and 16.9% absolute, respectively.},
 address = {Valencia, Spain},
 author = {Khalifa, Salam and Hassan, Sara and Habash, Nizar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1305},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {35--45},
 publisher = {Association for Computational Linguistics},
 title = {A Morphological Analyzer for Gulf Arabic Verbs},
 year = {2017}
}

@inproceedings{W17-1306,
 abstract = {The automated processing of Arabic Dialects is challenging due to the lack of
spelling standards and to the scarcity of annotated data and resources in
general. Segmentation of words into its constituent parts is an important
processing building block. In this paper, we show how a segmenter can be
trained using only 350 annotated tweets using neural networks without any
normalization or use of lexical features or lexical resources. We deal with
segmentation as a sequence labeling problem at the character level. We show
experimentally that our model can rival state-of-the-art methods that rely on
additional resources.},
 address = {Valencia, Spain},
 author = {Samih, Younes and Attia, Mohammed and Eldesouki, Mohamed and Abdelali, Ahmed and Mubarak, Hamdy and Kallmeyer, Laura and Darwish, Kareem},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1306},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {46--54},
 publisher = {Association for Computational Linguistics},
 title = {A Neural Architecture for Dialectal Arabic Segmentation},
 year = {2017}
}

@inproceedings{W17-1307,
 abstract = {Dialectal Arabic (DA) is significantly different from the Arabic
language taught in schools and used in written communication and formal speech
(broadcast news, religion, politics, etc.). There are many existing researches
in the field of Arabic language Sentiment Analysis (SA); however, they are
generally restricted to Modern Standard Arabic (MSA) or some dialects of
economic or political interest. In this paper we are interested in the SA of
the Tunisian Dialect. We utilize Machine Learning techniques to determine the
polarity of comments written in Tunisian Dialect. First, we evaluate the SA
systems performances with models trained using freely available MSA and
Multi-dialectal data sets. We then collect and annotate a Tunisian Dialect
corpus of 17.000 comments from Facebook. This corpus allows us a significant
accuracy improvement compared to the best model trained on other Arabic
dialects or MSA data.
We believe that this first freely available corpus will be valuable to
researchers working in the field of Tunisian Sentiment Analysis and similar
areas.},
 address = {Valencia, Spain},
 author = {Medhaffar, Salima and Bougares, Fethi and Est\`{e}ve, Yannick and Hadrich-Belguith, Lamia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1307},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {55--61},
 publisher = {Association for Computational Linguistics},
 title = {Sentiment Analysis of Tunisian Dialects: Linguistic Ressources and Experiments},
 year = {2017}
}

@inproceedings{W17-1308,
 abstract = {Data generated on Twitter has become a rich source for various data mining
tasks.
Those data analysis tasks that are dependent on the tweet semantics, such as
sentiment
analysis, emotion mining, and rumor detection among others, suffer considerably
if
the tweet is not credible, not real, or spam. In this paper, we perform an
extensive
analysis on credibility of Arabic content on Twitter. We also build a
classification
model (CAT) to automatically predict the credibility of a given Arabic tweet.
Of particular originality is the inclusion of features extracted directly
or indirectly from the author's profile and timeline. To train and test CAT, we
annotated for credibility a data set of 9,000 Arabic tweets that are
topic independent. CAT achieved consistent improvements
in predicting the credibility of the tweets when compared to several baselines
and when
compared to the state-of-the-art approach with an improvement of 21% in
weighted
average F-measure. We also conducted experiments to highlight the importance of
the
user-based features as opposed to the content-based
features. We conclude our work with a feature reduction
experiment that highlights the best indicative features of credibility.},
 address = {Valencia, Spain},
 author = {El Ballouli, Rim and El-Hajj, Wassim and Ghandour, Ahmad and Elbassuoni, Shady and Hajj, Hazem and Shaban, Khaled},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1308},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {62--71},
 publisher = {Association for Computational Linguistics},
 title = {CAT: Credibility Analysis of Arabic Content on Twitter},
 year = {2017}
}

@inproceedings{W17-1309,
 abstract = {This paper aims to develop a new classification of errors made in Arabic by
those suffering from dyslexia to be used in the annotation of the Arabic
dyslexia corpus (BDAC). The dyslexic error classification for Arabic texts
(DECA) comprises a list of spelling errors extracted from previous studies and
a collection of texts written by people with dyslexia that can provide a
framework to help analyse specific errors committed by dyslexic writers. The
classification comprises 37 types of errors, grouped into nine categories. The
paper also discusses building a corpus of dyslexic Arabic texts that uses the
error annotation scheme and provides an analysis of the errors that were found
in the texts.},
 address = {Valencia, Spain},
 author = {Alamri, Maha and Teahan, William J.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1309},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {72--78},
 publisher = {Association for Computational Linguistics},
 title = {A New Error Annotation for Dyslexic texts in Arabic},
 year = {2017}
}

@inproceedings{W17-1310,
 abstract = {In this paper, we introduce an enhancement for speech recognition systems using
an unsupervised speaker clustering technique. The proposed technique is mainly
based on I-vectors and Self-Organizing Map Neural Network(SOM).The input to the
proposed algorithm is a set of speech utterances. For each utterance, we
extract 100-dimensional I-vector and then SOM is used to group the utterances
to different speakers. In our experiments, we compared our technique with
Normalized Cross Likelihood ratio Clustering (NCLR). Results show that the
proposed technique reduces the speaker error rate in comparison with NCLR.
Finally, we have experimented the effect of speaker clustering on Speaker
Adaptive Training (SAT) in a speech recognition system implemented to test the
performance of the proposed technique. It was noted that the proposed technique
reduced the WER over clustering speakers with NCLR.},
 address = {Valencia, Spain},
 author = {Ahmed, Hany and Elaraby, Mohamed and M. Mousa, Abdullah and Elhosiny, Mostafa and Abdou, Sherif and Rashwan, Mohsen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1310},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {79--83},
 publisher = {Association for Computational Linguistics},
 title = {An Unsupervised Speaker Clustering Technique based on SOM and I-vectors for Speech Recognition Systems},
 year = {2017}
}

@inproceedings{W17-1311,
 abstract = {This paper sheds light on a system that would be able to diacritize Arabic
texts automatically (SHAKKIL). In this system, the diacritization problem will
be handled through two levels; morphological and syntactic processing levels.
The adopted morphological disambiguation algorithm depends on four layers;
Uni-morphological form layer, rule-based morphological disambiguation layer, statistical-based disambiguation layer and Out Of  Vocabulary (OOV) layer. The
adopted syntactic disambiguation algorithms is concerned with detecting the
case ending diacritics depending on a rule based approach simulating the
shallow parsing technique. This will be achieved using an annotated corpus for
extracting the Arabic linguistic rules, building the language models and
testing the system output. This system is considered as a good trial of the
interaction between rule-based approach and statistical approach, where the
rules can help the statistics in detecting the right diacritization and vice
versa. At this point, the morphological Word Error Rate (WER) is 4.56% while
the morphological Diacritic Error Rate (DER) is 1.88% and the syntactic WER is
9.36%. The best WER is 14.78% compared to the best-published results, of
(Abandah, 2015); 11.68%, (Rashwan, et al., 2015); 12.90% and (Metwally, Rashwan, \& Atiya, 2016); 13.70%.},
 address = {Valencia, Spain},
 author = {Fashwan, Amany and Alansary, Sameh},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1311},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {84--93},
 publisher = {Association for Computational Linguistics},
 title = {SHAKKIL: An Automatic Diacritization System for Modern Standard Arabic Texts},
 year = {2017}
}

@inproceedings{W17-1312,
 abstract = {In this paper, we propose using a "bootstrapping" method for constructing a
dependency treebank of Arabic tweets. This method uses a rule-based parser to
create a small treebank of one thousand Arabic tweets and a data-driven parser
to create a larger treebank by using the small treebank as a seed training set.
We are able to create a dependency treebank from unlabelled tweets without any
manual intervention. Experiments results show that this method can improve the
speed of training the parser and the accuracy of the resulting parsers.},
 address = {Valencia, Spain},
 author = {Albogamy, Fahad and Ramsay, Allan and Ahmed, Hanady},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1312},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {94--99},
 publisher = {Association for Computational Linguistics},
 title = {Arabic Tweets Treebanking and Parsing: A Bootstrapping Approach},
 year = {2017}
}

@inproceedings{W17-1313,
 abstract = {Cross Language Information Retrieval (CLIR) systems are a valuable tool to
enable speakers of one language to search for content of interest expressed in
a different language. A group for whom this is of particular interest is
bilingual Arabic speakers who wish to search for English language content using
information needs expressed in Arabic queries. A key challenge in CLIR is
crossing the language barrier between the query and the documents. The most
common approach to bridging this gap is automated query translation, which can
be unreliable for vague or short queries. In this work, we examine the
potential for improving CLIR effectiveness by predicting the translation
effectiveness using Query Performance Prediction (QPP) techniques. We propose a
novel QPP method to estimate the quality of translation for an Arabic-English
Cross-lingual User-generated Speech Search (CLUGS) task. We present an
empirical evaluation that demonstrates the quality of our method on alternative
translation outputs extracted from an Arabic-to-English Machine Translation
system developed for this task. Finally, we show how this framework can be
integrated in CLUGS to find relevant translations for improved retrieval
performance.},
 address = {Valencia, Spain},
 author = {Khwileh, Ahmad and Afli, Haithem and Jones, Gareth and Way, Andy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1313},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {100--109},
 publisher = {Association for Computational Linguistics},
 title = {Identifying Effective Translations for Cross-lingual Arabic-to-English User-generated Speech Search},
 year = {2017}
}

@inproceedings{W17-1314,
 abstract = {Opinion mining in Arabic is a challenging task given the rich morphology of
the language. The task becomes more challenging when it is applied to Twitter
data, which contains additional sources of noise, such as the use of
unstandardized dialectal variations, the nonconformation to grammatical rules, the use of Arabizi and code-switching, and the use of non-text objects such as
images and URLs to express opinion. In this paper, we perform an analytical
study to observe how such linguistic phenomena
vary across different Arab regions. This study of Arabic Twitter
characterization aims at providing better understanding of Arabic Tweets, and
fostering advanced research on the topic. Furthermore, we explore the
performance of the two schools of machine learning on Arabic Twitter, namely
the feature engineering approach and the deep learning approach. We consider
models that have achieved state-of-the-art performance for opinion mining in
English. Results highlight the advantages of using deep learning-based models, and confirm the importance of using morphological abstractions to address
Arabic{\^a}s complex morphology.},
 address = {Valencia, Spain},
 author = {Baly, Ramy and Badaro, Gilbert and El-Khoury, Georges and Moukalled, Rawan and Aoun, Rita and Hajj, Hazem and El-Hajj, Wassim and Habash, Nizar and Shaban, Khaled},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1314},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {110--118},
 publisher = {Association for Computational Linguistics},
 title = {A Characterization Study of Arabic Twitter Data with a Benchmarking for State-of-the-Art Opinion Mining Models},
 year = {2017}
}

@inproceedings{W17-1315,
 abstract = {We present the MultiScript Phonetic Search algorithm to address the problem of
language learners looking up unfamiliar words that they heard. We apply it to
Arabic dictionary lookup with noisy queries done using both the Arabic and
Roman scripts. Our algorithm is based on a computational phonetic distance
metric that can be optionally machine learned. To benchmark our performance, we
created the ArabScribe dataset, containing 10,000 noisy transcriptions of
random Arabic dictionary words. Our algorithm outperforms Google Translate's
``did you mean" feature, as well as the Yamli smart Arabic keyboard.},
 address = {Valencia, Spain},
 author = {Zhang, Lingliang and Habash, Nizar and Toussaint, Godfried},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1315},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {119--129},
 publisher = {Association for Computational Linguistics},
 title = {Robust Dictionary Lookup in Multiple Noisy Orthographies},
 year = {2017}
}

@inproceedings{W17-1316,
 abstract = {This paper focuses on comparing between using Support Vector Machine based
ranking (SVM-Rank) and Bidirectional Long-Short-Term-Memory (bi-LSTM)
neural-network based sequence labeling in building a state-of-the-art Arabic
part-of-speech tagging system. Using SVM-Rank leads to state-of-the-art
results, but with a fair amount of feature engineering. Using bi-LSTM, particularly when combined with word embeddings, may lead to competitive
POS-tagging results by automatically deducing latent linguistic features.
However, we show that augmenting bi-LSTM sequence labeling with some of the
features that we used for the SVM-Rank based tagger yields to further
improvements. We also show that gains that realized by using embeddings may not
be additive with the gains achieved by the features. We are open-sourcing both
the SVM-Rank and the bi-LSTM based systems for free.},
 address = {Valencia, Spain},
 author = {Darwish, Kareem and Mubarak, Hamdy and Abdelali, Ahmed and Eldesouki, Mohamed},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1316},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {130--137},
 publisher = {Association for Computational Linguistics},
 title = {Arabic POS Tagging: Don't Abandon Feature Engineering Just Yet},
 year = {2017}
}

@inproceedings{W17-1317,
 abstract = {The success of machine learning for automatic
speech processing has raised the
need for large scale datasets. However, collecting such data is often a challenging
task as it implies significant investment involving
time and money cost. In this paper, we devise a recipe for building largescale
Speech Corpora by harnessing Web
resources namely YouTube, other Social
Media, Online Radio and TV. We illustrate
our methodology by building KALAM{\^a}DZ, An Arabic Spoken corpus dedicated to Algerian
dialectal varieties. The preliminary
version of our dataset covers all major Algerian
dialects. In addition, we make sure
that this material takes into account numerous
aspects that foster its richness. In
fact, we have targeted various speech topics.
Some automatic and manual annotations
are provided. They gather useful
information related to the speakers and
sub-dialect information at the utterance
level. Our corpus encompasses the 8 major
Algerian Arabic sub-dialects with 4881
speakers and more than 104.4 hours segmented
in utterances of at least 6 s.},
 address = {Valencia, Spain},
 author = {Bougrine, Soumia and Chorana, Aicha and Lakhdari, Abdallah and Cherroun, Hadda},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1317},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {138--146},
 publisher = {Association for Computational Linguistics},
 title = {Toward a Web-based Speech Corpus for Algerian Dialectal Arabic Varieties},
 year = {2017}
}

@inproceedings{W17-1318,
 abstract = {Although there is by now a considerable amount of research on subjectivity and
sentiment analysis on morphologically-rich languages, it is still unclear how
lexical information can best be modeled in these languages. To bridge this gap, we build effective models exploiting exclusively gold- and machine-segmented
lexical input and successfully employ syntactically motivated feature selection
to improve classification. Our best models achieve significantly above the
baselines, with 67.93% and 69.37% accuracies for subjectivity and sentiment
classification respectively.},
 address = {Valencia, Spain},
 author = {Abdul-Mageed, Muhammad},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1318},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {147--156},
 publisher = {Association for Computational Linguistics},
 title = {Not All Segments are Created Equal: Syntactically Motivated Sentiment Analysis in Lexical Space},
 year = {2017}
}

@inproceedings{W17-1319,
 abstract = {Automatic speech recognition for Arabic
is a very challenging task. Despite all the
classical techniques for Automatic Speech
Recognition (ASR), which can be efficiently applied to Arabic speech
recognition, it is essential to take into consideration
the language specificities to improve
the system performance. In this article, we
focus on Modern Standard Arabic (MSA)
speech recognition. We introduce the challenges
related to Arabic language, namely
the complex morphology nature of the language
and the absence of the short vowels
in written text, which leads to several potential
vowelization for each graphemes, which is often conflicting. We develop
an ASR system for MSA by using Kaldi
toolkit. Several acoustic and language
models are trained. We obtain a Word Error
Rate (WER) of 14.42 for the baseline
system and 12.2 relative improvement by
rescoring the lattice and by rewriting the
output with the right Z hamoza above or
below Alif.},
 address = {Valencia, Spain},
 author = {Menacer, Mohamed Amine and Mella, Odile and Fohr, Dominique and Jouvet, Denis and Langlois, David and Smaili, Kamel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1319},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {157--165},
 publisher = {Association for Computational Linguistics},
 title = {An enhanced automatic speech recognition system for Arabic},
 year = {2017}
}

@inproceedings{W17-1320,
 abstract = {We describe the process of creating NUDAR, a Universal Dependency treebank for
Arabic. We present the conversion from the Penn Arabic Tree- bank to the
Universal Dependency syntactic representation through an intermediate
dependency representation. We discuss the challenges faced in the conversion of
the trees, the decisions we made to solve them, and the validation of our
conversion. We also present initial parsing results on NUDAR.},
 address = {Valencia, Spain},
 author = {Taji, Dima and Habash, Nizar and Zeman, Daniel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1320},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {166--176},
 publisher = {Association for Computational Linguistics},
 title = {Universal Dependencies for Arabic},
 year = {2017}
}

@inproceedings{W17-1321,
 abstract = {In this paper we  present a system for automatic Arabic text diacritization
using three levels of analysis granularity in a layered back off manner. We
build and exploit diacritized language models (LM)  for each of three different
levels of granularity: surface form, morphologically segmented into
prefix/stem/suffix, and character level.  For each of the passes, we use
Viterbi search to pick the most probable diacritization per word in the input.
We start with the surface form LM, followed by the morphological level, then
finally we leverage the character level LM. Our system outperforms all of the
published systems evaluated against the same training and test data. It
achieves a 10.87% WER for complete full diacritization including lexical and
syntactic diacritization, and 3.0% WER for lexical diacritization, ignoring
syntactic diacritization.},
 address = {Valencia, Spain},
 author = {Al-Badrashiny, Mohamed and Hawwari, Abdelati and Diab, Mona},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1321},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {177--184},
 publisher = {Association for Computational Linguistics},
 title = {A Layered Language Model based Hybrid Approach to Automatic Full Diacritization of Arabic},
 year = {2017}
}

@inproceedings{W17-1322,
 abstract = {Determining the textual entailment be- tween texts is important in many NLP
tasks, such as summarization, question answering, and information extraction
and retrieval. Various methods have been suggested based on external knowledge
sources; however, such resources are not always available in all languages and
their acquisition is typically laborious and very costly. Distributional word
representations such as word embeddings learned over large corpora have been
shown to capture syntactic and semantic word relationships. Such models have
contributed to improv- ing the performance of several NLP tasks. In this paper, we address the problem of textual entailment in Arabic. We employ both
traditional features and distributional representations. Crucially, we do not
de- pend on any external resources in the pro- cess. Our suggested approach
yields state of the art performance on a standard data set, ArbTE, achieving an
accuracy of 76.2 % compared to state of the art of 69.3 %.},
 address = {Valencia, Spain},
 author = {Almarwani, Nada and Diab, Mona},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1322},
 booktitle = {Proceedings of the Third Arabic Natural Language Processing Workshop},
 month = {April},
 pages = {185--190},
 publisher = {Association for Computational Linguistics},
 title = {Arabic Textual Entailment with Word Embeddings},
 year = {2017}
}

@inproceedings{W17-1401,
 abstract = {There is great variation in the amount of NLP resources available for Slavonic
languages. For example, the Universal Dependency treebank (Nivre et al., 2016)
has about 2 MW of training resources for Czech, more than 1 MW for Russian, while only 950 words for Ukrainian and nothing for Belorussian, Bosnian or
Macedonian. Similarly, the Autodesk Machine Translation dataset only covers
three Slavonic languages (Czech, Polish and Russian). In this talk I will
discuss a general approach, which can be called Language Adaptation, similarly
to Domain Adaptation. In this approach, a model for a particular language
processing task is built by lexical transfer of cognate words and by learning a
new feature representation for a lesser-resourced (recipient) language starting
from a better-resourced (donor) language. More specifically, I will demonstrate
how language adaptation works in such training scenarios as Translation Quality
Estimation, Part-of-Speech tagging and Named Entity Recognition.},
 address = {Valencia, Spain},
 author = {Sharoff, Serge},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1401},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {1--2},
 publisher = {Association for Computational Linguistics},
 title = {Toward Pan-Slavic NLP: Some Experiments with Language Adaptation},
 year = {2017}
}

@inproceedings{W17-1402,
 abstract = {This paper presents a method of automatic construction extraction from a large
corpus of Russian. The term `construction' here means a multi-word expression
in which a variable can be replaced with another word from the same semantic
class, for example, `a glass of [water/juice/milk]'. We deal with constructions
that consist of a noun and its adjective modifier. We propose a method of
grouping such constructions into semantic classes via 2-step clustering of word
vectors in distributional models. We compare it with other clustering
techniques and evaluate it against A Russian-English Collocational Dictionary
of the Human Body that contains manually annotated groups of constructions with
nouns meaning human body parts.
The best performing method is used to cluster all adjective-noun bigrams in the
Russian National Corpus. Results of this procedure are publicly available and
can be used for building Russian construction dictionary as well as to
accelerate theoretical studies of constructions.},
 address = {Valencia, Spain},
 author = {Kutuzov, Andrey and Kuzmenko, Elizaveta and Pivovarova, Lidia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1402},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {3--13},
 publisher = {Association for Computational Linguistics},
 title = {Clustering of Russian Adjective-Noun Constructions using Word Embeddings},
 year = {2017}
}

@inproceedings{W17-1403,
 abstract = {Lexical substitution is a task of determining a meaning-preserving replacement
for a word in context. We report on a preliminary study of this task for the
Croatian language on a small-scale lexical sample dataset, manually annotated
using three different annotation schemes. We compare the annotations, analyze
the inter-annotator agreement, and observe a number of interesting language
specific details in the obtained lexical substitutes. Furthermore, we apply a
recently-proposed, dependency-based lexical substitution model to our dataset.
The model achieves a P$@$3 score of 0.35, which indicates the difficulty of the
task.},
 address = {Valencia, Spain},
 author = {Alagi\'{c}, Domagoj and \v{S}najder, Jan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1403},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {14--19},
 publisher = {Association for Computational Linguistics},
 title = {A Preliminary Study of Croatian Lexical Substitution},
 year = {2017}
}

@inproceedings{W17-1404,
 abstract = {Multiword expressions (MWEs) are linguistic objects containing two or more
words and showing idiosyncratic behavior at different levels. Treebanks with
annotated MWEs enable studies of such properties, as well as training and
evaluation of MWE-aware parsers. However, few treebanks contain full-fledged
MWE annotations. We show how this gap can be bridged in Polish by projecting 3
MWE resources on a constituency treebank.},
 address = {Valencia, Spain},
 author = {Savary, Agata and Waszczuk, Jakub},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1404},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {20--26},
 publisher = {Association for Computational Linguistics},
 title = {Projecting Multiword Expression Resources on a Polish Treebank},
 year = {2017}
}

@inproceedings{W17-1405,
 abstract = {This paper reports on challenges and results in developing NLP resources for
spoken Rusyn. Being a Slavic minority language, Rusyn does not have any
resources to make use of. We propose to build a morphosyntactic dictionary for
Rusyn, combining existing resources from the etymologically close Slavic
languages Russian, Ukrainian, Slovak, and Polish. We adapt these resources to
Rusyn by using vowel-sensitive Levenshtein distance, hand-written
language-specific transformation rules, and combinations of the two. Compared
to an exact match baseline, we increase the coverage of the resulting
morphological dictionary by up to 77.4% relative (42.9% absolute), which
results in a tagging recall increased by 11.6% relative (9.1% absolute). Our
research confirms and expands the results of previous studies showing the
efficiency of using NLP resources from neighboring languages for low-resourced
languages.},
 address = {Valencia, Spain},
 author = {Rabus, Achim and Scherrer, Yves},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1405},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {27--32},
 publisher = {Association for Computational Linguistics},
 title = {Lexicon Induction for Spoken Rusyn -- Challenges and Results},
 year = {2017}
}

@inproceedings{W17-1406,
 abstract = {This paper introduces the Universal Dependencies Treebank for Slovenian. We
overview the existing dependency treebanks for Slovenian and then detail the
conversion of the ssj200k treebank to the framework of Universal Dependencies
version 2. We explain the mapping of part-of-speech categories, morphosyntactic
features, and the dependency relations, focusing on the more problematic
language-specific issues. We conclude with a quantitative overview of the
treebank and directions for further work.},
 address = {Valencia, Spain},
 author = {Dobrovoljc, Kaja and Erjavec, Toma\v{z} and Krek, Simon},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1406},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {33--38},
 publisher = {Association for Computational Linguistics},
 title = {The Universal Dependencies Treebank for Slovenian},
 year = {2017}
}

@inproceedings{W17-1407,
 abstract = {The paper documents the procedure of building a new Universal Dependencies
(UDv2) treebank for Serbian starting from an existing Croatian UDv1 treebank
and taking into account the other Slavic UD annotation guidelines. We describe
the automatic and manual annotation procedures, discuss the annotation of
Slavic-specific categories (case governing quantifiers, reflexive pronouns, question particles) and propose an approach to handling deverbal nouns in
Slavic languages.},
 address = {Valencia, Spain},
 author = {Samard\v{z}i\'{c}, Tanja and Starovi\'{c}, Mirjana and Agi\'{c}, \v{Z}eljko and Ljube\v{s}i\'{c}, Nikola},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1407},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {39--44},
 publisher = {Association for Computational Linguistics},
 title = {Universal Dependencies for Serbian in Comparison with Croatian and Other Slavic Languages},
 year = {2017}
}

@inproceedings{W17-1408,
 abstract = {We present an algorithm for automatic correction of spelling errors on the
sentence level, which uses noisy channel model and feature-based reranking of
hypotheses. Our system is designed for Russian and clearly outperforms the
winner of SpellRuEval-2016 competition. We show that language model size has
the greatest influence on spelling correction quality. We also experiment with
different types of features and show that morphological and semantic
information also improves the accuracy of spellchecking.},
 address = {Valencia, Spain},
 author = {Sorokin, Alexey},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1408},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {45--53},
 publisher = {Association for Computational Linguistics},
 title = {Spelling Correction for Morphologically Rich Language: a Case Study of Russian},
 year = {2017}
}

@inproceedings{W17-1409,
 abstract = {Sentiment lexicons are widely used as an intuitive and inexpensive way of
tackling sentiment classification, often within a simple lexicon word-counting
approach or as part of a  supervised model.  However, it is an open question
whether these approaches can compete with supervised models that use only
word-representation features.  We address this question in the context of
domain-specific sentiment classification for Croatian. We experiment with the
graph-based acquisition of sentiment lexicons, analyze their quality, and
investigate how effectively they can be used in sentiment classification.  Our
results indicate that, even with as few as 500 labeled instances, a supervised
model substantially outperforms a word-counting model. We also observe that
adding lexicon-based features does not significantly improve supervised
sentiment classification.},
 address = {Valencia, Spain},
 author = {Gombar, Paula and Medi\'{c}, Zoran and Alagi\'{c}, Domagoj and \v{S}najder, Jan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1409},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {54--59},
 publisher = {Association for Computational Linguistics},
 title = {Debunking Sentiment Lexicons: A Case of Domain-Specific Sentiment Classification for Croatian},
 year = {2017}
}

@inproceedings{W17-1410,
 abstract = {In this paper we present the adaptations of a state-of-the-art tagger for South
Slavic languages to non-standard texts on the example of the Slovene language.
We investigate the impact of introducing in-domain training data as well as
additional supervision through external resources or tools like word clusters
and word normalization. We remove more than half of the error of the standard
tagger when applied to non-standard texts by training it on a combination of
standard and non-standard training data, while enriching the data
representation with external resources removes additional 11 percent of the
error. The final configuration achieves tagging accuracy of 87.41% on the full
morphosyntactic description, which is, nevertheless, still quite far from the
accuracy of 94.27% achieved on standard text.},
 address = {Valencia, Spain},
 author = {Ljube\v{s}i\'{c}, Nikola and Erjavec, Toma\v{z} and Fi\v{s}er, Darja},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1410},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {60--68},
 publisher = {Association for Computational Linguistics},
 title = {Adapting a State-of-the-Art Tagger for South Slavic Languages to Non-Standard Text},
 year = {2017}
}

@inproceedings{W17-1411,
 abstract = {We focus on the task of supervised sentiment classification of short and
informal texts in Croatian, using two simple yet effective methods: word
embeddings and string kernels. We investigate whether word embeddings offer any
advantage over corpus- and preprocessing-free string kernels, and how these
compare to bag-of-words baselines. We conduct a comparison on three different
datasets, using different preprocessing methods and kernel functions. Results
show that, on two out of three datasets, word embeddings outperform string
kernels, which in turn outperform word and n-gram bag-of-words baselines.},
 address = {Valencia, Spain},
 author = {Rotim, Leon and \v{S}najder, Jan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1411},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {69--75},
 publisher = {Association for Computational Linguistics},
 title = {Comparison of Short-Text Sentiment Analysis Methods for Croatian},
 year = {2017}
}

@inproceedings{W17-1412,
 abstract = {This paper describes the outcomes of the first challenge on multilingual named
entity recognition that aimed at recognizing mentions of named entities in web
documents in Slavic languages, their normalization/lemmatization, and
cross-language matching. It was organised in the context of the 6th
Balto-Slavic Natural Language Processing Workshop, co-located with the EACL
2017 conference. Although eleven teams signed up for the evaluation, due to the
complexity of the task(s) and short time available for elaborating a solution, only two teams submitted results on time. The reported evaluation figures
reflect the relatively higher level of complexity of named entity-related tasks
in the context of processing texts in Slavic languages. Since the duration of
the challenge goes beyond the date of the publication of this paper and updated
picture of the participating systems and their corresponding performance can be
found on the web page of the challenge.},
 address = {Valencia, Spain},
 author = {Piskorski, Jakub and Pivovarova, Lidia and \v{S}najder, Jan and Steinberger, Josef and Yangarber, Roman},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1412},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {76--85},
 publisher = {Association for Computational Linguistics},
 title = {The First Cross-Lingual Challenge on Recognition, Normalization, and Matching of Named Entities in Slavic Languages},
 year = {2017}
}

@inproceedings{W17-1413,
 abstract = {In the paper we present an adaptation of Liner2 framework to solve the BSNLP
2017 shared task on multilingual named entity recognition. The tool is tuned to
recognize and lemmatize named entities for Polish.},
 address = {Valencia, Spain},
 author = {Marci\'{n}czuk, Micha{\l} and Koco\'{n}, Jan and Oleksy, Marcin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1413},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {86--91},
 publisher = {Association for Computational Linguistics},
 title = {Liner2 {\^a} a Generic Framework for Named Entity Recognition},
 year = {2017}
}

@inproceedings{W17-1414,
 abstract = {The 2017 shared task at the Balto-Slavic NLP workshop requires identifying
coarse-grained named entities in seven languages, identifying each entity{\^a}s
base form, and clustering name mentions across the multilingual set of
documents. The fact that no training data is provided to systems for building
supervised classifiers further adds to the complexity. To complete the task we
first use publicly available parallel texts to project named entity recognition
capability from English to each evaluation language. We ignore entirely the
subtask of identifying non-inflected forms of names. Finally, we create
cross-document entity identifiers by clustering named mentions using a
procedure-based approach.},
 address = {Valencia, Spain},
 author = {Mayfield, James and McNamee, Paul and Costello, Cash},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1414},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {92--96},
 publisher = {Association for Computational Linguistics},
 title = {Language-Independent Named Entity Analysis Using Parallel Projection and Rule-Based Disambiguation},
 year = {2017}
}

@inproceedings{W17-1415,
 abstract = {In this paper we address the problem of filtering obscene lexis in Russian
texts. We use string similarity measures to find words similar or identical to
words from a stop list and establish both a test collection and a baseline for
the task. Our experiments show that a novel string similarity measure based on
the notion of an annotated suffix tree outperforms some of the other well known
measures.},
 address = {Valencia, Spain},
 author = {Chernyak, Ekaterina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1415},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {97--101},
 publisher = {Association for Computational Linguistics},
 title = {Comparison of String Similarity Measures for Obscenity Filtering},
 year = {2017}
}

@inproceedings{W17-1416,
 abstract = {Relation between gender and language has been studied by many authors, however, there is still some uncertainty left regarding gender influence on language
usage in the professional environment. Often, the studied data sets are too
small or texts of individual authors are too short in order to capture
differences of language usage wrt gender successfully. This study draws from a
larger corpus of speeches transcripts of the Lithuanian Parliament (1990-2013)
to explore language differences of political debates by gender via stylometric
analysis. Experimental set up consists of stylistic features that indicate
lexical style and do not require external linguistic tools, namely the most
frequent words, in combination with unsupervised machine learning algorithms.
Results show that gender differences in the language use remain in professional
environment not only in usage of function words, preferred linguistic
constructions, but in the presented topics as well.},
 address = {Valencia, Spain},
 author = {Mandravickaite, Justina and Krilavi\v{c}ius, Tomas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1416},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {102--107},
 publisher = {Association for Computational Linguistics},
 title = {Stylometric Analysis of Parliamentary Speeches: Gender Dimension},
 year = {2017}
}

@inproceedings{W17-1417,
 abstract = {This work deals with ontology learning from unstructured Russian text. We
implement one of components Never Ending Language Learner and introduce the
algorithm extensions aimed to gather specificity of morphologicaly rich
free-word-order language. We demonstrate that this method may be successfully
applied to Russian data. In addition we perform several additional experiments
comparing different settings of the training process. We demonstrate that
utilizing of morphological features significantly improves the system precision
while using of seed patterns helps to improve the coverage.},
 address = {Valencia, Spain},
 author = {Buraya, Kseniya and Pivovarova, Lidia and Budkov, Sergey and Filchenkov, Andrey},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1417},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {108--118},
 publisher = {Association for Computational Linguistics},
 title = {Towards Never Ending Language Learning for Morphologically Rich Languages},
 year = {2017}
}

@inproceedings{W17-1418,
 abstract = {We present results of the first gender classification experiments on Slovene
text to our knowledge. Inspired by the TwiSty corpus and experiments (Verhoeven
et al., 2016), we employed the Janes corpus (Erjavec et al., 2016) and its
gender annotations to perform gender classification experiments on Twitter text
comparing a token-based and a lemma-based approach. We find that the
token-based approach (92.6% accuracy), containing gender markings related to
the author, outperforms the lemma-based approach by about 5%. Especially in the
lemmatized version, we also observe stylistic and content-based differences in
writing between men (e.g. more profane language, numerals and beer mentions)
and women (e.g. more pronouns, emoticons and character flooding). Many of our
findings corroborate previous research on other languages.},
 address = {Valencia, Spain},
 author = {Verhoeven, Ben and \v{S}krjanec, Iza and Pollak, Senja},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1418},
 booktitle = {Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing},
 month = {April},
 pages = {119--125},
 publisher = {Association for Computational Linguistics},
 title = {Gender Profiling for Slovene Twitter communication: the Influence of Gender Marking, Content and Style},
 year = {2017}
}

@inproceedings{W17-1501,
 abstract = {Only a year ago, all state-of-the-art coreference resolvers were using an
extensive amount of surface features. Recently, there was a paradigm shift
towards using word embeddings and deep neural networks, where the use of
surface features is very limited. In this paper, we show that a simple SVM
model with surface features outperforms more complex neural models for
detecting anaphoric mentions. Our analysis suggests that using generalized
representations and surface features have different strength that should be
both taken into account for improving coreference resolution.},
 address = {Valencia, Spain},
 author = {Moosavi, Nafise Sadat and Strube, Michael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1501},
 booktitle = {Proceedings of the 2nd Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2017)},
 month = {April},
 pages = {1--7},
 publisher = {Association for Computational Linguistics},
 title = {Use Generalized Representations, But Do Not Forget Surface Features},
 year = {2017}
}

@inproceedings{W17-1502,
 abstract = {In this paper we present a Basque coreference resolution system enriched with
semantic knowledge. An error analysis carried out revealed the deficiencies
that the system had in resolving coreference cases in which semantic or world
knowledge is needed. We attempt to improve the deficiencies using two semantic
knowledge sources, specifically Wikipedia and WordNet.},
 address = {Valencia, Spain},
 author = {Soraluze, Ander and Arregi, Olatz and Arregi, Xabier and D\'{i}az de Ilarraza, Arantza},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1502},
 booktitle = {Proceedings of the 2nd Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2017)},
 month = {April},
 pages = {8--16},
 publisher = {Association for Computational Linguistics},
 title = {Enriching Basque Coreference Resolution System using Semantic Knowledge sources},
 year = {2017}
}

@inproceedings{W17-1503,
 abstract = {This paper presents results of an experiment integrating information from
valency dictionary of Polish into a mention detection system. Two types of
information is acquired: positions of syntactic schemata for nominal and verbal
constructs and secondary prepositions present in schemata. The syntactic
schemata are used to prevent (for verbal realizations) or encourage (for
nominal groups) constructing mentions from phrases filling multiple schema
positions, the secondary prepositions -- to filter out artificial mentions
created from their nominal components. Mention detection is evaluated against
the manual annotation of the Polish Coreference Corpus in two settings: taking
into account only mention heads or exact borders.},
 address = {Valencia, Spain},
 author = {Ogrodniczuk, Maciej and Nito\'{n}, Bart{\l}omiej},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1503},
 booktitle = {Proceedings of the 2nd Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2017)},
 month = {April},
 pages = {17--23},
 publisher = {Association for Computational Linguistics},
 title = {Improving Polish Mention Detection with Valency Dictionary},
 year = {2017}
}

@inproceedings{W17-1504,
 abstract = {This article presents the first collection of French Winograd Schemas. Winograd
Schemas form anaphora resolution problems that can only be resolved with
extensive world knowledge. For this reason the Winograd Schema Challenge has
been proposed as an alternative to the Turing Test. A very important feature of
Winograd Schemas is that it should be impossible to resolve them with
statistical information about word co-occurrences: they should be Google-proof.
We propose a measure of Google-proofness based on  Mutual Information, and
demonstrate the method on our collection of French Winograd Schemas.},
 address = {Valencia, Spain},
 author = {Amsili, Pascal and Seminck, Olga},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1504},
 booktitle = {Proceedings of the 2nd Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2017)},
 month = {April},
 pages = {24--29},
 publisher = {Association for Computational Linguistics},
 title = {A Google-Proof Collection of French Winograd Schemas},
 year = {2017}
}

@inproceedings{W17-1505,
 abstract = {In this paper, we present a proof-of-concept implementation of a
coreference-aware decoder for document-level machine translation.  We consider
that better translations should have coreference links that are closer to those
in the source text, and implement this criterion in two ways.  First, we define
a similarity measure between source and target coreference structures, by
projecting the target ones onto the source and reusing existing coreference
metrics.  Based on this similarity measure, we re-rank the translation
hypotheses of a baseline system for each sentence.  Alternatively, to address
the lack of diversity of mentions in the MT hypotheses, we focus on mention
pairs and integrate their coreference scores with MT ones, resulting in
post-editing decisions for mentions. The experimental results for Spanish to
English MT on the AnCora-ES corpus show that the second approach yields a
substantial increase in the accuracy of pronoun translation, with BLEU scores
remaining constant.},
 address = {Valencia, Spain},
 author = {Miculicich Werlen, Lesly and Popescu-Belis, Andrei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1505},
 booktitle = {Proceedings of the 2nd Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2017)},
 month = {April},
 pages = {30--40},
 publisher = {Association for Computational Linguistics},
 title = {Using Coreference Links to Improve Spanish-to-English Machine Translation},
 year = {2017}
}

@inproceedings{W17-1506,
 abstract = {In this paper, we examine the possibility of using annotation projection from
multiple sources for automatically obtaining coreference annotations in the
target language. We implement a multi-source annotation projection algorithm
and apply it on an English-German-Russian parallel corpus in order to transfer
coreference chains from two sources to the target side. Operating in two
settings -- a low-resource and a more linguistically-informed one -- we show
that automatic coreference transfer
could benefit from combining information from multiple languages, and assess
the quality of both the extraction and the linking of target coreference
mentions.},
 address = {Valencia, Spain},
 author = {Grishina, Yulia and Stede, Manfred},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1506},
 booktitle = {Proceedings of the 2nd Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2017)},
 month = {April},
 pages = {41--50},
 publisher = {Association for Computational Linguistics},
 title = {Multi-source annotation projection of coreference chains: assessing strategies and testing opportunities},
 year = {2017}
}

@inproceedings{W17-1507,
 abstract = {The CORBON 2017 Shared Task, organised as part of the Coreference Resolution
Beyond OntoNotes workshop at EACL 2017, presented a new challenge for
multilingual coreference resolution: we offer a projection-based setting in
which one is supposed to build a coreference resolver for a new language
exploiting little or even no knowledge of it, with our languages of interest
being German and Russian. We additionally offer a more traditional setting, targeting the development of a multilingual coreference resolver without any
restrictions on the resources and methods used. In this paper, we describe the
task setting and provide the results of one participant who successfully
completed the task, comparing their results to the closely related previous
research. Analysing the task setting and the results, we discuss the major
challenges and make suggestions on the future directions of coreference
evaluation.},
 address = {Valencia, Spain},
 author = {Grishina, Yulia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1507},
 booktitle = {Proceedings of the 2nd Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2017)},
 month = {April},
 pages = {51--55},
 publisher = {Association for Computational Linguistics},
 title = {CORBON 2017 Shared Task: Projection-Based Coreference Resolution},
 year = {2017}
}

@inproceedings{W17-1508,
 abstract = {The paper describes the system for coreference resolution in German and
Russian, trained exclusively on coreference relations project
ed through a parallel corpus from English.
The resolver operates on the level of deep syntax and makes use of multiple
specialized models.
It achieves 32 and 22 points in terms of CoNLL score for Russian and German, respectively.
Analysis of the evaluation results show that the resolver for Russian is able
to preserve 66% of the English resolver's quality in terms of CoNLL score.
The system was submitted to the Closed track of the CORBON 2017 Shared task.},
 address = {Valencia, Spain},
 author = {Nov\'{a}k, Michal and Nedoluzhko, Anna and \v{Z}abokrtsk\'{y}, Zden{\"A}k},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1508},
 booktitle = {Proceedings of the 2nd Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2017)},
 month = {April},
 pages = {56--64},
 publisher = {Association for Computational Linguistics},
 title = {Projection-based Coreference Resolution Using Deep Syntax},
 year = {2017}
}

@inproceedings{W17-1601,
 abstract = {Researchers and practitioners in natural-language processing (NLP) and related
fields should attend to ethical principles in study design, ascription of
categories/variables to study participants, and reporting of findings or
results. This paper discusses theoretical and ethical frameworks for using
gender as a variable in NLP studies and proposes four guidelines for
researchers and practitioners. The principles outlined here should guide
practitioners, researchers, and peer reviewers, and they may be applicable to
other social categories, such as race, applied to human beings connected to NLP
research.},
 address = {Valencia, Spain},
 author = {Larson, Brian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1601},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {1--11},
 publisher = {Association for Computational Linguistics},
 title = {Gender as a Variable in Natural-Language Processing: Ethical Considerations},
 year = {2017}
}

@inproceedings{W17-1602,
 abstract = {Stylometric and text categorization results show that author gender can be
discerned in texts with relatively high accuracy. However, it is difficult to
explain what gives rise to these results and there are many possible
confounding factors, such as the domain, genre, and target audience of a text.
More fundamentally, such classification efforts risk invoking stereotyping and
essentialism. We explore this issue in two datasets of Dutch literary novels, using commonly used descriptive (LIWC, topic modeling) and predictive (machine
learning) methods. Our results show the importance of controlling for variables
in the corpus and we argue for taking care not to overgeneralize from the
results.},
 address = {Valencia, Spain},
 author = {Koolen, Corina and van Cranenburgh, Andreas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1602},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {12--22},
 publisher = {Association for Computational Linguistics},
 title = {These are not the Stereotypes You are Looking For: Bias and Fairness in Authorial Gender Attribution},
 year = {2017}
}

@inproceedings{W17-1603,
 abstract = {We present results on a quantitative analysis of publications in the NLP domain
on collecting, publishing and availability of research data. We find that a
wide range of publications rely on data crawled from the web, but few give
details on how potentially sensitive data was treated. Additionally, we find
that while links to repositories of data are given, they often do not work even
a short time after publication. We put together several suggestions on how to
improve this situation based on publications from the NLP domain, but also
other research areas.},
 address = {Valencia, Spain},
 author = {Mieskes, Margot},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1603},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {23--29},
 publisher = {Association for Computational Linguistics},
 title = {A Quantitative Study of Data in the NLP community},
 year = {2017}
}

@inproceedings{W17-1604,
 abstract = {Natural language processing (NLP) systems analyze and/or generate human
language, typically on users{\^a} behalf. One natural and necessary question that
needs to be addressed in this context, both in research projects and in
production settings, is the question how ethical the work is, both regarding
the process and its outcome.
Towards this end, we articulate a set of issues, propose a set of best
practices, notably a process featuring an ethics review board, and sketch and
how they could be meaningfully applied. Our main argument is that ethical
outcomes ought to be achieved by design, i.e. by following a process aligned
by ethical values. We also offer some response options for those facing ethics
issues.
While a number of previous works exist that discuss ethical issues, in
particular around big data and machine learning, to the authors{\^a} knowledge
this is the first account of NLP and ethics from the perspective of a
principled process.},
 address = {Valencia, Spain},
 author = {Leidner, Jochen L. and Plachouras, Vassilis},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1604},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {30--40},
 publisher = {Association for Computational Linguistics},
 title = {Ethical by Design: Ethics Best Practices for Natural Language Processing},
 year = {2017}
}

@inproceedings{W17-1605,
 abstract = {Automated scoring of written and spoken responses is an NLP application that
can significantly impact lives especially when deployed as part of high-stakes
tests such as the GRE\textregistered~ and the TOEFL\textregistered~. Ethical considerations require that
automated scoring algorithms treat all test- takers fairly. The educational
measurement community has done significant research on fairness in assessments
and automated scoring systems must incorporate their recommendations. The best
way to do that is by making available automated, non-proprietary tools to NLP
researchers that directly incorporate these recommendations and generate the
analyses needed to help identify and resolve biases in their scoring systems.
In this paper, we attempt to provide such a solution.},
 address = {Valencia, Spain},
 author = {Madnani, Nitin and Loukina, Anastassia and von Davier, Alina and Burstein, Jill and Cahill, Aoife},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1605},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {41--52},
 publisher = {Association for Computational Linguistics},
 title = {Building Better Open-Source Tools to Support Fairness in Automated Scoring},
 year = {2017}
}

@inproceedings{W17-1606,
 abstract = {This project evaluates the accuracy of YouTube's automatically-generated
captions across two genders and five dialect groups. Speakers' dialect and
gender was controlled for by using videos uploaded as part of the ``accent tag
challenge", where speakers explicitly identify their language background. The
results show robust differences in accuracy across both gender and dialect, with lower accuracy for 1) women and 2) speakers from Scotland. This finding
builds on earlier research finding that speaker's sociolinguistic identity may
negatively impact their ability to use automatic speech recognition, and
demonstrates the need for sociolinguistically-stratified validation of systems.},
 address = {Valencia, Spain},
 author = {Tatman, Rachael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1606},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {53--59},
 publisher = {Association for Computational Linguistics},
 title = {Gender and Dialect Bias in YouTube's Automatic Captions},
 year = {2017}
}

@inproceedings{W17-1607,
 abstract = {We examine the impact of the EU General
Data Protection Regulation and the push
from research funders to provide open access
research data on the current practices
in Language Technology Research.
We analyse the challenges that arise and
the opportunities to address many of them
through the use of existing open data practices.
We discuss the impact of this also on
current practice in research ethics.},
 address = {Valencia, Spain},
 author = {Lewis, Dave and Moorkens, Joss and Fatema, Kaniz},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1607},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {60--65},
 publisher = {Association for Computational Linguistics},
 title = {Integrating the Management of Personal Data Protection and Open Science with Research Ethics},
 year = {2017}
}

@inproceedings{W17-1608,
 abstract = {Shared tasks are increasingly common in our field, and new challenges are
suggested at almost every conference and  workshop. However, as this has become
an established way of pushing research forward, it is important to discuss how
we researchers organise and participate in shared tasks, and make that
information available to the  community to allow further research improvements.
In this paper, we present a number of ethical issues along with other areas of
concern that are related to the competitive nature of shared tasks. As such
issues could potentially impact on research ethics in the Natural Language
Processing community, we also propose the development of a framework for the
organisation of and participation in shared tasks that can help mitigate
against these issues arising.},
 address = {Valencia, Spain},
 author = {Parra Escart\'{i}n, Carla and Reijers, Wessel and Lynn, Teresa and Moorkens, Joss and Way, Andy and Liu, Chao-Hong},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1608},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {66--73},
 publisher = {Association for Computational Linguistics},
 title = {Ethical Considerations in NLP Shared Tasks},
 year = {2017}
}

@inproceedings{W17-1609,
 abstract = {We analyze the Stanford Natural Language Inference (SNLI) corpus in an
investigation of bias and stereotyping in NLP data. The SNLI human-elicitation
protocol makes it prone to amplifying bias and stereotypical associations, which we demonstrate statistically (using pointwise mutual information) and
with qualitative examples.},
 address = {Valencia, Spain},
 author = {Rudinger, Rachel and May, Chandler and Van Durme, Benjamin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1609},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {74--79},
 publisher = {Association for Computational Linguistics},
 title = {Social Bias in Elicited Natural Language Inferences},
 year = {2017}
}

@inproceedings{W17-1610,
 abstract = {Clinical NLP has an immense potential in contributing to how clinical practice
will be revolutionized by the advent of large scale processing of clinical
records. However, this potential has remained largely untapped due to slow
progress primarily caused by strict data access policies for researchers. In
this paper, we discuss the concern for privacy and the measures it entails. We
also suggest sources of less sensitive data. Finally, we draw attention to
biases that can compromise the validity of empirical research and lead to
socially harmful applications.},
 address = {Valencia, Spain},
 author = {Suster, Simon and Tulkens, Stephan and Daelemans, Walter},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1610},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {80--87},
 publisher = {Association for Computational Linguistics},
 title = {A Short Review of Ethical Challenges in Clinical Natural Language Processing},
 year = {2017}
}

@inproceedings{W17-1611,
 abstract = {The argument made in this paper is that to act ethically in machine learning
and NLP requires focusing on goals. NLP projects are often classificatory
systems that deal with human subjects, which means that goals from people
affected by the systems should be included. The paper takes as its core example
a model that detects criminality, showing the problems of training data, categories, and outcomes. The paper is oriented to the kinds of critiques on
power and the reproduction of inequality that are found in social theory, but
it also includes concrete suggestions on how to put goal-oriented design into
practice.},
 address = {Valencia, Spain},
 author = {Schnoebelen, Tyler},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1611},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {88--93},
 publisher = {Association for Computational Linguistics},
 title = {Goal-Oriented Design for Ethical Machine Learning and NLP},
 year = {2017}
}

@inproceedings{W17-1612,
 abstract = {Social media have transformed data-driven research in political science, the
social sciences, health, and medicine. Since health research often touches on
sensitive topics that relate to ethics of treatment and patient privacy, similar ethical considerations should be acknowledged when using social media
data in health research.  While much has been said regarding the ethical
considerations of social media research, health research leads to an additional
set of concerns.  We provide practical suggestions in the form of guidelines
for researchers working with social media data in health research.  These
guidelines can inform an IRB proposal for researchers new to social media
health research.},
 address = {Valencia, Spain},
 author = {Benton, Adrian and Coppersmith, Glen and Dredze, Mark},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1612},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {94--102},
 publisher = {Association for Computational Linguistics},
 title = {Ethical Research Protocols for Social Media Health Research},
 year = {2017}
}

@inproceedings{W17-1613,
 abstract = {We discuss the ethical implications of Natural Language Generation systems.
We use one particular system as a case study to identify and classify issues, and we provide an ethics checklist, in the hope that future system designers
may benefit from conducting their own ethics reviews based on our checklist.},
 address = {Valencia, Spain},
 author = {Smiley, Charese and Schilder, Frank and Plachouras, Vassilis and Leidner, Jochen L.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1613},
 booktitle = {Proceedings of the First ACL Workshop on Ethics in Natural Language Processing},
 month = {April},
 pages = {103--108},
 publisher = {Association for Computational Linguistics},
 title = {Say the Right Thing Right: Ethics Issues in Natural Language Generation Systems},
 year = {2017}
}

@inproceedings{W17-1701,
 abstract = {We present a new freely available dictionary of paraphrases of Czech complex
predicates with light verbs, ParaDi. Candidates for single predicative
paraphrases of selected complex predicates have been extracted automatically
from large monolingual data using word2vec. They have been manually verified
and further refined. We demonstrate one of many possible applications of ParaDi
in an experiment with improving machine translation quality.},
 address = {Valencia, Spain},
 author = {Barancikova, Petra and Kettnerov\'{a}, V\'{a}clava},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1701},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {ParaDi: Dictionary of Paraphrases of Czech Complex Predicates with Light Verbs},
 year = {2017}
}

@inproceedings{W17-1702,
 abstract = {This paper describes an approach for the classification of millions of existing
multi-word entities (MWEntities), such as organisation or event names, into
thirteen category types, based only on the tokens they contain.
In order to classify our very large in-house collection of multilingual
MWEntities into an application-oriented set of entity categories, we trained
and tested distantly-supervised classifiers in 43 languages based on MWEntities
extracted from BabelNet. The best-performing classifier was the multi-class SVM
using a TF.IDF-weighted data representation. Interestingly, one unique
classifier trained on a mix of all languages consistently performed better than
classifiers trained for individual languages, reaching an averaged F1-value of
88.8%. In this paper, we present the training and test data, including a human
evaluation of its accuracy, describe the methods used to train the classifiers, and discuss the results.},
 address = {Valencia, Spain},
 author = {Chesney, Sophie and Jacquet, Guillaume and Steinberger, Ralf and Piskorski, Jakub},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1702},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {11--20},
 publisher = {Association for Computational Linguistics},
 title = {Multi-word Entity Classification in a Highly Multilingual Environment},
 year = {2017}
}

@inproceedings{W17-1703,
 abstract = {This paper presents a new strategy for multilingual collocation extraction
which takes advantage of parallel corpora to learn bilingual word-embeddings.
Monolingual collocation candidates are retrieved using Universal Dependencies, while the distributional models are then applied to search for equivalents of
the elements of each collocation in the target languages. The proposed method
extracts not only collocation equivalents with direct translation between
languages, but also other cases where the collocations in the two languages are
not literal translations of each other.
Several experiments -evaluating collocations with three syntactic patterns- in
English, Spanish, and Portuguese show that our approach can effectively extract
large pairs of bilingual equivalents with an average precision of about 90%.
Moreover, preliminary results on comparable corpora suggest that the
distributional models can be applied for identifying new bilingual collocations
in different domains.},
 address = {Valencia, Spain},
 author = {Garcia, Marcos and Garc\'{i}a-Salido, Marcos and Alonso-Ramos, Margarita},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1703},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {21--30},
 publisher = {Association for Computational Linguistics},
 title = {Using bilingual word-embeddings for multilingual collocation extraction},
 year = {2017}
}

@inproceedings{W17-1704,
 abstract = {Multiword expressions (MWEs) are
known as a {\^a}pain in the neck{\^a} for NLP
due to their idiosyncratic behaviour.
While some categories of MWEs have
been addressed by many studies, verbal
MWEs (VMWEs), such as to take a
decision, to break one{\^a}s heart or to turn
off, have been rarely modelled. This is
notably due to their syntactic variability, which hinders treating them as {\^a}words
with spaces{\^a}. We describe an initiative
meant to bring about substantial progress
in understanding, modelling and process-
ing VMWEs. It is a joint effort, carried
out within a European research network, to elaborate universal terminologies and
annotation guidelines for 18 languages. Its
main outcome is a multilingual 5-million-
word annotated corpus which underlies a
shared task on automatic identification of
VMWEs. This paper presents the corpus
annotation methodology and outcome, the
shared task organisation and the results of
the participating systems.},
 address = {Valencia, Spain},
 author = {Savary, Agata and Ramisch, Carlos and Cordeiro, Silvio and Sangati, Federico and Vincze, Veronika and QasemiZadeh, Behrang and Candito, Marie and Cap, Fabienne and Giouli, Voula and Stoyanova, Ivelina and Doucet, Antoine},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1704},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {31--47},
 publisher = {Association for Computational Linguistics},
 title = {The PARSEME Shared Task on Automatic Identification of Verbal Multiword Expressions},
 year = {2017}
}

@inproceedings{W17-1705,
 abstract = {The paper describes our system submitted for the Workshop on Multiword
Expressions{\^a} shared task on automatic identification of verbal multiword
expressions. It uses POS tagging and dependency parsing to identify single- and
multi-token verbal MWEs in text. Our system is language independent and
competed on nine of the eighteen languages. Our paper describes how our system
works and gives its error analysis for the languages it was submitted for.},
 address = {Valencia, Spain},
 author = {Simk\'{o}, Katalin Ilona and Kov\'{a}cs, Vikt\'{o}ria and Vincze, Veronika},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1705},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {48--53},
 publisher = {Association for Computational Linguistics},
 title = {USzeged: Identifying Verbal Multiword Expressions with POS Tagging and Parsing Techniques},
 year = {2017}
}

@inproceedings{W17-1706,
 abstract = {Identifying multiword expressions (MWEs) in a sentence in order to ensure their
proper processing in subsequent applications, like machine translation, and
performing the syntactic analysis of the sentence are interrelated processes.
In our approach, priority is given to parsing alternatives involving
collocations, and hence collocational information helps the parser through the
maze of alternatives, with the aim to lead to substantial improvements in the
performance of both tasks (collocation identification and parsing), and in that
of a subsequent task (machine translation). In this paper, we are going to
present our system and the procedure that we have followed in order to
participate to the open track of the PARSEME shared task on automatic
identification of verbal multiword expressions (VMWEs) in running texts.},
 address = {Valencia, Spain},
 author = {Nerima, Luka and Foufi, Vasiliki and Wehrli, Eric},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1706},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {54--59},
 publisher = {Association for Computational Linguistics},
 title = {Parsing and MWE Detection: Fips at the PARSEME Shared Task},
 year = {2017}
}

@inproceedings{W17-1707,
 abstract = {In this paper we describe the MUMULS system that participated to the 2017
shared task on automatic identification of verbal multiword expressions
(VMWEs). The MUMULS system was implemented using a supervised approach based on
recurrent neural networks using the open source library TensorFlow. The model
was trained on a data set containing annotated VMWEs as well as morphological
and syntactic information. The MUMULS system performed the identification of
VMWEs in 15 languages, it was one of few systems that could categorize VMWEs
type in nearly all languages.},
 address = {Valencia, Spain},
 author = {Klyueva, Natalia and Doucet, Antoine and Straka, Milan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1707},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {60--65},
 publisher = {Association for Computational Linguistics},
 title = {Neural Networks for Multi-Word Expression Detection},
 year = {2017}
}

@inproceedings{W17-1708,
 abstract = {Ambiguity represents an obstacle for distributional semantic models(DSMs), which typically subsume the contexts of all word senses within one vector.
While individual vector space approaches have been concerned with sense
discrimination (e.g., Sch\"{u}tze 1998, Erk 2009, Erk and Pado 2010), such
discrimination has rarely been integrated into DSMs across semantic tasks. This
paper presents a soft-clustering approach to sense discrimination that filters
sense-irrelevant features when predicting the degrees of compositionality for
German noun-noun compounds and German particle verbs.},
 address = {Valencia, Spain},
 author = {Bott, Stefan and Schulte im Walde, Sabine},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1708},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {66--72},
 publisher = {Association for Computational Linguistics},
 title = {Factoring Ambiguity out of the Prediction of Compositionality for German Multi-Word Expressions},
 year = {2017}
}

@inproceedings{W17-1709,
 abstract = {Multiword expressions (MWEs) pose a problem for lexicalist theories like
Lexical Functional Grammar (LFG), since they are prima facie counterexamples to
a strong form of the lexical integrity principle, which entails that a lexical
item can only be realised as a single, syntactically atomic word. In this
paper, I demonstrate some of the problems facing any strongly lexicalist
account of MWEs, and argue that the lexical integrity principle must be
weakened. I conclude by sketching a formalism which integrates a Tree Adjoining
Grammar into the LFG architecture, taking advantage of this relaxation.},
 address = {Valencia, Spain},
 author = {Findlay, Jamie Y.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1709},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {73--79},
 publisher = {Association for Computational Linguistics},
 title = {Multiword expressions and lexicalism: the view from LFG},
 year = {2017}
}

@inproceedings{W17-1710,
 abstract = {This study investigates the processing of idiomatic variants through an
eye-tracking experiment. Four types of idiom variants were included, in
addition to the canonical form and the literal meaning. Results suggest that
modifications to idioms, modulo obvious effects of length differences, are not
more difficult to process than the canonical forms themselves. This fits with
recent corpus findings.},
 address = {Valencia, Spain},
 author = {Geeraert, Kristina and Baayen, R. Harald and Newman, John},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1710},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {80--90},
 publisher = {Association for Computational Linguistics},
 title = {Understanding Idiomatic Variation},
 year = {2017}
}

@inproceedings{W17-1711,
 abstract = {We propose a method for joint unsupervised discovery of multiword expressions
(MWEs) and their translations from parallel corpora. First, we apply
independent monolingual MWE extraction in source and target languages
simultaneously. Then, we calculate translation probability, association score
and distributional  similarity of co-occurring pairs. Finally, we rank all
translations of a given MWE using a linear combination of these features.
Preliminary experiments on light verb constructions show promising results.},
 address = {Valencia, Spain},
 author = {Vargas, Natalie and Ramisch, Carlos and Caseli, Helena},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1711},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {91--96},
 publisher = {Association for Computational Linguistics},
 title = {Discovering Light Verb Constructions and their Translations from Parallel Corpora without Word Alignment},
 year = {2017}
}

@inproceedings{W17-1712,
 abstract = {We discuss an experiment on automatic identification of bi-gram multi-word
expressions in parallel Latvian and Lithuanian corpora. Raw corpora, lexical
association measures (LAMs) and supervised machine learning (ML) are used due
to deficit and quality of lexical resources (e.g., POS-tagger, parser) and
tools. While combining LAMs with ML is rather effective for other languages, it
has shown some nice results for Lithuanian and Latvian as well. Combining LAMs
with ML we have achieved 92,4% precision and 52,2% recall for Latvian and 95,1%
precision and 77,8% recall for Lithuanian.},
 address = {Valencia, Spain},
 author = {Mandravickaite, Justina and Krilavi\v{c}ius, Tomas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1712},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {97--101},
 publisher = {Association for Computational Linguistics},
 title = {Identification of Multiword Expressions for Latvian and Lithuanian: Hybrid Approach},
 year = {2017}
}

@inproceedings{W17-1713,
 abstract = {We use word alignment variance as an indicator for the non-compositionality of
German and English noun compounds. Our work-in-progress results are on their
own not competitive with state-of-the art approaches, but they show that
alignment variance is correlated with compositionality and thus worth a
closer look in the future.},
 address = {Valencia, Spain},
 author = {Cap, Fabienne},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1713},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {102--107},
 publisher = {Association for Computational Linguistics},
 title = {Show Me Your Variance and I Tell You Who You Are - Deriving Compound Compositionality from Word Alignments},
 year = {2017}
}

@inproceedings{W17-1714,
 abstract = {Noun compounds (NCs) are semantically complex and not fully compositional, as
is often assumed. This paper presents a pilot study regarding the semantic
annotation of environmental NCs with a view to accessing their semantics and
exploring their domain-based contextual variation. Our results showed that the
semantic annotation of NCs afforded important insights into how context impacts
their conceptualization.},
 address = {Valencia, Spain},
 author = {Cabezas-Garc\'{i}a, Melania and San Mart\'{i}n, Antonio},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1714},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {108--113},
 publisher = {Association for Computational Linguistics},
 title = {Semantic annotation to characterize contextual variation in terminological noun compounds: a pilot study},
 year = {2017}
}

@inproceedings{W17-1715,
 abstract = {A description of a system for identifying Verbal Multi-Word Expressions (VMWEs)
in running text is presented. The system mainly exploits universal syntactic
dependency features through a Conditional Random Fields (CRF) sequence model.
The system competed in the Closed Track at the PARSEME VMWE Shared Task 2017, ranking 2nd place in most languages on full VMWE-based evaluation and 1st in
three languages on token-based evaluation. In addition, this paper presents an
option to re-rank the 10 best CRF-predicted sequences via semantic vectors, boosting its scores above other systems in the competition. We also show that
all systems in the competition would struggle to beat a simple lookup baseline
system and argue for a more purpose-specific evaluation scheme.},
 address = {Valencia, Spain},
 author = {Maldonado, Alfredo and Han, Lifeng and Moreau, Erwan and Alsulaimani, Ashjan and Chowdhury, Koel Dutta and Vogel, Carl and Liu, Qun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1715},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {114--120},
 publisher = {Association for Computational Linguistics},
 title = {Detection of Verbal Multi-Word Expressions via Conditional Random Fields with Syntactic Dependency Features and Semantic Re-Ranking},
 year = {2017}
}

@inproceedings{W17-1716,
 abstract = {"Multiword expressions" are groups of words acting as a morphologic, syntactic
and semantic unit in linguistic analysis. Verbal multiword expressions
represent the subgroup of multiword expressions, namely that in which a verb is
the syntactic head of the group considered in its canonical (or dictionary)
form. All multiword expressions are a great challenge for natural language
processing, but the verbal ones are particularly interesting for tasks such as
parsing, as the verb is the central element in the syntactic organization of a
sentence. In this paper we introduce our data-driven approach to verbal
multiword expressions which was objectively validated during the PARSEME shared
task on verbal multiword expressions identification. We tested our approach on
12 languages, and we provide detailed information about corpora composition, feature selection process, validation procedure and performance on all
languages.},
 address = {Valencia, Spain},
 author = {Boro\c{s}, Tiberiu and Pipa, Sonia and Barbu Mititelu, Verginica and Tufi\c{s}, Dan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1716},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {121--126},
 publisher = {Association for Computational Linguistics},
 title = {A data-driven approach to verbal multiword expression detection. PARSEME Shared Task system description paper},
 year = {2017}
}

@inproceedings{W17-1717,
 abstract = {We describe the ATILF-LLF system built for the MWE 2017 Shared Task on
automatic identification of verbal multiword expressions. We participated in
the closed track only, for all the 18 available languages. Our system is a
robust greedy transition-based system, in which MWE are identified through a
MERGE transition. The system was meant to accommodate the variety of linguistic
resources provided for each language, in terms of accompanying morphological
and syntactic information. Using per-MWE Fscore, the system was ranked first
for all but two languages (Hungarian and Romanian).},
 address = {Valencia, Spain},
 author = {Al Saied, Hazem and Constant, Matthieu and Candito, Marie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1717},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {127--132},
 publisher = {Association for Computational Linguistics},
 title = {The ATILF-LLF System for Parseme Shared Task: a Transition-based Verbal Multiword Expression Tagger},
 year = {2017}
}

@inproceedings{W17-1718,
 abstract = {This study investigates the supervised
token-based identification of Multiword
Expressions (MWEs). This is an ongoing
research to exploit the information contained
in the contexts in which different instances
of an expression could occur. This
information is used to investigate the question
of whether an expression is literal or
MWE. Lexical and syntactic context features
derived from vector representations
are shown to be more effective over traditional
statistical measures to identify tokens
of MWEs.},
 address = {Valencia, Spain},
 author = {Taslimipoor, Shiva and Rohanian, Omid and Mitkov, Ruslan and Fazly, Afsaneh},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1718},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {133--138},
 publisher = {Association for Computational Linguistics},
 title = {Investigating the Opacity of Verb-Noun Multiword Expression Usages in Context},
 year = {2017}
}

@inproceedings{W17-1719,
 abstract = {We are developing a broad-coverage deep semantic lexicon for a system that
parses sentences into a logical form expressed in a rich ontology that supports
reasoning. In this paper we look at verb-particle constructions (VPCs), and the
extent to which they can be treated compositionally vs idiomatically. First we
distinguish between the different types of VPCs based on their compositionality
and then present a set of heuristics for classifying specific instances as
compositional or not. We then identify a small set of general sense classes for
particles when used compositionally and discuss the resulting lexical
representations that are being added to the lexicon. By treating VPCs as
compositional whenever possible, we attain broad coverage in a compact way, and
also enable interpretations of novel VPC usages not explicitly present in the
lexicon.},
 address = {Valencia, Spain},
 author = {Bhatia, Archna and Teng, Choh Man and Allen, James},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1719},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {139--148},
 publisher = {Association for Computational Linguistics},
 title = {Compositionality in Verb-Particle Constructions},
 year = {2017}
}

@inproceedings{W17-1720,
 abstract = {This paper presents a method to improve the translation of Verb-Noun
Combinations (VNCs) in a rule-based Machine Translation (MT) system for
Spanish-Basque. Linguistic information about a set of VNCs is gathered from the
public database Konbitzul, and it is integrated into the MT system, leading to
an improvement in BLEU, NIST and TER scores, as well as the results being
evidently better according to human evaluators.},
 address = {Valencia, Spain},
 author = {I\~{n}urrieta, Uxoa and Aduriz, Itziar and Diaz de Ilarraza, Arantza and Labaka, Gorka and Sarasola, Kepa},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1720},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {149--154},
 publisher = {Association for Computational Linguistics},
 title = {Rule-Based Translation of Spanish Verb-Noun Combinations into Basque},
 year = {2017}
}

@inproceedings{W17-1721,
 abstract = {In this paper, we investigate the behavior of verb-particle constructions in
English questions. We present a small dataset that contains questions and
verb-particle
construction candidates. We demonstrate that there are significant differences
in the distribution of WH-words, verbs and prepositions/particles in sentences
that contain VPCs and sentences that contain only verb + prepositional phrase
combinations both by statistical means and in machine learning experiments.
Hence, VPCs and non-VPCs can be effectively separated from each other by using
a rich feature set, containing several novel features.},
 address = {Valencia, Spain},
 author = {Vincze, Veronika},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1721},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {155--160},
 publisher = {Association for Computational Linguistics},
 title = {Verb-Particle Constructions in Questions},
 year = {2017}
}

@inproceedings{W17-1722,
 abstract = {This paper presents a simple method for
German compound splitting that combines
a basic frequency-based approach with a
form-to-lemma mapping to approximate
morphological operations. With the exception
of a small set of hand-crafted rules
for modeling transitional elements, this
approach is resource-poor. In our evaluation, the simple splitter outperforms a splitter
relying on rich morphological resources.},
 address = {Valencia, Spain},
 author = {Weller-Di Marco, Marion},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1722},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {161--166},
 publisher = {Association for Computational Linguistics},
 title = {Simple Compound Splitting for German},
 year = {2017}
}

@inproceedings{W17-1723,
 abstract = {We present a simple and efficient tagger capable of identifying highly
ambiguous multiword expressions (MWEs) in French texts. It is based on
conditional random fields (CRF), using local context information as features.
We show that this approach can obtain results that, in some cases, approach
more sophisticated parser-based MWE identification methods without requiring
syntactic trees from a treebank. Moreover, we study how well the CRF can take
into account external information coming from a lexicon.},
 address = {Valencia, Spain},
 author = {Scholivet, Manon and Ramisch, Carlos},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1723},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {167--175},
 publisher = {Association for Computational Linguistics},
 title = {Identification of Ambiguous Multiword Expressions Using Sequence Models and Lexical Resources},
 year = {2017}
}

@inproceedings{W17-1724,
 abstract = {This paper aims at assessing to what extent a syntax-based method (Recurring
Lexico-syntactic Trees                                (RLT) extraction) allows us to
extract
large
phraseological units such as prefabricated routines, e.g. "as previously said"
or "as far as we/I know" in scientific writing.  In order to evaluate this
method, we compare it to the classical ngram extraction technique, on a subset
of recurring segments including speech verbs in a French corpus of scientific
writing. Results show that  the LRT extraction technique is far more efficient
for extended MWEs such as routines or collocations but performs more poorly for
surface phenomena such as syntactic constructions or fully frozen expressions.},
 address = {Valencia, Spain},
 author = {Tutin, Agn\`{e}s and Kraif, Olivier},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1724},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {176--180},
 publisher = {Association for Computational Linguistics},
 title = {Comparing Recurring Lexico-Syntactic Trees (RLTs) and Ngram Techniques for Extended Phraseology Extraction},
 year = {2017}
}

@inproceedings{W17-1725,
 abstract = {This article evaluates the extension of a dependency parser that performs joint
syntactic analysis and multiword expression identification. We show that, given
sufficient training data, the parser benefits from explicit multiword
information and improves overall labeled accuracy score in eight of the ten
evaluation cases.},
 address = {Valencia, Spain},
 author = {Constant, Matthieu and Mart\'{i}nez Alonso, H\'{e}ctor},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1725},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {181--186},
 publisher = {Association for Computational Linguistics},
 title = {Benchmarking Joint Lexical and Syntactic Analysis on Multiword-Rich Data},
 year = {2017}
}

@inproceedings{W17-1726,
 abstract = {This paper presents a methodology for identifying and resolving various kinds
of inconsistency in the context of merging dependency and multiword expression
(MWE) annotations, to generate a dependency treebank with comprehensive MWE
annotations. Candidates for correction are identified using a variety of
heuristics, including an entirely novel one which identifies violations of MWE
constituency in the dependency tree, and resolved by arbitration with minimal
human intervention. Using this technique, we identified and corrected several
hundred errors across both parse and MWE annotations, representing changes to a
significant percentage (well over 10%) of the MWE instances in the joint
corpus.},
 address = {Valencia, Spain},
 author = {Chan, King and Brooke, Julian and Baldwin, Timothy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1726},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {187--193},
 publisher = {Association for Computational Linguistics},
 title = {Semi-Automated Resolution of Inconsistency for a Harmonized Multiword Expression and Dependency Parse Annotation},
 year = {2017}
}

@inproceedings{W17-1727,
 abstract = {As multiword expressions (MWEs) exhibit a range of idiosyncrasies, their
automatic detection warrants the use of many different features. Tsvetkov and
Wintner (2014) proposed a Bayesian network model that combines linguistically
motivated features and also models their interactions. In this paper, we extend
their model with new features and apply it to Croatian, a morphologically
complex and a relatively free word order language, achieving a satisfactory
performance of 0.823 F1-score. Furthermore, by comparing against (semi)naive
Bayes models, we demonstrate that manually modeling feature interactions is
indeed important.  We make our annotated dataset of Croatian MWEs freely
available.},
 address = {Valencia, Spain},
 author = {Buljan, Maja and \v{S}najder, Jan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1727},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {194--199},
 publisher = {Association for Computational Linguistics},
 title = {Combining Linguistic Features for the Detection of Croatian Multiword Expressions},
 year = {2017}
}

@inproceedings{W17-1728,
 abstract = {This paper compares a neural network DSM relying on textual co-occurrences with
a multi-modal model integrating visual information. We focus on nominal vs.
verbal compounds, and zoom into lexical, empirical and perceptual target
properties to explore the contribution of the visual modality. Our experiments
show that (i)  visual features contribute differently for verbs than for nouns, and (ii) images complement textual information, if (a) the textual modality by
itself is poor and appropriate image subsets are used, or (b) the textual
modality by itself is rich and large (potentially noisy) images are added.},
 address = {Valencia, Spain},
 author = {K\"{o}per, Maximilian and Schulte im Walde, Sabine},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1728},
 booktitle = {Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)},
 month = {April},
 pages = {200--206},
 publisher = {Association for Computational Linguistics},
 title = {Complex Verbs are Different: Exploring the Visual Modality in Multi-Modal Models to Predict Compositionality},
 year = {2017}
}

@inproceedings{W17-1801,
 abstract = {Interpersonal violence (IPV) is a prominent sociological problem that affects
people of all demographic backgrounds. By analyzing how readers interpret, perceive, and react to experiences narrated in social media posts, we explore
an understudied source for discourse about abuse. We asked readers to annotate
Reddit posts about relationships with vs. without IPV for stakeholder roles and
emotion, while measuring their galvanic skin response (GSR), pulse, and facial
expression. We map annotations to coreference resolution output to obtain a
labeled coreference chain for stakeholders in texts, and apply automated
semantic role labeling for analyzing IPV discourse. Findings provide insights
into how readers process roles and emotion in narratives. For example, abusers
tend to be linked with violent actions and certain affect states. We train
classifiers to predict stakeholder categories of coreference chains. We also
find that subjects' GSR noticeably changed for IPV texts, suggesting that
co-collected measurement-based data about annotators can be used to support
text annotation.},
 address = {Valencia, Spain},
 author = {Calderwood, Alexander and Pruett, Elizabeth A. and Ptucha, Raymond and Homan, Christopher and Ovesdotter Alm, Cecilia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1801},
 booktitle = {Proceedings of the Workshop Computational Semantics Beyond Events and Roles},
 month = {April},
 pages = {1--9},
 publisher = {Association for Computational Linguistics},
 title = {Understanding the Semantics of Narratives of Interpersonal Violence through Reader Annotations and Physiological Reactions},
 year = {2017}
}

@inproceedings{W17-1802,
 abstract = {This paper describes current efforts in developing an annotation schema and
guidelines for sentences in Episodic Logic (EL).  We focus on important
distinctions for representing modality, attitudes, and tense and present an
annotation schema that makes these distinctions.  EL has proved competitive
with other logical formulations in speed and inference-enablement, while
expressing a wider array of natural language phenomena including intensional
modification of predicates and sentences, propositional attitudes, and tense
and aspect.},
 address = {Valencia, Spain},
 author = {Kim, Gene and Schubert, Lenhart},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1802},
 booktitle = {Proceedings of the Workshop Computational Semantics Beyond Events and Roles},
 month = {April},
 pages = {10--15},
 publisher = {Association for Computational Linguistics},
 title = {Intension, Attitude, and Tense Annotation in a High-Fidelity Semantic Representation},
 year = {2017}
}

@inproceedings{W17-1803,
 abstract = {This paper presents ongoing work for the
construction of a French FactBank and a
lexicon of French event-selecting predi-
cates (ESPs), by applying the factuality
detection algorithm introduced in (Saur\'{i}
and Pustejovsky, 2012). This algorithm
relies on a lexicon of ESPs, specifying
how these predicates influence the polar-
ity of their embedded events. For this pilot
study, we focused on French factive and
implicative verbs, and capitalised on a lex-
ical resource for the English counterparts
of these verbs provided by the CLSI Group
(Nairn et al., 2006; Karttunen, 2012).},
 address = {Valencia, Spain},
 author = {Falk, Ingrid and Martin, Fabienne},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1803},
 booktitle = {Proceedings of the Workshop Computational Semantics Beyond Events and Roles},
 month = {April},
 pages = {16--21},
 publisher = {Association for Computational Linguistics},
 title = {Towards a lexicon of event-selecting predicates for a French FactBank},
 year = {2017}
}

@inproceedings{W17-1804,
 abstract = {Many language technology applications would benefit from the ability to
represent negation and its scope on top of widely-used linguistic resources. In
this paper, we investigate the possibility of obtaining a first-order logic
representation with negation scope marked using Universal Dependencies. To do
so, we enhance UDepLambda, a framework that converts dependency graphs to
logical forms. The resulting UDepLambda$\lnot$ is able to handle phenomena
related to scope by means of an higher-order type theory, relevant not only to
negation but also to universal quantification and other complex semantic
phenomena. The initial conversion we did for English is promising, in that one
can represent the scope of negation also in the presence of more complex
phenomena such as universal quantifiers.},
 address = {Valencia, Spain},
 author = {Fancellu, Federico and Reddy, Siva and Lopez, Adam and Webber, Bonnie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1804},
 booktitle = {Proceedings of the Workshop Computational Semantics Beyond Events and Roles},
 month = {April},
 pages = {22--32},
 publisher = {Association for Computational Linguistics},
 title = {Universal Dependencies to Logical Form with Negation Scope},
 year = {2017}
}

@inproceedings{W17-1805,
 abstract = {In this talk I will discuss the analysis of several semantic phenomena that
need meaning representations that can describe attributes of propositional
contexts. I will do this in a version of Discourse Representation Theory, using
a universal semantic tagset developed as part of a project that aims to produce
a large meaning bank (a semantically-annotated corpus) for four languages
(English, Dutch, German and Italian).},
 address = {Valencia, Spain},
 author = {Bos, Johan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1805},
 booktitle = {Proceedings of the Workshop Computational Semantics Beyond Events and Roles},
 month = {April},
 pages = {33},
 publisher = {Association for Computational Linguistics},
 title = {Meaning Banking beyond Events and Roles},
 year = {2017}
}

@inproceedings{W17-1806,
 abstract = {In this paper we present a complete framework for the annotation of negation in
Italian, which accounts for both negation scope and negation focus, and also
for language-specific phenomena such as negative concord. In our view, the
annotation of negation complements more comprehensive Natural Language
Processing tasks, such as temporal information processing and sentiment
analysis. We applied the proposed framework and the guidelines built on top of
it to the annotation of written texts, namely news articles and tweets, thus
producing annotated data for a total of over 36,000 tokens.},
 address = {Valencia, Spain},
 author = {Altuna, Bego\~{n}a and Minard, Anne-Lyse and Speranza, Manuela},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1806},
 booktitle = {Proceedings of the Workshop Computational Semantics Beyond Events and Roles},
 month = {April},
 pages = {34--42},
 publisher = {Association for Computational Linguistics},
 title = {The Scope and Focus of Negation: A Complete Annotation Framework for Italian},
 year = {2017}
}

@inproceedings{W17-1807,
 abstract = {This paper presents the IULA Spanish Clinical Record Corpus, a corpus of 3,194
sentences extracted from anonymized clinical records and manually annotated
with negation markers and their scope. The corpus was conceived as a resource
to support clinical text-mining systems, but it is also a useful resource for
other Natural Language Processing systems handling clinical texts: automatic
encoding of clinical records, diagnosis support, term extraction, among others, as well as for the study of clinical texts. The corpus is publicly available
with a CC-BY-SA 3.0 license.},
 address = {Valencia, Spain},
 author = {Marimon, Montserrat and Vivaldi, Jorge and Bel, N\'{u}ria},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1807},
 booktitle = {Proceedings of the Workshop Computational Semantics Beyond Events and Roles},
 month = {April},
 pages = {43--52},
 publisher = {Association for Computational Linguistics},
 title = {Annotation of negation in the IULA Spanish Clinical Record Corpus},
 year = {2017}
}

@inproceedings{W17-1808,
 abstract = {In this paper we present  on-going work on annotating negation in Spanish
clinical documents. A corpus of anamnesis and radiology reports has been
annotated by two domain expert annotators with negation markers and negated
events. The Dice coefficient for inter-annotator agreement is higher than 0.94
for negation markers and higher than 0.72 for negated events. The corpus will
be publicly released when the annotation process is finished, constituting the
first corpus annotated with negation for Spanish clinical reports available for
the NLP community.},
 address = {Valencia, Spain},
 author = {Cruz, Noa and Morante, Roser and Ma\~{n}a L\'{o}pez, Manuel J. and Mata V\'{a}zquez, Jacinto and Parra Calder\'{o}n, Carlos L.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1808},
 booktitle = {Proceedings of the Workshop Computational Semantics Beyond Events and Roles},
 month = {April},
 pages = {53--58},
 publisher = {Association for Computational Linguistics},
 title = {Annotating Negation in Spanish Clinical Texts},
 year = {2017}
}

@inproceedings{W17-1809,
 abstract = {Negation cue detection involves identifying the span inherently expressing
negation in a negative sentence. In Chinese, negative cue detection is
complicated by morphological proprieties of the language. Previous work has
shown that negative cue detection in Chinese can benefit from specific lexical
and morphemic features, as well as cross-lingual information. We show here that
they are not necessary: A bi-directional LSTM can perform equally well, with
minimal feature engineering. In particular, the use of a character-based model
allows us to capture characteristics of negation cues in Chinese using
word-embedding information only. Not only does our model performs on par with
previous work, further error analysis clarifies what problems remain to be
addressed.},
 address = {Valencia, Spain},
 author = {He, Hangfeng and Fancellu, Federico and Webber, Bonnie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1809},
 booktitle = {Proceedings of the Workshop Computational Semantics Beyond Events and Roles},
 month = {April},
 pages = {59--63},
 publisher = {Association for Computational Linguistics},
 title = {Neural Networks for Negation Cue Detection in Chinese},
 year = {2017}
}

@inproceedings{W17-1810,
 abstract = {This paper presents an open-source toolkit for negation detection. It
identifies negation cues and their corresponding scope in either raw or parsed
text using maximum-margin classification. The system design draws on best
practice from the existing literature on negation detection, aiming for a
simple and portable system that still achieves competitive performance.
Pre-trained models and experimental results are provided for English.},
 address = {Valencia, Spain},
 author = {Enger, Martine and Velldal, Erik and {\O}vrelid, Lilja},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1810},
 booktitle = {Proceedings of the Workshop Computational Semantics Beyond Events and Roles},
 month = {April},
 pages = {64--69},
 publisher = {Association for Computational Linguistics},
 title = {An open-source tool for negation detection: a maximum-margin approach},
 year = {2017}
}

@inproceedings{W17-1901,
 abstract = {This article describes a method to build semantic representations of composite
expressions in a compositional way by using WordNet relations to represent the
meaning of words. The meaning of a target word is modelled as a vector in which
its semantically related words are assigned weights according to both the type
of the relationship and the distance to the target word. Word vectors are
compositionally combined by syntactic dependencies. Each syntactic dependency
triggers two complementary compositional functions: the named head function and
dependent function. The experiments show that the proposed compositional
method outperforms the state-of-the-art for both intransitive subject-verb and
transitive subject-verb-object constructions.},
 address = {Valencia, Spain},
 author = {Gamallo, Pablo and Pereira-Fari\~{n}a, Mart\'{i}n},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1901},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {1--11},
 publisher = {Association for Computational Linguistics},
 title = {Compositional Semantics using Feature-Based Models from WordNet},
 year = {2017}
}

@inproceedings{W17-1902,
 abstract = {We present a fully unsupervised method for automated construction of WordNets
based upon recent advances in distributional representations of sentences and
word-senses combined with readily available machine translation tools. The
approach requires very few linguistic resources and is thus extensible to
multiple target languages. To evaluate our method we construct two 600-word
testsets for word-to-synset matching in French and Russian using native
speakers and evaluate the performance of our method along with several other
recent approaches. Our method exceeds the best language-specific and
multi-lingual automated WordNets in F-score for both languages. The databases
we construct for French and Russian, both languages without large publicly
available manually constructed WordNets, will be publicly released along with
the testsets.},
 address = {Valencia, Spain},
 author = {Khodak, Mikhail and Risteski, Andrej and Fellbaum, Christiane and Arora, Sanjeev},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1902},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {12--23},
 publisher = {Association for Computational Linguistics},
 title = {Automated WordNet Construction Using Word Embeddings},
 year = {2017}
}

@inproceedings{W17-1903,
 abstract = {Abstract words refer to things that can not be seen, heard, felt, smelled, or
tasted as opposed to concrete words. Among other applications, the degree of
abstractness has been shown to be a useful information for metaphor detection.
Our
contribution to this topic are as follows: i) we compare supervised techniques
to
learn and extend abstractness ratings for huge vocabularies ii) we learn and
investigate norms for larger units by propagating abstractness to verb-noun
pairs which lead to better metaphor detection iii) we overcome the limitation
of learning a single rating per word and show that multi-sense abstractness
ratings are potentially useful for metaphor detection. Finally, with this paper
we publish automatically created abstractness norms for 3million English words
and multi-words as well as automatically created sense specific abstractness
ratings},
 address = {Valencia, Spain},
 author = {K\"{o}per, Maximilian and Schulte im Walde, Sabine},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1903},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {24--30},
 publisher = {Association for Computational Linguistics},
 title = {Improving Verb Metaphor Detection by Propagating Abstractness to Words, Phrases and Individual Senses},
 year = {2017}
}

@inproceedings{W17-1904,
 abstract = {This paper presents a novel approach to the task of automatically inferring the
most probable diagnosis from a given clinical narrative. Structured Knowledge
Bases (KBs) can be useful for such complex tasks but not sufficient. Hence, we
leverage a vast amount of unstructured free text to integrate with structured
KBs. The key innovative ideas include building a concept graph from both
structured and unstructured knowledge sources and ranking the diagnosis
concepts using the enhanced word embedding vectors learned from integrated
sources. Experiments on the TREC CDS and HumanDx datasets showed that our
methods improved the results of clinical diagnosis inference.},
 address = {Valencia, Spain},
 author = {Ling, Yuan and An, Yuan and Hasan, Sadid},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1904},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {31--36},
 publisher = {Association for Computational Linguistics},
 title = {Improving Clinical Diagnosis Inference through Integration of Structured and Unstructured Knowledge},
 year = {2017}
}

@inproceedings{W17-1905,
 abstract = {This paper proposes a method for classifying the type of lexical-semantic
relation between a given pair of words. Given an inventory of target
relationships, this task can be seen as a multi-class classification problem.
We train a supervised classifier by assuming: (1) a specific type of
lexical-semantic relation between a pair of words would be indicated by a
carefully designed set of relation-specific similarities associated with the
words; and (2) the similarities could be effectively computed by ``sense
representations'' (sense/concept embeddings). The experimental results show
that the proposed method clearly outperforms an existing state-of-the-art
method that does not utilize sense/concept embeddings, thereby demonstrating
the effectiveness of the sense representations.},
 address = {Valencia, Spain},
 author = {Kanada, Kentaro and Kobayashi, Tetsunori and Hayashi, Yoshihiko},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1905},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {37--46},
 publisher = {Association for Computational Linguistics},
 title = {Classifying Lexical-semantic Relationships by Exploiting Sense/Concept Representations},
 year = {2017}
}

@inproceedings{W17-1906,
 abstract = {Usage similarity (USim) is an approach to determining word meaning in context
that does not rely on a sense inventory. Instead, pairs of usages of a target
lemma are rated on a scale. In this paper we propose unsupervised approaches to
USim based on embeddings for words, contexts, and sentences, and achieve
state-of-the-art results over two USim datasets. We further consider supervised
approaches to USim, and find that although they outperform unsupervised
approaches, they are unable to generalize to lemmas that are unseen in the
training data.},
 address = {Valencia, Spain},
 author = {King, Milton and Cook, Paul},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1906},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {47--52},
 publisher = {Association for Computational Linguistics},
 title = {Supervised and unsupervised approaches to measuring usage similarity},
 year = {2017}
}

@inproceedings{W17-1907,
 abstract = {Properly written texts in Igbo, a low-resource African language, are rich in
both orthographic and tonal diacritics. Diacritics are essential in capturing
the distinctions in pronunciation and meaning of words, as well as in lexical
disambiguation. Unfortunately, most electronic texts in diacritic languages are
written without diacritics. This makes diacritic restoration a necessary step
in corpus building and language processing tasks for languages with diacritics.
In our previous work, we built some n-gram models with simple smoothing
techniques based on a closed-world assumption. However, as a classification
task, diacritic restoration is well suited for and will be more generalisable
with machine learning. This paper, therefore, presents a more standard approach
to dealing with the task which involves the application of machine learning
algorithms.},
 address = {Valencia, Spain},
 author = {Ezeani, Ignatius and Hepple, Mark and Onyenwe, Ikechukwu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1907},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {53--60},
 publisher = {Association for Computational Linguistics},
 title = {Lexical Disambiguation of Igbo using Diacritic Restoration},
 year = {2017}
}

@inproceedings{W17-1908,
 abstract = {Creating high-quality wide-coverage multilingual
semantic lexicons to support
knowledge-based approaches is a challenging
time-consuming manual task.
This has traditionally been performed by
linguistic experts: a slow and expensive
process. We present an experiment in
which we adapt and evaluate crowdsourcing
methods employing native speakers to
generate a list of coarse-grained senses under
a common multilingual semantic taxonomy
for sets of words in six languages.
451 non-experts (including 427 Mechanical
Turk workers) and 15 expert participants
semantically annotated 250 words
manually for Arabic, Chinese, English, Italian, Portuguese and Urdu lexicons. In
order to avoid erroneous (spam) crowdsourced
results, we used a novel task-specific
two-phase filtering process where
users were asked to identify synonyms in
the target language, and remove erroneous
senses.},
 address = {Valencia, Spain},
 author = {El-Haj, Mahmoud and Rayson, Paul and Piao, Scott and Wattam, Stephen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1908},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {61--71},
 publisher = {Association for Computational Linguistics},
 title = {Creating and Validating Multilingual Semantic Representations for Six Languages: Expert versus Non-Expert Crowds},
 year = {2017}
}

@inproceedings{W17-1909,
 abstract = {We introduce a new method for unsupervised knowledge-based word sense
disambiguation (WSD) based on a resource that links two types of sense-aware
lexical networks: one is induced from a corpus using distributional semantics, the other is manually constructed. The combination of two networks reduces the
sparsity of sense representations used for WSD. We evaluate these enriched
representations within two lexical sample sense disambiguation benchmarks. Our
results indicate that (1) features extracted from the corpus-based resource
help to significantly outperform a model based solely on the lexical resource;
(2) our method achieves results comparable or better to four state-of-the-art
unsupervised knowledge-based WSD systems including three hybrid systems that
also rely on text corpora. In contrast to these hybrid methods, our approach
does not require access to web search engines, texts mapped to a sense
inventory, or machine translation systems.},
 address = {Valencia, Spain},
 author = {Panchenko, Alexander and Faralli, Stefano and Ponzetto, Simone Paolo and Biemann, Chris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1909},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {72--78},
 publisher = {Association for Computational Linguistics},
 title = {Using Linked Disambiguated Distributional Networks for Word Sense Disambiguation},
 year = {2017}
}

@inproceedings{W17-1910,
 abstract = {In this paper, we investigate whether an a priori disambiguation of word senses
is strictly necessary or whether the meaning of a word in context can be
disambiguated through composition alone. We evaluate the performance of
off-the-shelf single-vector and multi-sense vector models on a benchmark phrase
similarity task and a novel task for word-sense discrimination. We find that
single-sense vector models perform as well or better than multi-sense vector
models despite arguably less clean elementary representations. Our findings
furthermore show that simple composition functions such as pointwise addition
are able to recover sense specific information from a single-sense vector model
remarkably well.},
 address = {Valencia, Spain},
 author = {Kober, Thomas and Weeds, Julie and Wilkie, John and Reffin, Jeremy and Weir, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1910},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {79--90},
 publisher = {Association for Computational Linguistics},
 title = {One Representation per Word - Does it make Sense for Composition?},
 year = {2017}
}

@inproceedings{W17-1911,
 abstract = {In this paper, we introduce a method of identifying the components (i.e.
dimensions) of word embeddings that strongly signifies properties of a word. By
elucidating such properties hidden in word embeddings, we could make word
embeddings more interpretable, and also could perform property-based meaning
comparison. With the capability, we can answer questions like "To what degree
a given word has the property cuteness?" or "In what perspective two words
are similar?". We verify our method by examining how the strength of
property-signifying components correlates with the degree of prototypicality of
a target word.},
 address = {Valencia, Spain},
 author = {Jang, Kyoung-Rok and Myaeng, Sung-Hyon},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1911},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {91--95},
 publisher = {Association for Computational Linguistics},
 title = {Elucidating Conceptual Properties from Word Embeddings},
 year = {2017}
}

@inproceedings{W17-1912,
 abstract = {In this paper we introduce the TTCS\^{}e, a linguistic resource that relies on
BabelNet, NASARI and ConceptNet, that has now been used to compute the
conceptual similarity between concept pairs. The conceptual representation
herein provides uniform access to concepts based on BabelNet synset IDs, and
consists of a vector-based semantic representation which is compliant with the
Conceptual Spaces, a geometric framework for common-sense knowledge
representation and reasoning. The TTCS\^{}e has been evaluated in a preliminary
experimentation on a conceptual similarity task.},
 address = {Valencia, Spain},
 author = {Mensa, Enrico and Radicioni, Daniele P. and Lieto, Antonio},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1912},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {96--101},
 publisher = {Association for Computational Linguistics},
 title = {TTCS\^{}e: a Vectorial Resource for Computing Conceptual Similarity},
 year = {2017}
}

@inproceedings{W17-1913,
 abstract = {This paper describes a method to measure the lexical gap of action verbs in
Italian and English by using the IMAGACT ontology of action. The fine-grained
categorization of action concepts of the data source allowed to have wide
overview of the relation between concepts in the two languages. The calculated
lexical gap for both English and Italian is about 30% of the action concepts, much higher than previous results. Beyond this general numbers a deeper
analysis has been performed in order to evaluate the impact that lexical gaps
can have on translation. In particular a distinction has been made between the
cases in which the presence of a lexical gap affects translation correctness
and completeness at a semantic level. The results highlight a high percentage
of concepts that can be considered hard to translate (about 18% from English to
Italian and 20% from Italian to English) and confirms that action verbs are a
critical lexical class for translation tasks.},
 address = {Valencia, Spain},
 author = {Gregori, Lorenzo and Panunzi, Alessandro},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1913},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {102--109},
 publisher = {Association for Computational Linguistics},
 title = {Measuring the Italian-English lexical gap for action verbs and its impact on translation},
 year = {2017}
}

@inproceedings{W17-1914,
 abstract = {The role of word sense disambiguation in lexical substitution has been
questioned due to the high performance of vector space models which propose
good substitutes without explicitly accounting for sense. We show that a
filtering
mechanism based on a sense inventory optimized for substitutability can improve
the results of these models. Our sense inventory is constructed using a
clustering method which generates paraphrase clusters that are congruent with
lexical substitution annotations in a development set. The results show that
lexical substitution can still benefit from senses which can improve the output
of vector space paraphrase ranking models.},
 address = {Valencia, Spain},
 author = {Cocos, Anne and Apidianaki, Marianna and Callison-Burch, Chris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1914},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {110--119},
 publisher = {Association for Computational Linguistics},
 title = {Word Sense Filtering Improves Embedding-Based Lexical Substitution},
 year = {2017}
}

@inproceedings{W17-1915,
 abstract = {This paper compares two approaches to word sense disambiguation using word
embeddings trained on unambiguous synonyms. The first is unsupervised method
based on computing log probability from sequences of word embedding vectors, taking into account ambiguous word senses and guessing correct sense from
context. The second method is supervised. We use a multilayer neural network
model to learn a context-sensitive transformation that maps an input vector of
ambiguous word into an output vector representing its sense. We evaluate both
methods on corpora with manual annotations of word senses from the Polish
wordnet (plWordnet).},
 address = {Valencia, Spain},
 author = {Wawer, Aleksander and Mykowiecka, Agnieszka},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-1915},
 booktitle = {Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications},
 month = {April},
 pages = {120--125},
 publisher = {Association for Computational Linguistics},
 title = {Supervised and Unsupervised Word Sense Disambiguation on Word Embedding Vectors of Unambigous Synonyms},
 year = {2017}
}

@inproceedings{W17-2001,
 abstract = {We motivate and describe a new freely available human-human dialogue data set
for interactive learning of visually grounded word meanings through ostensive
definition by a tutor to a learner. The data has been collected using a novel, character-by-character variant of the DiET
chat tool (Healey et al., 2003; anon.) with a novel task, where a Learner needs
to learn invented visual attribute words (such as {\^a}burchak{\^a} for square)
from a tutor. As such, the text-based interactions closely resemble
face-to-face conversation and thus contain many of the linguistic
phenomena encountered in natural, spontaneous dialogue. These include self- and
other-correction, mid-sentence continuations, interruptions, turn overlaps, fillers, hedges and many kinds of ellipsis. We also present a generic n-gram
framework for building user (i.e. tutor) simulations from this type of
incremental dialogue data, which is freely available to researchers. We show
that the simulations produce outputs that are similar to the original data
(e.g. 78% turn match similarity). Finally, we train and evaluate a
Reinforcement Learning dialogue control agent for learning visually grounded
word meanings, trained from the BURCHAK corpus. The learned policy shows
comparable performance to a rule-based system built previously.},
 address = {Valencia, Spain},
 author = {Yu, Yanchao and Eshghi, Arash and Mills, Gregory and Lemon, Oliver},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2001},
 booktitle = {Proceedings of the Sixth Workshop on Vision and Language},
 month = {April},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {The BURCHAK corpus: a Challenge Data Set for Interactive Learning of Visually Grounded Word Meanings},
 year = {2017}
}

@inproceedings{W17-2002,
 abstract = {In this paper, a retrieval-based caption generation system that searches the
web for suitable image descriptions is studied. Google's reverse image search
is used to find potentially relevant web multimedia content for query images.
Sentences are extracted from web pages and the likelihood of the descriptions
is
computed to select one sentence from the retrieved text documents. The search
mechanism is modified to replace the caption generated by Google with a caption
composed of labels and spatial prepositions as part of the query's text
alongside the image. The object labels are obtained using an off-the-shelf
R-CNN and a machine learning model is developed to predict the prepositions.
The effect on the caption generation system performance when using the
generated text is investigated. Both human evaluations and automatic metrics
are used to evaluate the retrieved descriptions. Results show that the
web-retrieval-based approach performed better when describing single-object
images with sentences extracted from stock photography websites. On the other
hand, images with two image objects were better described with
template-generated sentences composed of object labels and prepositions.},
 address = {Valencia, Spain},
 author = {Birmingham, Brandon and Muscat, Adrian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2002},
 booktitle = {Proceedings of the Sixth Workshop on Vision and Language},
 month = {April},
 pages = {11--20},
 publisher = {Association for Computational Linguistics},
 title = {The Use of Object Labels and Spatial Prepositions as Keywords in a Web-Retrieval-Based Image Caption Generation System},
 year = {2017}
}

@inproceedings{W17-2003,
 abstract = {We investigate animal recognition models learned from wildlife video
documentaries by using the weak supervision of the textual subtitles. This is a
particularly challenging setting, since i) the animals occur in their natural
habitat and are often largely occluded and ii) subtitles are to a large degree
complementary to the visual content, providing a very weak supervisory signal.
This is in contrast to most work on integrated vision and language in the
literature, where textual descriptions are tightly linked to the image content, and often generated in a curated fashion for the task at hand. In particular, we investigate different image representations and models, including a support
vector machine on top of activations of a pretrained convolutional neural
network, as well as a Naive Bayes framework on a 'bag-of-activations' image
representation, where each element of the bag is considered separately. This
representation allows key components in the image to be isolated, in spite of
largely varying backgrounds and image clutter, without an object detection or
image segmentation step. The methods are evaluated based on how well they
transfer to unseen camera-trap images captured across diverse topographical
regions under different environmental conditions and illumination settings, involving a large domain shift.},
 address = {Valencia, Spain},
 author = {Nurani Venkitasubramanian, Aparna and Tuytelaars, Tinne and Moens, Marie-Francine},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2003},
 booktitle = {Proceedings of the Sixth Workshop on Vision and Language},
 month = {April},
 pages = {21--30},
 publisher = {Association for Computational Linguistics},
 title = {Learning to Recognize Animals by Watching Documentaries: Using Subtitles as Weak Supervision},
 year = {2017}
}

@inproceedings{W17-2004,
 abstract = {In this paper, we study how humans perceive the use of images as an additional
knowledge source to machine-translate user-generated product listings in an
e-commerce company. We conduct a human evaluation where we assess how a
multi-modal neural machine translation (NMT) model compares to two text-only
approaches: a conventional state-of-the-art attention-based NMT and a
phrase-based statistical machine translation (PBSMT) model. We evaluate
translations obtained with different systems and also discuss the data set of
user-generated product listings, which in our case comprises both product
listings and associated images. We found that humans preferred translations
obtained with a PBSMT system to both text-only and multi-modal NMT over 56% of
the time. Nonetheless, human evaluators ranked translations from a multi-modal
NMT model as better than those of a text-only NMT over 88% of the time, which
suggests that images do help NMT in this use-case.},
 address = {Valencia, Spain},
 author = {Calixto, Iacer and Stein, Daniel and Matusov, Evgeny and Castilho, Sheila and Way, Andy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2004},
 booktitle = {Proceedings of the Sixth Workshop on Vision and Language},
 month = {April},
 pages = {31--37},
 publisher = {Association for Computational Linguistics},
 title = {Human Evaluation of Multi-modal Neural Machine Translation: A Case-Study on E-Commerce Listing Titles},
 year = {2017}
}

@inproceedings{W17-2005,
 abstract = {We present BreakingNews, a novel dataset with approximately 100K news articles
including images, text and captions, and enriched with heterogeneous meta-data
(e.g. GPS coordinates and popularity metrics). The tenuous connection between
the images and text in news data is appropriate to take work at the
intersection of Computer Vision and Natural Language Processing to the next
step, hence we hope this dataset will help spur progress in the field.},
 address = {Valencia, Spain},
 author = {Ramisa, Arnau and Yan, Fei and Moreno-Noguer, Francesc and Mikolajczyk, Krystian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2005},
 booktitle = {Proceedings of the Sixth Workshop on Vision and Language},
 month = {April},
 pages = {38--39},
 publisher = {Association for Computational Linguistics},
 title = {The BreakingNews Dataset},
 year = {2017}
}

@inproceedings{W17-2006,
 abstract = {We present an approach where an SVM classifier learns to classify head
movements based on measurements of velocity, acceleration, and the third
derivative of position with respect to time, jerk. Consequently, annotations of head movements are added to new video data. The results of the
automatic annotation are evaluated against manual annotations in the same data
and show an accuracy of 68% with respect to these. The results also show that
using jerk improves accuracy. We then conduct an investigation of the
overlap between temporal sequences classified as either movement or
non-movement and the speech
stream of the person performing the gesture. The statistics derived from this
analysis show that using word features may help increase the accuracy of the
model.},
 address = {Valencia, Spain},
 author = {Paggio, Patrizia and Navarretta, Costanza and Jongejan, Bart},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2006},
 booktitle = {Proceedings of the Sixth Workshop on Vision and Language},
 month = {April},
 pages = {40--42},
 publisher = {Association for Computational Linguistics},
 title = {Automatic identification of head movements in video-recorded conversations: can words help?},
 year = {2017}
}

@inproceedings{W17-2007,
 abstract = {Finding a product in the fashion world can be a daunting task. Everyday, e-commerce sites are updating with thousands of images and their associated
metadata (textual information), deepening the problem. In this paper, we
leverage both the images and textual metadata and propose a joint multi-modal
embedding that maps both the text and images into a common latent space.
Distances in the latent space correspond to similarity between products, allowing us to effectively perform retrieval in this latent space. We compare
against existing approaches and show significant improvements in retrieval
tasks on a large-scale e-commerce dataset.},
 address = {Valencia, Spain},
 author = {Rubio Romano, Antonio and Yu, LongLong and Simo-Serra, Edgar and Moreno-Noguer, Francesc},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2007},
 booktitle = {Proceedings of the Sixth Workshop on Vision and Language},
 month = {April},
 pages = {43--45},
 publisher = {Association for Computational Linguistics},
 title = {Multi-Modal Fashion Product Retrieval},
 year = {2017}
}

@inproceedings{W17-2201,
 abstract = {Metaphor is indispensable in poetry. It showcases the poet's creativity, and
contributes to the overall emotional pertinence of the poem while honing its
specific rhetorical impact. Previous work on metaphor detection relies on
either rule-based or statistical models, none of them applied to poetry. Our
method focuses on metaphor detection in a poetry corpus. It combines rule-based
and statistical models (word embeddings) to develop a new classification
system. Our system has achieved a precision of 0.759 and a recall of 0.804 in
identifying one type of metaphor in poetry.},
 address = {Vancouver, Canada},
 author = {Kesarwani, Vaibhav and Inkpen, Diana and Szpakowicz, Stan and Tanasescu, Chris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2201},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {1--9},
 publisher = {Association for Computational Linguistics},
 title = {Metaphor Detection in a Poetry Corpus},
 year = {2017}
}

@inproceedings{W17-2202,
 abstract = {This paper presents a newly funded international project for machine
translation and automated analysis of ancient cuneiform languages where NLP
specialists and Assyriologists collaborate to create an information retrieval
system for Sumerian. This research is conceived in response to the need to
translate large numbers of administrative texts that are only available in
transcription, in order to make them accessible to a wider audience. The
methodology includes creation of a specialized NLP pipeline and also the use of
linguistic linked open data to increase access to the results.},
 address = {Vancouver, Canada},
 author = {Pag\'{e}-Perron, \'{E}milie and Sukhareva, Maria and Khait, Ilya and Chiarcos, Christian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2202},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {10--16},
 publisher = {Association for Computational Linguistics},
 title = {Machine Translation and Automated Analysis of the Sumerian Language},
 year = {2017}
}

@inproceedings{W17-2203,
 abstract = {Literary genres are commonly viewed as being defined in terms of content and
stylistic features. In this paper, we focus on one particular class of lexical
features, namely emotion information, and investigate the hypothesis that
emotion-related information correlates with particular genres. Us- ing genre
classification as a testbed, we compare a model that computes lexicon- based
emotion scores globally for complete stories with a model that tracks emotion
arcs through stories on a subset of Project Gutenberg with five genres.
Our main findings are: (a), the global emotion model is competitive with a
large-vocabulary bag-of-words genre classifier (80%F1); (b), the emotion arc
model shows a lower performance (59 % F1) but shows complementary behavior to
the global model, as indicated by a very good performance of an oracle model
(94 % F1) and an improved performance of an ensemble model (84 % F1); (c), genres differ in the extent to which stories follow the same emotional arcs, with particularly uniform behavior for anger (mystery) and fear (ad- ventures, romance, humor, science fiction).},
 address = {Vancouver, Canada},
 author = {Kim, Evgeny and Pad\'{o}, Sebastian and Klinger, Roman},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2203},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {17--26},
 publisher = {Association for Computational Linguistics},
 title = {Investigating the Relationship between Literary Genres and Emotional Plot Development},
 year = {2017}
}

@inproceedings{W17-2204,
 abstract = {Enjambment takes place when a syntactic unit is broken up across two lines of
poetry, giving rise to different stylistic effects. In Spanish literary
studies, there are unclear points about the types of stylistic effects that can
arise, and under which linguistic conditions. To systematically gather evidence
about this, we developed a system to automatically identify enjambment (and its
type) in Spanish. For evaluation, we manually annotated a reference corpus
covering different periods. As a scholarly corpus to apply the tool, from
public HTML sources we created a diachronic corpus covering four centuries of
sonnets (3750 poems), and we analyzed the occurrence of enjambment across
stanzaic boundaries in different periods. Besides, we found examples that
highlight limitations in current definitions of enjambment.},
 address = {Vancouver, Canada},
 author = {Ruiz, Pablo and Mart\'{i}nez Cant\'{o}n, Clara and Poibeau, Thierry and Gonz\'{a}lez-Blanco, Elena},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2204},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {27--32},
 publisher = {Association for Computational Linguistics},
 title = {Enjambment Detection in a Large Diachronic Corpus of Spanish Sonnets},
 year = {2017}
}

@inproceedings{W17-2205,
 abstract = {The post-modern novel {\^a}Wittgenstein{\^a}s Mistress{\^a} by David Markson (1988)
presents the reader with a very challenging non-linear narrative, that itself
appears to one of the novel{\^a}s themes. We present a distant reading of this
work designed to complement a close reading of it by David Foster Wallace
(1990).   Using a combination of text analysis, entity recognition and
networks, we plot repetitive structures in the novel{\^a}s narrative relating
them to its critical analysis.},
 address = {Vancouver, Canada},
 author = {Kelleher, Conor and Keane, Mark},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2205},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {33--39},
 publisher = {Association for Computational Linguistics},
 title = {Plotting Markson's "Mistress"},
 year = {2017}
}

@inproceedings{W17-2206,
 abstract = {In this paper, we present the annotation challenges we have encountered when
working on a historical language that was undergoing elaboration processes. We
especially focus on syntactic ambiguity and gradience in Middle Low German, which causes uncertainty to some extent. Since current annotation tools
consider construction contexts and the dynamics of the grammaticalization only
partially, we plan to extend CorA - a web-based annotation tool for historical
and other non-standard language data - to capture elaboration phenomena and
annotator unsureness. Moreover, we seek to interactively learn morphological as
well as syntactic annotations.},
 address = {Vancouver, Canada},
 author = {Seemann, Nina and Merten, Marie-Luis and Geierhos, Michaela and Tophinke, Doris and H\"{u}llermeier, Eyke},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2206},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {40--45},
 publisher = {Association for Computational Linguistics},
 title = {Annotation Challenges for Reconstructing the Structural Elaboration of Middle Low German},
 year = {2017}
}

@inproceedings{W17-2207,
 abstract = {The oral component of medieval poetry was integral to its performance and
reception. Yet many believe that the medieval voice has been forever lost, and
any attempts at rediscovering it are doomed to failure due to scribal
practices, manuscript mouvance, and linguistic normalization in editing
practices. This paper offers a method to abstract from this noise and better
understand relative differences in phonological soundscapes by considering
syllable qualities. The presented syllabification method and soundscape
analysis offer themselves as cross-disciplinary tools for low-resource
languages. As a case study, we examine medieval German lyric and argue that the
heavily debated lyrical {\^a}I{\^a} follows a unique trajectory through
soundscapes, shedding light on the performance and practice of these poets.},
 address = {Vancouver, Canada},
 author = {Hench, Christopher},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2207},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {46--56},
 publisher = {Association for Computational Linguistics},
 title = {Phonological Soundscapes in Medieval Poetry},
 year = {2017}
}

@inproceedings{W17-2208,
 abstract = {This paper presents an approach to extract co-occurrence networks from literary
texts. It is a deliberate decision not to aim for a fully automatic pipeline, as the literary research questions need to guide both the definition of the
nature of the things that co-occur as well as how to decide co-occurrence. We
showcase the approach on a Middle High German romance, \parz. Manual inspection
and discussion shows the huge impact various choices  have.},
 address = {Vancouver, Canada},
 author = {Blessing, Andre and Echelmeyer, Nora and John, Markus and Reiter, Nils},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2208},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {57--67},
 publisher = {Association for Computational Linguistics},
 title = {An End-to-end Environment for Research Question-Driven Entity Extraction and Network Analysis},
 year = {2017}
}

@inproceedings{W17-2209,
 abstract = {We present a data-driven approach to investigate
intra-textual variation by combining
entropy and surprisal. With this
approach we detect linguistic variation
based on phrasal lexico-grammatical patterns
across sections of research articles.
Entropy is used to detect patterns typical
of specific sections. Surprisal is used
to differentiate between more and less
informationally-loaded patterns as well as
type of information (topical vs. stylistic).
While we here focus on research articles in
biology/genetics, the methodology is especially
interesting for digital humanities
scholars, as it can be applied to any text
type or domain and combined with additional
variables (e.g. time, author or social
group).},
 address = {Vancouver, Canada},
 author = {Degaetano-Ortlieb, Stefania and Teich, Elke},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2209},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {68--77},
 publisher = {Association for Computational Linguistics},
 title = {Modeling intra-textual variation with entropy and surprisal: topical vs. stylistic patterns},
 year = {2017}
}

@inproceedings{W17-2210,
 abstract = {We investigate in this paper the problem of classifying the stylome of
characters in a literary work. Previous research in the field of authorship
attribution has shown that the writing style of an author can be characterized
and distinguished from that of other authors automatically. In this paper we
take a look at the less approached problem of how the styles of different
characters can be distinguished, trying to verify if an author managed to
create believable characters with individual styles. We present the results of
some initial experiments developed on the novel "Liaisons Dangereuses", showing
that a
simple bag of words model can be used to classify the characters.},
 address = {Vancouver, Canada},
 author = {Dinu, Liviu P. and Uban, Ana Sabina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2210},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {78--82},
 publisher = {Association for Computational Linguistics},
 title = {Finding a Character{\^a}s Voice: Stylome Classification on Literary Characters},
 year = {2017}
}

@inproceedings{W17-2211,
 abstract = {In this paper, we present our preliminary
study on an ontology-based method to extract
and classify compositional nominal
compounds in specific domains of knowledge.
This method is based on the assumption
that, applying a conceptual model to
represent knowledge domain, it is possible
to improve the extraction and classification
of lexicon occurrences for that domain
in a semi-automatic way. We explore
the possibility of extracting and classifying
a specific construction type (nominal
compounds) spanning a specific domain
(Cultural Heritage) and a specific
language (Italian).},
 address = {Vancouver, Canada},
 author = {di Buono, Maria Pia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2211},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {83--88},
 publisher = {Association for Computational Linguistics},
 title = {An Ontology-Based Method for Extracting and Classifying Domain-Specific Compositional Nominal Compounds},
 year = {2017}
}

@inproceedings{W17-2212,
 abstract = {In this paper, we present ongoing work for developing language resources and
basic NLP tools for an undocumented variety of Romansh, in the context of a
language documentation and language acquisition project. Our tools are meant to
improve the speed and reliability of corpus annotations for noisy data
involving large amounts of code-switching, occurrences of child-speech and
orthographic noise. Being able to increase the efficiency of language resource
development for language documentation and acquisition research also
constitutes a step towards solving the data sparsity issues with which
researchers have been struggling.},
 address = {Vancouver, Canada},
 author = {Walther, G\'{e}raldine and Sagot, Beno\^{i}t},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2212},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {89--94},
 publisher = {Association for Computational Linguistics},
 title = {Speeding up corpus development for linguistic research: language documentation and acquisition in Romansh Tuatschin},
 year = {2017}
}

@inproceedings{W17-2213,
 abstract = {This paper presents a statistical approach to automatic morphosyntactic
annotation of Hittite transcripts. Hittite is an extinct Indo-European language
using the cuneiform script. There are currently no morphosyntactic annotations
available for Hittite, so we explored methods of distant supervision. The
annotations were projected from parallel German translations of the Hittite
texts. In order to reduce data sparsity, we applied stemming of German and
Hittite texts. As there is no off-the-shelf Hittite stemmer, a stemmer for
Hittite was developed for this purpose. The resulting annotation projections
were used to train a POS tagger, achieving an accuracy of 69% on a test sample.
To our knowledge, this is the first attempt of statistical POS tagging of a
cuneiform language.},
 address = {Vancouver, Canada},
 author = {Sukhareva, Maria and Fuscagni, Francesco and Daxenberger, Johannes and G\"{o}rke, Susanne and Prechel, Doris and Gurevych, Iryna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2213},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {95--104},
 publisher = {Association for Computational Linguistics},
 title = {Distantly Supervised POS Tagging of Low-Resource Languages under Extreme Data Sparsity: The Case of Hittite},
 year = {2017}
}

@inproceedings{W17-2214,
 abstract = {The last decade saw a surge in digitisation efforts for ancient manuscripts in
Sanskrit. Due to various linguistic peculiarities inherent to the language, even the preliminary tasks such as word segmentation are non-trivial in
Sanskrit. Elegant models for Word Segmentation in Sanskrit are indispensable
for further syntactic and semantic processing of the manuscripts. Current works
in word segmentation for Sanskrit, though commendable in their novelty, often
have variations in their objective and evaluation criteria. In this work, we
set the record straight. We formally define the objectives and the requirements
for the word segmentation task. In order to encourage research in the field and
to alleviate the time and effort required in pre-processing, we release a
dataset of 115,000 sentences for word segmentation. For each sentence in the
dataset we include the input character sequence, ground truth segmentation, and
additionally lexical and morphological information about all the phonetically
possible segments for the given sentence. In this work, we also discuss the
linguistic considerations made while generating the candidate space of the
possible segments.},
 address = {Vancouver, Canada},
 author = {Krishna, Amrith and Satuluri, Pavan Kumar and Goyal, Pawan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2214},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {105--114},
 publisher = {Association for Computational Linguistics},
 title = {A Dataset for Sanskrit Word Segmentation},
 year = {2017}
}

@inproceedings{W17-2215,
 abstract = {Language processing architectures are often evaluated in near-to-perfect
conditions with respect to processed content. The tools which perform
sufficiently well on electronic press, books and other type of non-interactive
content may poorly handle littered, colloquial and multilingual textual data
which make the majority of communication today. This paper aims at
investigating how Polish Twitter data (in a slightly controlled `political'
flavour) differs from expectation of linguistic tools and how they could be
corrected to be ready for processing by standard language processing chains
available for Polish. The setting includes specialised components for spelling
correction of tweets as well as hashtag and username decoding.},
 address = {Vancouver, Canada},
 author = {Ogrodniczuk, Maciej and Kope\'{c}, Mateusz},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2215},
 booktitle = {Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature},
 month = {August},
 pages = {115--125},
 publisher = {Association for Computational Linguistics},
 title = {Lexical Correction of Polish Twitter Political Data},
 year = {2017}
}

@inproceedings{W17-2301,
 abstract = {We present a system for automatically detecting and classifying phonologically
anomalous productions in the speech of individuals with aphasia.
Working from transcribed discourse samples, our system identifies neologisms, and uses a combination of string alignment and language models to produce a
lattice of plausible words that the speaker may have intended to produce.
We then score this lattice according to various features, and attempt to
determine whether the anomalous production represented a phonemic error or a
genuine neologism.
This approach has the potential to be expanded to consider other types of
paraphasic errors, and could be applied to a wide variety of screening and
therapeutic applications.},
 address = {Vancouver, Canada,},
 author = {Adams, Joel and Bedrick, Steven and Fergadiotis, Gerasimos and Gorman, Kyle and van Santen, Jan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2301},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {1--8},
 publisher = {Association for Computational Linguistics},
 title = {Target word prediction and paraphasia classification in spoken discourse},
 year = {2017}
}

@inproceedings{W17-2302,
 abstract = {We propose a novel attention mechanism for a Convolutional Neural Network
(CNN)-based Drug-Drug Interaction (DDI) extraction model. CNNs have been shown
to have a great potential on DDI extraction tasks; however, attention
mechanisms, which emphasize important words in the sentence of a target-entity
pair, have not been investigated with the CNNs despite the fact that attention
mechanisms are shown to be effective for a general domain relation
classification task. We evaluated our model on the Task 9.2 of the
DDIExtraction-2013 shared task. As a result, our attention mechanism improved
the performance of our base CNN-based DDI model, and the model achieved an
F-score of 69.12%, which is competitive with the state-of-the-art models.},
 address = {Vancouver, Canada,},
 author = {Asada, Masaki and Miwa, Makoto and Sasaki, Yutaka},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2302},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {9--18},
 publisher = {Association for Computational Linguistics},
 title = {Extracting Drug-Drug Interactions with Attention CNNs},
 year = {2017}
}

@inproceedings{W17-2303,
 abstract = {Analogy completion has been a popular task in recent years for evaluating the
semantic properties of word embeddings, but the standard methodology makes a
number of assumptions about analogies that do not always hold, either in recent
benchmark datasets or when expanding into other domains.  Through an analysis
of analogies in the biomedical domain, we identify three assumptions: that of a
Single Answer for any given analogy, that the pairs involved describe the Same
Relationship, and that each pair is Informative with respect to the other. We
propose modifying the standard methodology to relax these assumptions by
allowing for multiple correct answers, reporting MAP and MRR in addition to
accuracy, and using multiple example pairs.  We further present BMASS, a novel
dataset for evaluating linguistic regularities in biomedical embeddings, and
demonstrate that the relationships described in the dataset pose significant
semantic challenges to current word embedding methods.},
 address = {Vancouver, Canada,},
 author = {Newman-Griffis, Denis and Lai, Albert and Fosler-Lussier, Eric},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2303},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {19--28},
 publisher = {Association for Computational Linguistics},
 title = {Insights into Analogy Completion from the Biomedical Domain},
 year = {2017}
}

@inproceedings{W17-2304,
 abstract = {State-of-the-art methods for protein-protein interaction (PPI) extraction are
primarily feature-based or kernel-based by leveraging lexical and syntactic
information. But how to incorporate such knowledge in the recent deep learning
methods remains an open question. In this paper, we propose a
multichannel dependency-based convolutional neural network model (McDepCNN). It
applies one channel to the embedding vector of each word in the sentence, and
another channel to the embedding vector of the head of the corresponding word.
Therefore, the model can use richer information obtained from different
channels. Experiments on two public benchmarking datasets, AIMed and BioInfer, demonstrate that McDepCNN provides up to 6% F1-score improvement over rich
feature-based methods and single-kernel methods. In addition, McDepCNN achieves
24.4% relative improvement in F1-score over the state-of-the-art methods on
cross-corpus evaluation and 12% improvement in F1-score over kernel-based
methods on "difficult" instances. These results suggest that McDepCNN
generalizes more easily over different corpora, and is capable of capturing
long distance features in the sentences.},
 address = {Vancouver, Canada,},
 author = {Peng, Yifan and Lu, Zhiyong},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2304},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {29--38},
 publisher = {Association for Computational Linguistics},
 title = {Deep learning for extracting protein-protein interactions from biomedical literature},
 year = {2017}
}

@inproceedings{W17-2305,
 abstract = {Linking spans of natural language text to concepts in a structured source is an
important task for many problems. It allows intelligent systems to leverage
rich knowledge available in those sources (such as concept properties and
relations) to enhance the semantics of the mentions of these concepts in text.
In the medical domain, it is common to link text spans to medical concepts in
large, curated knowledge repositories such as the Unified Medical Language
System.
Different approaches have different strengths: some are precision-oriented, some recall-oriented; some better at considering context but more prone to
hallucination. The variety of techniques suggests that ensembling could
outperform component technologies at this task.
In this paper, we describe our process for building a Stacking ensemble using
additional, auxiliary features for Entity Linking in the medical domain. We
report experiments that show that naive ensembling does not always outperform
component Entity Linking systems, that stacking usually outperforms naive
ensembling, and that auxiliary features added to the stacker further improve
its performance on three distinct datasets. Our best model produces
state-of-the-art results on several medical datasets.},
 address = {Vancouver, Canada,},
 author = {Rajani, Nazneen Fatema and Bornea, Mihaela and Barker, Ken},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2305},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {39--47},
 publisher = {Association for Computational Linguistics},
 title = {Stacking With Auxiliary Features for Entity Linking in the Medical Domain},
 year = {2017}
}

@inproceedings{W17-2306,
 abstract = {The goal of the BioASQ challenge is to engage researchers into creating
cuttingedge biomedical information systems. Specifically, it aims at the
promotion of systems and methodologies that are able to deal with a plethora of
different tasks in the biomedical domain. This is achieved through the
organization of challenges. The fifth challenge consisted of three tasks:
semantic indexing, question answering and a new task on information extraction.
In total, 29 teams with more than 95 systems participated in the challenge.
Overall, as in previous years, the best systems were able to outperform the
strong baselines. This suggests that stateof- the art systems are continuously
improving, pushing the frontier of research.},
 address = {Vancouver, Canada,},
 author = {Nentidis, Anastasios and Bougiatiotis, Konstantinos and Krithara, Anastasia and Paliouras, Georgios and Kakadiaris, Ioannis},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2306},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {48--57},
 publisher = {Association for Computational Linguistics},
 title = {Results of the fifth edition of the BioASQ Challenge},
 year = {2017}
}

@inproceedings{W17-2307,
 abstract = {In this paper, we describe our participation in phase B of task 5b of the fifth
edition of the annual BioASQ challenge, which includes answering factoid, list, yes-no and summary questions from biomedical data. We describe our techniques
with an emphasis on ideal answer generation, where the goal is to produce a
relevant, precise, non-redundant, query-oriented summary from multiple relevant
documents. We make use of extractive summarization techniques to address this
task and experiment with different biomedical ontologies and various algorithms
including agglomerative clustering, Maximum Marginal Relevance (MMR) and
sentence compression. We propose a novel word embedding based tf-idf similarity
metric and a soft positional constraint which improve our system performance.
We evaluate our techniques on test batch 4 from the fourth edition of the
challenge. Our best system achieves a ROUGE-2 score of 0.6534 and ROUGE-SU4
score of 0.6536.},
 address = {Vancouver, Canada,},
 author = {Chandu, Khyathi and Naik, Aakanksha and Chandrasekar, Aditya and Yang, Zi and Gupta, Niloy and Nyberg, Eric},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2307},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {58--66},
 publisher = {Association for Computational Linguistics},
 title = {Tackling Biomedical Text Summarization: OAQA at BioASQ 5B},
 year = {2017}
}

@inproceedings{W17-2308,
 abstract = {Macquarie University's contribution to the BioASQ challenge (Task 5b Phase B)
focused on the use of query-based extractive summarisation techniques for the
generation of the ideal answers. Four runs were submitted, with approaches
ranging from a trivial system that selected the first $n$ snippets, to the use
of deep learning approaches under a regression framework. Our experiments and
the ROUGE results of the five test batches of BioASQ indicate surprisingly good
results for the trivial approach. Overall, most of our runs on the first three
test batches achieved the best ROUGE-SU4 results in the challenge.},
 address = {Vancouver, Canada,},
 author = {Molla, Diego},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2308},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {67--75},
 publisher = {Association for Computational Linguistics},
 title = {Macquarie University at BioASQ 5b -- Query-based Summarisation Techniques for Selecting the Ideal Answers},
 year = {2017}
}

@inproceedings{W17-2309,
 abstract = {This paper describes our submission to the 2017 BioASQ challenge. We
participated in Task B, Phase B which is concerned with biomedical question
answering (QA). We focus on factoid and list question, using an extractive QA
model, that is, we restrict our system to output  substrings of the provided
text snippets. At the core of our system, we use FastQA, a state-of-the-art
neural QA system. We extended it with biomedical word embeddings and changed
its answer layer to be able to answer list questions in addition to factoid
questions. We pre-trained the model on a large-scale open-domain QA dataset, SQuAD, and then fine-tuned the parameters on the BioASQ training set. With our
approach, we achieve state-of-the-art results on factoid questions and
competitive results on list questions.},
 address = {Vancouver, Canada,},
 author = {Wiese, Georg and Weissenborn, Dirk and Neves, Mariana},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2309},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {76--79},
 publisher = {Association for Computational Linguistics},
 title = {Neural Question Answering at BioASQ 5B},
 year = {2017}
}

@inproceedings{W17-2310,
 abstract = {We introduce an end-to-end system capable of named-entity detection, normalization and relation extraction for extracting information about bacteria
and their habitats from biomedical literature. Our system is based on deep
learning, CRF classifiers and vector space models. We train and evaluate the
system on the BioNLP 2016 Shared Task Bacteria Biotope data. The official
evaluation shows that the joint performance of our entity detection and
relation extraction models outperforms the winning team of the Shared Task by
19pp on F1-score, establishing a new top score for the task. We also achieve
state-of-the-art results in the normalization task. Our system is open source
and freely available at https://github.com/TurkuNLP/BHE.},
 address = {Vancouver, Canada,},
 author = {Mehryary, Farrokh and Hakala, Kai and Kaewphan, Suwisa and Bj\"{o}rne, Jari and Salakoski, Tapio and Ginter, Filip},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2310},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {80--90},
 publisher = {Association for Computational Linguistics},
 title = {End-to-End System for Bacteria Habitat Extraction},
 year = {2017}
}

@inproceedings{W17-2311,
 abstract = {ext mining automatically extracts information from the literature with the goal
of making it available for further analysis, for example by incorporating it
into biomedical databases.  A key first step towards this goal is to identify
and normalize the named entities, such as proteins and species, which are
mentioned in text.  Despite the large detrimental impact that viruses have on
human and agricultural health, very little previous text-mining work has
focused on identifying virus species and proteins in the literature.  Here, we
present an improved dictionary-based system for viral species and the first
dictionary for viral proteins, which we benchmark on a new corpus of 300
manually annotated abstracts.  We achieve 81.0\% precision and 72.7\% recall at
the task of recognizing and normalizing viral species and 76.2\% precision and
34.9\% recall on viral proteins.  These results are achieved despite the many
challenges involved with the names of viral species and, especially, proteins.
This work provides a foundation that can be used to extract more complicated
relations about viruses from the literature.},
 address = {Vancouver, Canada,},
 author = {Cook, Helen and Berzins, Rudolfs and Rodr{\"A}$\pm$guez, Cristina Leal and Cejuela, Juan Miguel and Jensen, Lars Juhl},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2311},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {91--98},
 publisher = {Association for Computational Linguistics},
 title = {Creation and evaluation of a dictionary-based tagger for virus species and proteins},
 year = {2017}
}

@inproceedings{W17-2312,
 abstract = {We propose in this paper a semi-supervised method for labeling terms of texts
with concepts of a domain ontology. The method generates continuous vector
representations of complex terms in a semantic space structured by the
ontology. The proposed method relies on a distributional semantics approach, which generates initial vectors for each of the extracted terms. Then these
vectors are embedded in the vector space constructed from the structure of the
ontology. This embedding is carried out by training a linear model. Finally, we
apply a distance calculation to determine the proximity between vectors of
terms and vectors of concepts and thus to assign ontology labels to terms. We
have evaluated the quality of these representations for a normalization task by
using the concepts of an ontology as semantic labels. Normalization of terms is
an important step to extract a part of the information containing in texts, but
the vector space generated might find other applications. The performance of
this method is comparable to that of the state of the art for this task of
standardization, opening up encouraging prospects.},
 address = {Vancouver, Canada,},
 author = {Ferr\'{e}, Arnaud and Zweigenbaum, Pierre and N\'{e}dellec, Claire},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2312},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {99--106},
 publisher = {Association for Computational Linguistics},
 title = {Representation of complex terms in a vector space structured by an ontology for a normalization task},
 year = {2017}
}

@inproceedings{W17-2313,
 abstract = {Vector space methods that measure semantic similarity and relatedness often
rely on distributional information such as co--occurrence frequencies or
statistical measures of association to weight the importance of particular
co--occurrences. In this paper, we extend these methods by incorporating a
measure of semantic similarity based on a human curated taxonomy into a
second--order vector representation. This results in a measure of semantic
relatedness that combines both the contextual  information available in a
corpus--based vector space representation with the semantic knowledge found in
a biomedical ontology. Our results show that incorporating semantic similarity
into a second order co-occurrence matrices improves correlation with human
judgments for both similarity and relatedness, and that our method compares
favorably to various different word embedding methods that have recently been
evaluated on the same reference standards we have used.},
 address = {Vancouver, Canada,},
 author = {McInnes, Bridget and Pedersen, Ted},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2313},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {107--116},
 publisher = {Association for Computational Linguistics},
 title = {Improving Correlation with Human Judgments by Integrating Semantic Similarity with Second--Order Vectors},
 year = {2017}
}

@inproceedings{W17-2314,
 abstract = {The goal of active learning is to minimise the cost of producing an annotated
dataset, in which annotators are assumed to be perfect, i.e., they always
choose the correct labels. However, in practice, annotators are not infallible, and they are likely to assign incorrect labels to some instances. Proactive
learning is a generalisation of active learning that can model different kinds
of annotators. Although proactive learning has been applied to certain
labelling tasks, such as text classification, there is little work on its
application to named entity (NE) tagging. In this paper, we propose a proactive
learning method for producing NE annotated corpora, using two annotators with
different levels of expertise, and who charge different amounts based on their
levels of experience. To optimise both cost and annotation quality, we also
propose a mechanism to present multiple sentences to annotators at each
iteration. Experimental results for several corpora show that our method
facilitates the construction of high-quality NE labelled datasets at minimal
cost.},
 address = {Vancouver, Canada,},
 author = {Li, Maolin and Nguyen, Nhung and Ananiadou, Sophia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2314},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {117--125},
 publisher = {Association for Computational Linguistics},
 title = {Proactive Learning for Named Entity Recognition},
 year = {2017}
}

@inproceedings{W17-2315,
 abstract = {We propose a novel, Abstract Meaning Representation (AMR) based approach to
identifying molecular events/interactions in biomedical text. Our key
contributions are: (1) an empirical validation of our hypothesis that an event
is a subgraph of the AMR graph, (2) a neural network-based model that
identifies such an event subgraph given an AMR, and (3) a distant supervision
based approach to gather additional training data. We evaluate our approach on
the 2013 Genia Event Extraction dataset and show promising results.},
 address = {Vancouver, Canada,},
 author = {Rao, Sudha and Marcu, Daniel and Knight, Kevin and Daum\'{e} III, Hal},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2315},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {126--135},
 publisher = {Association for Computational Linguistics},
 title = {Biomedical Event Extraction using Abstract Meaning Representation},
 year = {2017}
}

@inproceedings{W17-2316,
 abstract = {Social media sites (e.g., Twitter) have been used for surveillance of drug
safety at the population level, but studies that focus on the effects of
medications on specific sets of individuals have had to rely on other sources
of data. Mining social media data for this in-formation would require the
ability to distinguish indications of personal medication in-take in this
media. Towards that end, this paper presents an annotated corpus that can be
used to train machine learning systems to determine whether a tweet that
mentions a medication indicates that the individual posting has taken that
medication at a specific time. To demonstrate the utility of the corpus as a
training set, we present baseline results of supervised classification.},
 address = {Vancouver, Canada,},
 author = {Klein, Ari and Sarker, Abeed and Rouhizadeh, Masoud and O'Connor, Karen and Gonzalez, Graciela},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2316},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {136--142},
 publisher = {Association for Computational Linguistics},
 title = {Detecting Personal Medication Intake in Twitter: An Annotated Corpus and Baseline Classification System},
 year = {2017}
}

@inproceedings{W17-2317,
 abstract = {We present an unsupervised context-sensitive spelling correction method for
clinical free-text
that uses word and character n-gram embeddings. Our method generates
misspelling replacement candidates and ranks them
according to their semantic fit, by calculating a weighted cosine similarity
between the vectorized representation of a candidate
and the misspelling context. We greatly outperform two baseline off-the-shelf
spelling correction tools on a manually annotated MIMIC-III test set, and counter the frequency bias of an optimized noisy channel model, showing that neural embeddings can be successfully exploited to include
context-awareness in a spelling correction model.},
 address = {Vancouver, Canada,},
 author = {Fivez, Pieter and Suster, Simon and Daelemans, Walter},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2317},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {143--148},
 publisher = {Association for Computational Linguistics},
 title = {Unsupervised Context-Sensitive Spelling Correction of Clinical Free-Text with Word and Character N-Gram Embeddings},
 year = {2017}
}

@inproceedings{W17-2318,
 abstract = {Approximately 80% to 95% of patients with Amyotrophic Lateral Sclerosis (ALS)
eventually develop speech impairments, such as defective articulation, slow
laborious speech and hypernasality. The relationship between impaired speech
and asymptomatic speech may be seen as a divergence from a baseline. This
relationship can be characterized in terms of measurable combinations of
phonological characteristics that are indicative of the degree to which the two
diverge. We demonstrate that divergence measurements based on phonological
characteristics of speech correlate with physiological assessments of ALS.
Speech-based assessments offer benefits over commonly-used physiological
assessments in that they are inexpensive, non-intrusive, and do not require
trained clinical personnel for administering and interpreting the results.},
 address = {Vancouver, Canada,},
 author = {Bhatia, Archna and Dorr, Bonnie and Hollingshead, Kristy and Phillips, Samuel L. and McKenzie, Barbara},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2318},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {149--158},
 publisher = {Association for Computational Linguistics},
 title = {Characterization of Divergence in Impaired Speech of ALS Patients},
 year = {2017}
}

@inproceedings{W17-2319,
 abstract = {In clinical dictation, speakers try to be as concise as possible to save time, often resulting in utterances without explicit punctuation commands.  Since the
end product of a dictated report, e.g. an out-patient letter, does require
correct orthography, including exact punctuation, the latter need to be
restored, preferably by automated means.  This paper describes a method for
punctuation restoration based on a state-of-the-art stack of NLP and machine
learning techniques including B-RNNs with an attention mechanism and late
fusion, as well as a feature extraction technique tailored to the processing of
medical terminology using a novel vocabulary reduction model.  To the best of
our knowledge, the resulting performance is superior to that reported in prior
art on similar tasks.},
 address = {Vancouver, Canada,},
 author = {Salloum, Wael and Finley, Greg and Edwards, Erik and Miller, Mark and Suendermann-Oeft, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2319},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {159--164},
 publisher = {Association for Computational Linguistics},
 title = {Deep Learning for Punctuation Restoration in Medical Reports},
 year = {2017}
}

@inproceedings{W17-2320,
 abstract = {Detecting negated concepts in clinical texts is an important part of NLP
information extraction systems. However, generalizability of negation systems
is lacking, as cross-domain experiments suffer dramatic performance losses. We
examine the performance of multiple unsupervised domain adaptation algorithms
on clinical negation detection, finding only modest gains that fall well short
of in-domain performance.},
 address = {Vancouver, Canada,},
 author = {Miller, Timothy and Bethard, Steven and Amiri, Hadi and Savova, Guergana},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2320},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {165--170},
 publisher = {Association for Computational Linguistics},
 title = {Unsupervised Domain Adaptation for Clinical Negation Detection},
 year = {2017}
}

@inproceedings{W17-2321,
 abstract = {The Precision Medicine Track in BioCre-ative VI aims to bring together the
Bi-oNLP community for a novel challenge focused on mining the biomedical
litera-ture in search of mutations and protein-protein interactions (PPI). In
order to support this track with an effective train-ing dataset with limited
curator time, the track organizers carefully reviewed Pub-Med articles from two
different sources: curated public PPI databases, and the re-sults of
state-of-the-art public text mining tools. We detail here the data collection, manual review and annotation process and describe this training corpus
charac-teristics. We also describe a corpus per-formance baseline. This
analysis will provide useful information to developers and researchers for
comparing and devel-oping innovative text mining approaches for the BioCreative
VI challenge and other Precision Medicine related applica-tions.},
 address = {Vancouver, Canada,},
 author = {Islamaj Dogan, Rezarta and Chatr-aryamontri, Andrew and Kim, Sun and Wei, Chih-Hsuan and Peng, Yifan and Comeau, Donald and Lu, Zhiyong},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2321},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {171--175},
 publisher = {Association for Computational Linguistics},
 title = {BioCreative VI Precision Medicine Track: creating a training corpus for mining protein-protein interactions affected by mutations},
 year = {2017}
}

@inproceedings{W17-2322,
 abstract = {Relation extraction methods are essential for creating robust text mining tools
to help researchers find useful knowledge in the vast published literature.
Easy-to-use and generalizable methods are needed to encourage an ecosystem in
which researchers can easily use shared resources and build upon each others'
methods. We present the Kindred Python package for relation extraction. It
builds upon methods from the most successful tools in the recent BioNLP Shared
Task to predict high-quality predictions with low computational cost. It also
integrates with PubAnnotation, PubTator, and BioNLP Shared Task data in order
to allow easy development and application of relation extraction models.},
 address = {Vancouver, Canada,},
 author = {Lever, Jake and Jones, Steven},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2322},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {176--183},
 publisher = {Association for Computational Linguistics},
 title = {Painless Relation Extraction with Kindred},
 year = {2017}
}

@inproceedings{W17-2323,
 abstract = {Distant supervision has been applied to automatically generate labeled data for
biomedical relation extraction. Noise exists in both positively and
negatively-labeled data and affects the performance of supervised machine
learning methods. In this paper, we propose three novel heuristics based on the
notion of proximity, trigger word and confidence of patterns to leverage
lexical and syntactic information to reduce the level of noise in the distantly
labeled data. Experiments on three different tasks, extraction of
protein-protein-interaction, miRNA-gene regulation relation and
protein-localization event, show that the proposed methods can improve the
F-score over the baseline by 6, 10 and 14 points for the three tasks, respectively. We also show that when the models are configured to output
high-confidence results, high precisions can be obtained using the proposed
methods, making them promising for facilitating manual curation for databases.},
 address = {Vancouver, Canada,},
 author = {Li, Gang and Wu, Cathy and Vijay-Shanker, K.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2323},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {184--193},
 publisher = {Association for Computational Linguistics},
 title = {Noise Reduction Methods for Distantly Supervised Biomedical Relation Extraction},
 year = {2017}
}

@inproceedings{W17-2324,
 abstract = {Electronic medical records (EMR) have largely replaced hand-written patient
files in healthcare. The growing pool of EMR data presents a significant
resource in medical research, but the U.S. Health Insurance Portability and
Accountability Act (HIPAA) mandates redacting medical records before performing
any analysis on the same. This process complicates obtaining medical data and
can remove much useful information from the record. As part of a larger project
involving ontology-driven medical processing, we employ a method of recognizing
protected health information (PHI) that maps to ontological terms. We then use
the relationships defined in the ontology to redact medical texts so that roles
and semantics of terms are retained without compromising anonymity. The method
is evaluated by clinical experts on several hundred medical documents, achieving up to a 98.8% f-score, and has already shown promise for retaining
semantic information in later processing.},
 address = {Vancouver, Canada,},
 author = {Polsley, Seth and Tahir, Atif and Raju, Muppala and Akinleye, Akintayo and Steward, Duane},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2324},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {194--199},
 publisher = {Association for Computational Linguistics},
 title = {Role-Preserving Redaction of Medical Records to Enable Ontology-Driven Processing},
 year = {2017}
}

@inproceedings{W17-2325,
 abstract = {Pain and anesthesia information are crucial elements to identifying
surgery-related processes and outcomes. However pain is not consistently
recorded in the electronic medical record. Even when recorded, the rich complex
granularity of the pain experience may be lost. Similarly, anesthesia
information is recorded using local electronic collection systems; though the
accuracy and completeness of the information is unknown. We propose an
annotation schema to capture pain, pain management, and anesthesia event
information.},
 address = {Vancouver, Canada,},
 author = {Yim, Wen-wai and Tedesco, Dario and Curtin, Catherine and Hernandez-Boussard, Tina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2325},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {200--205},
 publisher = {Association for Computational Linguistics},
 title = {Annotation of pain and anesthesia events for surgery-related processes and outcomes extraction},
 year = {2017}
}

@inproceedings{W17-2326,
 abstract = {Comparison sentences are very commonly used by authors in biomedical literature
to report results of experiments. In such comparisons, authors typically make
observations under two different scenarios. In this paper, we present a system
to automatically identify such comparative sentences and their components i.e.
the compared entities, the scale of the comparison and the aspect on which the
entities are being compared. Our methodology is based on dependencies obtained
by applying a parser to extract a wide range of comparison structures. We
evaluated our system for its effectiveness in identifying comparisons and their
components. The system achieved a F-score of 0.87 for comparison sentence
identification and 0.77-0.81 for identifying its components.},
 address = {Vancouver, Canada,},
 author = {Gupta, Samir and Mahmood, A.S.M. Ashique and Ross, Karen and Wu, Cathy and Vijay-Shanker, K.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2326},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {206--215},
 publisher = {Association for Computational Linguistics},
 title = {Identifying Comparative Structures in Biomedical Text},
 year = {2017}
}

@inproceedings{W17-2327,
 abstract = {In this paper we present a solution for tagging funding bodies and grants in
scientific articles using a combination of trained sequential learning models, namely conditional random fields (CRF), hidden markov models (HMM) and maximum
entropy models (MaxEnt), on a benchmark set created in-house. We apply the
trained models to address the BioASQ challenge 5c, which is a newly introduced
task that aims to solve the problem of funding information extraction from
scientific articles. Results in the dry-run data set of BioASQ task 5c show
that the suggested approach can achieve a micro-recall of more than 85% in
tagging both funding bodies and grants.},
 address = {Vancouver, Canada,},
 author = {Kayal, Subhradeep and Afzal, Zubair and Tsatsaronis, George and Katrenko, Sophia and Coupet, Pascal and Doornenbal, Marius and Gregory, Michelle},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2327},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {216--221},
 publisher = {Association for Computational Linguistics},
 title = {Tagging Funding Agencies and Grants in Scientific Articles using Sequential Learning Models},
 year = {2017}
}

@inproceedings{W17-2328,
 abstract = {We describe a Deep Learning approach to modeling the relevance of a document's
text to a query, applied to biomedical literature. Instead of mapping each
document and query to a common semantic space, we compute a variable-length
difference vector between the query and document which is then passed through a
deep convolution stage followed by a deep regression network to produce the
estimated probability of the document's relevance to the query. Despite the
small amount of training data, this approach produces a more robust predictor
than computing similarities between semantic vector representations of the
query and document, and also results in significant improvements over
traditional IR text factors. In the future, we plan to explore its application
in improving PubMed search.},
 address = {Vancouver, Canada,},
 author = {Mohan, Sunil and Fiorini, Nicolas and Kim, Sun and Lu, Zhiyong},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2328},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {222--231},
 publisher = {Association for Computational Linguistics},
 title = {Deep Learning for Biomedical Information Retrieval: Learning Textual Relevance from Click Logs},
 year = {2017}
}

@inproceedings{W17-2329,
 abstract = {We investigate if writers with dementia can be automatically distinguished from
those without by analyzing linguistic markers in written text, in the form of
blog posts. We have built a corpus of several thousand blog posts, some by
people with dementia and others by people with loved ones with dementia. We use
this dataset to train and test several machine learning methods, and achieve
prediction performance at a level far above the baseline.},
 address = {Vancouver, Canada,},
 author = {Masrani, Vaden and Murray, Gabriel and Field, Thalia and Carenini, Giuseppe},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2329},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {232--237},
 publisher = {Association for Computational Linguistics},
 title = {Detecting Dementia through Retrospective Analysis of Routine Blog Posts by Bloggers with Dementia},
 year = {2017}
}

@inproceedings{W17-2330,
 abstract = {Literature in Molecular Biology is abundant with linguistic metaphors. There
have been works in the past that attempt to draw parallels between linguistics
and biology, driven by the fundamental premise that proteins have a language of
their own. Since word detection is crucial to the decipherment of any  unknown
language, we attempt to establish a problem mapping from natural language text
to protein sequences at the level of words. Towards this end, we explore the
use of an unsupervised text segmentation algorithm to the task of extracting
"biological words" from protein sequences. In particular, we demonstrate the
effectiveness of using domain knowledge to complement data driven approaches in
the text segmentation task, as well as in its biological counterpart. We also
propose a novel extrinsic evaluation measure for protein words through protein
family classification.},
 address = {Vancouver, Canada,},
 author = {Ganesan, Devi and Tendulkar, Ashish V. and Chakraborti, Sutanu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2330},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {238--246},
 publisher = {Association for Computational Linguistics},
 title = {Protein Word Detection using Text Segmentation Techniques},
 year = {2017}
}

@inproceedings{W17-2331,
 abstract = {This paper evaluates the impact of various event extraction systems on
automatic pathway curation using the popular mTOR pathway. We quantify the
impact of training data sets as well as different machine learning classifiers
and show that some improve the quality of automatically extracted pathways.},
 address = {Vancouver, Canada,},
 author = {Kusa, Wojciech and Spranger, Michael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2331},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {247--256},
 publisher = {Association for Computational Linguistics},
 title = {External Evaluation of Event Extraction Classifiers for Automatic Pathway Curation: An extended study of the mTOR pathway},
 year = {2017}
}

@inproceedings{W17-2332,
 abstract = {Severe sepsis and septic shock are conditions that affect millions of patients
and have close to 50% mortality rate. Early identification of at-risk patients
significantly improves outcomes. Electronic surveillance tools have been
developed to monitor structured Electronic Medical Records and automatically
recognize early signs of sepsis. However, many sepsis risk factors (e.g.
symptoms and signs of infection) are often captured only in free text clinical
notes. In this study, we developed a method for automatic monitoring of nursing
notes for signs and symptoms of infection. We utilized a creative approach to
automatically generate an annotated dataset. The dataset was used to create a
Machine Learning model that achieved an F1-score ranging from 79 to 96%.},
 address = {Vancouver, Canada,},
 author = {Apostolova, Emilia and Velez, Tom},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2332},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {257--262},
 publisher = {Association for Computational Linguistics},
 title = {Toward Automated Early Sepsis Alerting: Identifying Infection Patients from Nursing Notes},
 year = {2017}
}

@inproceedings{W17-2333,
 abstract = {Assigning a standard ICD-9-CM code to disease symptoms in medical texts is an
important task in the medical domain. Automating this process could greatly
reduce the costs. However, the effectiveness of an automatic ICD-9-CM code
classifier faces a serious problem, which can be triggered by unbalanced
training data. Frequent diseases often have more training data, which helps its
classification to perform better than that of an infrequent disease. However, a
disease{\^a}s frequency does not necessarily reflect its importance. To resolve
this training data shortage problem, we propose to strategically draw data from
PubMed to enrich the training data when there is such need. We validate our
method on the CMC dataset, and the evaluation results indicate that our method
can significantly improve the code assignment classifiers' performance at the
macro-averaging level.},
 address = {Vancouver, Canada,},
 author = {Zhang, Danchen and He, Daqing and Zhao, Sanqiang and Li, Lei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2333},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {263--271},
 publisher = {Association for Computational Linguistics},
 title = {Enhancing Automatic ICD-9-CM Code Assignment for Medical Texts with PubMed},
 year = {2017}
}

@inproceedings{W17-2334,
 abstract = {In this paper, we present an analysis of feature extraction methods via
dimensionality reduction for the task of biomedical Word Sense Disambiguation
(WSD). We modify the vector representations in the 2-MRD WSD algorithm, and
evaluate four dimensionality reduction methods: Word Embeddings using
Continuous Bag of Words and Skip Gram, Singular Value Decomposition (SVD), and
Principal Component Analysis (PCA). We also evaluate the effects of vector size
on the performance of each of these methods. Results are evaluated on five
standard evaluation datasets (Abbrev.100, Abbrev.200, Abbrev.300, NLM-WSD, and
MSH-WSD). We find that vector sizes of 100 are sufficient for all techniques
except SVD, for which a vector size of 1500 is referred. We also show that SVD
performs on par with Word Embeddings for all but one dataset.},
 address = {Vancouver, Canada,},
 author = {Henry, Sam and Cuffy, Clint and McInnes, Bridget},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2334},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {272--281},
 publisher = {Association for Computational Linguistics},
 title = {Evaluating Feature Extraction Methods for Knowledge-based Biomedical Word Sense Disambiguation},
 year = {2017}
}

@inproceedings{W17-2335,
 abstract = {In this paper, we present pilot work on characterising the
documentation of electronic cigarettes (e-cigarettes) in the United
States Veterans Administration Electronic Health Record.  The Veterans
Health Administration is the largest health care system in the United States
with 1,233 health care facilities nationwide, serving 8.9 million
veterans per year.   We identified a random sample of 2000 Veterans
Administration patients, coded as current tobacco users, from 2008 to
2014.                       Using simple keyword matching techniques combined with
qualitative analysis, we investigated the prevalence and distribution of
e-cigarette terms in these clinical notes, discovering that for
current smokers, 11.9\% of  patient records contain an e-cigarette related
term.},
 address = {Vancouver, Canada,},
 author = {Mowery, Danielle and South, Brett and Patterson, Olga and Zhu, Shu-Hong and Conway, Mike},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2335},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {282--286},
 publisher = {Association for Computational Linguistics},
 title = {Investigating the Documentation of Electronic Cigarette Use in the Veteran Affairs Electronic Health Record: A Pilot Study},
 year = {2017}
}

@inproceedings{W17-2336,
 abstract = {Dictated medical reports very often feature
a preamble containing metainformation
about the report such as patient and
physician names, location and name of the
clinic, date of procedure, and so on. In the
medical transcription process, the preamble
is usually omitted from the final report, as it contains information already available
in the electronic medical record. We
present a method which is able to automatically
identify preambles in medical dictations.
The method makes use of stateof-
the-art NLP techniques including word
embeddings and Bi-LSTMs and achieves
preamble detection performance superior
to humans.},
 address = {Vancouver, Canada,},
 author = {Salloum, Wael and Finley, Greg and Edwards, Erik and Miller, Mark and Suendermann-Oeft, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2336},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {287--295},
 publisher = {Association for Computational Linguistics},
 title = {Automated Preamble Detection in Dictated Medical Reports},
 year = {2017}
}

@inproceedings{W17-2337,
 abstract = {Question answering, the identification of short accurate answers to users
questions, is a longstanding challenge widely studied over the last decades in the open
domain. However, it still requires further efforts in the biomedical domain. In
this paper, we describe our participation in phase B of task 5b in the 2017
BioASQ
challenge using our biomedical question answering system. Our system, dealing
with four types of questions (i.e., yes/no, factoid, list, and summary), is
based on
(1) a dictionary-based approach for generating the exact answers of yes/no
questions, (2) UMLS metathesaurus and term frequency metric for extracting the
exact answers of factoid and list questions, and (3) the BM25 model and UMLS
concepts for retrieving the ideal answers (i.e., paragraph-sized summaries).
Preliminary
results show that our system achieves good and competitive results in both
exact and
ideal answers extraction tasks as compared with the participating systems.},
 address = {Vancouver, Canada,},
 author = {Sarrouti, Mourad and Ouatik El Alaoui, Said},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2337},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {296--301},
 publisher = {Association for Computational Linguistics},
 title = {A Biomedical Question Answering System in BioASQ 2017},
 year = {2017}
}

@inproceedings{W17-2338,
 abstract = {Word embeddings are a crucial component in modern NLP. Pre-trained embeddings
released by different groups have been a major reason for their popularity.
However, they are trained on generic corpora, which limits their direct use for
domain specific tasks. In this paper, we propose a method to add task specific
information to pre-trained word embeddings. Such information can improve their
utility. We add information from medical coding data, as well as the first
level from the hierarchy of ICD-10 medical code set to different pre-trained
word embeddings. We adapt CBOW algorithm from the word2vec package for our
purpose. We evaluated our approach on five different pre-trained word
embeddings. Both the original word embeddings, and their modified versions (the
ones with added information) were used for automated review of medical coding.
The modified word embeddings give an improvement in f-score by 1% on the
5-fold evaluation on a private medical claims dataset. Our results show that
adding extra information is possible and beneficial for the task at hand.},
 address = {Vancouver, Canada,},
 author = {Patel, Kevin and Patel, Divya and Golakiya, Mansi and Bhattacharyya, Pushpak and Birari, Nilesh},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2338},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {302--306},
 publisher = {Association for Computational Linguistics},
 title = {Adapting Pre-trained Word Embeddings For Use In Medical Coding},
 year = {2017}
}

@inproceedings{W17-2339,
 abstract = {Many tasks in the biomedical domain require the assignment of one or more
predefined labels to input text, where the labels are a part of a hierarchical
structure (such as a taxonomy). The conventional approach is to use a
one-vs.-rest (OVR) classification setup, where a binary classifier is trained
for each label in the taxonomy or ontology where all instances not belonging to
the class are considered negative examples. The main drawbacks to this approach
are that dependencies between classes are not leveraged in the training and
classification process, and the additional computational cost of training
parallel classifiers. In this paper, we apply a new method for hierarchical
multi-label text classification that initializes a neural network model final
hidden layer such that it leverages label co-occurrence relations such as
hypernymy. This approach elegantly lends itself to hierarchical classification.
We evaluated this approach using two hierarchical multi-label text
classification tasks in the biomedical domain using both sentence- and
document-level classification. Our evaluation shows promising results for this
approach.},
 address = {Vancouver, Canada,},
 author = {Baker, Simon and Korhonen, Anna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2339},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {307--315},
 publisher = {Association for Computational Linguistics},
 title = {Initializing neural networks for hierarchical multi-label text classification},
 year = {2017}
}

@inproceedings{W17-2340,
 abstract = {Biomedical events describe complex interactions between various biomedical
entities. Event trigger is a word or a phrase which typically signifies the
occurrence of an event. Event trigger identification is an important first step
in all event extraction methods. However many of the current approaches either
rely on complex hand-crafted features or consider features only within a
window. In this paper we propose a method that takes the advantage of recurrent
neural network (RNN) to extract higher level features present across the
sentence. Thus hidden state representation of RNN along with word and entity
type embedding as features avoid relying on the complex hand-crafted features
generated using various NLP toolkits. Our experiments have shown to achieve
state-of-art F1-score on Multi Level Event Extraction (MLEE) corpus. We have
also performed category-wise analysis of the result and discussed the
importance of various features in trigger identification task.},
 address = {Vancouver, Canada,},
 author = {V S S Patchigolla, Rahul and Sahu, Sunil and Anand, Ashish},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2340},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {316--321},
 publisher = {Association for Computational Linguistics},
 title = {Biomedical Event Trigger Identification Using Bidirectional Recurrent Neural Network Based Models},
 year = {2017}
}

@inproceedings{W17-2341,
 abstract = {Token sequences are often used as the input for Convolutional Neural Networks
(CNNs) in natural language processing. However, they might not be an ideal
representation for time expressions, which are long, highly varied, and
semantically complex. We describe a method for representing time expressions
with single pseudo-tokens for CNNs. With this method, we establish a new
state-of-the-art result for a clinical temporal relation extraction task.},
 address = {Vancouver, Canada,},
 author = {Lin, Chen and Miller, Timothy and Dligach, Dmitriy and Bethard, Steven and Savova, Guergana},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2341},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {322--327},
 publisher = {Association for Computational Linguistics},
 title = {Representations of Time Expressions for Temporal Relation Extraction with Convolutional Neural Networks},
 year = {2017}
}

@inproceedings{W17-2342,
 abstract = {Diagnosis autocoding services and research intend to both improve the
productivity of clinical coders and the accuracy of the coding. It is an
important step in data analysis for funding and reimbursement, as well as
health services planning and resource allocation. We investigate the
applicability of deep learning at autocoding of radiology reports using
International Classification of Diseases (ICD). Deep learning methods are known
to require large training data. Our goal is to explore how to use these methods
when the training data is sparse, skewed and relatively small, and how their
effectiveness compares to conventional methods. We identify optimal parameters
that could be used in setting up a convolutional neural network for autocoding
with comparable results to that of conventional methods.},
 address = {Vancouver, Canada,},
 author = {Karimi, Sarvnaz and Dai, Xiang and Hassanzadeh, Hamedh and Nguyen, Anthony},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2342},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {328--332},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Diagnosis Coding of Radiology Reports: A Comparison of Deep Learning and Conventional Classification Methods},
 year = {2017}
}

@inproceedings{W17-2343,
 abstract = {We present the work-in-progress of automating the classification of
doctor-patient questions in the context of a simulated consultation with a
virtual patient. We classify questions according to the computational strategy
(rule-based or other) needed for looking up data in the clinical record. We
compare {\^a}traditional{\^a} machine learning methods (Gaussian and Multinomial
Naive Bayes, and Support Vector Machines) and a neural network classifier
(FastText). We obtained the best results with the SVM using semantic
annotations, whereas the neural classifier achieved promising results without
it.},
 address = {Vancouver, Canada,},
 author = {Campillos Llanos, Leonardo and Rosset, Sophie and Zweigenbaum, Pierre},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2343},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {333--341},
 publisher = {Association for Computational Linguistics},
 title = {Automatic classification of doctor-patient questions for a virtual patient record query task},
 year = {2017}
}

@inproceedings{W17-2344,
 abstract = {Question answering (QA) can support physicians and biomedical researchers to
find answers to their questions in the scientific literature. Such systems
process large collections of documents in real time and include many natural
language processing (NLP) procedures. We recently developed Olelo, a QA system
for biomedicine which includes various NLP components, such as question processing, document and passage retrieval, answer processing
and multi-document summarization. In this work, we present an evaluation of our
system on the the fifth BioASQ challenge. We participated with the current
state of the application and with an extension based on semantic role labeling
that we are currently investigating. In addition
to the BioASQ evaluation, we compared our system to other on-line biomedical QA
systems in terms of the response time and the quality of the answers.},
 address = {Vancouver, Canada,},
 author = {Neves, Mariana and Eckert, Fabian and Folkerts, Hendrik and Uflacker, Matthias},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2344},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {342--350},
 publisher = {Association for Computational Linguistics},
 title = {Assessing the performance of Olelo, a real-time biomedical question answering application},
 year = {2017}
}

@inproceedings{W17-2345,
 abstract = {Event detection from clinical notes has been traditionally solved with rule
based and statistical natural language processing (NLP) approaches that
require extensive domain knowledge and feature engineering. In this paper, we
have explored the feasibility of approaching this task with recurrent neural
networks, clinical word embeddings and introduced a hybrid architecture to
improve detection for entities with smaller representation in the dataset. A
comparative analysis is also done which reveals the complementary behavior of
neural networks and conditional random fields in clinical entity detection.},
 address = {Vancouver, Canada,},
 author = {Maharana, Adyasha and Yetisgen, Meliha},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2345},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {351--355},
 publisher = {Association for Computational Linguistics},
 title = {Clinical Event Detection with Hybrid Neural Architecture},
 year = {2017}
}

@inproceedings{W17-2346,
 abstract = {In this paper, we describe a system for automatic construction of user disease
progression timelines from their posts in online support groups using minimal
supervision. In recent years, several online support groups have been
established which has led to a huge increase in the amount of patient-authored
text available. Creating systems which can automatically extract important
medical events and create disease progression timelines for users from such
text can help in patient health monitoring as well as studying links between
medical events and users' participation in support groups. Prior work in this
domain has used manually constructed keyword sets to detect medical events. In
this work, our aim is to perform medical event detection using minimal
supervision in order to develop a more general timeline construction system.
Our system achieves an accuracy of 55.17%, which is 92\% of the performance
achieved by a supervised baseline system.},
 address = {Vancouver, Canada,},
 author = {Naik, Aakanksha and Bogart, Chris and Rose, Carolyn},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2346},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {356--364},
 publisher = {Association for Computational Linguistics},
 title = {Extracting Personal Medical Events for User Timeline Construction using Minimal Supervision},
 year = {2017}
}

@inproceedings{W17-2347,
 abstract = {We study and compare two different approaches to the task of automatic
assignment of predefined classes to clinical free-text narratives. In the first
approach this is treated as a traditional mention-level named-entity
recognition task, while the second approach treats it as a sentence-level
multi-label classification task. Performance comparison across these two
approaches is conducted in the form of sentence-level evaluation and
state-of-the-art methods for both approaches are evaluated. The experiments are
done on two data sets consisting of Finnish clinical text, manually annotated
with respect to the topics pain and acute confusion. Our results suggest that
the mention-level named-entity recognition approach outperforms sentence-level
classification overall, but the latter approach still manages to achieve the
best prediction scores on several annotation classes.},
 address = {Vancouver, Canada,},
 author = {Moen, Hans and Hakala, Kai and Mehryary, Farrokh and Peltonen, Laura-Maria and Salakoski, Tapio and Ginter, Filip and Salanter\"{a}, Sanna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2347},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {365--372},
 publisher = {Association for Computational Linguistics},
 title = {Detecting mentions of pain and acute confusion in Finnish clinical text},
 year = {2017}
}

@inproceedings{W17-2348,
 abstract = {This paper describes the participation of USTB\_PRIR team in the 2017 BioASQ 5B
on question answering, including document retrieval, snippet retrieval, and
concept retrieval task. We introduce different multimodal query processing
strategies to enrich query terms and assign different weights to them.
Specifically, sequential dependence model (SDM), pseudo-relevance feedback
(PRF), fielded sequential dependence model (FSDM) and Divergence from
Randomness model (DFRM) are respectively performed on different fields of
PubMed articles, sentences extracted from relevant articles, the five
terminologies or ontologies (MeSH, GO, Jochem, Uniprot and DO) to achieve
better search performances. Preliminary results show that our systems
outperform others in the document and snippet retrieval task in the first two
batches.},
 address = {Vancouver, Canada,},
 author = {Jin, Zan-Xia and Zhang, Bo-Wen and Fang, Fan and Zhang, Le-Le and Yin, Xu-Cheng},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2348},
 booktitle = {BioNLP 2017},
 month = {August},
 pages = {373--380},
 publisher = {Association for Computational Linguistics},
 title = {A Multi-strategy Query Processing Approach for Biomedical Question Answering: USTB\_PRIR at BioASQ 2017 Task 5B},
 year = {2017}
}

@inproceedings{W17-2401,
 abstract = {Authorship attribution is a natural language processing task that has been
widely studied, often by considering small order statistics. In this paper, we
explore a complex network approach to assign the authorship of texts based on
their mesoscopic representation, in an attempt to capture the flow of the
narrative.  Indeed, as reported in this work, such an approach allowed the
identification of the dominant narrative structure of the studied authors.
This has been achieved due to the ability of the mesoscopic approach to take
into account relationships between different, not necessarily adjacent, parts
of the text, which is able to capture the story flow. The potential of the
proposed approach has been illustrated through principal component analysis, a
comparison with the chance baseline method, and network visualization. Such
visualizations reveal individual characteristics of the authors, which can be
understood as a kind of calligraphy.},
 address = {Vancouver, Canada},
 author = {Marinho, Vanessa Queiroz and de Arruda, Henrique Ferraz and Sinelli, Thales and Costa, Luciano da Fontoura and Amancio, Diego Raphael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2401},
 booktitle = {Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {August},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {On the "Calligraphy" of Books},
 year = {2017}
}

@inproceedings{W17-2402,
 abstract = {Word senses are not static and may have temporal, spatial or corpus-specific
scopes. Identifying such scopes might benefit the existing WSD systems largely.
In this paper, while studying corpus specific word senses, we adapt three
existing predominant and novel-sense discovery algorithms to identify these
corpus-specific senses. We make use of text data available in the form of
millions of digitized books and newspaper archives as two different sources of
corpora and propose automated methods to identify corpus-specific word senses
at various time points. We conduct an extensive and thorough human judgement
experiment to rigorously evaluate and compare the performance of these
approaches. Post adaptation, the output of the three algorithms are in the same
format and the accuracy results are also comparable, with roughly 45-60% of the
reported corpus-specific senses being judged as genuine.},
 address = {Vancouver, Canada},
 author = {Mathew, Binny and Maity, Suman Kalyan and Sarkar, Pratip and Mukherjee, Animesh and Goyal, Pawan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2402},
 booktitle = {Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {August},
 pages = {11--20},
 publisher = {Association for Computational Linguistics},
 title = {Adapting predominant and novel sense discovery algorithms for identifying corpus-specific sense differences},
 year = {2017}
}

@inproceedings{W17-2403,
 abstract = {Recently, different systems which learn to populate and extend a knowledge base
(KB) from the web in different languages have been presented. Although a large
set of concepts should be learnt independently from the language used to read, there are facts which are expected to be more easily gathered in local language
(e.g., culture or geography). A system that merges KBs learnt in different
languages will benefit from the complementary information as long as common
beliefs are identified, as well as from redundancy present in web pages written
in different languages. In this paper, we deal with the problem of identifying
equivalent beliefs (or concepts) across language specific KBs, assuming that
they share the same ontology of categories and relations. In a case study with
two KBs independently learnt from different inputs, namely web pages written in
English and web pages written in Portuguese respectively, we report on the
results of two methodologies: an approach based on personalized PageRank and an
inference technique to find out common relevant paths through the KBs. The
proposed inference technique efficiently identifies relevant paths, outperforming the baseline (a dictionary-based classifier) in the vast majority
of tested categories.},
 address = {Vancouver, Canada},
 author = {Hern\'{a}ndez-Gonz\'{a}lez, Jer\'{o}nimo and Hruschka Jr., Estevam R. and Mitchell, Tom M.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2403},
 booktitle = {Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {August},
 pages = {21--29},
 publisher = {Association for Computational Linguistics},
 title = {Merging knowledge bases in different languages},
 year = {2017}
}

@inproceedings{W17-2404,
 abstract = {Word embeddings are high-dimensional vector representations of words and are
thus difficult to interpret. In order to deal with this, we introduce an
unsupervised parameter free method for creating a hierarchical graphical
clustering of the full ensemble of word vectors and show that this structure is
a geometrically meaningful representation of the original relations between the
words. This newly obtained representation can be used for better understanding
and thus improving the embedding algorithm and exhibits semantic meaning, so it can also be utilized in a variety of language processing tasks like
categorization or measuring similarity.},
 address = {Vancouver, Canada},
 author = {Trost, Thomas Alexander and Klakow, Dietrich},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2404},
 booktitle = {Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {August},
 pages = {30--38},
 publisher = {Association for Computational Linguistics},
 title = {Parameter Free Hierarchical Graph-Based Clustering for Analyzing Continuous Word Embeddings},
 year = {2017}
}

@inproceedings{W17-2405,
 abstract = {In this paper, we propose a novel method for multimodal word embedding, which
exploit a generalized framework of multi-view spectral graph embedding to take
into account visual appearances or scenes denoted by words in a corpus.
We evaluated our method through word similarity tasks and
a concept-to-image search task, having found that it provides word
representations that reflect visual information, while somewhat trading-off the
performance on the word similarity tasks. Moreover, we demonstrate that our
method captures multimodal linguistic regularities, which enable recovering
relational similarities between words and images by vector arithmetics.},
 address = {Vancouver, Canada},
 author = {Fukui, Kazuki and Oshikiri, Takamasa and Shimodaira, Hidetoshi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2405},
 booktitle = {Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {August},
 pages = {39--44},
 publisher = {Association for Computational Linguistics},
 title = {Spectral Graph-Based Method of Multimodal Word Embedding},
 year = {2017}
}

@inproceedings{W17-2406,
 abstract = {This paper introduces a new, graph-based view of the data of the FrameNet
project, which we hope will make it easier to understand the mixture of
semantic and syntactic information contained in FrameNet annotation.  We show
how English FrameNet and other Frame Semantic resources can be represented as
sets of interconnected graphs of frames, frame elements, semantic types, and
annotated instances of them in text.  We display examples of the new graphical
representation based on the annotations, which combine Frame Semantics and
Construction Grammar, thus capturing most of the syntax and semantics of each
sentence.  We consider how graph theory could help researchers to make better
use of FrameNet data for tasks such as automatic Frame Semantic role labeling, paraphrasing, and translation.              Finally, we describe the development of
FrameNet-like lexical resources for other languages in the current Multilingual
FrameNet project.  which seeks to discover cross-lingual alignments, both in
the lexicon (for frames and lexical units within frames) and across parallel or
comparable texts.  We conclude with an example showing graphically the semantic
and syntactic similarities and differences between parallel sentences in
English and Japanese.  We will release software for displaying such graphs from
the current data releases.},
 address = {Vancouver, Canada},
 author = {Baker, Collin and Ellsworth, Michael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2406},
 booktitle = {Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {August},
 pages = {45--50},
 publisher = {Association for Computational Linguistics},
 title = {Graph Methods for Multilingual FrameNets},
 year = {2017}
}

@inproceedings{W17-2407,
 abstract = {In this work, we aim at developing an extractive summarizer in the
multi-document setting. We implement a rank based sentence selection using
continuous vector representations along with key-phrases. Furthermore, we
propose a model to tackle summary coherence for increasing readability.  We
conduct experiments on the Document Understanding Conference (DUC) 2004
datasets using ROUGE toolkit. Our experiments demonstrate that the methods
bring significant improvements over the state of the art methods in terms of
informativity and coherence.},
 address = {Vancouver, Canada},
 author = {Nayeem, Mir Tafseer and Chali, Yllias},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2407},
 booktitle = {Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {August},
 pages = {51--56},
 publisher = {Association for Computational Linguistics},
 title = {Extract with Order for Coherent Multi-Document Summarization},
 year = {2017}
}

@inproceedings{W17-2408,
 abstract = {In this paper, we present an empirical study of email classification into
two main categories ``Business" and ``Personal".  We train on the Enron
email corpus, and test on the Enron and Avocado email corpora. We show
that information from the email exchange networks improves the
performance of classification. We represent the email exchange networks
as social networks with
graph structures. For this classification task, we extract social
networks features from the graphs in addition to lexical features from
email content and we compare the performance of SVM and Extra-Trees
classifiers using these features.  Combining graph features with lexical
features improves the performance on both classifiers. We also provide
manually annotated sets of the Avocado and Enron email corpora as
a supplementary contribution.},
 address = {Vancouver, Canada},
 author = {Alkhereyf, Sakhar and Rambow, Owen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2408},
 booktitle = {Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {August},
 pages = {57--65},
 publisher = {Association for Computational Linguistics},
 title = {Work Hard, Play Hard: Email Classification on the Avocado and Enron Corpora},
 year = {2017}
}

@inproceedings{W17-2409,
 abstract = {Derivational nouns are widely used in Sanskrit corpora and represent an
important cornerstone of productivity in the language. Currently there exists
no analyser that identifies the derivational nouns. We propose a semi
supervised approach for identification of derivational nouns in Sanskrit. We
not only identify the derivational words, but also link them to their
corresponding source words. Our novelty comes in the design of the network
structure for the task. The edge weights are featurised based on the phonetic, morphological, syntactic and the semantic similarity shared between the words
to be identified. We find that our model is effective for the task, even when
we employ a labelled dataset which is only 5 \% to that of the entire dataset.},
 address = {Vancouver, Canada},
 author = {Krishna, Amrith and Satuluri, Pavankumar and Ponnada, Harshavardhan and Ahmed, Muneeb and Arora, Gulab and Hiware, Kaustubh and Goyal, Pawan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2409},
 booktitle = {Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {August},
 pages = {66--75},
 publisher = {Association for Computational Linguistics},
 title = {A Graph Based Semi-Supervised Approach for Analysis of Derivational Nouns in Sanskrit},
 year = {2017}
}

@inproceedings{W17-2410,
 abstract = {Coherence is a crucial feature of text because
it is indispensable for conveying its
communication purpose and meaning to
its readers. In this paper, we propose an
unsupervised text coherence scoring based
on graph construction in which edges are
established between semantically similar
sentences represented by vertices. The
sentence similarity is calculated based on
the cosine similarity of semantic vectors
representing sentences. We provide three
graph construction methods establishing
an edge from a given vertex to a preceding
adjacent vertex, to a single similar
vertex, or to multiple similar vertices.
We evaluated our methods in the document
discrimination task and the insertion
task by comparing our proposed methods
to the supervised (Entity Grid) and unsupervised
(Entity Graph) baselines. In the
document discrimination task, our method
outperformed the unsupervised baseline
but could not do the supervised baseline, while in the insertion task, our method outperformed
both baselines.},
 address = {Vancouver, Canada},
 author = {Putra, Jan Wira Gotama and Tokunaga, Takenobu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2410},
 booktitle = {Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {August},
 pages = {76--85},
 publisher = {Association for Computational Linguistics},
 title = {Evaluating text coherence based on semantic similarity graph},
 year = {2017}
}

@inproceedings{W17-2501,
 abstract = {Despite numerous studies devoted to mining parallel material from bilingual
data, we have yet to see the resulting technologies wholeheartedly adopted by
professional translators and terminologists alike. I argue that this state of
affairs is mainly due to two factors: the emphasis published authors put on
models (even though data is as important), and the conspicuous lack of concern
for actual end-users.},
 address = {Vancouver, Canada},
 author = {Langlais, Phillippe},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2501},
 booktitle = {Proceedings of the 10th Workshop on Building and Using Comparable Corpora},
 month = {August},
 pages = {1--5},
 publisher = {Association for Computational Linguistics},
 title = {Users and Data: The Two Neglected Children of Bilingual Natural Language Processing Research},
 year = {2017}
}

@inproceedings{W17-2502,
 abstract = {This paper is a deep investigation of cross-language plagiarism detection
methods on a new recently introduced open dataset, which contains parallel and
com- parable collections of documents with multiple characteristics (different
genres, languages and sizes of texts). We investigate cross-language plagiarism
detection methods for 6 language pairs on 2 granularities of text units in
order to draw robust conclusions on the best methods while deeply analyzing
correlations across document styles and languages.},
 address = {Vancouver, Canada},
 author = {Ferrero, J\'{e}r\'{e}my and Besacier, Laurent and Schwab, Didier and Agn\`{e}s, Fr\'{e}d\'{e}ric},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2502},
 booktitle = {Proceedings of the 10th Workshop on Building and Using Comparable Corpora},
 month = {August},
 pages = {6--15},
 publisher = {Association for Computational Linguistics},
 title = {Deep Investigation of Cross-Language Plagiarism Detection Methods},
 year = {2017}
}

@inproceedings{W17-2503,
 abstract = {In this paper, we propose a novel two step algorithm for sentence alignment in
monolingual corpora using Unfolding Recursive Autoencoders. First, we use
unfolding recursive auto-encoders (RAE) to learn feature vectors for phrases in
syntactical tree of the sentence. To compare two sentences we use a similarity
matrix which has dimensions proportional to the size of the two sentences.
Since the similarity matrix generated to compare two sentences has varying
dimension due to different sentence lengths, a dynamic pooling layer is used to
map it to a matrix of fixed dimension. The resulting matrix is used to
calculate the similarity scores between the two sentences. The second step of
the algorithm captures the contexts in which the sentences occur in the
document by using a dynamic programming algorithm for global alignment.},
 address = {Vancouver, Canada},
 author = {Grover, Jeenu and Mitra, Pabitra},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2503},
 booktitle = {Proceedings of the 10th Workshop on Building and Using Comparable Corpora},
 month = {August},
 pages = {16--20},
 publisher = {Association for Computational Linguistics},
 title = {Sentence Alignment using Unfolding Recursive Autoencoders},
 year = {2017}
}

@inproceedings{W17-2504,
 abstract = {With the advent of informal electronic communications such as social media, colloquial languages that were historically unwritten are being written for the
first time in heavily code-switched environments. We present a method for
inducing portions of translation lexicons through the use of expert knowledge
in these settings where there are approximately zero resources available other
than a language informant, potentially not even large amounts of monolingual
data. We investigate inducing a Moroccan Darija-English translation lexicon via
French loanwords bridging into English and find that a useful lexicon is
induced for human-assisted translation and statistical machine translation.},
 address = {Vancouver, Canada},
 author = {Bloodgood, Michael and Strauss, Benjamin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2504},
 booktitle = {Proceedings of the 10th Workshop on Building and Using Comparable Corpora},
 month = {August},
 pages = {21--25},
 publisher = {Association for Computational Linguistics},
 title = {Acquisition of Translation Lexicons for Historically Unwritten Languages via Bridging Loanwords},
 year = {2017}
}

@inproceedings{W17-2505,
 abstract = {Twitter has become a rich source for linguistic data. Here, a possibility of
building a trilingual Latvian-Russian-English corpus of tweets from Riga, Latvia is investigated. Such a corpus, once constructed, might be of great use
for multiple purposes including  training machine translation models, examining
cross-lingual phenomena and studying the population of Riga. This pilot study
shows that it is feasible to build such a resource by collecting and analysing
a pilot corpus, which is made publicly available and can be used to construct a
large comparable corpus.},
 address = {Vancouver, Canada},
 author = {Milajevs, Dmitrijs},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2505},
 booktitle = {Proceedings of the 10th Workshop on Building and Using Comparable Corpora},
 month = {August},
 pages = {26--30},
 publisher = {Association for Computational Linguistics},
 title = {Toward a Comparable Corpus of Latvian, Russian and English Tweets},
 year = {2017}
}

@inproceedings{W17-2506,
 abstract = {This paper presents a methodology to extract parallel speech corpora based on
any language pair from dubbed movies, together with an application framework in
which some corresponding prosodic parameters are extracted. The obtained
parallel corpora are especially suitable for speech-to-speech translation
applications when a prosody transfer between source and target languages is
desired.},
 address = {Vancouver, Canada},
 author = {\"{O}ktem, Alp and Farr\'{u}s, Mireia and Wanner, Leo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2506},
 booktitle = {Proceedings of the 10th Workshop on Building and Using Comparable Corpora},
 month = {August},
 pages = {31--35},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Extraction of Parallel Speech Corpora from Dubbed Movies},
 year = {2017}
}

@inproceedings{W17-2507,
 abstract = {Parallel collections of documents are crucial resources for training and
evaluating
machine translation (MT) systems. Even though large collections are available
for
certain domains and language pairs, these are still scarce in the biomedical
domain. We developed a parallel corpus of clinical trials in Portuguese and
English. The documents are derived from the Brazilian Clinical Trials Registry
and the corpus currently contains a total of 1188 documents. In this paper, we
describe the corpus construction and discuss the quality of the translation and
the sentence alignment that we obtained.},
 address = {Vancouver, Canada},
 author = {Neves, Mariana},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2507},
 booktitle = {Proceedings of the 10th Workshop on Building and Using Comparable Corpora},
 month = {August},
 pages = {36--40},
 publisher = {Association for Computational Linguistics},
 title = {A parallel collection of clinical trials in Portuguese and English},
 year = {2017}
}

@inproceedings{W17-2508,
 abstract = {This article presents the STACCw system for the BUCC 2017 shared task on
parallel sentence extraction from comparable corpora. The original STACC
approach, based on set-theoretic operations over bags of words, had been
previously shown to be efficient and portable across domains and alignment
scenarios. Wedescribe an extension of this approach with a new weighting scheme
and show that it provides significant improvements on the datasets provided for
the shared task.},
 address = {Vancouver, Canada},
 author = {Azpeitia, Andoni and Etchegoyhen, Thierry and Mart\'{i}nez Garcia, Eva},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2508},
 booktitle = {Proceedings of the 10th Workshop on Building and Using Comparable Corpora},
 month = {August},
 pages = {41--45},
 publisher = {Association for Computational Linguistics},
 title = {Weighted Set-Theoretic Alignment of Comparable Sentences},
 year = {2017}
}

@inproceedings{W17-2509,
 abstract = {This paper describes our participation in BUCC 2017 shared task:
identifying parallel sentences in comparable corpora. Our goal is to leverage
continuous vector representations and distributional semantics with a minimal
use of external preprocessing and postprocessing tools. We report experiments
that were conducted after transmitting our results.},
 address = {Vancouver, Canada},
 author = {Gr\'{e}goire, Francis and Langlais, Philippe},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2509},
 booktitle = {Proceedings of the 10th Workshop on Building and Using Comparable Corpora},
 month = {August},
 pages = {46--50},
 publisher = {Association for Computational Linguistics},
 title = {BUCC 2017 Shared Task: a First Attempt Toward a Deep Learning Framework for Identifying Parallel Sentences in Comparable Corpora},
 year = {2017}
}

@inproceedings{W17-2510,
 abstract = {This paper describes the zNLP system for the BUCC 2017 shared task. Our system
identifies parallel sentence pairs in Chinese-English comparable corpora by
translating word-by-word Chinese sentences into English, using the search engine Solr to select near-parallel sentences and then by
using an SVM classifier to identify true parallel sentences from the previous
results. It obtains an F1-score of 45% (resp. 32%) on the test (training) set.},
 address = {Vancouver, Canada},
 author = {Zhang, Zheng and Zweigenbaum, Pierre},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2510},
 booktitle = {Proceedings of the 10th Workshop on Building and Using Comparable Corpora},
 month = {August},
 pages = {51--55},
 publisher = {Association for Computational Linguistics},
 title = {zNLP: Identifying Parallel Sentences in Chinese-English Comparable Corpora},
 year = {2017}
}

@inproceedings{W17-2511,
 abstract = {A Statistical Machine Translation (SMT) system is always trained using large
parallel corpus to produce effective translation. Not only is the corpus
scarce, it also involves a lot of manual labor and cost. Parallel corpus can be
prepared by employing comparable corpora where a pair of corpora is in two
different languages pointing to the same domain. In the present work, we try to
build a parallel corpus for French-English language pair from a given
comparable corpus. The data and the problem set are provided as part of the
shared task organized by BUCC 2017. We have proposed a system that first
translates the sentences by heavily relying on Moses and then group the
sentences based on sentence length similarity. Finally, the one to one sentence
selection was done based on Cosine Similarity algorithm.},
 address = {Vancouver, Canada},
 author = {Mahata, Sainik and Das, Dipankar and Bandyopadhyay, Sivaji},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2511},
 booktitle = {Proceedings of the 10th Workshop on Building and Using Comparable Corpora},
 month = {August},
 pages = {56--59},
 publisher = {Association for Computational Linguistics},
 title = {BUCC2017: A Hybrid Approach for Identifying Parallel Sentences in Comparable Corpora},
 year = {2017}
}

@inproceedings{W17-2512,
 abstract = {This paper presents the BUCC 2017 shared task on parallel sentence extraction
from comparable corpora.  It recalls the design of the datasets, presents their
final construction and statistics and the methods used to evaluate system
results.
13 runs were submitted to the shared task by 4 teams, covering three of the
four proposed language pairs: French-English (7 runs), German-English (3 runs), and Chinese-English (3 runs).
The best F-scores as measured against the gold standard were 0.84
(German-English), 0.80 (French-English), and 0.43 (Chinese-English).  Because
of the design of the dataset, in which not all gold parallel sentence pairs are
known, these are only minimum values.
We examined manually a small sample of the false negative sentence pairs for
the most precise French-English runs and estimated the number of parallel
sentence pairs not yet in the provided gold standard.  Adding them to the gold
standard leads to revised estimates for the French-English F-scores of at most
+1.5pt.  This suggests that the BUCC 2017 datasets provide a reasonable
approximate evaluation of the parallel sentence spotting task.},
 address = {Vancouver, Canada},
 author = {Zweigenbaum, Pierre and Sharoff, Serge and Rapp, Reinhard},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2512},
 booktitle = {Proceedings of the 10th Workshop on Building and Using Comparable Corpora},
 month = {August},
 pages = {60--67},
 publisher = {Association for Computational Linguistics},
 title = {Overview of the Second BUCC Shared Task: Spotting Parallel Sentences in Comparable Corpora},
 year = {2017}
}

@inproceedings{W17-2601,
 abstract = {Little attention has been paid to distributional compositional methods which
employ syntactically structured vector models. As word vectors belonging to
different syntactic categories                                      have incompatible
syntactic
distributions, no
trivial compositional operation can be applied to combine them into a new
compositional vector.
In this article, we generalize the method described by

Erk
and
Pad\'{o}
(2009) by
proposing a dependency-base framework that contextualize not only lemmas but
also selectional preferences.  The main contribution of the article is to
expand their model to a fully compositional framework in which syntactic
dependencies are put at the core of semantic composition.
We claim that semantic composition is mainly driven by syntactic dependencies.
Each syntactic dependency generates two new compositional vectors representing
the contextualized sense of the two related lemmas.  The sequential
application of the compositional operations associated to the dependencies
results in as many contextualized vectors as lemmas the composite expression
contains. At the end of the semantic process, we do not obtain a single
compositional vector representing the semantic denotation of the whole
composite expression, but one contextualized vector for each lemma of the whole
expression. Our method avoids the troublesome high-order tensor representations
by defining lemmas and selectional restrictions as first-order tensors (i.e.
standard vectors).
A corpus-based experiment is performed to both evaluate the quality of the
compositional vectors built with our strategy, and to compare them to other
approaches on distributional compositional semantics. The experiments show that
our dependency-based compositional method performs as  (or even better than)
the state-of-the-art.},
 address = {Vancouver, Canada},
 author = {Gamallo, Pablo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2601},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {1--9},
 publisher = {Association for Computational Linguistics},
 title = {Sense Contextualization in a Dependency-Based Compositional Distributional Model},
 year = {2017}
}

@inproceedings{W17-2602,
 abstract = {With a strikingly simple architecture and the ability to learn meaningful word
embeddings efficiently from texts containing billions of words, word2vec
remains one of the most popular neural language models used today. However, as
only a single embedding is learned for every word in the vocabulary, the model
fails to optimally represent words with multiple meanings and, additionally, it
is not possible to create embeddings for new (out-of-vocabulary) words on the
spot. Based on an intuitive interpretation of the continuous bag-of-words
(CBOW) word2vec model's negative sampling training objective in terms of
predicting context based similarities, we motivate an extension of the model we
call context encoders (ConEc). By multiplying the matrix of trained word2vec
embeddings with a word's average context vector, out-of-vocabulary (OOV)
embeddings and representations for words with multiple meanings can be created
based on the words' local contexts. The benefits of this approach are
illustrated by using these word embeddings as features in the CoNLL 2003 named
entity recognition (NER) task.},
 address = {Vancouver, Canada},
 author = {Horn, Franziska},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2602},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {10--14},
 publisher = {Association for Computational Linguistics},
 title = {Context encoders as a simple but powerful extension of word2vec},
 year = {2017}
}

@inproceedings{W17-2603,
 abstract = {We propose a recurrent neural model that generates natural-language questions
from documents, conditioned on answers. We show how to train the model using a
combination of supervised and reinforcement learning. After teacher forcing for
standard maximum likelihood training, we fine-tune the model using policy
gradient techniques to maximize several rewards that measure question quality.
Most notably, one of these rewards is the performance of a question-answering
system. We motivate question generation as a means to improve the performance
of question answering systems. Our model is trained and evaluated on the
recent question-answering dataset SQuAD.},
 address = {Vancouver, Canada},
 author = {Yuan, Xingdi and Wang, Tong and Gulcehre, Caglar and Sordoni, Alessandro and Bachman, Philip and Zhang, Saizheng and Subramanian, Sandeep and Trischler, Adam},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2603},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {15--25},
 publisher = {Association for Computational Linguistics},
 title = {Machine Comprehension by Text-to-Text Neural Question Generation},
 year = {2017}
}

@inproceedings{W17-2604,
 abstract = {A significant number of neural architectures for reading comprehension have
recently been developed and evaluated on large cloze-style datasets.
We present experiments supporting the emergence of "predication structure" in
the hidden state vectors of these readers.  More specifically, we provide
evidence that the hidden state vectors represent atomic formulas $\Phi[c]$
where $\Phi$ is a semantic property (predicate) and $c$ is a constant symbol
entity identifier.},
 address = {Vancouver, Canada},
 author = {Wang, Hai and Onishi, Takeshi and Gimpel, Kevin and McAllester, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2604},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {26--36},
 publisher = {Association for Computational Linguistics},
 title = {Emergent Predication Structure in Hidden State Vectors of Neural Readers},
 year = {2017}
}

@inproceedings{W17-2605,
 abstract = {Coreference resolution task demands comprehending a discourse, especially for
anaphoric mentions which require semantic information for resolving
antecedents. We investigate into how memory networks can be helpful for
coreference resolution when posed as question answering problem. The
comprehension capability of memory networks assists coreference resolution, particularly for the mentions that require semantic and context information. We
experiment memory networks for coreference resolution, with 4 synthetic
datasets generated for coreference resolu- tion with varying difficulty levels.
Our system{\^a}s performance is compared with a traditional coreference
resolution system to show why memory network can be promising for coreference
resolution.},
 address = {Vancouver, Canada},
 author = {Cheri, Joe and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2605},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {37--42},
 publisher = {Association for Computational Linguistics},
 title = {Towards Harnessing Memory Networks for Coreference Resolution},
 year = {2017}
}

@inproceedings{W17-2606,
 abstract = {Word representation models have achieved great success in natural language
processing tasks, such as relation classification. However, it does not always
work on informal text, and the morphemes of some misspelling  words may carry
important short-distance semantic information.
We propose a hybrid model, combining the merits of word-level and
character-level representations to learn better representations on informal
text.
Experiments on two dataset of relation classification, SemEval-2010 Task8 and a
large-scale one we compile from informal text, show that our model achieves a
competitive result in the former and state-of-the-art with the other.},
 address = {Vancouver, Canada},
 author = {Liang, Dongyun and Xu, Weiran and Zhao, Yinge},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2606},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {43--47},
 publisher = {Association for Computational Linguistics},
 title = {Combining Word-Level and Character-Level Representations for Relation Classification of Informal Text},
 year = {2017}
}

@inproceedings{W17-2607,
 abstract = {The goal of semantic parsing is to map natural language to a machine
interpretable meaning representation language (MRL). One of the constraints
that limits full exploration of deep learning technologies for semantic parsing
is the lack of sufficient annotation training data. In this paper, we propose
using sequence-to-sequence in a multi-task setup for semantic parsing with
focus on transfer learning. We explore three multi-task architectures for
sequence-to-sequence model and compare their performance with the independently
trained model. Our experiments show that the multi-task setup aids transfer
learning from an auxiliary task with large labeled data to the target task with
smaller labeled data. We see an absolute accuracy gain ranging from 1.0% to
4.4% in in our in-house data set and we also see good gains ranging from 2.5%
to 7.0% on the ATIS semantic parsing tasks with syntactic and semantic
auxiliary tasks.},
 address = {Vancouver, Canada},
 author = {Fan, Xing and Monti, Emilio and Mathias, Lambert and Dreyer, Markus},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2607},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {48--56},
 publisher = {Association for Computational Linguistics},
 title = {Transfer Learning for Neural Semantic Parsing},
 year = {2017}
}

@inproceedings{W17-2608,
 abstract = {Recent studies on knowledge base completion, the task of recovering missing
relationships based on recorded relations, demonstrate the importance of
learning embeddings from multi-step relations. However, due to the size of
knowledge bases, learning multi-step relations directly on top of observed
triplets could be costly. Hence, a manually designed procedure is often used
when training the models. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform multi-step inference implicitly through a
controller and shared memory. Without a human-designed inference procedure, IRNs use training data to learn to perform multi-step inference in an embedding
neural space through the shared memory and controller. While the inference
procedure does not explicitly operate on top of observed triplets, our proposed
model outperforms all previous approaches on the popular FB15k benchmark by
more than 5.7%.},
 address = {Vancouver, Canada},
 author = {Shen, Yelong and Huang, Po-Sen and Chang, Ming-Wei and Gao, Jianfeng},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2608},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {57--68},
 publisher = {Association for Computational Linguistics},
 title = {Modeling Large-Scale Structured Relationships with Shared Memory for Knowledge Base Completion},
 year = {2017}
}

@inproceedings{W17-2609,
 abstract = {Many papers have been published on the knowledge base completion task in the
past few years. Most of these introduce novel architectures for relation
learning that are evaluated on standard datasets like FB15k and WN18. This
paper shows that the accuracy of almost all models published on the FB15k can
be outperformed by an appropriately tuned baseline --- our reimplementation of
the DistMult model.
Our findings cast doubt on the claim that the performance improvements of
recent models are due to architectural changes as opposed to hyper-parameter
tuning or different training objectives.
This should prompt future research to re-consider how the performance of models
is evaluated and reported.},
 address = {Vancouver, Canada},
 author = {Kadlec, Rudolf and Bajgar, Ondrej and Kleindienst, Jan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2609},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {69--74},
 publisher = {Association for Computational Linguistics},
 title = {Knowledge Base Completion: Baselines Strike Back},
 year = {2017}
}

@inproceedings{W17-2610,
 abstract = {In this paper we  propose a neural network model with a novel Sequential
Attention layer that extends soft attention by assigning weights to words in an
input sequence in a way that takes into account not just how well that word
matches a query, but how well surrounding words match. We evaluate this
approach on the task of reading comprehension (on the Who did What and CNN
datasets) and show that it dramatically improves a strong baseline---the
Stanford Reader---and is competitive with the state of the art.},
 address = {Vancouver, Canada},
 author = {Brarda, Sebastian and Yeres, Philip and Bowman, Samuel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2610},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {75--80},
 publisher = {Association for Computational Linguistics},
 title = {Sequential Attention: A Context-Aware Alignment Function for Machine Reading},
 year = {2017}
}

@inproceedings{W17-2611,
 abstract = {Vector representations and vector space modeling (VSM) play a central role in
modern machine learning. We propose a novel approach to {\^a}vector similarity
searching{\^a} over dense semantic representations of words and documents that
can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity.
We show that this approach allows the indexing and querying of dense vectors in
text domains. This opens up exciting avenues for major efficiency gains, along
with simpler deployment, scaling and monitoring.
The end result is a fast and scalable vector database with a tunable trade-off
between vector search performance and quality, backed by a standard fulltext
engine such as Elasticsearch.
We empirically demonstrate its querying performance and quality by applying
this solution to the task of semantic searching over a dense vector
representation of the entire English Wikipedia.},
 address = {Vancouver, Canada},
 author = {Rygl, Jan and Pomik\'{a}lek, Jan and {\AA}eh{\AA}¯\v{r}ek, Radim and R{\AA}¯\v{z}i\v{c}ka, Michal and Novotn\'{y}, V\'{i}t and Sojka, Petr},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2611},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {81--90},
 publisher = {Association for Computational Linguistics},
 title = {Semantic Vector Encoding and Similarity Search Using Fulltext Search Engines},
 year = {2017}
}

@inproceedings{W17-2612,
 abstract = {Many domain adaptation approaches rely
on learning cross domain shared representations
to transfer the knowledge learned
in one domain to other domains. Traditional
domain adaptation only considers
adapting for one task. In this paper, we
explore multi-task representation learning
under the domain adaptation scenario. We
propose a neural network framework that
supports domain adaptation for multiple
tasks simultaneously, and learns shared
representations that better generalize for
domain adaptation. We apply the proposed
framework to domain adaptation
for sequence tagging problems considering
two tasks: Chinese word segmentation
and named entity recognition. Experiments
show that multi-task domain adaptation
works better than disjoint domain
adaptation for each task, and achieves the
state-of-the-art results for both tasks in the
social media domain.},
 address = {Vancouver, Canada},
 author = {Peng, Nanyun and Dredze, Mark},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2612},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {91--100},
 publisher = {Association for Computational Linguistics},
 title = {Multi-task Domain Adaptation for Sequence Tagging},
 year = {2017}
}

@inproceedings{W17-2613,
 abstract = {Word embeddings, which represent a word as a point in a vector space, have
become ubiquitous to several NLP tasks.
A recent line of work uses bilingual (two languages) corpora to learn a
different vector
for each sense of a word, by exploiting crosslingual signals to aid sense
identification.
We present a multi-view Bayesian non-parametric algorithm which improves
multi-sense wor
d embeddings by
(a) using multilingual (i.e., more than two languages) corpora to significantly
improve
sense embeddings beyond what one achieves with bilingual information, and (b)
uses a principled approach to learn a variable number of senses per word, in a
data-driven manner.
Ours is the first approach with the ability to leverage multilingual corpora
efficiently
for multi-sense representation learning.
Experiments show that multilingual training significantly improves performance
over monolingual and bilingual training, by allowing us to combine different
parallel corpora to
leverage multilingual context. Multilingual training yields comparable
performance to a
state of the art monolingual model trained on five times more training data.},
 address = {Vancouver, Canada},
 author = {Upadhyay, Shyam and Chang, Kai-Wei and Taddy, Matt and Kalai, Adam and Zou, James},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2613},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {101--110},
 publisher = {Association for Computational Linguistics},
 title = {Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context},
 year = {2017}
}

@inproceedings{W17-2614,
 abstract = {Tagging news articles or blog posts with relevant tags from a collection of
predefined ones is coined as document tagging in this work. Accurate tagging of
articles can benefit several downstream applications such as recommendation and
search. In this work, we propose a novel yet simple approach called DocTag2Vec
to accomplish this task. We substantially extend Word2Vec and Doc2Vec -- two
popular models for learning  distributed representation of words and documents.
In DocTag2Vec, we simultaneously learn the representation of words, documents, and tags in a joint vector space during training, and employ the simple
k-nearest neighbor search to predict tags for unseen documents. In contrast to
previous multi-label learning methods, DocTag2Vec directly deals with raw text
instead of provided feature vector, and in addition, enjoys advantages like the
learning of tag representation, and the ability of handling newly created tags.
To demonstrate the effectiveness of our approach, we conduct experiments on
several datasets and show promising results against state-of-the-art methods.},
 address = {Vancouver, Canada},
 author = {Chen, Sheng and Soni, Akshay and Pappu, Aasish and Mehdad, Yashar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2614},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {111--120},
 publisher = {Association for Computational Linguistics},
 title = {DocTag2Vec: An Embedding Based Multi-label Learning Approach for Document Tagging},
 year = {2017}
}

@inproceedings{W17-2615,
 abstract = {Recently Le \& Mikolov described two log-linear models, called Paragraph Vector, that can be used to learn state-of-the-art distributed representations of
documents. Inspired by this work, we present Binary Paragraph Vector models:
simple neural networks that learn short binary codes for fast information
retrieval. We show that binary paragraph vectors outperform autoencoder-based
binary codes, despite using fewer bits. We also evaluate their precision in
transfer learning settings, where binary codes are inferred for documents
unrelated to the training corpus. Results from these experiments indicate that
binary paragraph vectors can capture semantics relevant for various
domain-specific documents. Finally, we present a model that simultaneously
learns short binary codes and longer, real-valued representations. This model
can be used to rapidly retrieve a short list of highly relevant documents from
a large document collection.},
 address = {Vancouver, Canada},
 author = {Grzegorczyk, Karol and Kurdziel, Marcin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2615},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {121--130},
 publisher = {Association for Computational Linguistics},
 title = {Binary Paragraph Vectors},
 year = {2017}
}

@inproceedings{W17-2616,
 abstract = {A novel character-level neural language model is proposed in this paper. The
proposed model incorporates a biologically inspired temporal hierarchy in the
architecture for representing multiple compositions of language in order to
handle longer sequences for the character-level language model. The temporal
hierarchy is introduced in the language model by utilizing a Gated Recurrent
Neural Network with multiple timescales. The proposed model incorporates a
timescale adaptation mechanism for enhancing the performance of the language
model. We evaluate our proposed model using the popular Penn Treebank and Text8
corpora. The experiments show that the use of multiple timescales in a Neural
Language Model (NLM) enables improved performance despite having fewer
parameters and with no additional computation requirements. Our experiments
also demonstrate the ability of the adaptive temporal hierarchies to represent
multiple compositonality without the help of complex hierarchical architectures
and shows that better representation of the longer sequences lead to enhanced
performance of the probabilistic language model.},
 address = {Vancouver, Canada},
 author = {Moirangthem, Dennis Singh and Son, Jegyung and Lee, Minho},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2616},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {131--138},
 publisher = {Association for Computational Linguistics},
 title = {Representing Compositionality based on Multiple Timescales Gated Recurrent Neural Networks with Adaptive Temporal Hierarchy for Character-Level Language Models},
 year = {2017}
}

@inproceedings{W17-2617,
 abstract = {We propose a simple log-bilinear softmax-based model to deal with vocabulary
expansion in machine translation. Our model uses word embeddings trained on
significantly large unlabelled monolingual
corpora and learns over a fairly small, word-to-word bilingual dictionary.
Given an out-of-vocabulary source word, the model generates a probabilistic
list of possible translations in the target language using the trained
bilingual embeddings. We integrate these translation options into a standard
phrase-based statistical machine translation system and obtain consistent
improvements in translation quality on the English--Spanish language pair. When
tested over an out-of-domain testset, we get a significant improvement of 3.9
BLEU points.},
 address = {Vancouver, Canada},
 author = {Madhyastha, Pranava Swaroop and Espa\~{n}a-Bonet, Cristina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2617},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {139--145},
 publisher = {Association for Computational Linguistics},
 title = {Learning Bilingual Projections of Embeddings for Vocabulary Expansion in Machine Translation},
 year = {2017}
}

@inproceedings{W17-2618,
 abstract = {Automatic completion of frame-to-frame (F2F) relations in the FrameNet (FN)
hierarchy has received little attention, although they incorporate meta-level
commonsense knowledge and are used in downstream approaches. We address the
problem of sparsely annotated F2F relations. First, we examine whether the
manually defined F2F relations emerge from text by learning text-based frame
embeddings. Our analysis reveals insights about the difficulty of
reconstructing F2F relations purely from text. Second, we present different
systems for predicting F2F relations; our best-performing one uses the FN
hierarchy to train on and to ground embeddings in. A comparison of systems and
embeddings exposes the crucial influence of knowledge-based embeddings to a
system{\^a}s performance in predicting F2F relations.},
 address = {Vancouver, Canada},
 author = {Botschen, Teresa and Mousselly Sergieh, Hatem and Gurevych, Iryna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2618},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {146--156},
 publisher = {Association for Computational Linguistics},
 title = {Prediction of Frame-to-Frame Relations in the FrameNet Hierarchy with Frame Embeddings},
 year = {2017}
}

@inproceedings{W17-2619,
 abstract = {In this paper, we use the framework of neural machine translation to learn
joint sentence representations across six very different languages. Our aim is
that a representation which is independent of the language, is likely to
capture the underlying semantics.  We define a new cross-lingual similarity
measure, compare up to 1.4M sentence representations and study the
characteristics of close sentences.
We provide experimental evidence that sentences that are close in embedding
space are indeed semantically highly related, but often have quite different
structure and syntax.  These relations also hold when comparing sentences in
different languages.},
 address = {Vancouver, Canada},
 author = {Schwenk, Holger and Douze, Matthijs},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2619},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {157--167},
 publisher = {Association for Computational Linguistics},
 title = {Learning Joint Multilingual Sentence Representations with Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-2620,
 abstract = {End-to-end training of automated speech recognition (ASR) systems requires
massive data and compute resources. We explore transfer learning based on model
adaptation as an approach for training ASR models under constrained GPU memory, throughput and training data. We conduct several systematic experiments
adapting a Wav2Letter convolutional neural network originally trained for
English ASR to the German language. We show that this technique allows faster
training on consumer-grade resources while requiring less training data in
order to achieve the same accuracy, thereby lowering the cost of training ASR
models in other languages. Model introspection revealed that small adaptations
to the network's weights were sufficient for good performance, especially for
inner layers.},
 address = {Vancouver, Canada},
 author = {Kunze, Julius and Kirsch, Louis and Kurenkov, Ilia and Krug, Andreas and Johannsmeier, Jens and Stober, Sebastian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2620},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {168--177},
 publisher = {Association for Computational Linguistics},
 title = {Transfer Learning for Speech Recognition on a Budget},
 year = {2017}
}

@inproceedings{W17-2621,
 abstract = {Learning word representations to capture the semantics and compositionality of
language has received much research interest in natural language processing.
Beyond the popular vector space models, matrix representations for words have
been proposed, since then, matrix multiplication can serve as natural
composition operation. In this work, we investigate the problem of learning
matrix representations of words. We present a learning approach for
compositional matrix-space models for the task of sentiment analysis. We show
that our approach, which learns the matrices gradually in two steps, outperforms other approaches and a gradient-descent baseline in terms of
quality and computational cost.},
 address = {Vancouver, Canada},
 author = {Asaadi, Shima and Rudolph, Sebastian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2621},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {178--185},
 publisher = {Association for Computational Linguistics},
 title = {Gradual Learning of Matrix-Space Models of Language for Sentiment Analysis},
 year = {2017}
}

@inproceedings{W17-2622,
 abstract = {In this paper, we introduce the novel concept of densely connected layers into
recurrent neural networks. We evaluate our proposed architecture on the Penn
Treebank language modeling task. We show that we can obtain similar perplexity
scores with six times fewer parameters compared to a standard stacked 2-
layer LSTM model trained with dropout (Zaremba et al., 2014). In contrast with
the current usage of skip connections, we show that densely connecting only a
few
stacked layers with skip connections already yields significant perplexity
reductions.},
 address = {Vancouver, Canada},
 author = {Godin, Fr\'{e}deric and Dambre, Joni and De Neve, Wesley},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2622},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {186--190},
 publisher = {Association for Computational Linguistics},
 title = {Improving Language Modeling using Densely Connected Recurrent Neural Networks},
 year = {2017}
}

@inproceedings{W17-2623,
 abstract = {We present NewsQA, a challenging machine comprehension dataset of over 100,000
human-generated question-answer pairs. Crowdworkers supply questions and
answers based on a set of over 10,000 news articles from CNN, with answers
consisting of spans of text in the articles. We collect this dataset through a
four-stage process designed to solicit exploratory questions that require
reasoning. Analysis confirms that NewsQA demands abilities beyond simple
word matching and recognizing textual entailment. We measure human performance
on the dataset and compare it to several strong neural models. The performance
gap between humans and machines (13.3% F1) indicates that significant progress
can be made on NewsQA through future research. The dataset is freely available
online.},
 address = {Vancouver, Canada},
 author = {Trischler, Adam and Wang, Tong and Yuan, Xingdi and Harris, Justin and Sordoni, Alessandro and Bachman, Philip and Suleman, Kaheer},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2623},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {191--200},
 publisher = {Association for Computational Linguistics},
 title = {NewsQA: A Machine Comprehension Dataset},
 year = {2017}
}

@inproceedings{W17-2624,
 abstract = {Language in social media is a dynamic system, constantly evolving and adapting, with words and concepts rapidly emerging, disappearing, and changing their
meaning. These changes can be estimated using word representations in context, over time and across locations. A number of methods have been proposed to track
these spatiotemporal changes but no general method exists to evaluate the
quality of these representations. Previous work largely focused on qualitative
evaluation, which we improve by proposing a set of visualizations that
highlight changes in text representation over both space and time. We
demonstrate usefulness of novel spatiotemporal representations to explore and
characterize specific aspects of the corpus of tweets collected from European
countries over a two-week period centered around the terrorist attacks in
Brussels in March 2016. In addition, we quantitatively evaluate spatiotemporal
representations by feeding them into a downstream classification task -- event
type prediction. Thus, our work is the first to provide both intrinsic
(qualitative) and extrinsic (quantitative) evaluation of text representations
for spatiotemporal trends.},
 address = {Vancouver, Canada},
 author = {Phillips, Lawrence and Shaffer, Kyle and Arendt, Dustin and Hodas, Nathan and Volkova, Svitlana},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2624},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {201--210},
 publisher = {Association for Computational Linguistics},
 title = {Intrinsic and Extrinsic Evaluation of Spatiotemporal Text Representations in Twitter Streams},
 year = {2017}
}

@inproceedings{W17-2625,
 abstract = {We study the skip-thought model with neighborhood information as weak
supervision. More specifically, we propose a skip-thought neighbor model to
consider the adjacent sentences as a neighborhood. We train our skip-thought
neighbor model on a large corpus with continuous sentences, and then evaluate
the trained model on 7 tasks, which include semantic relatedness, paraphrase
detection, and classification benchmarks. Both quantitative comparison and
qualitative investigation are conducted. We empirically show that, our
skip-thought neighbor model performs as well as the skip-thought model on
evaluation tasks. In addition, we found that, incorporating an autoencoder path
in our model didn't aid our model to perform better, while it hurts the
performance of the skip-thought model.},
 address = {Vancouver, Canada},
 author = {Tang, Shuai and Jin, Hailin and Fang, Chen and Wang, Zhaowen and de Sa, Virginia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2625},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {211--218},
 publisher = {Association for Computational Linguistics},
 title = {Rethinking Skip-thought: A Neighborhood based Approach},
 year = {2017}
}

@inproceedings{W17-2626,
 abstract = {Recently, resources and tasks were proposed to go beyond state tracking in
dialogue systems. An example is the frame tracking task, which requires
recording multiple frames, one for each user goal set during the dialogue. This
allows a user, for instance, to compare items corresponding to different goals.
This paper proposes a model which takes as input the list of frames created so
far during the dialogue, the current user utterance as well as the dialogue
acts, slot types, and slot values associated with this utterance. The model
then outputs the frame being referenced by each  triple of dialogue act, slot
type, and slot value. We show that on the recently published Frames dataset, this model significantly outperforms a previously proposed rule-based baseline.
In addition, we propose an extensive analysis of the frame tracking task by
dividing it into sub-tasks and assessing their difficulty with respect to our
model.},
 address = {Vancouver, Canada},
 author = {Schulz, Hannes and Zumer, Jeremie and El Asri, Layla and Sharma, Shikhar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2626},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {219--227},
 publisher = {Association for Computational Linguistics},
 title = {A Frame Tracking Model for Memory-Enhanced Dialogue Systems},
 year = {2017}
}

@inproceedings{W17-2627,
 abstract = {We investigate the integration of a planning mechanism into an encoder-decoder
architecture with attention. We develop a model that can plan ahead when it
computes alignments between the source and target sequences not only for a
single time-step but for the next k time-steps as well by constructing a matrix
of proposed future alignments and a commitment vector that governs whether to
follow or recompute the plan. This mechanism is inspired by strategic attentive
reader and writer (STRAW) model, a recent neural architecture for planning with
hierarchical reinforcement learning that can also learn higher level temporal
abstractions. Our proposed model is end-to-end trainable with differentiable
operations. We show that our model outperforms strong baselines on
character-level translation task from WMT'15 with fewer parameters and computes
alignments that are qualitatively intuitive.},
 address = {Vancouver, Canada},
 author = {Gulcehre, Caglar and Dutil, Francis and Trischler, Adam and Bengio, Yoshua},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2627},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {228--234},
 publisher = {Association for Computational Linguistics},
 title = {Plan, Attend, Generate: Character-Level Neural Machine Translation with Planning},
 year = {2017}
}

@inproceedings{W17-2628,
 abstract = {We investigate the pertinence of methods from algebraic topology for text data
analysis. These methods enable the development of mathematically-principled
isometric-invariant mappings from a set of vectors to a document embedding, which is stable with respect to the geometry of the document in the selected
metric space.
In this work, we evaluate the utility of these topology-based document
representations in traditional NLP tasks, specifically document clustering and
sentiment classification.
We find that the embeddings do not benefit text analysis. In fact, performance
is worse than simple techniques like tf-idf, indicating that the geometry of
the document does not provide enough variability for classification on the
basis of topic or sentiment in the chosen datasets.},
 address = {Vancouver, Canada},
 author = {Michel, Paul and Ravichander, Abhilasha and Rijhwani, Shruti},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2628},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {235--240},
 publisher = {Association for Computational Linguistics},
 title = {Does the Geometry of Word Embeddings Help Document Classification? A Case Study on Persistent Homology-Based Representations},
 year = {2017}
}

@inproceedings{W17-2629,
 abstract = {Generative Adversarial Networks (GANs) have gathered a lot of attention from
the computer vision community, yielding impressive results for image
generation. Advances in the adversarial generation of natural language from
noise however are not commensurate with the progress made in generating images, and still lag far behind likelihood based methods. In this paper, we take a
step towards generating natural language  with a GAN objective alone. We
introduce a simple baseline that addresses the discrete output space problem
without relying on gradient estimators and show that it is able to achieve
state-of-the-art results on a Chinese poem generation dataset. We present
quantitative results on generating sentences from context-free and
probabilistic context-free grammars, and qualitative language modeling results.
A conditional version is also described that can generate sequences conditioned
on sentence characteristics.},
 address = {Vancouver, Canada},
 author = {Subramanian, Sandeep and Rajeswar, Sai and Dutil, Francis and Pal, Chris and Courville, Aaron},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2629},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {241--251},
 publisher = {Association for Computational Linguistics},
 title = {Adversarial Generation of Natural Language},
 year = {2017}
}

@inproceedings{W17-2630,
 abstract = {Deep neural networks
have advanced the state of the art
in named entity recognition.
However, under typical training procedures, advantages over classical methods
emerge only with large datasets.
As a result,  deep learning is employed
only when large public datasets or a large budget
for manually labeling data is available.
In this work, we show otherwise:
by combining deep learning with active learning, we can outperform classical methods
even with a significantly smaller amount of training data.},
 address = {Vancouver, Canada},
 author = {Shen, Yanyao and Yun, Hyokun and Lipton, Zachary and Kronrod, Yakov and Anandkumar, Animashree},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2630},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {252--256},
 publisher = {Association for Computational Linguistics},
 title = {Deep Active Learning for Named Entity Recognition},
 year = {2017}
}

@inproceedings{W17-2631,
 abstract = {Many recent advances in deep learning for natural language processing have come
at increasing computational cost, but the power of these state-of-the-art
models is not needed for every example in a dataset. We demonstrate two
approaches to reducing unnecessary computation in cases where a fast but weak
baseline classier and a stronger, slower model are both available. Applying an
AUC-based metric to the task of sentiment classification, we find significant
efficiency gains with both a probability-threshold method for reducing
computational cost and one that uses a secondary decision network.},
 address = {Vancouver, Canada},
 author = {Johansen, Alexander and Socher, Richard},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2631},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {257--264},
 publisher = {Association for Computational Linguistics},
 title = {Learning when to skim and when to read},
 year = {2017}
}

@inproceedings{W17-2632,
 abstract = {We present models for embedding words in the context of surrounding words.
Such models, which we refer to as token embeddings, represent the
characteristics of a word that are specific to a given context, such as word
sense, syntactic category, and semantic role. We explore simple, efficient
token embedding models based on standard neural network architectures. We learn
token embeddings on a large amount of unannotated text and evaluate them as
features for part-of-speech taggers and dependency parsers trained on much
smaller amounts of annotated data.  We find that predictors endowed with token
embeddings consistently outperform baseline predictors across a range of
context window and training set sizes.},
 address = {Vancouver, Canada},
 author = {Tu, Lifu and Gimpel, Kevin and Livescu, Karen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2632},
 booktitle = {Proceedings of the 2nd Workshop on Representation Learning for NLP},
 month = {August},
 pages = {265--275},
 publisher = {Association for Computational Linguistics},
 title = {Learning to Embed Words in Context for Syntactic Tasks},
 year = {2017}
}

@inproceedings{W17-2701,
 abstract = {We propose a method to aggregate and organize a large, multi-source dataset of
news articles into a collection of major stories, and automatically name and
visualize these stories in a working system. The approach is able to run
online, as new articles are added, processing 4 million news articles from 20
news sources, and extracting 80000 major stories, some of which span several
years. The visual interface consists of lanes of timelines, each annotated with
information that is deemed important for the story, including extracted
quotations. The working system allows a user to search and navigate 8 years of
story information.},
 address = {Vancouver, Canada},
 author = {Laban, Philippe and Hearst, Marti},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2701},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {1--9},
 publisher = {Association for Computational Linguistics},
 title = {newsLens: building and visualizing long-ranging news stories},
 year = {2017}
}

@inproceedings{W17-2702,
 abstract = {Detecting events from social media data has important applications in public
security, political issues, and public health. Many studies have focused on
detecting specific or unspecific events from Twitter streams. However, not much
attention has been paid to detecting changes, and their impact, in online
conversations related to an event. We propose methods for detecting such
changes, using clustering of temporal profiles of hashtags, and three change
point detection algorithms. The methods were tested on two Twitter datasets:
one covering the 2014 Ottawa shooting event, and one covering the Sochi winter
Olympics. We compare our approach to a baseline consisting of detecting change
from raw counts in the conversation. We show that our method produces large
gains in change detection accuracy on both datasets.},
 address = {Vancouver, Canada},
 author = {Wang, Yunli and Goutte, Cyril},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2702},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {10--14},
 publisher = {Association for Computational Linguistics},
 title = {Detecting Changes in Twitter Streams using Temporal Clusters of Hashtags},
 year = {2017}
}

@inproceedings{W17-2703,
 abstract = {Recent methods for Event Detection focus on Deep Learning for automatic feature
generation and feature ranking. However, most of those approaches fail to
exploit rich semantic information, which results in relatively poor recall.
This paper is a small \& focused contribution, where we introduce an Event
Detection and classification system, based on deep semantic information
retrieved from a frame-semantic parser. Our experiments show that our system
achieves higher recall than state-of-the-art systems. Further, we claim that
enhancing our system with deep learning techniques like feature ranking can
achieve even better results, as it can benefit from both approaches.},
 address = {Vancouver, Canada},
 author = {Spiliopoulou, Evangelia and Hovy, Eduard and Mitamura, Teruko},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2703},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {15--20},
 publisher = {Association for Computational Linguistics},
 title = {Event Detection Using Frame-Semantic Parser},
 year = {2017}
}

@inproceedings{W17-2704,
 abstract = {Event knowledge represents the knowledge of causal and temporal relations
between events. Shared arguments of event knowledge encode patterns of role
shifting in successive events. A two-stage framework was proposed for the task
of Japanese event knowledge acquisition, in which related event pairs are first extracted, and shared arguments are then
identified to form the complete event knowledge. This paper focuses on the
second stage of this framework, and proposes a method to improve the shared
argument identification of related event pairs. We constructed a gold dataset
for shared argument learning. By evaluating our system on this gold dataset, we
found that our proposed model outperformed the baseline models by a large
margin.},
 address = {Vancouver, Canada},
 author = {Huang, Yin Jou and Kurohashi, Sadao},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2704},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {21--30},
 publisher = {Association for Computational Linguistics},
 title = {Improving Shared Argument Identification in Japanese Event Knowledge Acquisition},
 year = {2017}
}

@inproceedings{W17-2705,
 abstract = {Recent studies have shown that word embedding models can be used to trace
time-related (diachronic) semantic shifts in particular words. In this paper, we evaluate some of these approaches on the new task of predicting the dynamics
of global armed conflicts on a year-to-year basis, using a dataset from the
conflict research field as the gold standard and the Gigaword news corpus as
the training data. The results show that much work still remains in extracting
`cultural' semantic shifts from diachronic word embedding models. At the same
time, we present a new task complete with an evaluation set and introduce the
`anchor words' method which outperforms previous approaches on this set.},
 address = {Vancouver, Canada},
 author = {Kutuzov, Andrey and Velldal, Erik and {\O}vrelid, Lilja},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2705},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {31--36},
 publisher = {Association for Computational Linguistics},
 title = {Tracing armed conflicts with diachronic word embedding models},
 year = {2017}
}

@inproceedings{W17-2706,
 abstract = {In this paper we describe the ongoing work on the Circumstantial Event Ontology
(CEO), a newly developed ontology for calamity events that models semantic
circumstantial relations between event classes. The circumstantial relations
are designed manually, based on the shared properties of each event class. We
discuss and contrast two types of event circumstantial relations: semantic
circumstantial relations and episodic circumstantial relations. Further, we
show the metamodel and the current contents of the ontology and outline the
evaluation of the CEO.},
 address = {Vancouver, Canada},
 author = {Segers, Roxane and Caselli, Tommaso and Vossen, Piek},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2706},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {37--41},
 publisher = {Association for Computational Linguistics},
 title = {The Circumstantial Event Ontology (CEO)},
 year = {2017}
}

@inproceedings{W17-2707,
 abstract = {We present an approach at identifying a specific class of events, movement
action events (MAEs), in a data set that consists of ca. 2,800 personal letters
exchanged by the German architect Erich Mendelsohn and his wife, Luise. A
backend system uses these and other semantic analysis results as input for an
authoring environment that digital curators can use to produce new pieces of
digital content. In our example case, the human expert will receive
recommendations from the system with the goal of putting together a travelogue, i.e., a description of the trips and journeys undertaken by the couple. We
describe the components and architecture and also apply the system to news
data.},
 address = {Vancouver, Canada},
 author = {Rehm, Georg and Moreno Schneider, Julian and bourgonje, peter and Srivastava, Ankit and Nehring, Jan and Berger, Armin and K\"{o}nig, Luca and R\"{a}uchle, S\"{o}ren and Gerth, Jens},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2707},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {42--51},
 publisher = {Association for Computational Linguistics},
 title = {Event Detection and Semantic Storytelling: Generating a Travelogue from a large Collection of Personal Letters},
 year = {2017}
}

@inproceedings{W17-2708,
 abstract = {Human understanding of narrative is mainly driven by reasoning about causal
relations between events and thus recognizing them is a key capability for
computational models of language understanding. Computational work in this area
has approached this via two different routes: by focusing on acquiring a
knowledge base of common causal relations between events, or by attempting to
understand a particular story or macro-event, along
with its storyline. In this position paper, we focus on knowledge acquisition
approach and claim that newswire is a relatively poor source for learning
fine-grained causal relations between everyday events. We describe experiments
using an unsupervised method to learn causal relations between events in the
narrative genres of first-person narratives and film
scene descriptions. We show that our method learns fine-grained causal
relations, judged by humans as likely to be causal over 80% of the time. We also
demonstrate that the learned event pairs do not exist in publicly available
event-pair datasets extracted from newswire.},
 address = {Vancouver, Canada},
 author = {Hu, Zhichao and Rahimtoroghi, Elahe and Walker, Marilyn},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2708},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {52--58},
 publisher = {Association for Computational Linguistics},
 title = {Inference of Fine-Grained Event Causality from Blogs and Films},
 year = {2017}
}

@inproceedings{W17-2709,
 abstract = {This paper reports on an effort of creating a corpus of structured information
on security-related events automatically extracted from on-line news, part of
which has been manually curated. The main motivation behind this effort is to
provide material to the NLP community working on event extraction that could be
used both for training and evaluation purposes.},
 address = {Vancouver, Canada},
 author = {Atkinson, Martin and Piskorski, Jakub and Tanev, Hristo and Zavarella, Vanni},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2709},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {59--65},
 publisher = {Association for Computational Linguistics},
 title = {On the Creation of a Security-Related Event Corpus},
 year = {2017}
}

@inproceedings{W17-2710,
 abstract = {With growing interest in automated event extraction, there is an increasing
need to overcome the labor costs of hand-written event templates, entity lists, and annotated corpora. In the last few years, more inductive approaches have
emerged, seeking to discover unknown event types and roles in raw text. The
main recent efforts use probabilistic generative models, as in topic modeling, which are formally concise but do not always yield stable or easily
interpretable results. We argue that event schema induction can benefit from
greater structure in the process and in linguistic features that distinguish
words' functions and themes. To maximize our use of limited data, we reverse
the typical schema induction steps and introduce new similarity measures, building an intuitive process for inducing the structure of unknown events.},
 address = {Vancouver, Canada},
 author = {Ahn, Natalie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2710},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {66--76},
 publisher = {Association for Computational Linguistics},
 title = {Inducing Event Types and Roles in Reverse: Using Function to Discover Theme},
 year = {2017}
}

@inproceedings{W17-2711,
 abstract = {This paper reports on the Event StoryLine Corpus (ESC) v1.0, a new benchmark
dataset for the temporal and causal relation detection. By developing this
dataset, we also introduce a new task, the StoryLine Extraction from news data, which aims at extracting and classifying events relevant for stories, from
across news documents spread in time and clustered around a single seminal
event or topic. In addition to describing the dataset, we also report on three
baselines systems whose results show the complexity of the task and suggest
directions for the development of more robust systems.},
 address = {Vancouver, Canada},
 author = {Caselli, Tommaso and Vossen, Piek},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2711},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {77--86},
 publisher = {Association for Computational Linguistics},
 title = {The Event StoryLine Corpus: A New Benchmark for Causal and Temporal Relation Extraction},
 year = {2017}
}

@inproceedings{W17-2712,
 abstract = {In this paper we describe a new lexical semantic resource, The Rich Event
On-tology, which provides an independent conceptual backbone to unify existing
semantic role labeling (SRL) schemas and augment them with event-to-event
causal and temporal relations.        By unifying the FrameNet, VerbNet, Automatic
Content Extraction, and Rich Entities, Relations and Events resources, the
ontology serves as a shared hub for the disparate annotation schemas and
therefore enables the combination of SRL training data into a larger, more
diverse corpus.  By adding temporal and causal relational information not found
in any of the independent resources, the ontology facilitates reasoning on and
across documents, revealing relationships between events that come together in
temporal and causal chains to build more complex scenarios.  We envision the
open resource serving as a valuable tool for both moving from the ontology to
text to query for event types and scenarios of interest, and for moving from
text to the ontology to access interpretations of events using the combined
semantic information housed there.},
 address = {Vancouver, Canada},
 author = {Brown, Susan and Bonial, Claire and Obrst, Leo and Palmer, Martha},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2712},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {87--97},
 publisher = {Association for Computational Linguistics},
 title = {The Rich Event Ontology},
 year = {2017}
}

@inproceedings{W17-2713,
 abstract = {Storyline research links together events in stories and specifies shared
participants in those stories. In these analyses, an atomic event is assumed to
be a single clause headed by a single verb. However, many analyses of verbal
semantics assume a decompositional analysis of events expressed in single
clauses. We present a formalization of a decompositional analysis of events in
which each participant in a clausal event has their own temporally extended
subevent, and the subevents are related through causal and other interactions.
This decomposition allows us to represent storylines as an evolving set of
interactions between participants over time.},
 address = {Vancouver, Canada},
 author = {Croft, William and Peskova, Pavlina and Regan, Michael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2713},
 booktitle = {Proceedings of the Events and Stories in the News Workshop},
 month = {August},
 pages = {98--109},
 publisher = {Association for Computational Linguistics},
 title = {Integrating Decompositional Event Structures into Storylines},
 year = {2017}
}

@inproceedings{W17-2801,
 abstract = {This paper describes how language is
grounded by a comprehension system
called Lucia within a robotic agent called
Rosie that can manipulate objects and
navigate indoors. The whole system is
built within the Soar cognitive architecture
and uses Embodied Construction Grammar
(ECG) as a formalism for describing
linguistic knowledge. Grounding is performed
using knowledge from the grammar
itself, from the linguistic context, from the agents perception, and from an
ontology of long-term knowledge about
object categories and properties and actions
the agent can perform. The paper
also describes a benchmark corpus of 200
sentences in this domain along with test
versions of the world model and ontology
and gold-standard meanings for each
of the sentences. The benchmark is contained
in the supplemental materials.},
 address = {Vancouver, Canada},
 author = {Lindes, Peter and Mininger, Aaron and Kirk, James R. and Laird, John E.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2801},
 booktitle = {Proceedings of the First Workshop on Language Grounding for Robotics},
 month = {August},
 pages = {1--9},
 publisher = {Association for Computational Linguistics},
 title = {Grounding Language for Interactive Task Learning},
 year = {2017}
}

@inproceedings{W17-2802,
 abstract = {We present an optimised multi-modal dialogue agent for interactive learning of
visually grounded word meanings from a human tutor, trained on real human-human
tutoring data. Within a life-long interactive learning period, the agent, trained using Reinforcement Learning (RL), must be able to handle natural
conversations with human users, and achieve  good learning performance (i.e.
accuracy) while minimising human effort in the learning process. We train and
evaluate this  system in interaction with a simulated human tutor, which is
built on the BURCHAK corpus -- a Human-Human Dialogue dataset for the visual
learning task. The results show that: 1) The learned policy can coherently
interact with the simulated user to achieve the goal of the task (i.e. learning
visual attributes of  objects, e.g. colour and shape); and 2) it finds a better
trade-off between  classifier accuracy and tutoring costs than hand-crafted
rule-based policies, including ones with dynamic policies.},
 address = {Vancouver, Canada},
 author = {Yu, Yanchao and Eshghi, Arash and Lemon, Oliver},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2802},
 booktitle = {Proceedings of the First Workshop on Language Grounding for Robotics},
 month = {August},
 pages = {10--19},
 publisher = {Association for Computational Linguistics},
 title = {Learning how to Learn: An Adaptive Dialogue Agent for Incrementally Learning Visually Grounded Word Meanings},
 year = {2017}
}

@inproceedings{W17-2803,
 abstract = {Multi-modal grounded language learning connects language predicates to physical
properties of objects in the world. Sensing with multiple modalities, such as
audio, haptics, and visual colors and shapes while performing interaction
behaviors like lifting, dropping, and looking on objects enables a robot to
ground non-visual predicates like ``empty'' as well as visual predicates like
``red''. Previous work has established that grounding in multi-modal space
improves performance on object retrieval from human descriptions. In this work, we gather behavior annotations from humans and demonstrate that these improve
language grounding performance by allowing a system to focus on relevant
behaviors for words like ``white'' or ``half-full'' that can be understood by
looking or lifting, respectively. We also explore adding modality annotations
(whether to focus on audio or haptics when performing a behavior), which
improves performance, and sharing information between linguistically related
predicates (if ``green'' is a color, ``white'' is a color), which improves
grounding recall but at the cost of precision.},
 address = {Vancouver, Canada},
 author = {Thomason, Jesse and Sinapov, Jivko and Mooney, Raymond},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2803},
 booktitle = {Proceedings of the First Workshop on Language Grounding for Robotics},
 month = {August},
 pages = {20--24},
 publisher = {Association for Computational Linguistics},
 title = {Guiding Interaction Behaviors for Multi-modal Grounded Language Learning},
 year = {2017}
}

@inproceedings{W17-2804,
 abstract = {Service robots are expected to operate in specific environments, where the
presence of humans plays a key role. A major feature of such robotics platforms
is thus the ability to react to spoken commands. This requires the
understanding of the user utterance with an accuracy able to trigger the robot
reaction.
Such correct interpretation of linguistic exchanges depends on physical, cognitive and language-dependent aspects related to the environment. In this
work, we present the empirical evaluation of an adaptive Spoken Language
Understanding chain for robotic commands, that explicitly depends on the
operational environment during both the learning and recognition stages. The
effectiveness of such a context-sensitive command interpretation is tested
against an extension of an already existing corpus of commands, that introduced
explicit perceptual knowledge: this enabled deeper measures proving that more
accurate disambiguation capabilities can be actually obtained.},
 address = {Vancouver, Canada},
 author = {Vanzo, Andrea and Croce, Danilo and Basili, Roberto and Nardi, Daniele},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2804},
 booktitle = {Proceedings of the First Workshop on Language Grounding for Robotics},
 month = {August},
 pages = {25--34},
 publisher = {Association for Computational Linguistics},
 title = {Structured Learning for Context-aware Spoken Language Understanding of Robotic Commands},
 year = {2017}
}

@inproceedings{W17-2805,
 abstract = {We present a cognitively plausible system capable of acquiring knowledge in
language and vision from pairs of short video clips and linguistic
descriptions. The aim of this work is to teach a robot manipulator how to
execute natural language commands by demonstration. This is achieved by first
learning a set of visual `concepts' that abstract the visual feature spaces
into concepts that have human-level meaning. Second, learning the
mapping/grounding between words and the extracted visual concepts. Third, inducing grammar rules via a semantic representation known as Robot Control
Language (RCL).
We evaluate our approach against state-of-the-art supervised and unsupervised
grounding and grammar induction systems, and show that a robot can learn to
execute never seen-before commands from pairs of unlabelled linguistic and
visual inputs.},
 address = {Vancouver, Canada},
 author = {Alomari, Muhannad and Duckworth, Paul and Hawasly, Majd and Hogg, David C. and Cohn, Anthony G.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2805},
 booktitle = {Proceedings of the First Workshop on Language Grounding for Robotics},
 month = {August},
 pages = {35--43},
 publisher = {Association for Computational Linguistics},
 title = {Natural Language Grounding and Grammar Induction for Robotic Manipulation Commands},
 year = {2017}
}

@inproceedings{W17-2806,
 abstract = {In this paper, we describe an improvement on the task of giving instructions to
robots in a simulated block world using unrestricted natural language commands.},
 address = {Vancouver, Canada},
 author = {Pi\v{s}l, Bed\v{r}ich and Mare\v{c}ek, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2806},
 booktitle = {Proceedings of the First Workshop on Language Grounding for Robotics},
 month = {August},
 pages = {44--48},
 publisher = {Association for Computational Linguistics},
 title = {Communication with Robots using Multilayer Recurrent Networks},
 year = {2017}
}

@inproceedings{W17-2807,
 abstract = {As robots begin to cohabit with humans in semi-structured environments, the
need arises to understand instructions involving rich variability---for
instance, learning to ground symbols in the physical world. Realistically, this
task must cope with small datasets consisting of a particular users' contextual
assignment of meaning to terms. We present a method for processing a raw stream
of cross-modal input---i.e., linguistic instructions, visual perception of a
scene and a concurrent trace of 3D eye tracking fixations---to produce the
segmentation of objects with a correspondent association to high-level
concepts. To test our framework we present experiments in a table-top object
manipulation scenario. Our results show our model learns the user's notion of
colour and shape from a small number of physical demonstrations, generalising
to identifying physical referents for novel combinations of the words.},
 address = {Vancouver, Canada},
 author = {Hristov, Yordan and Penkov, Svetlin and Lascarides, Alex and Ramamoorthy, Subramanian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2807},
 booktitle = {Proceedings of the First Workshop on Language Grounding for Robotics},
 month = {August},
 pages = {49--57},
 publisher = {Association for Computational Linguistics},
 title = {Grounding Symbols in Multi-Modal Instructions},
 year = {2017}
}

@inproceedings{W17-2808,
 abstract = {Robot-directed communication is variable, and may change based on human
perception of robot capabilities. To collect training data for a dialogue
system and to investigate possible communication changes over time, we
developed a Wizard-of-Oz study that (a) simulates a robot's limited
understanding, and (b) collects dialogues where human participants build a
progressively better mental model of the robot's understanding. With ten
participants, we collected ten hours of human-robot dialogue. We analyzed the
structure of instructions that participants gave to a remote robot before it
responded. Our findings show a general initial preference for including metric
information (e.g., move forward 3 feet) over landmarks (e.g., move to the desk)
in motion commands, but this decreased over time, suggesting changes in
perception.},
 address = {Vancouver, Canada},
 author = {Marge, Matthew and Bonial, Claire and Foots, Ashley and Hayes, Cory and Henry, Cassidy and Pollard, Kimberly and Artstein, Ron and Voss, Clare and Traum, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2808},
 booktitle = {Proceedings of the First Workshop on Language Grounding for Robotics},
 month = {August},
 pages = {58--66},
 publisher = {Association for Computational Linguistics},
 title = {Exploring Variation of Natural Human Commands to a Robot in a Collaborative Navigation Task},
 year = {2017}
}

@inproceedings{W17-2809,
 abstract = {Robots operating alongside humans in diverse, stochastic environments must be
able to accurately interpret natural language commands. These instructions
often fall into one of two categories: those that specify a goal condition or
target state, and those that specify explicit actions, or how to perform a
given task. Recent approaches have used reward functions as a semantic
representation of goal-based commands, which allows for the use of a
state-of-the-art planner to find a policy for the given task. However, these
reward functions cannot be directly used to represent action-oriented commands.
We introduce a new hybrid approach, the Deep Recurrent Action-Goal Grounding
Network (DRAGGN), for task grounding and execution that handles natural
language from either category as input, and generalizes to unseen environments.
Our robot-simulation results demonstrate that a system successfully
interpreting both goal-oriented and action-oriented task specifications brings
us closer to robust natural language understanding for human-robot interaction.},
 address = {Vancouver, Canada},
 author = {Karamcheti, Siddharth and Williams, Edward Clem and Arumugam, Dilip and Rhee, Mina and Gopalan, Nakul and Wong, Lawson L.S. and Tellex, Stefanie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2809},
 booktitle = {Proceedings of the First Workshop on Language Grounding for Robotics},
 month = {August},
 pages = {67--75},
 publisher = {Association for Computational Linguistics},
 title = {A Tale of Two DRAGGNs: A Hybrid Approach for Interpreting Action-Oriented and Goal-Oriented Instructions},
 year = {2017}
}

@inproceedings{W17-2810,
 abstract = {Distributional word representation methods exploit word co-occurrences to build
compact vector encodings of words. While these representations enjoy widespread
use in modern natural language processing, it is unclear whether they
accurately encode all necessary facets of conceptual meaning. In this paper, we
evaluate how well these representations can predict perceptual and conceptual
features of concrete concepts, drawing on two semantic norm datasets sourced
from human participants. We find that several standard word representations
fail to encode many salient perceptual features of concepts, and show that
these deficits correlate with word-word similarity prediction errors. Our
analyses provide motivation for grounded and embodied language learning
approaches, which may help to remedy these deficits.},
 address = {Vancouver, Canada},
 author = {Lucy, Li and Gauthier, Jon},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2810},
 booktitle = {Proceedings of the First Workshop on Language Grounding for Robotics},
 month = {August},
 pages = {76--85},
 publisher = {Association for Computational Linguistics},
 title = {Are Distributional Representations Ready for the Real World? Evaluating Word Vectors for Grounded Perceptual Meaning},
 year = {2017}
}

@inproceedings{W17-2811,
 abstract = {Recognition of social signals, coming from human facial expressions or prosody
of human speech, is a popular research topic in human-robot interaction
studies. There is also a long line of research in the spoken dialogue community
that investigates user satisfaction in relation to dialogue characteristics.
However, very little research relates a combination of multimodal social
signals and language features detected during spoken face-to-face human-robot
interaction to the resulting user perception of a robot. In this paper we show
how different emotional facial expressions of human users, in combination with
prosodic characteristics of human speech and features of human-robot dialogue, correlate with users{\^a} impressions of the robot after a conversation. We find
that happiness in the user{\^a}s recognised facial expression strongly correlates
with likeability of a robot, while dialogue-related features (such as number of
human turns or number of sentences per robot utterance) correlate with
perceiving a robot as intelligent. In addition, we show that the facial
expression emotional features and prosody are better predictors of
human ratings related to perceived robot likeability and anthropomorphism, while linguistic and non-linguistic features more often predict perceived robot
intelligence and interpretability. As such, these characteristics may in future
be used as an online reward signal for in-situ Reinforcement Learning-based
adaptive human-robot dialogue systems.},
 address = {Vancouver, Canada},
 author = {Novikova, Jekaterina and Dondrup, Christian and Papaioannou, Ioannis and Lemon, Oliver},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2811},
 booktitle = {Proceedings of the First Workshop on Language Grounding for Robotics},
 month = {August},
 pages = {86--94},
 publisher = {Association for Computational Linguistics},
 title = {Sympathy Begins with a Smile, Intelligence Begins with a Word: Use of Multimodal Features in Spoken Human-Robot Interaction},
 year = {2017}
}

@inproceedings{W17-2812,
 abstract = {Agents that communicate back and forth with humans to help them execute
non-linguistic tasks are a long sought goal of AI. These agents need to
translate between utterances and actionable meaning representations that can be
interpreted by task-specific problem solvers in a context-dependent manner.
They should also be able to learn such actionable interpretations for new
predicates on the fly. We define an agent architecture for this scenario and
present a series of experiments in the Blocks World domain that illustrate how
our architecture supports language learning and problem solving in this domain.},
 address = {Vancouver, Canada},
 author = {Narayan-Chen, Anjali and Graber, Colin and Das, Mayukh and Islam, Md Rakibul and Dan, Soham and Natarajan, Sriraam and Doppa, Janardhan Rao and Hockenmaier, Julia and Palmer, Martha and Roth, Dan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2812},
 booktitle = {Proceedings of the First Workshop on Language Grounding for Robotics},
 month = {August},
 pages = {95--103},
 publisher = {Association for Computational Linguistics},
 title = {Towards Problem Solving Agents that Communicate and Learn},
 year = {2017}
}

@inproceedings{W17-2901,
 abstract = {In this paper we present a set of experiments and analyses on predicting the
gender of Twitter users based on language-independent features extracted either
from the text or the metadata of users' tweets. We perform our experiments on
the TwiSty dataset containing manual gender annotations for users speaking six
different languages. Our classification results show that, while the prediction
model based on language-independent features performs worse than the
bag-of-words model when training and testing on the same language, it regularly
outperforms the bag-of-words model when applied to different languages, showing
very stable results across various languages. Finally we perform a comparative
analysis of feature effect sizes across the six languages and show that
differences in our features correspond to cultural distances.},
 address = {Vancouver, Canada},
 author = {Ljube\v{s}i\'{c}, Nikola and Fi\v{s}er, Darja and Erjavec, Toma\v{z}},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2901},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {1--6},
 publisher = {Association for Computational Linguistics},
 title = {Language-independent Gender Prediction on Twitter},
 year = {2017}
}

@inproceedings{W17-2902,
 abstract = {Sexism is prevalent in today{\^a}s society, both offline and online, and poses a
credible threat to social equality with respect to gender. According to
ambivalent sexism theory (Glick and Fiske, 1996), it comes in two forms:
Hostile and Benevolent. While hostile sexism is characterized by an explicitly
negative attitude, benevolent sexism is more subtle. Previous works on
computationally detecting sexism present online are restricted to identifying
the hostile form. Our objective is to investigate the less pronounced form of
sexism demonstrated online. We achieve this by creating and analyzing a dataset
of tweets that exhibit benevolent sexism. By using Support Vector Machines
(SVM), sequence-to-sequence models and FastText classifier, we classify tweets
into {\^a}Hostile{\^a}, {\^a}Benevolent{\^a} or {\^a}Others{\^a} class depending on the
kind of sexism they exhibit. We have been able to achieve an F1-score of 87.22%
using FastText classifier. Our work helps analyze and understand the much
prevalent ambivalent sexism in social media.},
 address = {Vancouver, Canada},
 author = {Jha, Akshita and Mamidi, Radhika},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2902},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {7--16},
 publisher = {Association for Computational Linguistics},
 title = {When does a compliment become sexist? Analysis and classification of ambivalent sexism using twitter data},
 year = {2017}
}

@inproceedings{W17-2903,
 abstract = {Personality plays a decisive role in how people behave in different scenarios, including online social media. Researchers have used such data to study how
personality can be predicted from language use. In this paper, we study phrase
choice as a particular stylistic linguistic difference, as opposed to the
mostly topical differences identified previously. Building on previous work on
demographic preferences, we quantify differences in paraphrase choice from a
massive Facebook data set with posts from over 115,000 users. We quantify the
predictive power of phrase choice in user profiling and use phrase choice to
study psycholinguistic hypotheses. This work is relevant to future applications
that aim to personalize text generation to specific personality types.},
 address = {Vancouver, Canada},
 author = {Preo{\AA}£iuc-Pietro, Daniel and Carpenter, Jordan and Ungar, Lyle},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2903},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {17--26},
 publisher = {Association for Computational Linguistics},
 title = {Personality Driven Differences in Paraphrase Preference},
 year = {2017}
}

@inproceedings{W17-2904,
 abstract = {Vector embeddings of words have been shown to encode meaningful semantic
relationships that enable solving of complex analogies. This vector embedding
concept has been extended successfully to many different domains and in this
paper we both create and visualize vector representations of an unstructured
collection of online communities based on user participation. Further, we
quantitatively and qualitatively show that these representations allow solving
of semantically meaningful community analogies and also other more general
types of relationships. These results could help improve community
recommendation engines and also serve as a tool for sociological studies of
community relatedness.},
 address = {Vancouver, Canada},
 author = {Martin, Trevor},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2904},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {27--31},
 publisher = {Association for Computational Linguistics},
 title = {community2vec: Vector representations of online communities encode semantic relationships},
 year = {2017}
}

@inproceedings{W17-2905,
 abstract = {In this paper, we evaluate the predictability of tweets associated with
controversial versus non-controversial topics. As a first step, we
crowd-sourced the scoring of a predefined set of topics on a Likert scale from
non-controversial to controversial. Our feature set entails and goes beyond
sentiment features, e.g., by leveraging empathic language and other features
that have been previously used but are new for this particular study. We find
focusing on the structural characteristics of tweets to be beneficial for this
task. Using a combination of emphatic, language-specific, and Twitter-specific
features for supervised learning resulted in 87% accuracy (F1) for
cross-validation of the training set and 63.4% accuracy when using the test
set. Our analysis shows that features specific to Twitter or social media, in
general, are more prevalent in tweets on controversial topics than in
non-controversial ones. To test the premise of the paper, we conducted two
additional sets of experiments, which led to mixed results. This finding will
inform our future investigations into the relationship between language use on
social media and the perceived controversiality of topics.},
 address = {Vancouver, Canada},
 author = {Addawood, Aseel and Rezapour, Rezvaneh and Abdar, Omid and Diesner, Jana},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2905},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {32--41},
 publisher = {Association for Computational Linguistics},
 title = {Telling Apart Tweets Associated with Controversial versus Non-Controversial Topics},
 year = {2017}
}

@inproceedings{W17-2906,
 abstract = {In this paper, we propose an approach for cross-lingual topical coding of
sentences from electoral manifestos of political parties in different
languages. To this end, we exploit continuous semantic text representations and
induce a joint multilingual semantic vector spaces to enable supervised
learning using manually-coded sentences across different languages. Our
experimental results show that classifiers trained on multilingual data yield
performance boosts over monolingual topic classification.},
 address = {Vancouver, Canada},
 author = {Glava\v{s}, Goran and Nanni, Federico and Ponzetto, Simone Paolo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2906},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {42--46},
 publisher = {Association for Computational Linguistics},
 title = {Cross-Lingual Classification of Topics in Political Texts},
 year = {2017}
}

@inproceedings{W17-2907,
 abstract = {Research in Social Science is usually based on survey data where individual
research questions relate to observable concepts (variables). However, due to a
lack of standards for data citations a reliable identification of the variables
used is often difficult. In this paper, we present a work-in-progress study
that seeks to provide a solution to the variable detection task based on
supervised machine learning algorithms, using a linguistic analysis pipeline to
extract a rich feature set, including terminological concepts and similarity
metric scores.
Further, we present preliminary results on a small dataset that has been
specifically designed for this task, yielding
a significant increase in performance over the random baseline.},
 address = {Vancouver, Canada},
 author = {Zielinski, Andrea and Mutschke, Peter},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2907},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {47--52},
 publisher = {Association for Computational Linguistics},
 title = {Mining Social Science Publications for Survey Variables},
 year = {2017}
}

@inproceedings{W17-2908,
 abstract = {There has been a long standing interest in understanding `Social Influence'
both in Social Sciences and in Computational Linguistics. In this paper, we
present a novel approach to study and measure interpersonal influence in daily
interactions. Motivated by the basic principles of influence, we attempt to
identify indicative linguistic features of the posts in an online knitting
community. We present the scheme used to operationalize and label the posts as
influential or non-influential. Experiments with the identified features show
an improvement in the classification accuracy of influence by 3.15\%. Our
results illustrate the important correlation between the structure of the
language and its potential to influence others.},
 address = {Vancouver, Canada},
 author = {Prabhumoye, Shrimai and Choudhary, Samridhi and Spiliopoulou, Evangelia and Bogart, Christopher and Rose, Carolyn and Black, Alan W},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2908},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {53--62},
 publisher = {Association for Computational Linguistics},
 title = {Linguistic Markers of Influence in Informal Interactions},
 year = {2017}
}

@inproceedings{W17-2909,
 abstract = {Previous work on classifying Twitter users' political alignment has mainly
focused on lexical and social network features. This study provides evidence
that political affiliation is also reflected in features which have been
previously overlooked: users' discourse patterns (proportion of Tweets that are
retweets or replies) and their rate of use of capitalization and punctuation.
We find robust differences between politically left- and right-leaning
communities with respect to these discourse and sub-lexical features, although
they are not enough to train a high-accuracy classifier.},
 address = {Vancouver, Canada},
 author = {Tatman, Rachael and Stewart, Leo and Paullada, Amandalynne and Spiro, Emma},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2909},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {63--67},
 publisher = {Association for Computational Linguistics},
 title = {Non-lexical Features Encode Political Affiliation on Twitter},
 year = {2017}
}

@inproceedings{W17-2910,
 abstract = {We explore a novel computational approach for analyzing member participation in
small group social sequences. Using a complex state representation combining
information about dialogue act types, sentiment expression, and participant
roles, we explore which sequence states are associated with high levels of
member participation. Using a Markov Rewards framework, we associate particular
states with immediate positive and negative rewards, and employ a Value
Iteration algorithm to calculate the expected value of all states. In our
findings, we focus on discourse states belonging to team leaders and project
managers which are either very likely or very unlikely to lead to participation
from the rest of the group members.},
 address = {Vancouver, Canada},
 author = {Murray, Gabriel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2910},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {68--72},
 publisher = {Association for Computational Linguistics},
 title = {Modelling Participation in Small Group Social Sequences with Markov Rewards Analysis},
 year = {2017}
}

@inproceedings{W17-2911,
 abstract = {Code-switching has been found to have social motivations in addition to
syntactic constraints.
In this work, we explore the social effect of code-switching in an online
community.
We present a task from the Arabic Wikipedia to capture language choice, in this
case code-switching between Arabic and other languages, as a predictor of
social influence in collaborative editing.
We find that code-switching is positively associated with Wikipedia editor
success, particularly borrowing technical language on pages with topics less
directly related to Arabic-speaking regions.},
 address = {Vancouver, Canada},
 author = {Yoder, Michael and Rijhwani, Shruti and Ros\'{e}, Carolyn and Levin, Lori},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2911},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {73--82},
 publisher = {Association for Computational Linguistics},
 title = {Code-Switching as a Social Act: The Case of Arabic Wikipedia Talk Pages},
 year = {2017}
}

@inproceedings{W17-2912,
 abstract = {Demographically-tagged social media messages are a common source of data for
computational social science.  While these messages can indicate differences in
beliefs and behaviors between demographic groups, we do not have a clear
understanding of how different demographic groups use platforms such as
Twitter.  This paper presents a preliminary analysis of how groups' differing
behaviors may confound analyses of the groups themselves.  We analyzed one
million Twitter users by first inferring demographic attributes, and then
measuring several indicators of Twitter behavior. We find differences in these
indicators across demographic groups, suggesting that there may be underlying
differences in how different demographic groups use Twitter.},
 address = {Vancouver, Canada},
 author = {Wood-Doughty, Zach and Smith, Michael and Broniatowski, David and Dredze, Mark},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2912},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {83--89},
 publisher = {Association for Computational Linguistics},
 title = {How Does Twitter User Behavior Vary Across Demographic Groups?},
 year = {2017}
}

@inproceedings{W17-2913,
 abstract = {Politicians carefully word their statements in order to influence how others
view an issue, a political strategy called framing. Simultaneously, these
frames may also reveal the beliefs or positions on an issue of the politician.
Simple language features such as unigrams, bigrams, and trigrams are important
indicators for identifying the general frame of a text, for both longer
congressional speeches and shorter tweets of politicians. However, tweets may
contain multiple unigrams across different frames which limits the
effectiveness of this approach. In this paper, we present a joint model which
uses both linguistic features of tweets and ideological phrase indicators
extracted from a state-of-the-art embedding-based model to predict the general
frame of political tweets.},
 address = {Vancouver, Canada},
 author = {Johnson, Kristen and Lee, I-Ta and Goldwasser, Dan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-2913},
 booktitle = {Proceedings of the Second Workshop on NLP and Computational Social Science},
 month = {August},
 pages = {90--99},
 publisher = {Association for Computational Linguistics},
 title = {Ideological Phrase Indicators for Classification of Political Discourse Framing on Twitter},
 year = {2017}
}

@inproceedings{W17-3001,
 abstract = {In this paper, we use a new categorical form of multidimensional register
analysis to identify the main dimensions of functional linguistic variation in
a corpus of abusive language, consisting of racist and sexist Tweets. By
analysing the use of a wide variety of parts-of-speech and grammatical
constructions, as well as various features related to Twitter and
computer-mediated communication, we discover three dimensions of linguistic
variation in this corpus, which we interpret as being related to the degree of
interactive, antagonistic and attitudinal language exhibited by individual
Tweets. We then demonstrate that there is a significant functional difference
between racist and sexist Tweets, with sexists Tweets tending to be more
interactive and attitudinal than racist Tweets.},
 address = {Vancouver, BC, Canada},
 author = {Clarke, Isobelle and Grieve, Dr. Jack},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3001},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Dimensions of Abusive Language on Twitter},
 year = {2017}
}

@inproceedings{W17-3002,
 abstract = {We discuss the characteristics of constructive news comments, and present
methods to identify them. First, we define the notion of constructiveness.
Second, we annotate a corpus for constructiveness. Third, we explore whether
available argumentation corpora can be useful to identify constructiveness in
news comments. Our model trained on argumentation corpora achieves a top
accuracy of 72.59% (baseline=49.44%) on our crowd-annotated test data. Finally, we examine the relation between constructiveness and toxicity. In our
crowd-annotated data, 21.42% of the non-constructive comments and 17.89% of the
constructive comments are toxic, suggesting that non-constructive comments are
not much more toxic than constructive comments.},
 address = {Vancouver, BC, Canada},
 author = {Kolhatkar, Varada and Taboada, Maite},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3002},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {11--17},
 publisher = {Association for Computational Linguistics},
 title = {Constructive Language in News Comments},
 year = {2017}
}

@inproceedings{W17-3003,
 abstract = {This paper proposes a system that can detect and rephrase profanity in Chinese
text.  Rather than just masking detected profanity, we want to revise the input
sentence by using inoffensive words while keeping their original meanings.  29
of such rephrasing rules were invented after observing sentences on real-word
social websites.  The overall accuracy of the proposed system is 85.56%},
 address = {Vancouver, BC, Canada},
 author = {Su, Hui-Po and Huang, Zhen-Jie and Chang, Hao-Tsung and Lin, Chuan-Jie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3003},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {18--24},
 publisher = {Association for Computational Linguistics},
 title = {Rephrasing Profanity in Chinese Text},
 year = {2017}
}

@inproceedings{W17-3004,
 abstract = {Experimenting with a new dataset of 1.6M user comments from a Greek news portal
and existing datasets of EnglishWikipedia comments, we show that an RNN
outperforms the previous state of the art in moderation. A deep, classification-specific attention mechanism improves further the overall
performance of the RNN. We also compare against a CNN and a word-list baseline, considering both fully automatic and semi-automatic moderation.},
 address = {Vancouver, BC, Canada},
 author = {Pavlopoulos, John and Malakasiotis, Prodromos and Androutsopoulos, Ion},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3004},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {25--35},
 publisher = {Association for Computational Linguistics},
 title = {Deep Learning for User Comment Moderation},
 year = {2017}
}

@inproceedings{W17-3005,
 abstract = {Common approaches  to text categorization essentially rely either on n-gram
counts or on word embeddings. This presents important difficulties in highly
dynamic or quickly-interacting environments, where the appearance of new words
and/or varied misspellings is the norm. A paradigmatic example of this
situation is abusive online behavior, with social networks and media platforms
struggling to effectively combat uncommon or non-blacklisted hate words. To
better deal with these issues in those fast-paced environments, we propose
using the error signal of class-based language models as input to text
classification algorithms. In particular, we train a next-character prediction
model for any given class and then exploit the error of such class-based models
to inform a neural network classifier. This way, we shift from the {\^a}ability
to describe{\^a} seen documents to the {\^a}ability to predict{\^a} unseen content.
Preliminary studies using out-of-vocabulary splits from abusive tweet data show
promising results, outperforming competitive text categorization strategies by
4-11%.},
 address = {Vancouver, BC, Canada},
 author = {Serr\`{a}, Joan and Leontiadis, Ilias and Spathis, Dimitris and Stringhini, Gianluca and Blackburn, Jeremy and Vakali, Athena},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3005},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {36--40},
 publisher = {Association for Computational Linguistics},
 title = {Class-based Prediction Errors to Detect Hate Speech with Out-of-vocabulary Words},
 year = {2017}
}

@inproceedings{W17-3006,
 abstract = {Automatic abusive language detection is a difficult but important task for
online social media. Our research explores a two-step approach of performing
classification on abusive language and then classifying into specific types and
compares it with one-step approach of doing one multi-class classification for
detecting sexist and racist languages. With a public English Twitter corpus of
20 thousand tweets in the type of sexism and racism, our approach shows a
promising performance of 0.827 F-measure by using HybridCNN in one-step and
0.824 F-measure by using logistic regression in two-steps.
Author{2}{Affiliation}},
 address = {Vancouver, BC, Canada},
 author = {Park, Ji Ho and Fung, Pascale},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3006},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {41--45},
 publisher = {Association for Computational Linguistics},
 title = {One-step and Two-step Classification for Abusive Language Detection on Twitter},
 year = {2017}
}

@inproceedings{W17-3007,
 abstract = {In this paper we present the legal framework, dataset and annotation schema of
socially unacceptable discourse practices on social networking platforms in
Slovenia. On this basis we aim to train an automatic identification and
classification system with which we wish contribute towards an improved
methodology, understanding and treatment of such practices in the contemporary, increasingly multicultural information society.},
 address = {Vancouver, BC, Canada},
 author = {Fi\v{s}er, Darja and Erjavec, Toma\v{z} and Ljube\v{s}i\'{c}, Nikola},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3007},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {46--51},
 publisher = {Association for Computational Linguistics},
 title = {Legal Framework, Dataset and Annotation Schema for Socially Unacceptable Online Discourse Practices in Slovene},
 year = {2017}
}

@inproceedings{W17-3008,
 abstract = {In this paper, we present our work on detecting
abusive language on Arabic social
media. We extract a list of obscene
words and hashtags using common patterns
used in offensive and rude communications.
We also classify Twitter users
according to whether they use any of these
words or not in their tweets. We expand
the list of obscene words using this classification, and we report results on a
newly created dataset of classified Arabic tweets
(obscene, offensive, and clean). We make
this dataset freely available for research, in
addition to the list of obscene words and
hashtags. We are also publicly releasing
a large corpus of classified user comments
that were deleted from a popular Arabic
news site due to violations the site{\^a}s rules
and guidelines.},
 address = {Vancouver, BC, Canada},
 author = {Mubarak, Hamdy and Darwish, Kareem and Magdy, Walid},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3008},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {52--56},
 publisher = {Association for Computational Linguistics},
 title = {Abusive Language Detection on Arabic Social Media},
 year = {2017}
}

@inproceedings{W17-3009,
 abstract = {A study of conversations on Twitter found that some arguments between strangers
led to favorable change in discourse and even in attitudes. The authors propose
that such exchanges can be usefully distinguished according to whether
individuals or groups take part on each side, since the opportunity for a
constructive exchange of views seems to vary accordingly.},
 address = {Vancouver, BC, Canada},
 author = {Wright, Lucas and Ruths, Derek and Dillon, Kelly P and Saleem, Haji Mohammad and Benesch, Susan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3009},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {57--62},
 publisher = {Association for Computational Linguistics},
 title = {Vectors for Counterspeech on Twitter},
 year = {2017}
}

@inproceedings{W17-3010,
 abstract = {Although social media has made it easy for people to connect on a virtually
unlimited basis, it has also opened doors to people who misuse it to undermine, harass, humiliate, threaten and bully others. There is a lack of adequate
resources to detect and hinder its occurrence. In this paper, we  present our
initial NLP approach to detect invective posts as a first step to eventually
detect and deter cyberbullying. We crawl data containing profanities and then
determine whether or not it contains invective. Annotations on this data are
improved iteratively by in-lab annotations and crowdsourcing. We pursue
different NLP approaches containing various typical and some newer techniques
to distinguish the use of swear words in a neutral way from those instances in
which they are used in an insulting way. We also show that this model not only
works for our data set, but also can be successfully applied to different data
sets.},
 address = {Vancouver, BC, Canada},
 author = {Safi Samghabadi, Niloofar and Maharjan, Suraj and Sprague, Alan and Diaz-Sprague, Raquel and Solorio, Thamar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3010},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {63--72},
 publisher = {Association for Computational Linguistics},
 title = {Detecting Nastiness in Social Media},
 year = {2017}
}

@inproceedings{W17-3011,
 abstract = {This work is part of a new initiative to use machine learning to identify
online harassment in social media and comment streams. Online harassment goes
under-reported due to the reliance on humans to identify and report harassment, reporting that is further slowed by requirements to fill out forms providing
context. In addition, the time for moderators to respond and apply human
judgment can take days, but response times in terms of minutes are needed in
the online context. Though some of the major social media companies have been
doing proprietary work in automating the detection of harassment, there are few
tools available for use by the public. In addition, the amount of labeled
online harassment data and availability of cross-platform online harassment
datasets is limited. We present the methodology used to create a harassment
dataset and classifier and the dataset used to help the system learn what
harassment looks like.},
 address = {Vancouver, BC, Canada},
 author = {Kennedy, George and McCollough, Andrew and Dixon, Edward and Bastidas, Alexei and Ryan, John and Loo, Chris and Sahay, Saurav},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3011},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {73--77},
 publisher = {Association for Computational Linguistics},
 title = {Technology Solutions to Combat Online Harassment},
 year = {2017}
}

@inproceedings{W17-3012,
 abstract = {As the body of research on abusive language detection and analysis grows, there
is a need for critical consideration of the relationships between different
subtasks that have been grouped under this label. Based on work on hate speech, cyberbullying, and online abuse we propose a typology that captures central
similarities and differences between subtasks and discuss the implications of
this for data annotation and feature construction. We emphasize the practical
actions that can be taken by researchers to best approach their abusive
language detection subtask of interest.},
 address = {Vancouver, BC, Canada},
 author = {Waseem, Zeerak and Davidson, Thomas and Warmsley, Dana and Weber, Ingmar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3012},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {78--84},
 publisher = {Association for Computational Linguistics},
 title = {Understanding Abuse: A Typology of Abusive Language Detection Subtasks},
 year = {2017}
}

@inproceedings{W17-3013,
 abstract = {The paper introduces a deep learning-based Twitter hate-speech text
classification system. The classifier assigns each tweet to one of four
predefined categories: racism, sexism, both (racism and sexism) and
non-hate-speech. Four Convolutional Neural Network models were trained on resp.
character 4-grams, word vectors based on semantic information built using
word2vec, randomly generated word vectors, and word vectors combined with
character n-grams. The feature set was down-sized in the networks by
max-pooling, and a softmax function used to classify tweets. Tested by 10-fold
cross-validation, the model based on word2vec embeddings performed best, with
higher precision than recall, and a 78.3% F-score.},
 address = {Vancouver, BC, Canada},
 author = {Gamb\"{a}ck, Bj\"{o}rn and Sikdar, Utpal Kumar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3013},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {85--90},
 publisher = {Association for Computational Linguistics},
 title = {Using Convolutional Neural Networks to Classify Hate-Speech},
 year = {2017}
}

@inproceedings{W17-3014,
 abstract = {This paper focuses on a particular type of abusive language, targeting
expressions in which typically neutral adjectives take on pejorative meaning
when used as nouns - compare 'gay people' to 'the gays'. We first collect and
analyze a corpus of hand-curated, expert-annotated pejorative nominalizations
for four target adjectives: female, gay, illegal, and poor. We then collect a
second corpus of automatically-extracted and POS-tagged, crowd-annotated
tweets. For both corpora, we find support for the hypothesis that some
adjectives, when nominalized, take on negative meaning. The targeted
constructions are non-standard yet widely-used, and part-of-speech taggers
mistag some nominal forms as adjectives. We implement a tool called NomCatcher
to correct these mistaggings, and find that the same tool is effective for
identifying new adjectives subject to transformation via nominalization into
abusive language.},
 address = {Vancouver, BC, Canada},
 author = {Palmer, Alexis and Robinson, Melissa and Phillips, Kristy K.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3014},
 booktitle = {Proceedings of the First Workshop on Abusive Language Online},
 month = {August},
 pages = {91--100},
 publisher = {Association for Computational Linguistics},
 title = {Illegal is not a Noun: Linguistic Form for Detection of Pejorative Nominalizations},
 year = {2017}
}

@inproceedings{W17-3101,
 abstract = {Automatic detection of depression has attracted increasing attention from
researchers in psychology, computer science, linguistics, and related
disciplines. As a result, promising depression detection systems have been
reported. This paper surveys these efforts by presenting the first cross-modal
review of depression detection systems and discusses best practices and most
promising approaches to this task.},
 address = {Vancouver, BC},
 author = {Morales, Michelle and Scherer, Stefan and Levitan, Rivka},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3101},
 booktitle = {Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology --- From Linguistic Signal to Clinical Reality},
 month = {August},
 pages = {1--12},
 publisher = {Association for Computational Linguistics},
 title = {A Cross-modal Review of Indicators for Depression Detection Systems},
 year = {2017}
}

@inproceedings{W17-3102,
 abstract = {In this paper, we provide the first quantified exploration of the structure of
the language of dreams, their linguistic style and emotional content. We
present a collection of digital dream logs as a viable corpus for the growing
study of mental health through the lens of language, complementary to the work
done examining more traditional social media. This paper is largely
exploratory in nature to lay the groundwork for subsequent research in mental
health, rather than optimizing a particular text classification task.},
 address = {Vancouver, BC},
 author = {Niederhoffer, Kate and Schler, Jonathan and Crutchley, Patrick and Loveys, Kate and Coppersmith, Glen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3102},
 booktitle = {Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology --- From Linguistic Signal to Clinical Reality},
 month = {August},
 pages = {13--25},
 publisher = {Association for Computational Linguistics},
 title = {In your wildest dreams: the language and psychological features of dreams},
 year = {2017}
}

@inproceedings{W17-3103,
 abstract = {Social connection and social isolation are associated with depressive symptoms, particularly in adolescents and young adults, but how these concepts are
documented in clinical notes is unknown. This pilot study aimed to identify the
topics relevant to social connection and isolation by analyzing 145 clinical
notes from patients with depression diagnosis. We found that providers, including physicians, nurses, social workers, and psychologists, document
descriptions of both social connection and social isolation.},
 address = {Vancouver, BC},
 author = {Guo, Jia-Wen and Mowery, Danielle L and Lai, Djin and Sward, Katherine and Conway, Mike},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3103},
 booktitle = {Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology --- From Linguistic Signal to Clinical Reality},
 month = {August},
 pages = {26--31},
 publisher = {Association for Computational Linguistics},
 title = {A Corpus Analysis of Social Connections and Social Isolation in Adolescents Suffering from Depressive Disorders},
 year = {2017}
}

@inproceedings{W17-3104,
 abstract = {We propose an automated system that can identify at-risk users from their
public social media activity, more specifically, from Twitter. The data that we
collected is from the \#BellLetsTalk campaign, which is a wide-reaching, multi-year program designed to break the silence around mental illness and
support mental health across Canada. To achieve our goal, we trained a
user-level classifier that can detect at-risk users that achieves a reasonable
precision and recall. We also trained a tweet-level classifier that predicts if
a tweet indicates depression. This task was much more difficult due to the
imbalanced data. In the dataset that we labeled, we came across 5% depression
tweets and 95% non-depression tweets. To handle this class imbalance, we used
undersampling methods. The resulting classifier had high recall, but low
precision. Therefore, we only use this classifier to compute the estimated
percentage of depressed tweets and to add this value as a feature for the
user-level classifier.},
 address = {Vancouver, BC},
 author = {Jamil, Zunaira and Inkpen, Diana and Buddhitha, Prasadith and White, Kenton},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3104},
 booktitle = {Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology --- From Linguistic Signal to Clinical Reality},
 month = {August},
 pages = {32--40},
 publisher = {Association for Computational Linguistics},
 title = {Monitoring Tweets for Depression to Detect At-risk Users},
 year = {2017}
}

@inproceedings{W17-3105,
 abstract = {In this paper, we use qualitative research methods to investigate the attitudes
of social media users towards the (opt-in) integration of social media data
with routine mental health care and diagnosis. Our investigation was based on
secondary analysis of a series of five focus groups with Twitter users, including three groups consisting of participants with a self-reported history
of depression, and two groups consisting of participants without a self
reported history of depression. Our results indicate that, overall, research
participants were enthusiastic about the possibility of using social media (in
conjunction with automated Natural Language Processing algorithms) for mood
tracking under the supervision of a mental health practitioner. However, for at
least some participants, there was skepticism related to how well social media
represents the mental health of users, and hence its usefulness in the clinical
context.},
 address = {Vancouver, BC},
 author = {Mikal, Jude and Hurst, Samantha and Conway, Mike},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3105},
 booktitle = {Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology --- From Linguistic Signal to Clinical Reality},
 month = {August},
 pages = {41--47},
 publisher = {Association for Computational Linguistics},
 title = {Investigating Patient Attitudes Towards the use of Social Media Data to Augment Depression Diagnosis and Treatment: a Qualitative Study},
 year = {2017}
}

@inproceedings{W17-3106,
 abstract = {Obsessive-compulsive disorder (OCD) is an anxiety-based disorder that affects
around 2.5% of the population. A common treatment for OCD is exposure therapy, where the patient repeatedly confronts a feared experience, which has the
long-term effect of decreasing their anxiety. Some exposures consist of reading
and writing stories about an imagined anxiety-provoking scenario. In this
paper, we present a technology that enables patients to interactively
contribute to exposure stories by supplying natural language input (typed or
spoken) that advances a scenario. This interactivity could potentially increase
the patient's sense of immersion in an exposure and contribute to its success.
We introduce the NLP task behind processing inputs to predict new events in the
scenario, and describe our initial approach. We then illustrate the future
possibility of this work with an example of an exposure scenario authored with
our application.},
 address = {Vancouver, BC},
 author = {Roemmele, Melissa and Mardo, Paola and Gordon, Andrew},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3106},
 booktitle = {Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology --- From Linguistic Signal to Clinical Reality},
 month = {August},
 pages = {48--57},
 publisher = {Association for Computational Linguistics},
 title = {Natural-language Interactive Narratives in Imaginal Exposure Therapy for Obsessive-Compulsive Disorder},
 year = {2017}
}

@inproceedings{W17-3107,
 abstract = {Previous investigations into detecting mental illnesses through social media
have predominately focused on detecting depression through Twitter corpora. In
this paper, we study anxiety disorders through personal narratives collected
through the popular social media website, Reddit. We build a substantial data
set of typical and anxiety-related posts, and we apply N-gram language
modeling, vector embeddings, topic analysis, and emotional norms to generate
features that accurately classify posts related to binary levels of anxiety. We
achieve an accuracy of 91% with vector-space word embeddings, and an accuracy
of 98% when combined with lexicon-based features.},
 address = {Vancouver, BC},
 author = {Shen, Judy Hanwen and Rudzicz, Frank},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3107},
 booktitle = {Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology --- From Linguistic Signal to Clinical Reality},
 month = {August},
 pages = {58--65},
 publisher = {Association for Computational Linguistics},
 title = {Detecting Anxiety through Reddit},
 year = {2017}
}

@inproceedings{W17-3108,
 abstract = {Individuals on social media may reveal themselves to be in various states of
crisis (e.g. suicide, self-harm, abuse, or eating disorders). Detecting crisis
from social media text automatically and accurately can have profound
consequences. However, detecting a general state of crisis without explaining
why has limited applications. An explanation in this context is a coherent, concise subset of the text that rationalizes the crisis detection. We explore
several methods to detect and explain crisis using a combination of neural and
non-neural techniques. We evaluate these techniques on a unique data set
obtained from Koko, an anonymous emotional support network available through
various messaging applications. We annotate a small subset of the samples
labeled with crisis with corresponding explanations. Our best technique
significantly outperforms the baseline for detection and explanation.},
 address = {Vancouver, BC},
 author = {Kshirsagar, Rohan and Morris, Robert and Bowman, Samuel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3108},
 booktitle = {Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology --- From Linguistic Signal to Clinical Reality},
 month = {August},
 pages = {66--73},
 publisher = {Association for Computational Linguistics},
 title = {Detecting and Explaining Crisis},
 year = {2017}
}

@inproceedings{W17-3109,
 abstract = {People typically assume that killers are mentally ill or fundamentally
different from the rest of humanity. Similarly, people often associate mental
health conditions (such as schizophrenia or autism) with violence and otherness
- treatable perhaps, but not empathically understandable. We take a dictionary
approach to explore word use in a set of autobiographies, comparing the
narratives of 2 killers (Adolf Hitler and Elliot Rodger) and 39 non-killers.
Although results suggest several dimensions that differentiate these
autobiographies - such as sentiment, temporal orientation, and references to
death - they appear to reflect subject matter rather than psychology per se.
Additionally, the Rodger text shows roughly typical developmental arcs in its
use of words relating to friends, family, sex, and affect. From these data, we
discuss the challenges of understanding killers and people in general.},
 address = {Vancouver, BC},
 author = {Iserman, Micah and Ireland, Molly},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3109},
 booktitle = {Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology --- From Linguistic Signal to Clinical Reality},
 month = {August},
 pages = {74--84},
 publisher = {Association for Computational Linguistics},
 title = {A Dictionary-Based Comparison of Autobiographies by People and Murderous Monsters},
 year = {2017}
}

@inproceedings{W17-3110,
 abstract = {Many psychological phenomena occur in small time windows, measured in minutes
or hours. However, most computational linguistic techniques look at data on the
order of weeks, months, or years. We explore micropatterns in sequences of
messages occurring over a short time window for their prevalence and power for
quantifying psychological phenomena, specifically, patterns in affect. We
examine affective micropatterns in social media posts from users with anxiety, eating disorders, panic attacks, schizophrenia, suicidality, and matched
controls.},
 address = {Vancouver, BC},
 author = {Loveys, Kate and Crutchley, Patrick and Wyatt, Emily and Coppersmith, Glen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3110},
 booktitle = {Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology --- From Linguistic Signal to Clinical Reality},
 month = {August},
 pages = {85--95},
 publisher = {Association for Computational Linguistics},
 title = {Small but Mighty: Affective Micropatterns for Quantifying Mental Health from Social Media Language},
 year = {2017}
}

@inproceedings{W17-3201,
 abstract = {Recently, the attention mechanism plays a key role to achieve high performance
for Neural Machine Translation models. However, as it computes a score function
for the encoder states in all positions at each decoding step, the attention
model greatly increases the computational complexity. In this paper, we
investigate the adequate vision span of attention models in the context of
machine translation, by proposing a novel attention framework that is capable
of reducing redundant score computation dynamically. The term "vision span"'
means a window of the encoder states considered by the attention model in one
step. In our experiments, we found that the average window size of vision span
can be reduced by over 50% with modest loss in accuracy on English-Japanese and
German-English translation tasks.},
 address = {Vancouver},
 author = {Shu, Raphael and Nakayama, Hideki},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3201},
 booktitle = {Proceedings of the First Workshop on Neural Machine Translation},
 month = {August},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {An Empirical Study of Adequate Vision Span for Attention-Based Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-3202,
 abstract = {In this paper, we offer an in-depth analysis about the modeling and search
performance. We address the question if a more complex search algorithm is
necessary. Furthermore, we investigate the question if more complex models
which might only be applicable during rescoring are promising.
By separating the search space and the modeling using n-best list reranking, we
analyze the influence of both parts of an NMT system independently. By
comparing differently performing NMT systems, we show that the better
translation is already in the search space of the translation systems with less
performance. This results indicate that the current search algorithms are
sufficient for the NMT systems. Furthermore, we could show that even a
relatively small $n$-best list of $50$ hypotheses already contain notably
better translations.},
 address = {Vancouver},
 author = {Niehues, Jan and Cho, Eunah and Ha, Thanh-Le and Waibel, Alex},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3202},
 booktitle = {Proceedings of the First Workshop on Neural Machine Translation},
 month = {August},
 pages = {11--17},
 publisher = {Association for Computational Linguistics},
 title = {Analyzing Neural MT Search and Model Performance},
 year = {2017}
}

@inproceedings{W17-3203,
 abstract = {Interest in neural machine translation has grown rapidly as its effectiveness
has been demonstrated across language and data scenarios.  New research
regularly introduces architectural and algorithmic improvements that lead to
significant gains over ``vanilla'' NMT implementations.  However, these new
techniques are rarely evaluated in the context of previously published
techniques, specifically those that are widely used in state-of-the-art
production and shared-task systems.  As a result, it is often difficult to
determine whether improvements from research will carry over to systems
deployed for real-world use.  In this work, we recommend three specific methods
that are relatively easy to implement and result in much stronger experimental
systems.  Beyond reporting significantly higher BLEU scores, we conduct an
in-depth analysis of where improvements originate and what inherent weaknesses
of basic NMT models are being addressed.  We then compare the relative gains
afforded by several other techniques proposed in the literature when starting
with vanilla systems versus our stronger baselines, showing that experimental
conclusions may change depending on the baseline chosen.  This indicates that
choosing a strong baseline is crucial for reporting reliable experimental
results.},
 address = {Vancouver},
 author = {Denkowski, Michael and Neubig, Graham},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3203},
 booktitle = {Proceedings of the First Workshop on Neural Machine Translation},
 month = {August},
 pages = {18--27},
 publisher = {Association for Computational Linguistics},
 title = {Stronger Baselines for Trustable Results in Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-3204,
 abstract = {We explore six challenges for neural machine translation: domain mismatch, amount of training data, rare words, long sentences, word alignment, and beam
search. We show both deficiencies and improvements over the quality of
phrase-based statistical machine translation.},
 address = {Vancouver},
 author = {Koehn, Philipp and Knowles, Rebecca},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3204},
 booktitle = {Proceedings of the First Workshop on Neural Machine Translation},
 month = {August},
 pages = {28--39},
 publisher = {Association for Computational Linguistics},
 title = {Six Challenges for Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-3205,
 abstract = {In this paper, we propose a new domain adaptation technique for neural machine
translation called cost weighting, which is appropriate for adaptation
scenarios in which a small in-domain data set and a large general-domain data
set are available. Cost weighting incorporates a domain classifier into the
neural machine translation training algorithm, using features derived from the
encoder representation in order to distinguish in-domain from out-of-domain
data. Classifier probabilities are used to weight sentences according to their
domain similarity when updating the parameters of the neural translation model.
We compare cost weighting to two traditional domain adaptation techniques
developed for statistical machine translation: data selection and sub-corpus
weighting. Experiments on two large-data tasks show that both the traditional
techniques and our novel proposal lead to significant gains, with cost
weighting outperforming the traditional methods.},
 address = {Vancouver},
 author = {Chen, Boxing and Cherry, Colin and Foster, George and Larkin, Samuel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3205},
 booktitle = {Proceedings of the First Workshop on Neural Machine Translation},
 month = {August},
 pages = {40--46},
 publisher = {Association for Computational Linguistics},
 title = {Cost Weighting for Neural Machine Translation Domain Adaptation},
 year = {2017}
}

@inproceedings{W17-3206,
 abstract = {Despite its promise, neural machine translation (NMT) has a serious problem in
that source content may be mistakenly left untranslated. The ability to detect
untranslated content is important for the practical use of NMT. We evaluate two
types of probability with which to detect untranslated content: the cumulative
attention (ATN) probability and back translation (BT) probability from the
target sentence to the source sentence. Experiments on detecting untranslated
content in Japanese-English patent translations show that ATN and BT are each
more effective than random choice, BT is more effective than ATN, and the
combination of the two provides further improvements. We also confirmed the
effectiveness of using ATN and BT to rerank the n-best NMT outputs.},
 address = {Vancouver},
 author = {Goto, Isao and Tanaka, Hideki},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3206},
 booktitle = {Proceedings of the First Workshop on Neural Machine Translation},
 month = {August},
 pages = {47--55},
 publisher = {Association for Computational Linguistics},
 title = {Detecting Untranslated Content for Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-3207,
 abstract = {The basic concept in Neural Machine Translation (NMT) is to train a large
Neural Network that maximizes the translation performance on a given parallel
corpus. NMT is then using a simple left-to-right beam-search decoder to
generate new translations that approximately maximize the trained conditional
probability. The current beam search strategy generates the target sentence
word by word from left-to-right while keeping a fixed amount of active
candidates at each time step. First, this simple search is less adaptive as it
also expands candidates whose scores are much worse than the current best.
Secondly, it does not expand hypotheses if they are not within the best scoring
candidates, even if their scores are close to the best one. The latter one can
be avoided by increasing the beam size until no performance improvement can be
observed. While you can reach better performance, this has the drawback of a
slower decoding speed. In this paper, we concentrate on speeding up the decoder
by applying a more flexible beam search strategy whose candidate size may vary
at each time step depending on the candidate scores. We speed up the original
decoder by up to 43% for the two language pairs German to English and Chinese
to English without losing any translation quality.},
 address = {Vancouver},
 author = {Freitag, Markus and Al-Onaizan, Yaser},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3207},
 booktitle = {Proceedings of the First Workshop on Neural Machine Translation},
 month = {August},
 pages = {56--60},
 publisher = {Association for Computational Linguistics},
 title = {Beam Search Strategies for Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-3208,
 abstract = {Training of neural machine translation (NMT) models usually uses mini-batches
for efficiency purposes.
During the mini-batched training process, it is necessary to pad shorter
sentences in a mini-batch to be equal in length to the longest sentence therein
for efficient computation.
Previous work has noted that sorting the corpus based on the sentence length
before making mini-batches reduces the amount of padding and increases the
processing speed.
However, despite the fact that mini-batch creation is an essential step in NMT
training, widely used NMT toolkits implement disparate strategies for doing so, which have not been empirically validated or compared.
This work investigates mini-batch creation strategies with experiments over two
different datasets.
Our results suggest that the choice of a mini-batch creation strategy has a
large effect on NMT training and some length-based sorting strategies do not
always work well compared with simple shuffling.},
 address = {Vancouver},
 author = {Morishita, Makoto and Oda, Yusuke and Neubig, Graham and Yoshino, Koichiro and Sudoh, Katsuhito and Nakamura, Satoshi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3208},
 booktitle = {Proceedings of the First Workshop on Neural Machine Translation},
 month = {August},
 pages = {61--68},
 publisher = {Association for Computational Linguistics},
 title = {An Empirical Study of Mini-Batch Creation Strategies for Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-3209,
 abstract = {Parallel corpora are often not as parallel as one might assume: non-literal
translations and noisy translations abound, even in curated corpora routinely
used for training and evaluation. We use a cross-lingual textual entailment
system to distinguish sentence pairs that are parallel in meaning from those
that are not, and show that filtering out divergent examples from training
improves translation quality.},
 address = {Vancouver},
 author = {Carpuat, Marine and Vyas, Yogarshi and Niu, Xing},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3209},
 booktitle = {Proceedings of the First Workshop on Neural Machine Translation},
 month = {August},
 pages = {69--79},
 publisher = {Association for Computational Linguistics},
 title = {Detecting Cross-Lingual Semantic Divergence for Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-3401,
 address = {London, UK},
 author = {Shimada, Junri},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3401},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {BE Is Not the Unique Homomorphism That Makes the Partee Triangle Commute},
 year = {2017}
}

@inproceedings{W17-3402,
 address = {London, UK},
 author = {Hoenen, Armin and Eger, Steffen and Gehrke, Ralf},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3402},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {11--21},
 publisher = {Association for Computational Linguistics},
 title = {How Many Stemmata with Root Degree k?},
 year = {2017}
}

@inproceedings{W17-3403,
 address = {London, UK},
 author = {Jardine, Adam},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3403},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {22--35},
 publisher = {Association for Computational Linguistics},
 title = {On the Logical Complexity of Autosegmental Representations},
 year = {2017}
}

@inproceedings{W17-3404,
 address = {London, UK},
 author = {Rogers, James and Lambert, Dakotah},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3404},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {36--46},
 publisher = {Association for Computational Linguistics},
 title = {Extracting Forbidden Factors from Regular Stringsets},
 year = {2017}
}

@inproceedings{W17-3405,
 address = {London, UK},
 author = {Cohen, Shay},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3405},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {47--58},
 publisher = {Association for Computational Linguistics},
 title = {Latent-Variable PCFGs: Background and Applications},
 year = {2017}
}

@inproceedings{W17-3406,
 address = {London, UK},
 author = {Francez, Nissim},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3406},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {59--67},
 publisher = {Association for Computational Linguistics},
 title = {A Proof-Theoretic Semantics for Transitive Verbs with an Implicit Object},
 year = {2017}
}

@inproceedings{W17-3407,
 address = {London, UK},
 author = {Parikh, Rohit},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3407},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {68--74},
 publisher = {Association for Computational Linguistics},
 title = {Why We Speak},
 year = {2017}
}

@inproceedings{W17-3408,
 address = {London, UK},
 author = {Icard, Thomas and Moss, Lawrence and Tune, William},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3408},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {75--87},
 publisher = {Association for Computational Linguistics},
 title = {A Monotonicity Calculus and Its Completeness},
 year = {2017}
}

@inproceedings{W17-3409,
 address = {London, UK},
 author = {Drewes, Frank},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3409},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {88--99},
 publisher = {Association for Computational Linguistics},
 title = {DAG Automata for Meaning Representation},
 year = {2017}
}

@inproceedings{W17-3410,
 address = {London, UK},
 author = {Gilroy, Sorcha and Lopez, Adam and Maneth, Sebastian and Simonaitis, Pijus},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3410},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {100--113},
 publisher = {Association for Computational Linguistics},
 title = {(Re)introducing Regular Graph Languages},
 year = {2017}
}

@inproceedings{W17-3411,
 address = {London, UK},
 author = {Graf, Thomas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3411},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {114--126},
 publisher = {Association for Computational Linguistics},
 title = {Graph Transductions and Typological Gaps in Morphological Paradigms},
 year = {2017}
}

@inproceedings{W17-3412,
 address = {London, UK},
 author = {Clark, Stephen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3412},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {127},
 publisher = {Association for Computational Linguistics},
 title = {Introducing Structure into Neural Network-Based Semantic Models},
 year = {2017}
}

@inproceedings{W17-3413,
 address = {London, UK},
 author = {Kuznetsov, Stepan and Morrill, Glyn and Valent\'{i}n, Oriol},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3413},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {128--139},
 publisher = {Association for Computational Linguistics},
 title = {Count-Invariance Including Exponentials},
 year = {2017}
}

@inproceedings{W17-3414,
 address = {London, UK},
 author = {Kuznetsov, Stepan and Okhotin, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3414},
 booktitle = {Proceedings of the 15th Meeting on the Mathematics of Language},
 month = {July},
 pages = {140--151},
 publisher = {Association for Computational Linguistics},
 title = {Conjunctive Categorial Grammars},
 year = {2017}
}

@inproceedings{W17-3501,
 abstract = {In this paper, we study AMR-to-text generation, framing it as a translation
task and comparing two different MT approaches (Phrase-based and Neural MT). We
systematically study the effects of 3 AMR preprocessing steps
(Delexicalisation, Compression, and Linearisation) applied before the MT phase.
Our results show that preprocessing indeed helps, although the benefits differ
for the two MT models.},
 address = {Santiago de Compostela, Spain},
 author = {Castro Ferreira, Thiago and Calixto, Iacer and Wubben, Sander and Krahmer, Emiel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3501},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Linguistic realisation as machine translation: Comparing different MT models for AMR-to-text generation},
 year = {2017}
}

@inproceedings{W17-3502,
 abstract = {Poetry generation is becoming popular among researchers of Natural Language
Generation, Computational Creativity and, broadly, Artificial Intelligence.
To produce text that may be regarded as poetry, poetry generation systems are
typically knowledge-intensive and have to deal with several levels of language, from lexical to semantics.
Interest on the topic resulted in the development of several poetry generators
described in the literature, with different features covered or handled
differently, by a broad range of alternative approaches, as well as different
perspectives on evaluation, another challenging aspect due the underlying
subjectivity.
This paper surveys intelligent poetry generators around a set of relevant
axis for poetry generation -- targeted languages, form and content features, techniques, reutilisation of material, and evaluation -- and aims to organise
work developed on this topic so far.},
 address = {Santiago de Compostela, Spain},
 author = {Gon\c{c}alo Oliveira, Hugo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3502},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {11--20},
 publisher = {Association for Computational Linguistics},
 title = {A Survey on Intelligent Poetry Generation: Languages, Features, Techniques, Reutilisation and Evaluation},
 year = {2017}
}

@inproceedings{W17-3503,
 abstract = {Automatic image description systems are commonly trained and evaluated on large
image description datasets. Recently, researchers have started to collect such
datasets for languages other than English. An unexplored question is how
different these datasets are from English and, if there are any differences, what causes them to differ. This paper provides a cross-linguistic comparison
of Dutch, English, and German image descriptions. We find that these
descriptions are similar in many respects, but the familiarity of crowd workers
with the subjects of the images has a noticeable influence on the specificity
of the descriptions.},
 address = {Santiago de Compostela, Spain},
 author = {van Miltenburg, Emiel and Elliott, Desmond and Vossen, Piek},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3503},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {21--30},
 publisher = {Association for Computational Linguistics},
 title = {Cross-linguistic differences and similarities in image descriptions},
 year = {2017}
}

@inproceedings{W17-3504,
 abstract = {We study the task of constructing sports news report automatically from live
commentary and focus on content selection. Rather than receiving every piece of
text of a sports match before news construction, as in previous related work, we novelly verify the feasibility of a more challenging but more useful setting
to generate news report on the fly by treating live text input as a stream.
Specifically, we design various scoring functions to address different
requirements of the task. The near submodularity of scoring functions makes it
possible to adapt efficient greedy algorithms even in stream data settings.
Experiments suggest that our proposed framework can already produce comparable
results compared with previous work that relies on a supervised
learning-to-rank model with heavy feature engineering.},
 address = {Santiago de Compostela, Spain},
 author = {Yao, Jin-ge and Zhang, Jianmin and Wan, Xiaojun and Xiao, Jianguo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3504},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {31--40},
 publisher = {Association for Computational Linguistics},
 title = {Content Selection for Real-time Sports News Construction from Commentary Texts},
 year = {2017}
}

@inproceedings{W17-3505,
 abstract = {We present a flexible Natural Language Generation approach for Spanish, focused
on the surface realisation stage, which integrates an inflection module in
order to improve the naturalness and expressivity of the generated language.
This inflection module inflects the verbs using an ensemble of trainable
algorithms
whereas the other types of words (e.g. nouns, determiners, etc) are inflected
using hand-crafted rules. We show that our approach achieves 2% higher accuracy
than two state-of-art inflection generation approaches. Furthermore, our
proposed approach also predicts an extra feature: the inflection of the
imperative mood, which was not taken into account by previous work. We also
present a user evaluation, where we demonstrate that the proposed method
significantly improves the perceived naturalness of the generated language.},
 address = {Santiago de Compostela, Spain},
 author = {Barros, Cristina and Gkatzia, Dimitra and Lloret, Elena},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3505},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {41--50},
 publisher = {Association for Computational Linguistics},
 title = {Improving the Naturalness and Expressivity of Language Generation for Spanish},
 year = {2017}
}

@inproceedings{W17-3506,
 abstract = {Image captioning has evolved into a core task for Natural Language Generation
and has also proved to be an important testbed for deep learning approaches to
handling multimodal representations. Most contemporary approaches rely on a
combination of a convolutional network to handle image features, and a
recurrent network to encode linguistic information. The latter is typically
viewed as the primary ``generation'' component. Beyond this high-level
characterisation, a CNN+RNN model supports a variety of architectural designs.
The dominant model in the literature is one in which visual features encoded by
a CNN are ``injected'' as part of the linguistic encoding process, driving the
RNN's linguistic choices. By contrast, it is possible to envisage an
architecture in which visual and linguistic features are encoded separately, and merged at a subsequent stage. In this paper, we address two related
questions: (1) Is direct injection the best way of combining multimodal
information, or is a late merging alternative better for the image captioning
task? (2) To what extent should a recurrent network be viewed as actually
generating, rather than simply encoding, linguistic information?},
 address = {Santiago de Compostela, Spain},
 author = {Tanti, Marc and Gatt, Albert and Camilleri, Kenneth},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3506},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {51--60},
 publisher = {Association for Computational Linguistics},
 title = {What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption Generator?},
 year = {2017}
}

@inproceedings{W17-3507,
 abstract = {Describing people and characters can be very useful in different contexts, such
as computational narrative or image description for the visually impaired.
However, a review of the existing literature shows that the automatic
generation of people descriptions has not received much attention. Our work
focuses on the description of people in snapshots from a 3D environment. First, we have conducted a survey to identify the way in which people describe other
people under different conditions. We have used the information extracted from
this survey to design several Referring Expression Generation algorithms which
produce similar results. We have evaluated these algorithms with users in order
to identify which ones generate the best description for specific characters in
different situations. The evaluation has shown that, in order to generate good
descriptions, a combination of different algorithms has to be used depending on
the features and situation of the person to be described.},
 address = {Santiago de Compostela, Spain},
 author = {M\'{e}ndez, Gonzalo and Herv\'{a}s, Raquel and Bautista, Susana and Rabadan, Adrian and Rodriguez, Teresa},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3507},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {61--69},
 publisher = {Association for Computational Linguistics},
 title = {Exploring the Behavior of Classic REG Algorithms in the Description of Characters in 3D Images},
 year = {2017}
}

@inproceedings{W17-3508,
 abstract = {Co-PoeTryMe is a web application for poetry composition, guided by the user, though with the help of automatic features, such as the generation of full
(editable) drafts, as well as the acquisition of additional well-formed lines, or semantically-related words, possibly constrained by the number of syllables, rhyme, or polarity.
Towards the final poem, the latter can replace lines or words in the draft.},
 address = {Santiago de Compostela, Spain},
 author = {Gon\c{c}alo Oliveira, Hugo and Mendes, Tiago and Boavida, Ana},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3508},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {70--71},
 publisher = {Association for Computational Linguistics},
 title = {Co-PoeTryMe: a Co-Creative Interface for the Composition of Poetry},
 year = {2017}
}

@inproceedings{W17-3509,
 abstract = {Current referring expression generation systems mostly deliver their output as
one-shot, written expressions. We present on-going work on incremental
generation of spoken expressions referring to objects in real-world images.
This approach extends upon previous work using the words-as-classifier model
for generation. We implement this generator in an incremental dialogue
processing framework such that we can exploit an existing interface to
incremental text-to-speech synthesis. Our system generates and synthesizes
referring expressions while continuously observing non-verbal user reactions.},
 address = {Santiago de Compostela, Spain},
 author = {Zarrie{\ss}, Sina and L\'{o}pez Gambino, M. Soledad and Schlangen, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3509},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {72--73},
 publisher = {Association for Computational Linguistics},
 title = {Refer-iTTS: A System for Referring in Spoken Installments to Objects in Real-World Images},
 year = {2017}
}

@inproceedings{W17-3510,
 abstract = {This talk will present a few NLG systems developed within Thomson Reuters
providing information to professionals such as lawyers, accountants or traders.
Based on the experience developing these system, I will discuss the usefulness
of automatic metrics, crowd-sourced evaluation, corpora studies and expert
reviews. I will conclude with exploring the question of whether developers of
NLG systems need to follow ethical guidelines and how those guidelines could be
established.},
 address = {Santiago de Compostela, Spain},
 author = {Schilder, Frank},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3510},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {74},
 publisher = {Association for Computational Linguistics},
 title = {Finding the "right" answers for customers},
 year = {2017}
}

@inproceedings{W17-3511,
 abstract = {For situated agents to effectively engage in natural-language interactions with
humans, they must be able to refer to entities such as people, locations, and
objects. While classic referring expression generation (REG) algorithms like
the Incremental Algorithm (IA) assume perfect, complete, and accessible
knowledge of all referents, this is not always possible. In this work, we show
how a previously presented consultant framework (which facilitates reference
resolution when knowledge is uncertain, heterogeneous and distributed) can be
used to extend the IA to produce DIST-PIA, a domain-independent algorithm for
REG under uncertain, heterogeneous, and distributed knowledge. We also present
a novel framework that can be used to evaluate such REG algorithms without
conflating the performance of the algorithm with the performance of classifiers
it employs.},
 address = {Santiago de Compostela, Spain},
 author = {Williams, Tom and Scheutz, Matthias},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3511},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {75--84},
 publisher = {Association for Computational Linguistics},
 title = {Referring Expression Generation under Uncertainty: Algorithm and Evaluation Framework},
 year = {2017}
}

@inproceedings{W17-3512,
 abstract = {There has been continuous growth in the volume and ubiquity of video material.
It has become essential to define video semantics in order to aid the
searchability and retrieval of this data. We present a framework that produces
textual descriptions of video, based on the visual semantic content. Detected
action classes rendered as verbs, participant objects converted to noun
phrases, visual properties of detected objects rendered as adjectives and
spatial relations between objects rendered as prepositions. Further, in cases
of zero-shot action recognition, a language model is used to infer a missing
verb, aided by the detection of objects and scene settings. These extracted
features are converted into textual descriptions using a template-based
approach. The proposed video descriptions framework evaluated on the NLDHA
dataset using ROUGE scores and human judgment evaluation.},
 address = {Santiago de Compostela, Spain},
 author = {Alharbi, Nouf and Gotoh, Yoshihiko},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3512},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {85--94},
 publisher = {Association for Computational Linguistics},
 title = {Natural Language Descriptions for Human Activities in Video Streams},
 year = {2017}
}

@inproceedings{W17-3513,
 abstract = {We present PASS, a data-to-text system that generates Dutch soccer reports from
match statistics. One of the novel elements of PASS is the fact that the system
produces corpus-based texts tailored towards fans of one club or the other, which can most prominently be observed in the tone of voice used in the
reports. Furthermore, the system is open source and uses a modular design, which makes it relatively easy for people to add extensions. Human-based
evaluation shows that people are generally positive towards PASS in regards to
its clarity and fluency, and that the tailoring is accurately recognized in
most cases.},
 address = {Santiago de Compostela, Spain},
 author = {van der Lee, Chris and Krahmer, Emiel and Wubben, Sander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3513},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {95--104},
 publisher = {Association for Computational Linguistics},
 title = {PASS: A Dutch data-to-text system for soccer, targeted towards specific audiences},
 year = {2017}
}

@inproceedings{W17-3514,
 abstract = {Natural Language Generation (NLG) can be used to generate personalized health
information, which is especially useful when provided in one's own language.
However, the NLG technique widely used in different domains and
languages---templates---was shown to be inapplicable to Bantu languages, due to
their characteristic agglutinative structure. We present here our use of the
grammar engine NLG technique to generate text in Runyankore, a Bantu language
indigenous to Uganda. Our grammar engine adds to previous work in this field
with new rules for cardinality constraints, prepositions in roles, the passive, and phonological conditioning. We evaluated the generated text with linguists
and non-linguists, who regarded most text as grammatically correct and
understandable; and over 60\% of them regarded all the text generated by our
system to have been authored by a human being.},
 address = {Santiago de Compostela, Spain},
 author = {Byamugisha, Joan and Keet, C. Maria and DeRenzi, Brian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3514},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {105--113},
 publisher = {Association for Computational Linguistics},
 title = {Evaluation of a Runyankore grammar engine for healthcare messages},
 year = {2017}
}

@inproceedings{W17-3515,
 abstract = {We use language to talk about the world, and so reference is a crucial property
of language. However, modeling reference is particularly difficult, as it
involves both continuous and discrete as-pects of language. For instance, referring expressions like "the big mug" or "it" typically contain content
words ("big", "mug"), which are notoriously fuzzy or vague in their meaning, and also fun-ction words ("the", "it") that largely serve as discrete pointers.
Data-driven, distributed models based on distributional semantics or deep
learning excel at the former, but struggle with the latter, and the reverse is
true for symbolic models. I present ongoing work on modeling reference with a
distribu-ted model aimed at capturing both aspects, and learns to refer
directly from reference acts.},
 address = {Santiago de Compostela, Spain},
 author = {Boleda, Gemma},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3515},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {114},
 publisher = {Association for Computational Linguistics},
 title = {Talking about the world with a distributed model},
 year = {2017}
}

@inproceedings{W17-3516,
 abstract = {We propose a new shared task for tactical data-to-text generation in the domain
of source code libraries. Specifically, we focus on text generation of function
descriptions from example software projects. Data is drawn from existing
resources used for studying the related problem of semantic parser induction, and spans a wide variety of both natural languages and programming languages.
In this paper, we describe these existing resources, which will serve as
training and development data for the task, and discuss plans for building new
independent test sets.},
 address = {Santiago de Compostela, Spain},
 author = {Richardson, Kyle and Zarrie{\ss}, Sina and Kuhn, Jonas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3516},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {115--119},
 publisher = {Association for Computational Linguistics},
 title = {The Code2Text Challenge: Text Generation in Source Libraries},
 year = {2017}
}

@inproceedings{W17-3517,
 abstract = {We propose a shared task on multilingual Surface Realization, i.e., on mapping
unordered and uninflected universal dependency trees to correctly ordered and
inflected sentences in a number of languages. A second deeper input will be
available in which, in addition, functional words, fine-grained PoS and
morphological information will be removed from the input trees. The first
shared task on Surface Realization was carried out in 2011 with a similar
setup, with a focus on English. We think that it is time for relaunching such a
shared task effort in view of the arrival of Universal Dependencies annotated
treebanks for a large number of languages on the one hand, and the increasing
dominance of Deep Learning, which proved to be a game changer for NLP, on the
other hand.},
 address = {Santiago de Compostela, Spain},
 author = {Mille, Simon and Bohnet, Bernd and Wanner, Leo and Belz, Anja},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3517},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {120--123},
 publisher = {Association for Computational Linguistics},
 title = {Shared Task Proposal: Multilingual Surface Realization Using Universal Dependency Trees},
 year = {2017}
}

@inproceedings{W17-3518,
 abstract = {The WebNLG challenge consists in mapping sets of RDF triples to text. It
provides a common benchmark on which to train, evaluate and compare
{\^a}microplanners{\^a}, i.e. generation systems that verbalise a given content by
making a range of complex interacting choices including referring expression
generation, aggregation, lexicalisation, surface realisation and sentence
segmentation. In this paper, we introduce the microplanning task, describe data
preparation, introduce our evaluation methodology, analyse participant results
and provide a brief description of the participating systems.},
 address = {Santiago de Compostela, Spain},
 author = {Gardent, Claire and Shimorina, Anastasia and Narayan, Shashi and Perez-Beltrachini, Laura},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3518},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {124--133},
 publisher = {Association for Computational Linguistics},
 title = {The WebNLG Challenge: Generating Text from RDF Data},
 year = {2017}
}

@inproceedings{W17-3519,
 abstract = {I briefly describe some of the commercial work which XXX is doing in referring
expression algorithms, and highlight differences between what is commercially
important (at least to XXX) and the NLG research literature.  In particular, XXX is less interested in generic reference algorithms than in high-quality
algorithms for specific types of references, such as components of machines, named entities, and dates.},
 address = {Santiago de Compostela, Spain},
 author = {Reiter, Ehud},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3519},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {134--138},
 publisher = {Association for Computational Linguistics},
 title = {A Commercial Perspective on Reference},
 year = {2017}
}

@inproceedings{W17-3520,
 abstract = {Integrating surface realization and the generation of referring
expressions into a single algorithm can improve the quality of the
generated sentences. Existing algorithms for doing this, such as
SPUD and CRISP, are search-based and can be slow or incomplete. We
offer a chart-based algorithm for integrated sentence generation and
demonstrate its runtime efficiency.},
 address = {Santiago de Compostela, Spain},
 author = {Koller, Alexander and Engonopoulos, Nikos},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3520},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {139--143},
 publisher = {Association for Computational Linguistics},
 title = {Integrated sentence generation using charts},
 year = {2017}
}

@inproceedings{W17-3521,
 abstract = {We describe SimpleNLG-ES, an adaptation of the SimpleNLG realization library
for the Spanish language. Our implementation is based on the bilingual
English-French SimpleNLG-EnFr adaptation. The library has been tested using a
battery of examples that ensure that the most common syntax, morphology and
orthography rules for Spanish are met. The library is currently being used in
three different projects for the development of data-to-text systems in the
meteorological, statistical data information, and business intelligence
application domains.},
 address = {Santiago de Compostela, Spain},
 author = {Ramos Soto, Alejandro and Janeiro Gallardo, Julio and Bugar\'{i}n Diz, Alberto},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3521},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {144--148},
 publisher = {Association for Computational Linguistics},
 title = {Adapting SimpleNLG to Spanish},
 year = {2017}
}

@inproceedings{W17-3522,
 abstract = {Corpora of referring expressions elicited from human participants in a
controlled environment are an important resource for research on automatic
referring expression generation.
We here present G-TUNA, a new corpus of referring expressions for German. Using
the furniture stimuli set developed for the TUNA and D-TUNA corpora, our corpus
extends on these corpora by providing data collected in a simulated driving
dual-task setting, and additionally provides exact duration annotations for the
spoken referring expressions. This corpus will hence allow researchers to
analyze the interaction between referring expression length and speech rate, under conditions where the listener is under high vs.~low cognitive load.},
 address = {Santiago de Compostela, Spain},
 author = {Howcroft, David and Vogels, Jorrig and Demberg, Vera},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3522},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {149--153},
 publisher = {Association for Computational Linguistics},
 title = {G-TUNA: a corpus of referring expressions in German, including duration information},
 year = {2017}
}

@inproceedings{W17-3523,
 abstract = {There are many domain-specific and language-specific NLG systems, of which it
may be possible to adapt to related domains and languages. The languages in the
Bantu language family have their own set of features distinct from other major
groups, which therefore severely limits the options to bootstrap an NLG system
from existing ones. We present here our first proof-of-concept application for
knowledge-to-text NLG as a plugin to the Protege 5.x ontology development
system, tailored to Runyankore, a Bantu language indigenous to Uganda. It
comprises a basic annotation model for linguistic information such as noun
class, an implementation of existing verbalisation rules and a CFG for verbs, and a basic interface for data entry.},
 address = {Santiago de Compostela, Spain},
 author = {Byamugisha, Joan and Keet, C. Maria and DeRenzi, Brian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3523},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {154--155},
 publisher = {Association for Computational Linguistics},
 title = {Toward an NLG System for Bantu languages: first steps with Runyankore (demo)},
 year = {2017}
}

@inproceedings{W17-3524,
 abstract = {A fully fledged practical working application for a rule-based NLG system is
presented that is able to create non-trivial, human sounding narrative from
structured data, in any language and for any topic.},
 address = {Santiago de Compostela, Spain},
 author = {Wei{\ss}graeber, Robert and Madsack, Andreas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3524},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {156--157},
 publisher = {Association for Computational Linguistics},
 title = {A working, non-trivial, topically indifferent NLG System for 17 languages},
 year = {2017}
}

@inproceedings{W17-3525,
 abstract = {We present two approaches to generate titles for browse pages in five different
languages, namely English, German, French, Italian and Spanish.
These browse pages are structured search pages in an e-commerce domain.
We first present a rule-based approach to generate these browse page titles.
In addition, we also present a hybrid approach which uses a phrase-based
statistical machine translation engine on top of the rule-based system to
assemble the best title.
For the two languages English and German we have access to a large amount of
already available rule-based generated and curated titles.
For these languages we present an automatic post-editing approach which learns
how to post-edit the rule-based titles into curated titles.},
 address = {Santiago de Compostela, Spain},
 author = {Mathur, Prashant and Ueffing, Nicola and Leusch, Gregor},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3525},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {158--167},
 publisher = {Association for Computational Linguistics},
 title = {Generating titles for millions of browse pages on an e-Commerce site},
 year = {2017}
}

@inproceedings{W17-3526,
 abstract = {Data-to-text generation is very essential and important in machine writing
applications. The recent deep learning models, like Recurrent Neural Networks
(RNNs), have shown a bright future for relevant text generation tasks. However, rare work has been done for automatic generation of long reviews from user
opinions. In this paper, we introduce a deep neural network model to generate
long Chinese reviews from aspect-sentiment scores representing users{\^a}
opinions. We conduct our study within the framework of encoder-decoder
networks, and we propose a hierarchical structure with aligned attention in the
Long-Short Term Memory (LSTM) decoder. Experiments show that our model
outperforms retrieval based baseline methods, and also beats the sequential
generation models in qualitative evaluations.},
 address = {Santiago de Compostela, Spain},
 author = {Zang, Hongyu and Wan, Xiaojun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3526},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {168--177},
 publisher = {Association for Computational Linguistics},
 title = {Towards Automatic Generation of Product Reviews from Aspect-Sentiment Scores},
 year = {2017}
}

@inproceedings{W17-3527,
 abstract = {Most work on automatic generation of narratives, and more specifically
suspenseful narrative, has focused on detailed domain-specific modelling of
character psychology and plot structure. Recent work in computational
linguistics on the automatic learning of narrative schemas suggests an
alternative approach that exploits such schemas as a starting point for
modelling and measuring suspense. We propose a domain-independent model for
tracking suspense in a story which can be used to predict the audience's
suspense response on a sentence-by-sentence basis at the content determination
stage of narrative generation. The model lends itself as the theoretical
foundation for a suspense module that is compatible with alternative narrative
generation theories. The proposal is evaluated by human judges' normalised
average scores correlate strongly with predicted values.},
 address = {Santiago de Compostela, Spain},
 author = {Doust, Richard and Piwek, Paul},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3527},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {178--187},
 publisher = {Association for Computational Linguistics},
 title = {A model of suspense for narrative generation},
 year = {2017}
}

@inproceedings{W17-3528,
 abstract = {Despite increasing amounts of data and ever improving natural language
generation techniques, work on automated journalism is still relatively scarce.
In this paper, we explore the field and challenges associated with building a
journalistic natural language generation system. We present a set of
requirements that should guide system design, including transparency, accuracy, modifiability and transferability. Guided by the requirements, we present a
data-driven architecture for automated journalism that is largely domain and
language independent. We illustrate its practical application in the production
of news articles about the 2017 Finnish municipal elections in three languages, demonstrating the successfulness of the data-driven, modular approach of the
design. We then draw some lessons for future automated journalism.},
 address = {Santiago de Compostela, Spain},
 author = {Lepp\"{a}nen, Leo and Munezero, Myriam and Granroth-Wilding, Mark and Toivonen, Hannu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3528},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {188--197},
 publisher = {Association for Computational Linguistics},
 title = {Data-Driven News Generation for Automated Journalism},
 year = {2017}
}

@inproceedings{W17-3529,
 abstract = {Data augmentation is widely used to train deep neural networks for image
classification tasks. Simply flipping images can help learning tremendously by
increasing the number of training images by a factor of two. However, little
work has been done studying data augmentation in natural language processing.
Here, we describe two methods for data augmentation for Visual Question
Answering (VQA). The first uses existing semantic annotations to generate new
questions. The second method is a generative approach using recurrent neural
networks. Experiments show that the proposed data augmentation improves
performance of both baseline and state-of-the-art VQA algorithms.},
 address = {Santiago de Compostela, Spain},
 author = {Kafle, Kushal and Yousefhussien, Mohammed and Kanan, Christopher},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3529},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {198--202},
 publisher = {Association for Computational Linguistics},
 title = {Data Augmentation for Visual Question Answering},
 year = {2017}
}

@inproceedings{W17-3530,
 abstract = {This work proposes an organization of
knowledge to facilitate the generation of personalized
questions, answers and grammars
from web documents. To reduce the human
effort needed in the generation of the linguistic
resources for a new domain, the general
aspects that can be reuse across domains are
separated from those more specific. The proposed
approach is based on the representation
of the main domain concepts as a set of attributes.
These attributes are related to a
syntactico-semantic taxonomy representing
the general relationships between conceptual
and linguistic knowledge. User models are
incorporated by distinguishing different user
groups and relating each group to the appropriate
conceptual attributes. Then, the data is
extracted from the web documents and represented
as instances of the domain concepts.
Questions, answers and grammars are generated from these instances.},
 address = {Santiago de Compostela, Spain},
 author = {Gatius, Marta},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3530},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {203--207},
 publisher = {Association for Computational Linguistics},
 title = {Personalized Questions, Answers and Grammars: Aiding the Search for Relevant Web Information},
 year = {2017}
}

@inproceedings{W17-3531,
 abstract = {We compare several language models for the word-ordering task and propose a new
bag-to-sequence neural model based on attention-based sequence-to-sequence
models. We evaluate the model on a large German WMT data set where it
significantly outperforms existing models. We also describe a novel search
strategy for LM-based word ordering and report results on the English Penn
Treebank. Our best model setup outperforms prior work both in terms of speed
and quality.},
 address = {Santiago de Compostela, Spain},
 author = {Hasler, Eva and Stahlberg, Felix and Tomalin, Marcus and de Gispert, Adria and Byrne, Bill},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3531},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {208--212},
 publisher = {Association for Computational Linguistics},
 title = {A Comparison of Neural Models for Word Ordering},
 year = {2017}
}

@inproceedings{W17-3532,
 abstract = {East Asian languages are thought to handle reference differently from languages
such as English, particularly in terms of the marking of definiteness and
number. We present the first Data-Text corpus for Referring Expressions in
Mandarin, and we use this corpus to test some initial hypotheses inspired by
the theoretical linguistics literature. Our findings suggest that function
words deserve more attention in Referring Expressions Generation than they have
so far received, and they have a bearing on the debate about whether different
languages make different trade-offs between clarity and brevity.},
 address = {Santiago de Compostela, Spain},
 author = {van Deemter, Kees and Sun, Le and Sybesma, Rint and Li, Xiao and Bo, Chen and Yang, Muyun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3532},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {213--217},
 publisher = {Association for Computational Linguistics},
 title = {Investigating the content and form of referring expressions in Mandarin: introducing the Mtuna corpus},
 year = {2017}
}

@inproceedings{W17-3533,
 abstract = {We propose sentence chunking as a way to reduce the time and memory costs of
realization of long sentences. During chunking we divide the semantic
representation of a sentence into smaller components which can be processed and
recombined without loss of information. Our meaning representation of choice is
the Dependency Minimal Recursion Semantics (DMRS). We show that realizing
chunks of a sentence and combining the results of such realizations increases
the coverage for long sentences, significantly reduces the resources required
and does not affect the quality of the realization.},
 address = {Santiago de Compostela, Spain},
 author = {Muszy\'{n}ska, Ewa and Copestake, Ann},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3533},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {218--222},
 publisher = {Association for Computational Linguistics},
 title = {Realization of long sentences using chunking},
 year = {2017}
}

@inproceedings{W17-3534,
 abstract = {Every time we buy something online, we are confronted with Terms of Services.
However, only a few people actually read these terms, before accepting them, often to their disadvantage. In this paper, we present the SaToS browser plugin
which summarises and simplifies Terms of Services from German webshops.},
 address = {Santiago de Compostela, Spain},
 author = {Braun, Daniel and Scepankova, Elena and Holl, Patrick and Matthes, Florian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3534},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {223--227},
 publisher = {Association for Computational Linguistics},
 title = {SaToS: Assessing and Summarising Terms of Services from German Webshops},
 year = {2017}
}

@inproceedings{W17-3535,
 abstract = {Many data-to-text NLG systems work with data sets which are incomplete, ie some
of the data is missing. We have worked with data journalists to understand how
they describe incomplete data, and are building NLG algorithms based on these
insights. A pilot evaluation showed mixed results, and highlighted several
areas where we need to improve our system.},
 address = {Santiago de Compostela, Spain},
 author = {Inglis, Stephanie and Reiter, Ehud and Sripada, Somayajulu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3535},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {228--232},
 publisher = {Association for Computational Linguistics},
 title = {Textually Summarising Incomplete Data},
 year = {2017}
}

@inproceedings{W17-3536,
 abstract = {Referring expression generation (REG) models that use speaker-dependent
information require a considerable amount of training data produced by every
individual speaker, or may otherwise perform poorly. In this work we propose a
simple personalised method for this task, in which speakers are grouped into
profiles according to  their referential behaviour. Intrinsic evaluation shows
that  the use of speaker's profiles generally outperforms the personalised
method found in previous work.},
 address = {Santiago de Compostela, Spain},
 author = {Castro Ferreira, Thiago and Paraboni, Ivandr\'{e}},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3536},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {233--237},
 publisher = {Association for Computational Linguistics},
 title = {Improving the generation of personalised descriptions},
 year = {2017}
}

@inproceedings{W17-3537,
 abstract = {A generation system can only be as good as the data it is trained on. In this
short paper, we propose a methodology for analysing data-to-text corpora used
for training Natural Language Generation (NLG) systems. We apply this
methodology to three existing benchmarks. We conclude by eliciting a set of
criteria for the creation of a data-to-text benchmark which could help better
support the development, evaluation and comparison of linguistically
sophisticated data-to-text generators.},
 address = {Santiago de Compostela, Spain},
 author = {Perez-Beltrachini, Laura and Gardent, Claire},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3537},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {238--242},
 publisher = {Association for Computational Linguistics},
 title = {Analysing Data-To-Text Generation Benchmarks},
 year = {2017}
}

@inproceedings{W17-3538,
 abstract = {Monitoring and analysis of complex phenomena attract the attention of both
academy and industry. Dealing with data produced by complex phenomena requires
the use of advance computational intelligence techniques. Namely, linguistic
description of complex phenomena constitutes a mature research line. It is
supported by the Computational Theory of Perceptions grounded on the Fuzzy Sets
Theory. Its aim is the development of computational systems with the ability to
generate vague descriptions of the world in a similar way how humans do. This
is a human-centric
and multi-disciplinary research work. Moreover, its success is a matter of
careful design; thus, developers play a key role. The rLDCP R package was
designed to facilitate the development of new applications. This demo
introduces the use of rLDCP, for both beginners and advance developers, in
practical use cases.},
 address = {Santiago de Compostela, Spain},
 author = {Alonso, Jose and Conde-Clemente, Patricia and Trivino, Gracian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3538},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {243--244},
 publisher = {Association for Computational Linguistics},
 title = {Linguistic Description of Complex Phenomena with the rLDCP R Package},
 year = {2017}
}

@inproceedings{W17-3539,
 abstract = {This demo paper presents the multilingual deep sentence generator developed by
the TALN group at Universitat Pompeu Fabra, implemented as a series of
rule-based graph-transducers for the syntacticization of the input graphs, the
resolution of morphological agreements, and the linearization of the trees.},
 address = {Santiago de Compostela, Spain},
 author = {Mille, Simon and Wanner, Leo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3539},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {245--246},
 publisher = {Association for Computational Linguistics},
 title = {A demo of FORGe: the Pompeu Fabra Open Rule-based Generator},
 year = {2017}
}

@inproceedings{W17-3540,
 abstract = {We introduce the properties to be satisfied by measures of referential success
of set referring expressions with fuzzy properties. We define families of
measures on the basis of n-cardinality measures and we illustrate some of them
with a toy example.},
 address = {Santiago de Compostela, Spain},
 author = {Marin, Nicolas and Rivas-Gervilla, Gustavo and Sanchez, Daniel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3540},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {247--251},
 publisher = {Association for Computational Linguistics},
 title = {Referential Success of Set Referring Expressions with Fuzzy Properties},
 year = {2017}
}

@inproceedings{W17-3541,
 abstract = {We present a neural response generation model that generates responses
conditioned on a target personality. The model learns high level features based
on the target personality, and uses them to update its hidden state. Our model
achieves performance improvements in both perplexity and BLEU scores over a
baseline sequence-to-sequence model, and is validated by human judges.},
 address = {Santiago de Compostela, Spain},
 author = {Herzig, Jonathan and Shmueli-Scheuer, Michal and Sandbank, Tommy and Konopnicki, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3541},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {252--256},
 publisher = {Association for Computational Linguistics},
 title = {Neural Response Generation for Customer Service based on Personality Traits},
 year = {2017}
}

@inproceedings{W17-3542,
 abstract = {Progress in statistical paraphrase generation has been hindered for a long time
by the lack of large monolingual parallel corpora. In this paper, we adapt the
neural machine translation approach to paraphrase generation and perform
transfer learning from the closely related task of entailment generation. We
evaluate the model on the Microsoft Research Paraphrase (MSRP) corpus and show
that the model is able to generate sentences that capture part of the original
meaning, but fails to pick up on important words or to show large lexical
variation.},
 address = {Santiago de Compostela, Spain},
 author = {Brad, Florin and Rebedea, Traian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-3542},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 month = {September},
 pages = {257--261},
 publisher = {Association for Computational Linguistics},
 title = {Neural Paraphrase Generation using Transfer Learning},
 year = {2017}
}

@inproceedings{W17-4101,
 abstract = {Most of neural language models use different kinds of embeddings for
word prediction. While word embeddings can be associated to each
word in the vocabulary or derived from characters as well as
factored morphological decomposition, these word representations are
mainly used to parametrize the input, i.e. the context of
prediction.  This work investigates the effect of using subword
units (character and factored morphological decomposition) to build
output representations for neural language modeling. We present a
case study on Czech, a morphologically-rich language, experimenting
with different input and output representations.  When working with
the full training vocabulary, despite unstable training, our
experiments show that augmenting the output word representations
with character-based embeddings can significantly improve the
performance of the model. Moreover, reducing the size of the output
look-up table, to let the character-based embeddings represent rare
words, brings further improvement.},
 address = {Copenhagen, Denmark},
 author = {Labeau, Matthieu and Allauzen, Alexandre},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4101},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {1--13},
 publisher = {Association for Computational Linguistics},
 title = {Character and Subword-Based Word Representation for Neural Language Modeling Prediction},
 year = {2017}
}

@inproceedings{W17-4102,
 abstract = {We explore the use of segments learnt using Byte Pair Encoding (referred to as
BPE units) as basic units for statistical machine translation between related
languages and compare it with orthographic syllables, which are currently the
best performing basic units for this translation task. BPE identifies the most
frequent character sequences as basic units, while orthographic syllables are
linguistically motivated pseudo-syllables. We show that BPE units modestly
outperform orthographic syllables as units of translation, showing up to 11%
increase in BLEU score. While orthographic syllables can be used only for
languages whose writing systems use vowel representations, BPE is writing
system independent and we show that BPE outperforms other units for non-vowel
writing systems too. Our results are supported by extensive experimentation
spanning multiple language families and writing systems.},
 address = {Copenhagen, Denmark},
 author = {Kunchukuttan, Anoop and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4102},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {14--24},
 publisher = {Association for Computational Linguistics},
 title = {Learning variable length units for SMT between related languages via Byte Pair Encoding},
 year = {2017}
}

@inproceedings{W17-4103,
 abstract = {Detecting neologisms is essential in real-time natural language processing
applications. Not only can it enable to follow the lexical evolution of
languages, but it is also essential for updating  linguistic resources and
parsers.
In this paper, neology detection is considered as a classification task where
a system has to assess whether a given lexical item is an actual neologism or
not.
We propose a combination of an unsupervised data mining technique and a
supervised machine learning approach.
It is inspired by current researches in stylometry and on token-level and
character-level patterns.
We train and evaluate our system on a manually designed reference dataset in
French and Russian.
We show that this approach is able to largely outperform state-of-the-art
neology detection systems. Furthermore, character-level patterns exhibit good
properties for multilingual extensions of the system.},
 address = {Copenhagen, Denmark},
 author = {Lejeune, Ga\"{e}l and Cartier, Emmanuel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4103},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {25--30},
 publisher = {Association for Computational Linguistics},
 title = {Character Based Pattern Mining for Neology Detection},
 year = {2017}
}

@inproceedings{W17-4104,
 abstract = {In this study we address the problem of automated word stress detection in
Russian using character level models and no part-speech-taggers. We use a
simple bidirectional RNN with LSTM nodes and achieve accuracy of 90\% or
higher. We experiment with two training datasets and show that using the data
from an annotated corpus is much more efficient than using only a dictionary, since it allows to retain the context of the word and its morphological
features.},
 address = {Copenhagen, Denmark},
 author = {Ponomareva, Maria and Milintsevich, Kirill and Chernyak, Ekaterina and Starostin, Anatoly},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4104},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {31--35},
 publisher = {Association for Computational Linguistics},
 title = {Automated Word Stress Detection in Russian},
 year = {2017}
}

@inproceedings{W17-4105,
 abstract = {Word embedding has become a fundamental component to many NLP tasks such as
named entity recognition and machine translation. However, popular models that
learn such embeddings are unaware of the morphology of words, so it is not
directly applicable to highly agglutinative languages such as Korean. We
propose a syllable-based learning model for Korean using a convolutional neural
network, in which word representation is composed of trained syllable vectors.
Our model successfully produces morphologically meaningful representation of
Korean words compared to the original Skip-gram embeddings. The results also
show that it is quite robust to the Out-of-Vocabulary problem.},
 address = {Copenhagen, Denmark},
 author = {Choi, Sanghyuk and Kim, Taeuk and Seol, Jinseok and Lee, Sang-goo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4105},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {36--40},
 publisher = {Association for Computational Linguistics},
 title = {A Syllable-based Technique for Word Embeddings of Korean Words},
 year = {2017}
}

@inproceedings{W17-4106,
 abstract = {Recently, there has been increased interest in utilizing characters or subwords
for natural language processing (NLP) tasks. However, the effect of utilizing
character, subword, and word-level information simultaneously has not been
examined so far. In this paper, we propose a model to leverage various levels
of input features to improve on the performance of an supersense tagging task.
Detailed analysis of experimental results show that different levels of input
representation offer distinct characteristics that explain performance
discrepancy among different tasks.},
 address = {Copenhagen, Denmark},
 author = {Shin, Youhyun and Lee, Sang-goo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4106},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {41--45},
 publisher = {Association for Computational Linguistics},
 title = {Supersense Tagging with a Combination of Character, Subword, and Word-level Representations},
 year = {2017}
}

@inproceedings{W17-4107,
 abstract = {Most NLP resources that offer annotations at the word segment level provide
morphological annotation that includes features indicating tense, aspect, modality, gender, case, and other inflectional information.  Such information
is rarely aligned to the relevant parts of the words---i.e. the allomorphs, as
such annotation would be very costly.  These unaligned weak labelings are
commonly provided by annotated NLP corpora such as treebanks in various
languages.  Although they lack alignment information, the presence/absence of
labels at the word level is also consistent with the amount of supervision
assumed to be provided to L1 and L2 learners. In this paper, we explore several
methods to learn this latent alignment between parts of word forms and the
grammatical information provided.  All the methods under investigation favor
hypotheses regarding allomorphs of morphemes that re-use a small inventory, i.e. implicitly minimize the number of allomorphs that a morpheme can be
realized as.  We show that the provided information offers a significant
advantage for both word segmentation and the learning of allomorphy.},
 address = {Copenhagen, Denmark},
 author = {Silfverberg, Miikka and Hulden, Mans},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4107},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {46--56},
 publisher = {Association for Computational Linguistics},
 title = {Weakly supervised learning of allomorphy},
 year = {2017}
}

@inproceedings{W17-4108,
 abstract = {We present a model for predicting word forms based on
\emph{morphological relational reasoning} with analogies. While
previous work has explored tasks such as morphological inflection
and reinflection, these models rely on an explicit enumeration
of morphological features, which may not be available in all cases.
%
To address the task of predicting a word form given a \emph{demo
relation} (a pair of word forms) and a \emph{query word}, we
devise a character-based recurrent neural network architecture
using three separate encoders and a decoder.
%
We also investigate a multiclass learning setup, where the
prediction of the relation type label is used as an auxiliary task.
Our results show that the exact form can be predicted for
English with an accuracy of 94.7\%. For Swedish, which has a more
complex morphology with more inflectional patterns for nouns and
verbs, the accuracy is 89.3\%. We also show that using the
auxiliary task of learning the relation type speeds up convergence
and improves the prediction accuracy for the word generation task.},
 address = {Copenhagen, Denmark},
 author = {Mogren, Olof and Johansson, Richard},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4108},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {57--63},
 publisher = {Association for Computational Linguistics},
 title = {Character-based recurrent neural networks for morphological relational reasoning},
 year = {2017}
}

@inproceedings{W17-4109,
 abstract = {Given the advantage and recent success of English character-level and
subword-unit models in several NLP tasks, we consider the equivalent modeling
problem for Chinese. Chinese script is logographic and many Chinese logograms
are composed of common substructures that provide semantic, phonetic and
syntactic hints. In this work, we propose to explicitly incorporate the visual
appearance of a character{\^a}s glyph in its representation, resulting in a novel
glyph-aware embedding of Chinese characters. Being inspired by the success of
convolutional neural networks in computer vision, we use them to incorporate
the spatio-structural patterns of Chinese glyphs as rendered in raw pixels. In
the context of two basic Chinese NLP tasks of language modeling and word
segmentation, the model learns to represent each character{\^a}s task-relevant
semantic and syntactic information in the character-level embedding.},
 address = {Copenhagen, Denmark},
 author = {Dai, Falcon and Cai, Zheng},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4109},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {64--69},
 publisher = {Association for Computational Linguistics},
 title = {Glyph-aware Embedding of Chinese Characters},
 year = {2017}
}

@inproceedings{W17-4110,
 abstract = {Multi-task training is an effective method to mitigate the data sparsity
problem.
It has recently been applied for cross-lingual transfer learning for paradigm
completion---the task of producing inflected forms of lemmata---with
sequence-to-sequence networks.
However, it is still vague how the model transfers knowledge across languages, as well as if and which information is shared.
To investigate this, we propose a set of data-dependent experiments using an
existing
encoder-decoder recurrent neural network for the task. Our results show that
indeed the performance gains surpass a pure regularization effect and that
knowledge about language and
morphology can be transferred.},
 address = {Copenhagen, Denmark},
 author = {Jin, Huiming and Kann, Katharina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4110},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {70--75},
 publisher = {Association for Computational Linguistics},
 title = {Exploring Cross-Lingual Transfer of Morphological Knowledge In Sequence-to-Sequence Models},
 year = {2017}
}

@inproceedings{W17-4111,
 abstract = {We present a semi-supervised way of training a character-based encoder-decoder
recurrent neural network for morphological reinflection---the task of
generating one inflected wordform from another. This is achieved by using
unlabeled tokens or random strings as training data for an autoencoding task, adapting a network for morphological reinflection, and performing multi-task
training.
We thus use limited labeled data more effectively, obtaining up to 9.92%
improvement over state-of-the-art baselines for 8 different languages.},
 address = {Copenhagen, Denmark},
 author = {Kann, Katharina and Sch\"{u}tze, Hinrich},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4111},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {76--81},
 publisher = {Association for Computational Linguistics},
 title = {Unlabeled Data for Morphological Generation With Character-Based Sequence-to-Sequence Models},
 year = {2017}
}

@inproceedings{W17-4112,
 abstract = {We consider two related problems in this paper. Given an undeciphered
alphabetic writing system or mono-alphabetic cipher, determine: (1) which of
its letters are vowels and which are consonants; and (2) whether the writing
system is a vocalic alphabet or an abjad.  We are able to show that a very
simple spectral decomposition based on character co-occurrences provides nearly
perfect performance with respect to answering both question types.},
 address = {Copenhagen, Denmark},
 author = {Thaine, Patricia and Penn, Gerald},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4112},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {82--91},
 publisher = {Association for Computational Linguistics},
 title = {Vowel and Consonant Classification through Spectral Decomposition},
 year = {2017}
}

@inproceedings{W17-4113,
 abstract = {We introduce a novel method to diminish the problem of out of vocabulary words
by introducing an embedding method which leverages the agglutinative property
of language. We propose additional embedding derived from syllables and
morphemes for the words to improve the performance of language model. We apply
the above method to input prediction tasks and achieve state of the art
performance in terms of Key Stroke Saving (KSS) w.r.t. to existing device input
prediction methods.},
 address = {Copenhagen, Denmark},
 author = {Yu, Seunghak and Kulkarni, Nilesh and Lee, Haejun and Kim, Jihie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4113},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {92--96},
 publisher = {Association for Computational Linguistics},
 title = {Syllable-level Neural Language Model for Agglutinative Language},
 year = {2017}
}

@inproceedings{W17-4114,
 abstract = {Recently, neural models have shown superior performance over conventional
models in NER tasks. These models use CNN to extract sub-word information along
with RNN to predict a tag for each word. However, these models have been tested
almost entirely on English texts. It remains unclear whether they perform
similarly in other languages. We worked on Japanese NER using neural models and
discovered two obstacles of the state-of-the-art model.
First, CNN is unsuitable for extracting Japanese sub-word information.
Secondly, a model predicting a tag for each word cannot extract an entity when
a part of a word composes an entity. The contributions of this work are (1)
verifying the effectiveness of the state-of-the-art NER model for Japanese, (2)
proposing a neural model for predicting a tag for each character using word and
character information. Experimentally obtained results demonstrate that our
model outperforms the state-of-the-art neural English NER model in Japanese.},
 address = {Copenhagen, Denmark},
 author = {Misawa, Shotaro and Taniguchi, Motoki and Miura, Yasuhide and Ohkuma, Tomoko},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4114},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {97--102},
 publisher = {Association for Computational Linguistics},
 title = {Character-based Bidirectional LSTM-CRF with words and characters for Japanese Named Entity Recognition},
 year = {2017}
}

@inproceedings{W17-4115,
 abstract = {Out-of-vocabulary words present a great challenge for Machine Translation.
Recently various character-level compositional models
were proposed to address this issue. In current research
we incorporate two most popular neural architectures, namely LSTM and CNN, into
hard- and soft-attentional models of translation for character-level
representation of the source. We propose semantic and morphological intrinsic
evaluation of encoder-level representations. Our analysis of the learned
representations reveals that character-based LSTM  seems to be better at
capturing morphological aspects compared to character-based CNN. We also show
that hard-attentional model provides better character-level representations
compared to vanilla one.},
 address = {Copenhagen, Denmark},
 author = {Vylomova, Ekaterina and Cohn, Trevor and He, Xuanli and Haffari, Gholamreza},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4115},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {103--108},
 publisher = {Association for Computational Linguistics},
 title = {Word Representation Models for Morphologically Rich Languages in Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-4116,
 abstract = {There are several native languages in Peru which are mostly agglutinative.
These languages are transmitted from generation to generation mainly in oral
form, causing different forms of writing across different communities. For this
reason, there are recent efforts to standardize the spelling in the written
texts, and it would be beneficial to support these tasks with an automatic tool
such as an spell-checker. In this way, this spelling corrector is being
developed based on two steps: an automatic rule-based syllabification method
and a character-level graph to detect the degree of error in a misspelled word.
The experiments were realized on Shipibo-konibo, a highly agglutinative and
amazonian language, and the results obtained have been promising in a dataset
built for the purpose.},
 address = {Copenhagen, Denmark},
 author = {Alva, Carlo and Oncevay, Arturo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4116},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {109--116},
 publisher = {Association for Computational Linguistics},
 title = {Spell-Checking based on Syllabification and Character-level Graphs for a Peruvian Agglutinative Language},
 year = {2017}
}

@inproceedings{W17-4117,
 abstract = {We propose a new type of subword embedding designed to provide more information
about unknown compounds, a major source for OOV words in German. We present an
extrinsic evaluation where we use the compound embeddings as input to a neural
dependency parser and compare the results to the ones obtained with other types
of embeddings. Our evaluation shows that adding compound embeddings yields a
significant improvement of 2% LAS over using word embeddings when no POS
information is available. When adding POS embeddings to the input, however, the effect levels out. This suggests that it is not the missing information
about the semantics of the unknown words that causes problems for parsing
German, but the lack of morphological information for unknown words. To augment
our evaluation, we also test the new embeddings in a language modelling task
that requires both syntactic and semantic information.},
 address = {Copenhagen, Denmark},
 author = {Do, Bich-Ngoc and Rehbein, Ines and Frank, Anette},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4117},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {117--123},
 publisher = {Association for Computational Linguistics},
 title = {What do we need to know about an unknown word when parsing German},
 year = {2017}
}

@inproceedings{W17-4118,
 abstract = {We present a general-purpose tagger based on convolutional neural networks
(CNN), used for both composing word vectors and encoding context information.
The CNN tagger is robust across different tagging tasks: without task-specific
tuning of hyper-parameters, it achieves state-of-the-art results in
part-of-speech tagging, morphological tagging and supertagging. The CNN tagger
is also robust against the out-of-vocabulary problem; it performs well on
artificially unnormalized texts.},
 address = {Copenhagen, Denmark},
 author = {Yu, Xiang and Falenska, Agnieszka and Vu, Ngoc Thang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4118},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {124--129},
 publisher = {Association for Computational Linguistics},
 title = {A General-Purpose Tagger with Convolutional Neural Networks},
 year = {2017}
}

@inproceedings{W17-4119,
 abstract = {Pre-trained word embeddings improve the performance of a neural model at the
cost of increasing the model size. We propose to benefit from this resource
without paying the cost by operating strictly at the sub-lexical level. Our
approach is quite simple: before task-specific training, we first optimize
sub-word parameters to reconstruct pre-trained word embeddings using various
distance measures. We report interesting results on a variety of tasks: word
similarity, word analogy, and part-of-speech tagging.},
 address = {Copenhagen, Denmark},
 author = {Stratos, Karl},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4119},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {130--135},
 publisher = {Association for Computational Linguistics},
 title = {Reconstruction of Word Embeddings from Sub-Word Parameters},
 year = {2017}
}

@inproceedings{W17-4120,
 abstract = {We present a novel supervised approach to inflection generation for verbs in
Spanish. Our system takes as input the verb's lemma form and the desired
features such as person, number, tense, and is able to predict the appropriate
grammatical conjugation. Even though our approach learns from fewer examples
comparing to previous work, it is able to deal with all the Spanish moods
(indicative, subjunctive and imperative) in contrast to previous work which
only focuses on indicative and subjunctive moods. We show that in an intrinsic
evaluation, our system achieves 99% accuracy, outperforming (although not
significantly) two competitive state-of-art systems. The successful results
obtained clearly indicate that our approach could be integrated into wider
approaches related to text generation in Spanish.},
 address = {Copenhagen, Denmark},
 author = {Barros, Cristina and Gkatzia, Dimitra and Lloret, Elena},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4120},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {136--141},
 publisher = {Association for Computational Linguistics},
 title = {Inflection Generation for Spanish Verbs using Supervised Learning},
 year = {2017}
}

@inproceedings{W17-4121,
 abstract = {We present a solution to the problem of paraphrase identification of questions.
We focus on a recent dataset of question pairs annotated with binary paraphrase
labels and show that a variant of the decomposable attention model (replacing
the word embeddings of the decomposable attention model of Parikh et al. 2016
with character n-gram representations) results in accurate performance on this
task, while being far simpler than many competing neural architectures.
Furthermore, when the model is pretrained on a noisy dataset of automatically
collected question paraphrases, it obtains the best reported performance on the
dataset.},
 address = {Copenhagen, Denmark},
 author = {Tomar, Gaurav Singh and Duque, Thyago and T\"{a}ckstr\"{o}m, Oscar and Uszkoreit, Jakob and Das, Dipanjan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4121},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {142--147},
 publisher = {Association for Computational Linguistics},
 title = {Neural Paraphrase Identification of Questions with Noisy Pretraining},
 year = {2017}
}

@inproceedings{W17-4122,
 abstract = {In East Asian languages such as Japanese and Chinese, the semantics of
a character are (somewhat) reflected in its sub-character
elements. This paper examines the effect of using sub-characters for
language modeling in Japanese. This is achieved by decomposing
characters according to a range of character decomposition datasets, and training a neural language model over variously decomposed
character representations. Our results indicate that language modelling
can be improved through the inclusion of sub-characters, though this
result depends on a good choice of decomposition dataset and the
appropriate granularity of decomposition.},
 address = {Copenhagen, Denmark},
 author = {Nguyen, Viet and Brooke, Julian and Baldwin, Timothy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4122},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {148--153},
 publisher = {Association for Computational Linguistics},
 title = {Sub-character Neural Language Modelling in Japanese},
 year = {2017}
}

@inproceedings{W17-4123,
 abstract = {This paper presents experiments comparing character-based and byte-based neural
machine translation systems. The main motivation of the byte-based neural
machine translation system is to build multi-lingual neural machine translation
systems that can share the same vocabulary. We compare the performance of both
systems in several language pairs and we see that the performance in test is
similar for most language pairs while the training time is slightly reduced in
the case of byte-based neural machine translation.},
 address = {Copenhagen, Denmark},
 author = {Costa-juss\`{a}, Marta R. and Escolano, Carlos and Fonollosa, Jos\'{e} A. R.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4123},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {154--158},
 publisher = {Association for Computational Linguistics},
 title = {Byte-based Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-4124,
 abstract = {Fine-grained sentiment analysis is receiving increasing attention in recent
years.
Extracting opinion target expressions (OTE) in reviews is often an important
step in fine-grained, aspect-based sentiment analysis.
Retrieving this information from user-generated text, however, can be
difficult.
Customer reviews, for instance, are prone to contain misspelled words and are
difficult to process due to their domain-specific language.
In this work, we investigate whether character-level models can improve the
performance for the identification of opinion target expressions.
We integrate information about the character structure of a word into a
sequence labeling system using character-level word embeddings and show their
positive impact on the system's performance.
Specifically, we obtain an increase by 3.3 points F1-score with respect to our
baseline model.
In further experiments, we reveal encoded character patterns of the learned
embeddings and give a nuanced view of the performance differences of both
models.},
 address = {Copenhagen, Denmark},
 author = {Jebbara, Soufian and Cimiano, Philipp},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4124},
 booktitle = {Proceedings of the First Workshop on Subword and Character Level Models in NLP},
 month = {September},
 pages = {159--167},
 publisher = {Association for Computational Linguistics},
 title = {Improving Opinion-Target Extraction with Character-Level Word Embeddings},
 year = {2017}
}

@inproceedings{W17-4201,
 abstract = {We present a preliminary study on predicting news values from headline text and
emotions. We perform a multivariate analysis on a dataset manually annotated
with news values and emotions, discovering interesting correlations among them.
We then train two competitive machine learning models -- an SVM and a CNN --
to predict news values from headline text and emotions as features. We find
that, while both models yield a satisfactory performance, some news values are
more difficult to detect than others, while some profit more from including
emotion information.},
 address = {Copenhagen, Denmark},
 author = {di Buono, Maria Pia and \v{S}najder, Jan and Dalbelo Basic, Bojana and Glava\v{s}, Goran and Tutek, Martin and Milic-Frayling, Natasa},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4201},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {1--6},
 publisher = {Association for Computational Linguistics},
 title = {Predicting News Values from Headline Text and Emotions},
 year = {2017}
}

@inproceedings{W17-4202,
 abstract = {We analyze user viewing behavior on an online news site. We collect
data from 64,000 news articles, and use text features to predict
frequency of user views. We compare predictiveness of the headline and
``teaser" (viewed before clicking) and the body (viewed after clicking). Both
are predictive of clicking behavior, with the full article text being most
predictive.},
 address = {Copenhagen, Denmark},
 author = {Hardt, Daniel and Rambow, Owen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4202},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {7--12},
 publisher = {Association for Computational Linguistics},
 title = {Predicting User Views in Online News},
 year = {2017}
}

@inproceedings{W17-4203,
 abstract = {This paper addresses the task of identifying the bias in news articles
published during a political or social conflict. We create a silver-standard
corpus based on the actions of users in social media. Specifically, we
reconceptualize bias in terms of how likely a given article is to be shared or
liked by each of the opposing sides. We apply our methodology to a dataset of
links collected in relation to the Russia-Ukraine Maidan crisis from 2013-2014.
We show that on the task of predicting which side is likely to prefer a given
article, a Naive Bayes classifier can record 90.3% accuracy looking only at
domain names of the news sources. The best accuracy of 93.5% is achieved by a
feed forward neural network. We also apply our methodology to gold-labeled set
of articles annotated for bias, where the aforementioned Naive Bayes classifier
records 82.6% accuracy and a feed-forward neural networks records 85.6%
accuracy.},
 address = {Copenhagen, Denmark},
 author = {Potash, Peter and Romanov, Alexey and Gronas, Mikhail and Rumshisky, Anna and Gronas, Mikhail},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4203},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {13--18},
 publisher = {Association for Computational Linguistics},
 title = {Tracking Bias in News Sources Using Social Media: the Russia-Ukraine Maidan Crisis of 2013--2014},
 year = {2017}
}

@inproceedings{W17-4204,
 abstract = {In this paper we present a recommender
system, What To Write and Why, capable
of suggesting to a journalist, for a given
event, the aspects still uncovered in news
articles on which the readers focus their interest.
The basic idea is to characterize an
event according to the echo it receives in
online news sources and associate it with
the corresponding readers{\^a} communicative
and informative patterns, detected through
the analysis of Twitter and Wikipedia, respectively.
Our methodology temporally
aligns the results of this analysis and recommends
the concepts that emerge as topics
of interest from Twitter andWikipedia, either not covered or poorly covered in the
published news articles.},
 address = {Copenhagen, Denmark},
 author = {Cucchiarelli, Alessandro and Morbidoni, Christian and Stilo, Giovanni and Velardi, Paola},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4204},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {19--24},
 publisher = {Association for Computational Linguistics},
 title = {What to Write? A topic recommender for journalists},
 year = {2017}
}

@inproceedings{W17-4205,
 abstract = {News media typically present biased accounts of news stories, and different
publications present different angles on the same event. In this research, we
investigate how different publications differ in their approach to stories
about climate change, by examining the sentiment and topics presented. To
understand these attitudes, we find sentiment targets by combining Latent
Dirichlet Allocation (LDA) with SentiWordNet, a general sentiment lexicon.
Using LDA, we generate topics containing keywords which represent the sentiment
targets, and then annotate the data using SentiWordNet before regrouping the
articles based on topic similarity. Preliminary analysis identifies clearly
different attitudes on the same issue presented in different news sources.
Ongoing work is investigating how systematic these attitudes are between
different publications, and how these may change over time.},
 address = {Copenhagen, Denmark},
 author = {Jiang, Ye and Song, Xingyi and Harrison, Jackie and Quegan, Shaun and Maynard, Diana},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4205},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {25--30},
 publisher = {Association for Computational Linguistics},
 title = {Comparing Attitudes to Climate Change in the Media using sentiment analysis based on Latent Dirichlet Allocation},
 year = {2017}
}

@inproceedings{W17-4206,
 abstract = {Faced with ever-growing news archives, media professionals are in need of
advanced tools to explore the information surrounding specific events.
This problem is most commonly answered by browsing news datasets, going from
article to article and viewing unaltered original content.
In this article, we introduce an efficient way to generate links between news
items, allowing such browsing through an easily explorable graph, and enrich
this graph by automatically typing links in order to inform the user on the
nature of the relation between two news pieces.
User evaluations are conducted on real world data with journalists in order to
assess for the interest of both the graph representation and link typing in a
press reviewing task, showing the system to be of significant help for their
work.},
 address = {Copenhagen, Denmark},
 author = {Bois, R\'{e}mi and Gravier, Guillaume and Jamet, Eric and Morin, Emmanuel and S\'{e}billot, Pascale and Robert, Maxime},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4206},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {31--36},
 publisher = {Association for Computational Linguistics},
 title = {Language-based Construction of Explorable News Graphs for Journalists},
 year = {2017}
}

@inproceedings{W17-4207,
 abstract = {Complexity of event data in texts makes it difficult to assess its content, especially when considering larger collections in which different sources
report on the same or similar situations. We present a system that makes it
possible to visually analyze complex event and emotion data extracted from
texts. We show that we can abstract from different data models for events and
emotions to a single data model that can show the complex relations in four
dimensions. The visualization has been applied to analyze 1) dynamic
developments in how people both conceive and express emotions in theater plays
and 2) how stories are told from the perspectyive of their sources based on
rich event data extracted from news or biographies.},
 address = {Copenhagen, Denmark},
 author = {van Meersbergen, Maarten and Vossen, Piek and van der Zwaan, Janneke and Fokkens, Antske and van Hage, Willem and Leemans, Inger and Maks, Isa},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4207},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {37--45},
 publisher = {Association for Computational Linguistics},
 title = {Storyteller: Visual Analytics of Perspectives on Rich Text Interpretations},
 year = {2017}
}

@inproceedings{W17-4208,
 abstract = {We address the issue of the quality of journalism and analyze daily article
revision logs from a Japanese newspaper company. The revision logs contain data
that can help reveal the requirements of quality journalism such as the types
and number of edit operations and aspects commonly focused in revision. This
study also dis- cusses potential applications such as quality assessment and
automatic article revision as our future research directions.},
 address = {Copenhagen, Denmark},
 author = {Tamori, Hideaki and Hitomi, Yuta and Okazaki, Naoaki and Inui, Kentaro},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4208},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {46--50},
 publisher = {Association for Computational Linguistics},
 title = {Analyzing the Revision Logs of a Japanese Newspaper for Article Quality Assessment},
 year = {2017}
}

@inproceedings{W17-4209,
 abstract = {Experimenting with a dataset of approximately 1.6M user comments from a Greek
news sports portal, we explore how a state of the art RNN-based moderation
method can be improved by adding user embeddings, user type embeddings, user
biases, or user type biases. We observe improvements in all cases, with user
embeddings leading to the biggest performance gains.},
 address = {Copenhagen, Denmark},
 author = {Pavlopoulos, John and Malakasiotis, Prodromos and Bakagianni, Juli and Androutsopoulos, Ion},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4209},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {51--55},
 publisher = {Association for Computational Linguistics},
 title = {Improved Abusive Comment Moderation with User Embeddings},
 year = {2017}
}

@inproceedings{W17-4210,
 abstract = {This paper discusses the problem of incongruent headlines: those which do not
accurately represent the information contained in the article with which they
occur. We emphasise that this phenomenon should be considered separately from
recognised problematic headline types such as clickbait and sensationalism, arguing that existing natural language processing (NLP) methods applied to
these related concepts are not appropriate for the automatic detection of
headline incongruence, as an analysis beyond stylistic traits is necessary. We
therefore suggest a number of alternative methodologies that may be appropriate
to the task at hand as a foundation for future work in this area. In addition, we provide an analysis of existing data sets which are related to this work, and motivate the need for a novel data set in this domain.},
 address = {Copenhagen, Denmark},
 author = {Chesney, Sophie and Liakata, Maria and Poesio, Massimo and Purver, Matthew},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4210},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {56--61},
 publisher = {Association for Computational Linguistics},
 title = {Incongruent Headlines: Yet Another Way to Mislead Your Readers},
 year = {2017}
}

@inproceedings{W17-4211,
 abstract = {In this paper, we present an unsupervised pipeline approach for clustering news
articles based on identified event instances in their content. We leverage
press agency newswire and monolingual word alignment techniques to build
meaningful and linguistically varied clusters of articles from the web in the
perspective of a broader event type detection task. We validate our approach on
a manually annotated corpus of Web articles.},
 address = {Copenhagen, Denmark},
 author = {Ribeiro, Swen and Ferret, Olivier and Tannier, Xavier},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4211},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {62--67},
 publisher = {Association for Computational Linguistics},
 title = {Unsupervised Event Clustering and Aggregation from Newswire and Web Articles},
 year = {2017}
}

@inproceedings{W17-4212,
 abstract = {We present a prototypical content curation dashboard, to be used in the
newsroom, and several of its underlying semantic content analysis components
(such as named entity recognition, entity linking, summarisation and temporal
expression analysis). The idea is to enable journalists (a) to process incoming
content (agency reports, twitter feeds, reports, blog posts, social media etc.)
and (b) to create new articles more easily and more efficiently. The prototype
system also allows the automatic annotation of events in incoming content for
the purpose of supporting journalists in identifying important, relevant or
meaningful events and also to adapt the content currently in production
accordingly in a semi-automatic way. One of our long-term goals is to support
journalists building up entire storylines with automatic means. In the present
prototype they are generated in a backend service using clustering methods that
operate on the extracted events.},
 address = {Copenhagen, Denmark},
 author = {Moreno-Schneider, Julian and Srivastava, Ankit and Bourgonje, Peter and Wabnitz, David and Rehm, Georg},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4212},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {68--73},
 publisher = {Association for Computational Linguistics},
 title = {Semantic Storytelling, Cross-lingual Event Detection and other Semantic Services for a Newsroom Content Curation Dashboard},
 year = {2017}
}

@inproceedings{W17-4213,
 abstract = {News verification and automated fact checking tend to be very important issues
in our world. The research is initial. We collected a corpus for Russian (174
news reports, truthful and fake ones). We held two experiments, for both we
applied SVMs algorithm (linear/rbf kernel) and Random Forest to classify the
news reports into 2 classes: truthful/deceptive. In the first experiment, we
used 18 markers on lexics level, mostly frequencies of POS tags in texts. In
the second experiment, on discourse level we used frequencies of rhetorical
relations types in texts. The classification task in the first experiment is
solved better by SVMs (rbf kernel) (f-measure 0.65). The model based on RST
features shows best results with Random Forest Classifier (f-measure 0.54) and
should be modified. In the next research, the combination of different
deception detection markers for the Russian language should be taken in order
to make a better predictive model.},
 address = {Copenhagen, Denmark},
 author = {Pisarevskaya, Dina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4213},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {74--79},
 publisher = {Association for Computational Linguistics},
 title = {Deception Detection in News Reports in the Russian Language: Lexics and Discourse},
 year = {2017}
}

@inproceedings{W17-4214,
 abstract = {Fake news has become a hotly debated topic in journalism. In this paper, we
present our entry to the 2017 Fake News Challenge which models the detection of
fake news as a stance classification task that finished in 11th place on the
leader board. Our entry is an ensemble system of classifiers developed by
students in the context of their coursework.  We show how we used the stacking
ensemble method for this purpose and obtained improvements in classification
accuracy  exceeding each of the individual models' performance on the
development data. Finally, we discuss aspects of the experimental setup of the
challenge.},
 address = {Copenhagen, Denmark},
 author = {Thorne, James and Chen, Mingjie and Myrianthous, Giorgos and Pu, Jiashu and Wang, Xiaoxuan and Vlachos, Andreas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4214},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {80--83},
 publisher = {Association for Computational Linguistics},
 title = {Fake news stance detection using stacked ensemble of classifiers},
 year = {2017}
}

@inproceedings{W17-4215,
 abstract = {We present a system for the detection of the stance of headlines with regard to
their corresponding article bodies. The approach can be applied in fake news, especially clickbait detection scenarios. The component is part of a larger
platform for the curation of digital content; we consider veracity and
relevancy an increasingly important part of curating online information. We
want to contribute to the debate on how to deal with fake news and related
online phenomena with technological means, by providing means to separate
related from unrelated headlines and further classifying the related headlines.
On a publicly available data set annotated for the stance of headlines with
regard to their corresponding article bodies, we achieve a (weighted) accuracy
score of 89.59.},
 address = {Copenhagen, Denmark},
 author = {Bourgonje, Peter and Moreno Schneider, Julian and Rehm, Georg},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4215},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {84--89},
 publisher = {Association for Computational Linguistics},
 title = {From Clickbait to Fake News Detection: An Approach based on Detecting the Stance of Headlines to Articles},
 year = {2017}
}

@inproceedings{W17-4216,
 abstract = {Previous work on the epistemology of fact-checking indicated the dilemma
between the needs of binary answers for the public and ambiguity of political
discussion. Determining concepts represented by terms in political discourse
can be considered as a Word-Sense Disambiguation (WSD) task. The analysis of
political discourse, however, requires identifying precise concepts of terms
from relatively small data. This work attempts to provide a basic framework for
revealing concepts of terms in political discourse with explicit contextual
information. The framework consists of three parts: 1) extracting important
terms, 2) generating concordance for each term with stipulative definitions and
explanations, and 3) agglomerating similar information of the term by
hierarchical clustering. Utterances made by Prime Minister Abe Shinzo in the
Diet of Japan are used to examine our framework. Importantly, we revealed the
conceptual inconsistency of the term Sonritsu-kiki-jitai. The framework was
proved to work, but only for a small number of terms due to lack of explicit
contextual information.},
 address = {Copenhagen, Denmark},
 author = {Tang, Linyuan and Kageura, Kyo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4216},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {90--94},
 publisher = {Association for Computational Linguistics},
 title = {'Fighting' or 'Conflict'? An Approach to Revealing Concepts of Terms in Political Discourse},
 year = {2017}
}

@inproceedings{W17-4217,
 abstract = {Chain construction is an important requirement for understanding news and
establishing the context. A news chain can be defined as a coherent set of
articles that explains an event or a story. There's a lack of well-established
methods in this area.
In this work, we propose a methodology to evaluate the "goodness" of a given
news chain and implement a concept lattice-based news chain construction method
by Hossain et al.. The methodology part is vital as it directly affects the
growth of research in this area. Our proposed methodology consists of collected
news chains from different studies and two "goodness" metrics, minedge and
dispersion coefficient respectively. We assess the utility of the lattice-based
news chain construction method by our proposed methodology.},
 address = {Copenhagen, Denmark},
 author = {Toprak, Mustafa and \"{O}zkahraman, \"{O}zer and Tekir, Selma},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4217},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {95--99},
 publisher = {Association for Computational Linguistics},
 title = {A News Chain Evaluation Methodology along with a Lattice-based Approach for News Chain Construction},
 year = {2017}
}

@inproceedings{W17-4218,
 abstract = {We examine the extent to which we are able to automatically identify
constructive online comments. We build several classifiers using New York Times
Picks as positive examples and non-constructive thread comments from the Yahoo
News Annotated Comments Corpus as negative examples of constructive online
comments. We evaluate these classifiers on a crowd-annotated corpus containing
1,121 comments. Our best classifier achieves a top F1 score of 0.84.},
 address = {Copenhagen, Denmark},
 author = {Kolhatkar, Varada and Taboada, Maite},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4218},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {100--105},
 publisher = {Association for Computational Linguistics},
 title = {Using New York Times Picks to Identify Constructive Comments},
 year = {2017}
}

@inproceedings{W17-4219,
 abstract = {The discrepancy between science and media has been affecting the effectiveness
of science communication. Original findings from science publications may be
distorted with altered claim strength when reported to the public, causing
misinformation spread. This study conducts an NLP analysis of exaggerated
claims in science news, and then constructed prediction models for identifying
claim strength levels in science reporting. The results demonstrate different
writing styles journal articles and news/press releases use for reporting
scientific findings. Preliminary prediction models reached promising result
with room for further improvement.},
 address = {Copenhagen, Denmark},
 author = {LI, YINGYA and Zhang, Jieke and Yu, Bei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4219},
 booktitle = {Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism},
 month = {September},
 pages = {106--111},
 publisher = {Association for Computational Linguistics},
 title = {An NLP Analysis of Exaggerated Claims in Science News},
 year = {2017}
}

@inproceedings{W17-4301,
 abstract = {Dependency parses are an effective way to inject linguistic knowledge into many
downstream tasks, and many practitioners wish to efficiently parse sentences at
scale. Recent advances in GPU hardware have enabled neural networks to achieve
significant gains over the previous best models, these models still fail to
leverage GPUs' capability for massive parallelism due to their requirement of
sequential processing of the sentence. In response, we propose Dilated Iterated
Graph Convolutional Neural Networks (DIG-CNNs) for
graph-based dependency parsing, a graph convolutional architecture that allows
for efficient end-to-end GPU parsing. In experiments on the English Penn
TreeBank benchmark, we show that DIG-CNNs perform on par with some of the best
neural network parsers.},
 address = {Copenhagen, Denmark},
 author = {Strubell, Emma and McCallum, Andrew},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4301},
 booktitle = {Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing},
 month = {September},
 pages = {1--6},
 publisher = {Association for Computational Linguistics},
 title = {Dependency Parsing with Dilated Iterated Graph CNNs},
 year = {2017}
}

@inproceedings{W17-4302,
 abstract = {Standard approaches in entity identification hard-code boundary detection and
type prediction into labels and perform Viterbi. This has two disadvantages: 1.
the runtime complexity grows quadratically in the number of types, and 2. there
is no natural segment-level representation. In this paper, we propose a neural
architecture that addresses these disadvantages. We frame the problem as
multitasking, separating boundary detection and type prediction but optimizing
them jointly. Despite its simplicity, this architecture performs competitively
with fully structured models such as BiLSTM-CRFs while scaling linearly in the
number of types. Furthermore, by construction, the model induces
type-disambiguating embeddings of predicted mentions.},
 address = {Copenhagen, Denmark},
 author = {Stratos, Karl},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4302},
 booktitle = {Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing},
 month = {September},
 pages = {7--11},
 publisher = {Association for Computational Linguistics},
 title = {Entity Identification as Multitasking},
 year = {2017}
}

@inproceedings{W17-4303,
 abstract = {Building models that take advantage of the hierarchical structure of language
without a priori annotation is a longstanding goal in natural language
processing. We introduce such a model for the task of machine translation, pairing a recurrent neural network grammar encoder with a novel attentional
RNNG decoder and applying policy gradient reinforcement learning to induce
unsupervised tree structures on both the source and target. When trained on
character-level datasets with no explicit segmentation or parse annotation, the
model learns a plausible segmentation and shallow parse, obtaining performance
close to an attentional baseline.},
 address = {Copenhagen, Denmark},
 author = {Bradbury, James and Socher, Richard},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4303},
 booktitle = {Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing},
 month = {September},
 pages = {12--16},
 publisher = {Association for Computational Linguistics},
 title = {Towards Neural Machine Translation with Latent Tree Attention},
 year = {2017}
}

@inproceedings{W17-4304,
 abstract = {We present an algorithm for structured prediction under online bandit feedback.
The learner repeatedly predicts a sequence of actions, generating a structured
output. It then observes feedback for that output and no others. We consider
two cases: a pure bandit setting in which it only observes a loss, and more
fine-grained feedback in which it observes a loss for every action. We find
that the fine-grained feedback is necessary for strong empirical performance, because it allows for a robust variance-reduction strategy. We empirically
compare a number of different algorithms and exploration methods and show the
efficacy of BLS on sequence labeling and dependency parsing tasks.},
 address = {Copenhagen, Denmark},
 author = {Sharaf, Amr and Daum\'{e} III, Hal},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4304},
 booktitle = {Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing},
 month = {September},
 pages = {17--26},
 publisher = {Association for Computational Linguistics},
 title = {Structured Prediction via Learning to Search under Bandit Feedback},
 year = {2017}
}

@inproceedings{W17-4305,
 abstract = {In Semantic Role Labeling (SRL) task, the tree structured dependency relation
is rich in syntax information, but it is not well handled by existing models.
In this paper, we propose Syntax Aware Long Short Time Memory (SA-LSTM). The
structure of SA-LSTM changes according to dependency structure of each
sentence, so that SA-LSTM can model the whole tree structure of dependency
relation in an architecture engineering way. Experiments demonstrate that on
Chinese Proposition Bank (CPB) 1.0, SA-LSTM improves F1 by 2.06% than ordinary
bi-LSTM with feature engineered dependency relation information, and gives
state-of-the-art F1 of 79.92%. On English CoNLL 2005 dataset, SA-LSTM brings
improvement (2.1%) to bi-LSTM model and also brings slight improvement (0.3%)
when added to the state-of-the-art model.},
 address = {Copenhagen, Denmark},
 author = {Qian, Feng and Sha, Lei and Chang, Baobao and Liu, LuChen and Zhang, Ming},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4305},
 booktitle = {Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing},
 month = {September},
 pages = {27--32},
 publisher = {Association for Computational Linguistics},
 title = {Syntax Aware LSTM model for Semantic Role Labeling},
 year = {2017}
}

@inproceedings{W17-4306,
 abstract = {This work is on a previously formalized semantic evaluation task of spatial
role labeling (SpRL) that aims at extraction of formal spatial meaning from
text. Here, we report the results of initial efforts towards exploiting visual
information in the form of images to help spatial language understanding. We
discuss the way of designing new models in the framework of declarative
learning-based programming (DeLBP). The DeLBP framework facilitates combining
modalities and representing various data in a unified graph.
The learning and inference models exploit the structure of the unified graph
as well as the global first order domain constraints beyond the data to predict
the semantics which forms a structured meaning representation of the spatial
context. Continuous representations are used to relate the various elements of
the graph originating from different modalities. We improved over the
state-of-the-art results on SpRL.},
 address = {Copenhagen, Denmark},
 author = {Kordjamshidi, Parisa and Rahgooy, Taher and Manzoor, Umar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4306},
 booktitle = {Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing},
 month = {September},
 pages = {33--43},
 publisher = {Association for Computational Linguistics},
 title = {Spatial Language Understanding with Multimodal Graphs using Declarative Learning based Programming},
 year = {2017}
}

@inproceedings{W17-4307,
 abstract = {We present an architecture to boost the precision of existing information
extraction systems. This is achieved by augmenting the existing parser, which
may be constraint-based or hybrid statistical, with a character-level neural
network. Our architecture combines the ability of constraint-based or hybrid
extraction systems to easily incorporate domain knowledge with the ability of
deep neural networks to leverage large amounts of data to learn complex
features. The network is trained using a measure of consistency between
extracted data and existing databases as a form of cheap, noisy supervision.
Our architecture does not require large scale manual annotation or a system
rewrite. It has led to large precision improvements over an existing, highly-tuned production information extraction system used at Bloomberg LP for
financial language text.},
 address = {Copenhagen, Denmark},
 author = {Meerkamp, Philipp and Zhou, Zhengyi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4307},
 booktitle = {Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing},
 month = {September},
 pages = {44--51},
 publisher = {Association for Computational Linguistics},
 title = {Boosting Information Extraction Systems with Character-level Neural Networks and Free Noisy Supervision},
 year = {2017}
}

@inproceedings{W17-4308,
 abstract = {Advances in neural variational inference have facilitated the learning of
powerful directed graphical models with continuous latent variables, such as
variational autoencoders. The hope is that such models will learn to represent
rich, multi-modal latent factors in real-world data, such as natural language
text. However, current models often assume simplistic priors on the latent
variables - such as the uni-modal Gaussian distribution - which are incapable
of representing complex latent factors efficiently. To overcome this
restriction, we propose the simple, but highly flexible, piecewise constant
distribution. This distribution has the capacity to represent an exponential
number of modes of a latent target distribution, while remaining mathematically
tractable. Our results demonstrate that incorporating this new latent
distribution into different models yields substantial improvements in natural
language processing tasks such as document modeling and natural language
generation for dialogue.},
 address = {Copenhagen, Denmark},
 author = {Serban, Iulian Vlad and Ororbia II, Alexander and Pineau, Joelle and Courville, Aaron},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4308},
 booktitle = {Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing},
 month = {September},
 pages = {52--62},
 publisher = {Association for Computational Linguistics},
 title = {Piecewise Latent Variables for Neural Variational Text Processing},
 year = {2017}
}

@inproceedings{W17-4401,
 abstract = {This submission describes the development of a fine-grained, text-chunking
algorithm for the task of comprehensive MWE segmentation. This task notably
focuses on the identification of colloquial and idiomatic language. The
submission also includes a thorough model evaluation in the context of two
recent shared tasks, spanning 19 different languages and many text domains, including noisy, user-generated text. Evaluations exhibit the presented model
as the best overall for purposes of MWE segmentation, and open-source software
is released with the submission (although links are withheld for purposes of
anonymity). Additionally, the authors acknowledge the existence of a pre-print
document on arxiv.org, which should be avoided to maintain anonymity in review.},
 address = {Copenhagen, Denmark},
 author = {Williams, Jake},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4401},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Boundary-based MWE segmentation with text partitioning},
 year = {2017}
}

@inproceedings{W17-4402,
 abstract = {Videogame streaming platforms have become a paramount example of noisy
user-generated text. These are websites where gaming is broadcasted, and allows
interaction with viewers via integrated chatrooms. Probably the best known
platform of this kind is Twitch, which has more than 100 million monthly
viewers. Despite these numbers, and unlike other platforms featuring short
messages (e.g. Twitter), Twitch has not received much attention from the
Natural Language Processing community. In this paper we aim at bridging this
gap by proposing two important tasks specific to the Twitch platform, namely
(1) Emote prediction; and (2) Trolling detection. In our experiments, we
evaluate three models: a BOW baseline, a logistic supervised classifiers based
on word embeddings, and a bidirectional long short-term memory recurrent neural
network (LSTM). Our results show that the LSTM model outperforms the other two
models, where explicit features with proven effectiveness for similar tasks
were encoded.},
 address = {Copenhagen, Denmark},
 author = {Barbieri, Francesco and Espinosa Anke, Luis and Ballesteros, Miguel and Soler, Juan and Saggion, Horacio},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4402},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {11--20},
 publisher = {Association for Computational Linguistics},
 title = {Towards the Understanding of Gaming Audiences by Modeling Twitch Emotes},
 year = {2017}
}

@inproceedings{W17-4403,
 abstract = {For brands, gaining new customer is more expensive than keeping an existing
one. Therefore, the ability to keep customers in a brand is becoming more
challenging these days.  Churn happens when a customer leaves a brand to
another competitor. Most of the previous work considers the problem of churn
prediction using the Call Detail Records (CDRs). In this paper, we use
micro-posts to classify customers into churny or non-churny. We explore the
power of convolutional neural networks (CNNs) since they achieved
state-of-the-art in various computer vision and NLP applications. However, the
robustness of end-to-end models has some limitations such as the availability
of a large amount of labeled data and uninterpretability of these models. We
investigate the use of CNNs augmented with structured logic rules to overcome
or reduce this issue. We developed our system called Churn\_teacher by using an
iterative distillation method that transfers the knowledge, extracted using
just the combination of three logic rules, directly into the weight of the
DNNs. Furthermore, we used weight normalization to speed up training our
convolutional neural networks. Experimental results showed that with just these
three rules, we were able to get state-of-the-art on publicly available Twitter
dataset about three Telecom brands.},
 address = {Copenhagen, Denmark},
 author = {Gridach, Mourad and Haddad, Hatem and Mulki, Hala},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4403},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {21--30},
 publisher = {Association for Computational Linguistics},
 title = {Churn Identification in Microblogs using Convolutional Neural Networks with Structured Logical Knowledge},
 year = {2017}
}

@inproceedings{W17-4404,
 abstract = {Does normalization help Part-of-Speech (POS) tagging accuracy on noisy, non-canonical data?
To the best of our knowledge, little is known on the actual impact of
normalization in a real-world scenario, where gold error detection is not
available.  We investigate the effect of automatic normalization on POS tagging
of tweets.
We also compare normalization to strategies that leverage large amounts of
unlabeled data kept in its raw form.  Our results show that normalization
helps, but does not add  consistently beyond just word embedding layer
initialization. The latter approach yields a tagging model that is competitive
with a Twitter state-of-the-art tagger.},
 address = {Copenhagen, Denmark},
 author = {van der Goot, Rob and Plank, Barbara and Nissim, Malvina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4404},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {31--39},
 publisher = {Association for Computational Linguistics},
 title = {To normalize, or not to normalize: The impact of normalization on Part-of-Speech tagging},
 year = {2017}
}

@inproceedings{W17-4405,
 abstract = {In certain fields, real-time knowledge from events can help in making informed
decisions. In order to extract pertinent real-time knowledge related to an
event, it is important to identify the named entities and their corresponding
aliases related to the event. The problem of identifying aliases of named
entities that spike has remained unexplored. In this paper, we introduce an
algorithm, EntitySpike, that identifies entities that spike in popularity in
tweets from a given time period, and constructs an alias list for these spiked
entities. EntitySpike uses a temporal heuristic to identify named entities with
similar context that occur in the same time period (within minutes) during an
event. Each entity is encoded as a vector using this temporal heuristic. We
show how these entity-vectors can be used to create a named entity alias list.
We evaluated our algorithm on a dataset of temporally ordered tweets from a
single event, the 2013 Grammy Awards show. We carried out various experiments
on tweets that were published in the same time period and show that our
algorithm identifies most entity name aliases and outperforms a competitive
baseline.},
 address = {Copenhagen, Denmark},
 author = {Andy, Anietie and Dredze, Mark and Rwebangira, Mugizi and Callison-Burch, Chris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4405},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {40--44},
 publisher = {Association for Computational Linguistics},
 title = {Constructing an Alias List for Named Entities during an Event},
 year = {2017}
}

@inproceedings{W17-4406,
 abstract = {Low-dimensional vector representations of social media users can benefit
applications like recommendation systems and user attribute inference. Recent
work has shown that user embeddings can be improved by combining different
types of information, such as text and network data. We propose a data
augmentation method that allows novel feature types to be used within
off-the-shelf embedding models. Experimenting with the task of friend
recommendation on a dataset of 5,019 Twitter users, we show that our approach
can lead to substantial performance gains with the simple addition of network
and geographic features.},
 address = {Copenhagen, Denmark},
 author = {Xing, Linzi and Paul, Michael J.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4406},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {45--49},
 publisher = {Association for Computational Linguistics},
 title = {Incorporating Metadata into Content-Based User Embeddings},
 year = {2017}
}

@inproceedings{W17-4407,
 abstract = {The majority of research on extracting missing user attributes from social
media profiles use costly hand-annotated labels for supervised learning.
Distantly supervised methods exist, although these generally rely on knowledge
gathered using external sources. This paper demonstrates the effectiveness of
gathering distant labels for self-reported gender on Twitter using simple
queries. We confirm the reliability of this query heuristic by comparing with
manual annotation. Moreover, using these labels for distant supervision, we
demonstrate competitive model performance on the same data as models trained on
manual annotations. As such, we offer a cheap, extensible, and fast alternative
that can be employed beyond the task of gender classification.},
 address = {Copenhagen, Denmark},
 author = {Emmery, Chris and Chrupa{\l}a, Grzegorz and Daelemans, Walter},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4407},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {50--55},
 publisher = {Association for Computational Linguistics},
 title = {Simple Queries as Distant Labels for Predicting Gender on Twitter},
 year = {2017}
}

@inproceedings{W17-4408,
 abstract = {While language identification works well on standard texts, it performs much
worse on social media language, in particular dialectal language---even for
English. First, to support work on English language identification, we
contribute a new dataset of tweets annotated for English versus non-English, with attention to ambiguity, code-switching, and automatic generation issues.
It is randomly sampled from all public messages, avoiding biases towards
pre-existing language classifiers. Second, we find that a demographic language
model---which identifies messages with language similar to that used by several
U.S. ethnic populations on Twitter---can be used to improve English language
identification performance when combined with a traditional supervised language
identifier. It increases recall with almost no loss of precision, including, surprisingly, for English messages written by non-U.S. authors.
Our dataset and identifier ensemble are available online.},
 address = {Copenhagen, Denmark},
 author = {Blodgett, Su Lin and Wei, Johnny and O'Connor, Brendan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4408},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {56--61},
 publisher = {Association for Computational Linguistics},
 title = {A Dataset and Classifier for Recognizing Social Media English},
 year = {2017}
}

@inproceedings{W17-4409,
 abstract = {Recent work in geolocation has made several hypotheses about what linguistic
markers are relevant to detect where people write from. In this paper, we
examine six hypotheses against a corpus consisting of all geo-tagged tweets
from the
US, or whose geo-tags could be inferred, in a 19% sample of Twitter history.
Our
experiments lend support to all six hypotheses, including that spelling
variants
and hashtags are strong predictors of location. We also study what kinds of
common nouns are predictive of location after controlling for named entities
such as dolphins or sharks},
 address = {Copenhagen, Denmark},
 author = {Salehi, Bahar and S{\o}gaard, Anders},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4409},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {62--67},
 publisher = {Association for Computational Linguistics},
 title = {Evaluating hypotheses in geolocation on a very large sample of Twitter},
 year = {2017}
}

@inproceedings{W17-4410,
 abstract = {In this research we investigate the impact of mismatches in the density and
type of error between training and test data on a neural system correcting
preposition and determiner errors. We use synthetically produced training data
to control error density and type, and "real" error data for testing. Our
results show it is possible to combine error types, although prepositions and
determiners behave differently in terms of how much error should be
artificially introduced into the training data in order to get the best
results.},
 address = {Copenhagen, Denmark},
 author = {Bowen, Fraser and Dehdari, Jon and Van Genabith, Josef},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4410},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {68--76},
 publisher = {Association for Computational Linguistics},
 title = {The Effect of Error Rate in Artificially Generated Data for Automatic Preposition and Determiner Correction},
 year = {2017}
}

@inproceedings{W17-4411,
 abstract = {Human trafficking is a challenging law enforcement problem, and traces of
victims of such activity manifest as {\^a}escort advertisements{\^a} on various
online forums. Given the large, heterogeneous and noisy structure of this data, building models to predict instances of trafficking is a convoluted task. In
this paper we propose an entity resolution pipeline using a notion of proxy
labels, in order to extract clusters from this data with prior history of human
trafficking activity. We apply this pipeline to 5M records from backpage.com
and report on the performance of this approach, challenges in terms of
scalability, and some significant domain specific characteristics of our
resolved entities.},
 address = {Copenhagen, Denmark},
 author = {Nagpal, Chirag and Miller, Kyle and Boecking, Benedikt and Dubrawski, Artur},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4411},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {77--84},
 publisher = {Association for Computational Linguistics},
 title = {An Entity Resolution Approach to Isolate Instances of Human Trafficking Online},
 year = {2017}
}

@inproceedings{W17-4412,
 abstract = {Uyghur is the second largest and most actively used social media language in
China. However, a non-negligible part of Uyghur text appearing in social media
is unsystematically written with the Latin alphabet, and it continues to
increase in size. Uyghur text in this format is incomprehensible and ambiguous
even to native Uyghur speakers. In addition, Uyghur texts in this form lack the
potential for any kind of advancement for the NLP tasks related to the Uyghur
language. Restoring and preventing noisy Uyghur text written with unsystematic
Latin alphabets will be essential to the protection of Uyghur language and
improving the accuracy of Uyghur NLP tasks. To this purpose, in this work we
propose and compare the noisy channel model and the neural encoder-decoder
model as normalizing methods.},
 address = {Copenhagen, Denmark},
 author = {Tursun, Osman and Cakici, Ruket},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4412},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {85--93},
 publisher = {Association for Computational Linguistics},
 title = {Noisy Uyghur Text Normalization},
 year = {2017}
}

@inproceedings{W17-4413,
 abstract = {We present a novel method for obtaining high-quality, domain-targeted multiple
choice questions from crowd workers. Generating these questions can be
difficult without trading away originality, relevance or diversity in the
answer options. Our method addresses these problems by leveraging a large
corpus of domain-specific
text and a small set of existing questions. It produces model suggestions for
document selection and answer distractor choice which aid the human question
generation process. With this method we have assembled SciQ, a dataset of 13.7K
multiple choice science exam questions. We demonstrate that the method produces
in-domain questions by providing an analysis of this new dataset and by showing
that humans cannot distinguish the crowdsourced questions from original
questions. When using SciQ as additional training data to existing questions, we observe accuracy improvements on real science exams.},
 address = {Copenhagen, Denmark},
 author = {Welbl, Johannes and Liu, Nelson F. and Gardner, Matt},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4413},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {94--106},
 publisher = {Association for Computational Linguistics},
 title = {Crowdsourcing Multiple Choice Science Questions},
 year = {2017}
}

@inproceedings{W17-4414,
 abstract = {This paper investigates the problem of text normalisation; specifically, the
normalisation of non-standard words (NSWs) in English. Non-standard words can
be defined as those word tokens which do not have a dictionary entry, and
cannot be pronounced using the usual letter-to-phoneme conversion rules; e.g.
lbs, 99.3%, \#EMNLP2017. NSWs pose a challenge to the proper functioning of
text-to-speech technology, and the solution is to spell them out in such a way
that they can be pronounced appropriately. We describe our four-stage
normalisation system made up of components for detection, classification, division and expansion of NSWs. Performance is favourabe compared to previous
work in the field (Sproat et al. 2001, Normalization of non-standard words), as
well as state-of-the-art text-to-speech software. Further, we update Sproat et
al.'s NSW taxonomy, and create a more customisable system where users are able
to input their own abbreviations and specify into which variety of English
(currently available: British or American) they wish to normalise.},
 address = {Copenhagen, Denmark},
 author = {Flint, Emma and Ford, Elliot and Thomas, Olivia and Caines, Andrew and Buttery, Paula},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4414},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {107--115},
 publisher = {Association for Computational Linguistics},
 title = {A Text Normalisation System for Non-Standard English Words},
 year = {2017}
}

@inproceedings{W17-4415,
 abstract = {Geolocation is the task of identifying a social media user{\^a}s primary
location, and in natural language processing, there is a growing literature on
to what extent automated analysis of social media posts can help. However, not
all content features are equally revealing of a user{\^a}s location.
In this paper, we evaluate nine name entity (NE) types. Using various metrics, we find that GEO-LOC, FACILITY and SPORT-TEAM are more informative for
geolocation than other NE types. Using these types, we improve geolocation
accuracy and reduce distance error over various famous text-based methods.},
 address = {Copenhagen, Denmark},
 author = {Salehi, Bahar and Hovy, Dirk and Hovy, Eduard and S{\o}gaard, Anders},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4415},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {116--121},
 publisher = {Association for Computational Linguistics},
 title = {Huntsville, hospitals, and hockey teams: Names can reveal your location},
 year = {2017}
}

@inproceedings{W17-4416,
 abstract = {Technical documents contain a fair amount of unnatural language, such as
tables, formulas, and pseudo-code. Unnatural language can bean important factor
of confusing existing NLP tools. This paper presents an effective method of
distinguishing unnatural language from natural language, and evaluates the
impact of un-natural language detection on NLP tasks such as document
clustering.  We view this problem as an information extraction task and build a
multiclass classification model identifying unnatural language components into
four categories. First, we create a new annotated corpus by collecting slides
and papers in various for-mats, PPT, PDF, and HTML, where unnatural language
components are annotated into four categories. We then explore features
available from plain text to build a statistical model that can handle any
format as long as it is converted into plain text. Our experiments show that
re-moving unnatural language components gives an absolute improvement in
document cluster-ing by up to 15%.   Our corpus and tool are publicly available},
 address = {Copenhagen, Denmark},
 author = {Jang, Myungha and Choi, Jinho D. and Allan, James},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4416},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {122--130},
 publisher = {Association for Computational Linguistics},
 title = {Improving Document Clustering by Removing Unnatural Language},
 year = {2017}
}

@inproceedings{W17-4417,
 abstract = {In this paper, we describe the Lithium Natural Language Processing (NLP) system
- a resource-constrained, high- throughput and language-agnostic system for
information extraction from noisy user generated text on social media. Lithium
NLP extracts a rich set of information including entities, top- ics, hashtags
and sentiment from text. We discuss several real world applications of the
system currently incorporated in Lithium products. We also compare our system
with existing commercial and academic NLP systems in terms of performance, information extracted and languages supported. We show that Lithium NLP is at
par with and in some cases, outperforms state- of-the-art commercial NLP
systems.},
 address = {Copenhagen, Denmark},
 author = {Bhargava, Preeti and Spasojevic, Nemanja and Hu, Guoning},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4417},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {131--139},
 publisher = {Association for Computational Linguistics},
 title = {Lithium NLP: A System for Rich Information Extraction from Noisy User Generated Text on Social Media},
 year = {2017}
}

@inproceedings{W17-4418,
 abstract = {This shared task focuses on identifying unusual, previously-unseen entities in
the context of emerging discussions. Named entities form the basis of many
modern approaches to other tasks (like event clustering and summarization), but
recall on them is a real problem in noisy text - even among annotators. This
drop tends to be due to novel entities and surface forms. Take for example the
tweet "so.. kktny in 30 mins?!" -- even human experts find the entity 'kktny'
hard to detect and resolve. The goal of this task is to provide a definition of
emerging and of rare entities, and based on that, also datasets for detecting
these entities. The task as described in this paper evaluated the ability of
participating entries to detect and classify novel and emerging named entities
in noisy text.},
 address = {Copenhagen, Denmark},
 author = {Derczynski, Leon and Nichols, Eric and van Erp, Marieke and Limsopatham, Nut},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4418},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {140--147},
 publisher = {Association for Computational Linguistics},
 title = {Results of the WNUT2017 Shared Task on Novel and Emerging Entity Recognition},
 year = {2017}
}

@inproceedings{W17-4419,
 abstract = {Named Entity Recognition for social media data is challenging because of its
inherent noisiness. In addition to improper grammatical structures, it contains
spelling inconsistencies and numerous informal abbreviations. We propose a
novel multi-task approach by employing a more general secondary task of Named
Entity (NE) segmentation together with the primary task of fine-grained NE
categorization. The multi-task neural network architecture learns higher order
feature representations from word and character sequences along with basic
Part-of-Speech tags and gazetteer information. This neural network acts as a
feature extractor to feed a Conditional Random Fields classifier. We were able
to obtain the first position in the 3rd Workshop on Noisy User-generated Text
(WNUT-2017) with a 41.86% entity F1-score and a 40.24% surface F1-score.},
 address = {Copenhagen, Denmark},
 author = {Aguilar, Gustavo and Maharjan, Suraj and L\'{o}pez Monroy, Adrian Pastor and Solorio, Thamar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4419},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {148--153},
 publisher = {Association for Computational Linguistics},
 title = {A Multi-task Approach for Named Entity Recognition in Social Media Data},
 year = {2017}
}

@inproceedings{W17-4420,
 abstract = {This paper reports our participation in the W-NUT 2017 shared task on emerging
and rare entity recognition from user generated noisy text such as tweets, online reviews and forum discussions. To accomplish this challenging task, we
explore an approach that combines LDA topic modelling with deep learning on
word level and character level embeddings. The LDA topic modelling generates
topic representation for each tweet which is used as a feature for each word in
the tweet. The deep learning component consists of two-layer bidirectional LSTM
and a CRF output layer. Our submitted result performed at 39.98 (F1) on entity
and 37.77 on surface forms. Our new experiments after submission reached a best
performance of 41.81 on entity and 40.57 on surface forms.},
 address = {Copenhagen, Denmark},
 author = {Jansson, Patrick and Liu, Shuhua},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4420},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {154--159},
 publisher = {Association for Computational Linguistics},
 title = {Distributed Representation, LDA Topic Modelling and Deep Learning for Emerging Named Entity Recognition from Social Media},
 year = {2017}
}

@inproceedings{W17-4421,
 abstract = {In this paper, we present our multi-channel neural architecture for recognizing
emerging named entity in social media messages, which we applied in the Novel
and Emerging Named Entity Recognition shared task at the EMNLP 2017 Workshop on
Noisy User-generated Text (W-NUT). We propose a novel approach, which
incorporates comprehensive word representations with multi-channel information
and Conditional Random Fields (CRF) into a traditional Bidirectional Long
Short-Term Memory (BiLSTM) neural network without using any additional
hand-craft features such as gazetteers. In comparison with other systems
participating in the shared task, our system won the 2nd place.},
 address = {Copenhagen, Denmark},
 author = {Lin, Bill Y. and Xu, Frank and Luo, Zhiyi and Zhu, Kenny},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4421},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {160--165},
 publisher = {Association for Computational Linguistics},
 title = {Multi-channel BiLSTM-CRF Model for Emerging Named Entity Recognition in Social Media},
 year = {2017}
}

@inproceedings{W17-4422,
 abstract = {We present our system for the WNUT 2017 Named Entity Recognition challenge on
Twitter data. We describe two modifications of a basic neural network
architecture for sequence tagging. First, we show how we exploit additional
labeled data, where the Named Entity tags differ from the target task. Then, we
propose a way to incorporate sentence level features. Our system uses both
methods and ranked second for entity level annotations, achieving an F1-score
of 40.78, and second for surface form annotations, achieving an F1-score of
39.33.},
 address = {Copenhagen, Denmark},
 author = {von D\"{a}niken, Pius and Cieliebak, Mark},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4422},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {166--171},
 publisher = {Association for Computational Linguistics},
 title = {Transfer Learning and Sentence Level Features for Named Entity Recognition on Tweets},
 year = {2017}
}

@inproceedings{W17-4423,
 abstract = {This paper is a shared task system description for the 2017 W-NUT shared task
on Rare and Emerging Named Entities. Our paper describes the development and
application of a novel algorithm for named entity recognition that relies only
on the contexts of word forms. A comparison against the other submitted systems
is provided.},
 address = {Copenhagen, Denmark},
 author = {Williams, Jake and Santia, Giovanni},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4423},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {172--176},
 publisher = {Association for Computational Linguistics},
 title = {Context-Sensitive Recognition for Emerging and Rare Entities},
 year = {2017}
}

@inproceedings{W17-4424,
 abstract = {Detecting previously unseen named entities in text is a challenging task. The
paper describes how three initial classifier models were built using
Conditional Random Fields (CRFs), Support Vector Machines (SVMs) and a Long
Short-Term Memory (LSTM) recurrent neural network. The outputs of these three
classifiers were then used as features to train another CRF classifier working
as an ensemble.
5-fold cross-validation based on training and development data for the emerging
and rare named entity recognition shared task showed precision, recall and
F1-score of 66.87%, 46.75% and 54.97%, respectively. For surface form
evaluation, the CRF ensemble-based system achieved precision, recall and F1
scores of 65.18%, 45.20% and 53.30%. When applied to unseen test data, the
model reached 47.92% precision, 31.97% recall and 38.55% F1-score for entity
level evaluation, with the corresponding surface form evaluation values of
44.91%, 30.47% and 36.31%.},
 address = {Copenhagen, Denmark},
 author = {Sikdar, Utpal Kumar and Gamb\"{a}ck, Bj\"{o}rn},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4424},
 booktitle = {Proceedings of the 3rd Workshop on Noisy User-generated Text},
 month = {September},
 pages = {177--181},
 publisher = {Association for Computational Linguistics},
 title = {A Feature-based Ensemble Approach to Recognition of Emerging and Rare Named Entities},
 year = {2017}
}

@inproceedings{W17-4501,
 abstract = {With the prevalence of video sharing, there are increasing demands for
automatic video digestion such as highlight detection. Recently, platforms with
crowdsourced time-sync video comments have emerged worldwide, providing a good
opportunity for highlight detection. However, this task is non-trivial: (1)
time-sync comments often lag behind their corresponding shot; (2) time-sync
comments are semantically sparse and noisy; (3) to determine which shots are
highlights is highly subjective. The present paper aims to tackle these
challenges by proposing a framework that (1) uses concept-mapped lexical-chains
for lag-calibration; (2) models video highlights based on comment intensity and
combination of emotion and concept concentration of each shot; (3) summarize
each detected highlight using improved SumBasic with emotion and concept
mapping. Experiments on large real-world datasets show that our highlight
detection method and summarization method both outperform other benchmarks with
considerable margins.},
 address = {Copenhagen, Denmark},
 author = {Ping, Qing and Chen, Chaomei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4501},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {1--11},
 publisher = {Association for Computational Linguistics},
 title = {Video Highlights Detection and Summarization with Lag-Calibration based on Concept-Emotion Mapping of Crowdsourced Time-Sync Comments},
 year = {2017}
}

@inproceedings{W17-4502,
 abstract = {With the proliferation of Web-based social media, asynchronous conversations
have become very common for supporting online communication and collaboration.
Yet the increasing volume and complexity of conversational data often make
it very difficult to get insights about the discussions. We consider combining
textual summary with visual representation of conversational data as a
promising way of supporting the user in exploring conversations. In this paper, we report our current work on developing visual interfaces that
present multimedia summary combining text and visualization for online
conversations and how our solutions have been tailored for a variety of domain
problems. We then discuss the key challenges and opportunities for future work
in this research space.},
 address = {Copenhagen, Denmark},
 author = {Hoque, Enamul and Carenini, Giuseppe},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4502},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {12--19},
 publisher = {Association for Computational Linguistics},
 title = {Multimedia Summary Generation from Online Conversations: Current Approaches and Future Directions},
 year = {2017}
}

@inproceedings{W17-4503,
 abstract = {Recent neural headline generation models
have shown great results, but are generally
trained on very large datasets. We focus
our efforts on improving headline quality
on smaller datasets by the means of pretraining.
We propose new methods that
enable pre-training all the parameters of
the model and utilize all available text, resulting
in improvements by up to 32.4%
relative in perplexity and 2.84 points in
ROUGE.},
 address = {Copenhagen, Denmark},
 author = {Tilk, Ottokar and Alum\"{a}e, Tanel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4503},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {20--26},
 publisher = {Association for Computational Linguistics},
 title = {Low-Resource Neural Headline Generation},
 year = {2017}
}

@inproceedings{W17-4504,
 abstract = {Abstractive summarization, the task of rewriting and compressing a document
into a short summary, has achieved considerable success with neural
sequence-to-sequence models. However, these models can still benefit from
stronger natural language inference skills, since a correct summary is
logically entailed by the input document, i.e., it should not contain any
contradictory or unrelated information. We incorporate such knowledge into an
abstractive summarization model via multi-task learning, where we share its
decoder parameters with those of an entailment generation model. We achieve
promising initial improvements based on multiple metrics and datasets
(including a test-only setting). The domain mismatch between the entailment
(captions) and summarization (news) datasets suggests that the model is
learning some domain-agnostic inference skills.},
 address = {Copenhagen, Denmark},
 author = {Pasunuru, Ramakanth and Guo, Han and Bansal, Mohit},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4504},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {27--32},
 publisher = {Association for Computational Linguistics},
 title = {Towards Improving Abstractive Summarization via Entailment Generation},
 year = {2017}
}

@inproceedings{W17-4505,
 abstract = {Sequence-to-sequence models with attention have been successful for a variety
of NLP problems, but their speed does not scale well for tasks with long source
sequences such as document summarization.
We propose a novel coarse-to-fine attention model that hierarchically reads a
document, using coarse attention to select top-level chunks of text and fine
attention to read the words of the chosen chunks. While the computation for
training standard attention models scales linearly with source sequence length, our method scales with the number of top-level chunks and can handle much
longer sequences.
Empirically, we find that while coarse-to-fine attention models lag behind
state-of-the-art baselines, our method achieves the desired behavior of
sparsely attending to subsets of the document for generation.},
 address = {Copenhagen, Denmark},
 author = {Ling, Jeffrey and Rush, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4505},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {33--42},
 publisher = {Association for Computational Linguistics},
 title = {Coarse-to-Fine Attention Models for Document Summarization},
 year = {2017}
}

@inproceedings{W17-4506,
 abstract = {Summarization of spoken conversations is a challenging task, since it requires
deep understanding of dialogs. Abstractive summarization techniques rely on
linking the summary sentences to sets of original conversation sentences, i.e.
communities. Unfortunately, such linking information is rarely available or
requires trained annotators. We propose and experiment automatic community
creation using cosine similarity on different levels of representation: raw
text, WordNet SynSet IDs, and word embeddings. We show that the abstractive
summarization systems with automatic communities significantly outperform
previously published results on both English and Italian corpora.},
 address = {Copenhagen, Denmark},
 author = {Singla, Karan and Stepanov, Evgeny and Bayer, Ali Orkan and Carenini, Giuseppe and Riccardi, Giuseppe},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4506},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {43--47},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Community Creation for Abstractive Spoken Conversations Summarization},
 year = {2017}
}

@inproceedings{W17-4507,
 abstract = {We present a fully unsupervised, extractive text summarization system that
leverages a submodularity framework introduced by past research. The framework
allows summaries to be generated in a greedy way while preserving near-optimal
performance guarantees. Our main contribution is the novel coverage reward term
of the objective function optimized by the greedy algorithm. This component
builds on the graph-of-words representation of text and the k-core
decomposition algorithm to assign meaningful scores to words. We evaluate our
approach on the AMI and ICSI meeting speech corpora, and on the DUC2001 news
corpus. We reach state-of-the-art performance on all datasets. Results indicate
that our method is particularly well-suited to the meeting domain.},
 address = {Copenhagen, Denmark},
 author = {Tixier, Antoine and Meladianos, Polykarpos and Vazirgiannis, Michalis},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4507},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {48--58},
 publisher = {Association for Computational Linguistics},
 title = {Combining Graph Degeneracy and Submodularity for Unsupervised Extractive Summarization},
 year = {2017}
}

@inproceedings{W17-4508,
 abstract = {Recent advances in automatic text summarization have used deep neural networks
to generate high-quality abstractive summaries, but the performance of these
models strongly depends on large amounts of suitable training data. We propose
a new method for mining social media for author-provided summaries, taking
advantage of the common practice of appending a ``TL;DR'' to long posts. A case
study using a large Reddit crawl yields the Webis-TLDR-17 dataset, complementing existing corpora primarily from the news genre. Our technique is
likely applicable to other social media sites and general web crawls.},
 address = {Copenhagen, Denmark},
 author = {V\"{o}lske, Michael and Potthast, Martin and Syed, Shahbaz and Stein, Benno},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4508},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {59--63},
 publisher = {Association for Computational Linguistics},
 title = {TL;DR: Mining Reddit to Learn Automatic Summarization},
 year = {2017}
}

@inproceedings{W17-4509,
 abstract = {We envisioned responsive generic hierarchical text summarization with summaries
organized by section and paragraph based on hierarchical structure topic
models. But we had to be sure that topic models were stable for the sampled
corpora. To that end we developed a methodology for aligning multiple
hierarchical structure topic models run over the same corpus under similar
conditions, calculating a representative centroid model, and reporting
stability of the centroid model. We ran stability experiments for standard
corpora and a development corpus of Global Warming articles. We found flat and
hierarchical structures of two levels plus the root offer stable centroid
models, but hierarchical structures of three levels plus the root didn't seem
stable enough for use in hierarchical summarization.},
 address = {Copenhagen, Denmark},
 author = {Miller, John and McCoy, Kathleen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4509},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {64--73},
 publisher = {Association for Computational Linguistics},
 title = {Topic Model Stability for Hierarchical Summarization},
 year = {2017}
}

@inproceedings{W17-4510,
 abstract = {The evaluation of summaries is a challenging but crucial task of the
summarization field. In this work, we propose to learn an automatic scoring
metric based on the human judgements available as part of classical
summarization datasets like TAC-2008 and TAC-2009. Any existing automatic
scoring metrics can be included as features, the model learns the combination
exhibiting the best correlation with human judgments. The reliability of the
new metric is tested in a further manual evaluation where we ask humans to
evaluate summaries covering the whole scoring spectrum of the metric. We
release the trained metric as an open-source tool.},
 address = {Copenhagen, Denmark},
 author = {Peyrard, Maxime and Botschen, Teresa and Gurevych, Iryna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4510},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {74--84},
 publisher = {Association for Computational Linguistics},
 title = {Learning to Score System Summaries for Better Content Selection Evaluation.},
 year = {2017}
}

@inproceedings{W17-4511,
 abstract = {The centroid-based model for extractive document summarization is a simple and
fast baseline that ranks sentences based on their similarity to a centroid
vector. In this paper, we apply this ranking to possible summaries instead of
sentences and use a simple greedy algorithm to find the best summary.
Furthermore, we show possibilities to scale up to larger input document
collections by selecting a small number of sentences from each document prior
to constructing the summary.
Experiments were done on the DUC2004 dataset for multi-document summarization.
We observe a higher performance over the original model, on par with more
complex state-of-the-art methods.},
 address = {Copenhagen, Denmark},
 author = {Gholipour Ghalandari, Demian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4511},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {85--90},
 publisher = {Association for Computational Linguistics},
 title = {Revisiting the Centroid-based Method: A Strong Baseline for Multi-Document Summarization},
 year = {2017}
}

@inproceedings{W17-4512,
 abstract = {We investigate the problem of reader-aware multi-document summarization
(RA-MDS) and introduce a new dataset for this problem. To tackle RA-MDS, we
extend a variational auto-encodes (VAEs) based MDS framework by jointly
considering news documents and reader comments. To conduct evaluation for
summarization performance, we prepare a new dataset. We describe the methods
for data collection, aspect annotation, and summary writing as well as
scrutinizing by experts. Experimental results show that reader comments can
improve the summarization performance, which also demonstrates the usefulness
of the proposed dataset.},
 address = {Copenhagen, Denmark},
 author = {Li, Piji and Bing, Lidong and Lam, Wai},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4512},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {91--99},
 publisher = {Association for Computational Linguistics},
 title = {Reader-Aware Multi-Document Summarization: An Enhanced Model and The First Dataset},
 year = {2017}
}

@inproceedings{W17-4513,
 abstract = {We study the problem of domain adaptation for neural abstractive summarization.
We make initial efforts in investigating what information can be transferred to
a new domain. Experimental results on news stories and opinion articles
indicate that neural summarization model benefits from pre-training based on
extractive summaries. We also find that the combination of in-domain and
out-of-domain setup yields better summaries when in-domain data is
insufficient. Further analysis shows that, the model is capable to select
salient content even trained on out-of-domain data, but requires in-domain data
to capture the style for a target domain.},
 address = {Copenhagen, Denmark},
 author = {Hua, Xinyu and Wang, Lu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4513},
 booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},
 month = {September},
 pages = {100--106},
 publisher = {Association for Computational Linguistics},
 title = {A Pilot Study of Domain Adaptation Effect for Neural Abstractive Summarization},
 year = {2017}
}

@inproceedings{W17-4601,
 abstract = {Silence is an integral part of the most frequent turn-taking phenomena in
spoken conversations.  Silence is sized and placed within the conversation flow
and it is coordinated by the speakers along with the other speech acts. The
objective of this analytical study is twofold: to explore the functions of
silence with duration of one second and above, towards information flow in a
dyadic conversation utilizing the sequences of dialog acts present in the turns
surrounding the silence itself; and to design a feature space useful for
clustering the silences using a hierarchical concept formation algorithm. The
resulting clusters are manually grouped into functional categories based on
their similarities. It is observed that the silence plays an important role in
response preparation, also can indicate speakers' hesitation or indecisiveness.
It is also observed that sometimes long silences can be used deliberately to
get a forced response from another speaker thus making silence a
multi-functional and an important catalyst towards information flow.},
 address = {Copenhagen, Denmark},
 author = {Chowdhury, Shammur Absar and Stepanov, Evgeny and Danieli, Morena and Riccardi, Giuseppe},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4601},
 booktitle = {Proceedings of the Workshop on Speech-Centric Natural Language Processing},
 month = {September},
 pages = {1--9},
 publisher = {Association for Computational Linguistics},
 title = {Functions of Silences towards Information Flow in Spoken Conversation},
 year = {2017}
}

@inproceedings{W17-4602,
 abstract = {This paper presents our novel method to encode word confusion networks, which
can represent a rich hypothesis space of automatic speech recognition systems, via recurrent neural networks.
We demonstrate the utility of our approach for the task of dialog state
tracking in spoken dialog systems that relies on automatic speech recognition
output.
Encoding confusion networks outperforms encoding the best hypothesis of the
automatic speech recognition in a neural system for dialog state tracking on
the well-known second Dialog State Tracking Challenge dataset.},
 address = {Copenhagen, Denmark},
 author = {Jagfeld, Glorianna and Vu, Ngoc Thang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4602},
 booktitle = {Proceedings of the Workshop on Speech-Centric Natural Language Processing},
 month = {September},
 pages = {10--17},
 publisher = {Association for Computational Linguistics},
 title = {Encoding Word Confusion Networks with Recurrent Neural Networks for Dialog State Tracking},
 year = {2017}
}

@inproceedings{W17-4603,
 abstract = {Written sentences can be more ambiguous than spoken sentences. We investigate
this difference for two different types of ambiguity: prepositional phrase (PP)
attachment and sentences where the addition of commas changes the meaning. We
recorded a native English speaker saying several of each type of sentence both
with and without disambiguating contextual information.  These sentences were
then presented either as text or audio and either with or without context to
subjects who were asked to select the proper interpretation of the sentence.
Results suggest that comma-ambiguous sentences are easier to disambiguate than
PP-attachment-ambiguous sentences, possibly due to the presence of clear
prosodic boundaries, namely silent pauses. Subject performance for sentences
with PP-attachment ambiguity without context was 52% for text only while it was
72.4% for audio only, suggesting that audio has more disambiguating information
than text. Using an analysis of acoustic features of two PP-attachment
sentences, a simple classifier was implemented to resolve the PP-attachment
ambiguity being early or late closure with a mean accuracy of 80%.},
 address = {Copenhagen, Denmark},
 author = {Ghaly, Hussein and Mandel, Michael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4603},
 booktitle = {Proceedings of the Workshop on Speech-Centric Natural Language Processing},
 month = {September},
 pages = {18--26},
 publisher = {Association for Computational Linguistics},
 title = {Analyzing Human and Machine Performance In Resolving Ambiguous Spoken Sentences},
 year = {2017}
}

@inproceedings{W17-4604,
 abstract = {We present an analysis of parser performance on speech data, comparing word
type and token frequency distributions with written data, and evaluating parse
accuracy by length of input string. We find that parser performance tends to
deteriorate with increasing length of string, more so for spoken than for
written texts. We train an alternative parsing model with added speech data and
demonstrate improvements in accuracy on speech-units, with no deterioration in
performance on written text.},
 address = {Copenhagen, Denmark},
 author = {Caines, Andrew and McCarthy, Michael and Buttery, Paula},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4604},
 booktitle = {Proceedings of the Workshop on Speech-Centric Natural Language Processing},
 month = {September},
 pages = {27--36},
 publisher = {Association for Computational Linguistics},
 title = {Parsing transcripts of speech},
 year = {2017}
}

@inproceedings{W17-4605,
 abstract = {Parsing speech requires a richer representation than 1-best or n-best
hypotheses, e.g. lattices. Moreover, previous work shows that part-of-speech
(POS) tags are a valuable resource for parsing. In this paper, we therefore
explore a joint modeling approach of automatic speech recognition (ASR) and POS
tagging to enrich ASR word lattices. To that end, we manipulate the ASR process
from the pronouncing dictionary onward to use word-POS pairs instead of words.
We evaluate ASR, POS tagging and dependency parsing (DP) performance
demonstrating a successful lattice-based integration of ASR and POS tagging.},
 address = {Copenhagen, Denmark},
 author = {Stiefel, Moritz and Vu, Ngoc Thang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4605},
 booktitle = {Proceedings of the Workshop on Speech-Centric Natural Language Processing},
 month = {September},
 pages = {37--47},
 publisher = {Association for Computational Linguistics},
 title = {Enriching ASR Lattices with POS Tags for Dependency Parsing},
 year = {2017}
}

@inproceedings{W17-4606,
 abstract = {Most state-of-the-art information extraction approaches rely on token-level
labels to find the areas of interest in text. Unfortunately, these labels are
time-consuming and costly to create, and consequently, not available for many
real-life IE tasks. To make matters worse, token-level labels are usually not
the desired output, but just an intermediary step.
End-to-end (E2E) models, which take raw text as input and produce the desired
output directly, need not depend on token-level labels.
We propose an E2E model based on pointer networks, which can be trained
directly on pairs of raw input and output text.
We evaluate our model on the ATIS data set, MIT restaurant corpus and the MIT
movie corpus and compare to neural baselines that do use token-level labels. We
achieve competitive results, within a few percentage points of the baselines, showing the feasibility of E2E information extraction without the need for
token-level labels.
This opens up new possibilities, as for many tasks currently addressed by human
extractors, raw input and output data are available, but not token-level
labels.},
 address = {Copenhagen, Denmark},
 author = {Palm, Rasmus Berg and Hovy, Dirk and Laws, Florian and Winther, Ole},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4606},
 booktitle = {Proceedings of the Workshop on Speech-Centric Natural Language Processing},
 month = {September},
 pages = {48--52},
 publisher = {Association for Computational Linguistics},
 title = {End-to-End Information Extraction without Token-Level Supervision},
 year = {2017}
}

@inproceedings{W17-4607,
 abstract = {Vast amounts of speech data collected for language documentation and research
remain untranscribed and unsearchable, but often a small amount of speech may
have text translations available. We present a method for partially labeling
additional speech with translations in this scenario. We modify an unsupervised
speech-to-translation alignment model and obtain prototype speech segments that
match the translation words, which are in turn used to discover terms in the
unlabelled data. We evaluate our method on a Spanish-English speech translation
corpus and on two corpora of endangered languages, Arapaho and Ainu, demonstrating its appropriateness and applicability in an actual
very-low-resource scenario.},
 address = {Copenhagen, Denmark},
 author = {Anastasopoulos, Antonios and Bansal, Sameer and Chiang, David and Goldwater, Sharon and Lopez, Adam},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4607},
 booktitle = {Proceedings of the Workshop on Speech-Centric Natural Language Processing},
 month = {September},
 pages = {53--58},
 publisher = {Association for Computational Linguistics},
 title = {Spoken Term Discovery for Language Documentation using Translations},
 year = {2017}
}

@inproceedings{W17-4608,
 abstract = {This paper describes speech translation from Amharic-to-English, particularly
Automatic Speech Recognition (ASR) with post-editing feature and
Amharic-English Statistical Machine Translation (SMT). ASR experiment is
conducted using morpheme language model (LM) and phoneme acoustic model(AM).
Likewise,SMT conducted using word and morpheme as unit.
Morpheme based translation shows a 6.29 BLEU score at a 76.4% of recognition
accuracy while word based translation shows a 12.83 BLEU score using 77.4% word
recognition accuracy. Further, after post-edit on Amharic ASR using corpus
based n-gram, the word recognition accuracy increased by 1.42%. Since post-edit
approach reduces error propagation, the word based translation accuracy
improved by 0.25 (1.95%) BLEU score. We are now working towards further
improving propagated errors through different algorithms at each unit of speech
translation cascading component.},
 address = {Copenhagen, Denmark},
 author = {Melese, Michael and Besacier, Laurent and Meshesha, Million},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4608},
 booktitle = {Proceedings of the Workshop on Speech-Centric Natural Language Processing},
 month = {September},
 pages = {59--66},
 publisher = {Association for Computational Linguistics},
 title = {Amharic-English Speech Translation in Tourism Domain},
 year = {2017}
}

@inproceedings{W17-4609,
 abstract = {We consider the automatic scoring of a task for which both the content of the
response as well its spoken fluency are important. We combine features from a
text-only content scoring system originally designed for written responses with
several categories of acoustic features. Although adding any single category of
acoustic features to the text-only system on its own does not significantly
improve performance, adding all acoustic features together does yield a small
but significant improvement. These results are consistent for responses to
open-ended questions and to questions focused on some given source material.},
 address = {Copenhagen, Denmark},
 author = {Loukina, Anastassia and Madnani, Nitin and Cahill, Aoife},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4609},
 booktitle = {Proceedings of the Workshop on Speech-Centric Natural Language Processing},
 month = {September},
 pages = {67--77},
 publisher = {Association for Computational Linguistics},
 title = {Speech- and Text-driven Features for Automated Scoring of English Speaking Tasks},
 year = {2017}
}

@inproceedings{W17-4610,
 abstract = {Adding manually annotated prosodic information, specifically pitch accents and
phrasing, to the typical text-based feature set for coreference resolution has
previously been shown to have a positive effect on German data. Practical
applications on spoken language, however, would rely on automatically predicted
prosodic information. In this paper we predict pitch accents (and phrase
boundaries) using a convolutional neural network (CNN) model from acoustic
features extracted from the speech signal. After an assessment of the quality
of these automatic prosodic annotations, we show that they also significantly
improve coreference resolution.},
 address = {Copenhagen, Denmark},
 author = {Roesiger, Ina and Stehwien, Sabrina and Riester, Arndt and Vu, Ngoc Thang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4610},
 booktitle = {Proceedings of the Workshop on Speech-Centric Natural Language Processing},
 month = {September},
 pages = {78--83},
 publisher = {Association for Computational Linguistics},
 title = {Improving coreference resolution with automatically predicted prosodic information},
 year = {2017}
}

@inproceedings{W17-4701,
 address = {Copenhagen, Denmark},
 author = {Pu, Xiao and Pappas, Nikolaos and Popescu-Belis, Andrei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4701},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Sense-Aware Statistical Machine Translation using Adaptive Context-Dependent Clustering},
 year = {2017}
}

@inproceedings{W17-4702,
 address = {Copenhagen, Denmark},
 author = {Rios Gonzales, Annette and Mascarell, Laura and Sennrich, Rico},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4702},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {11--19},
 publisher = {Association for Computational Linguistics},
 title = {Improving Word Sense Disambiguation in Neural Machine Translation with Sense Embeddings},
 year = {2017}
}

@inproceedings{W17-4703,
 address = {Copenhagen, Denmark},
 author = {Burlot, Franck and Garc\'{i}a-Mart\'{i}nez, Mercedes and Barrault, Lo\"{i}c and Bougares, Fethi and Yvon, Fran\c{c}ois},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4703},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {20--31},
 publisher = {Association for Computational Linguistics},
 title = {Word Representations in Factored Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-4704,
 address = {Copenhagen, Denmark},
 author = {Tamchyna, Ale\v{s} and Weller-Di Marco, Marion and Fraser, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4704},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {32--42},
 publisher = {Association for Computational Linguistics},
 title = {Modeling Target-Side Inflection in Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-4705,
 address = {Copenhagen, Denmark},
 author = {Burlot, Franck and Yvon, Fran\c{c}ois},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4705},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {43--55},
 publisher = {Association for Computational Linguistics},
 title = {Evaluating the morphological competence of Machine Translation Systems},
 year = {2017}
}

@inproceedings{W17-4706,
 address = {Copenhagen, Denmark},
 author = {Huck, Matthias and Riess, Simon and Fraser, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4706},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {56--67},
 publisher = {Association for Computational Linguistics},
 title = {Target-side Word Segmentation Strategies for Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-4707,
 address = {Copenhagen, Denmark},
 author = {Nadejde, Maria and Reddy, Siva and Sennrich, Rico and Dwojak, Tomasz and Junczys-Dowmunt, Marcin and Koehn, Philipp and Birch, Alexandra},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4707},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {68--79},
 publisher = {Association for Computational Linguistics},
 title = {Predicting Target Language CCG Supertags Improves Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-4708,
 address = {Copenhagen, Denmark},
 author = {Niehues, Jan and Cho, Eunah},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4708},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {80--89},
 publisher = {Association for Computational Linguistics},
 title = {Exploiting Linguistic Resources for Neural Machine Translation Using Multi-task Learning},
 year = {2017}
}

@inproceedings{W17-4709,
 address = {Copenhagen, Denmark},
 author = {Miura, Akiva and Neubig, Graham and Sudoh, Katsuhito and Nakamura, Satoshi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4709},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {90--98},
 publisher = {Association for Computational Linguistics},
 title = {Tree as a Pivot: Syntactic Matching Methods in Pivot Translation},
 year = {2017}
}

@inproceedings{W17-4710,
 address = {Copenhagen, Denmark},
 author = {Miceli Barone, Antonio Valerio and Helcl, Jind\v{r}ich and Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4710},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {99--107},
 publisher = {Association for Computational Linguistics},
 title = {Deep architectures for Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-4711,
 address = {Copenhagen, Denmark},
 author = {Alkhouli, Tamer and Ney, Hermann},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4711},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {108--117},
 publisher = {Association for Computational Linguistics},
 title = {Biasing Attention-Based Recurrent Neural Networks Using External Alignment Information},
 year = {2017}
}

@inproceedings{W17-4712,
 address = {Copenhagen, Denmark},
 author = {Britz, Denny and Le, Quoc and Pryzant, Reid},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4712},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {118--126},
 publisher = {Association for Computational Linguistics},
 title = {Effective Domain Mixing for Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-4713,
 address = {Copenhagen, Denmark},
 author = {Farajian, M. Amin and Turchi, Marco and Negri, Matteo and Federico, Marcello},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4713},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {127--137},
 publisher = {Association for Computational Linguistics},
 title = {Multi-Domain Neural Machine Translation through Unsupervised Adaptation},
 year = {2017}
}

@inproceedings{W17-4714,
 address = {Copenhagen, Denmark},
 author = {Chinea-Rios, Mara and Peris, \'{A}lvaro and Casacuberta, Francisco},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4714},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {138--147},
 publisher = {Association for Computational Linguistics},
 title = {Adapting Neural Machine Translation with Parallel Synthetic Data},
 year = {2017}
}

@inproceedings{W17-4715,
 address = {Copenhagen, Denmark},
 author = {Currey, Anna and Miceli Barone, Antonio Valerio and Heafield, Kenneth},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4715},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {148--156},
 publisher = {Association for Computational Linguistics},
 title = {Copied Monolingual Data Improves Low-Resource Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-4716,
 address = {Copenhagen, Denmark},
 author = {Chatterjee, Rajen and Negri, Matteo and Turchi, Marco and Federico, Marcello and Specia, Lucia and Blain, Fr\'{e}d\'{e}ric},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4716},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {157--168},
 publisher = {Association for Computational Linguistics},
 title = {Guiding Neural Machine Translation Decoding with External Knowledge},
 year = {2017}
}

@inproceedings{W17-4717,
 address = {Copenhagen, Denmark},
 author = {Bojar, Ond\v{r}ej and Chatterjee, Rajen and Federmann, Christian and Graham, Yvette and Haddow, Barry and Huang, Shujian and Huck, Matthias and Koehn, Philipp and Liu, Qun and Logacheva, Varvara and Monz, Christof and Negri, Matteo and Post, Matt and Rubino, Raphael and Specia, Lucia and Turchi, Marco},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4717},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {169--214},
 publisher = {Association for Computational Linguistics},
 title = {Findings of the 2017 Conference on Machine Translation (WMT17)},
 year = {2017}
}

@inproceedings{W17-4718,
 address = {Copenhagen, Denmark},
 author = {Elliott, Desmond and Frank, Stella and Barrault, Lo\"{i}c and Bougares, Fethi and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4718},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {215--233},
 publisher = {Association for Computational Linguistics},
 title = {Findings of the Second Shared Task on Multimodal Machine Translation and Multilingual Image Description},
 year = {2017}
}

@inproceedings{W17-4719,
 address = {Copenhagen, Denmark},
 author = {Jimeno Yepes, Antonio and Neveol, Aurelie and Neves, Mariana and Verspoor, Karin and Bojar, Ondrej and Boyer, Arthur and Grozea, Cristian and Haddow, Barry and Kittner, Madeleine and Lichtblau, Yvonne and Pecina, Pavel and Roller, Roland and Rosa, Rudolf and Siu, Amy and Thomas, Philippe and Trescher, Saskia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4719},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {234--247},
 publisher = {Association for Computational Linguistics},
 title = {Findings of the WMT 2017 Biomedical Translation Shared Task},
 year = {2017}
}

@inproceedings{W17-4720,
 address = {Copenhagen, Denmark},
 author = {Sudarikov, Roman and Mare\v{c}ek, David and Kocmi, Tom and Varis, Dusan and Bojar, Ond\v{r}ej},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4720},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {248--256},
 publisher = {Association for Computational Linguistics},
 title = {CUNI submission in WMT17: Chimera goes neural},
 year = {2017}
}

@inproceedings{W17-4721,
 address = {Copenhagen, Denmark},
 author = {Burlot, Franck and Safari, Pooyan and Labeau, Matthieu and Allauzen, Alexandre and Yvon, Fran\c{c}ois},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4721},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {257--264},
 publisher = {Association for Computational Linguistics},
 title = {LIMSI$@$WMT'17},
 year = {2017}
}

@inproceedings{W17-4722,
 address = {Copenhagen, Denmark},
 author = {Deng, Yongchao and Kim, Jungi and Klein, Guillaume and KOBUS, Catherine and Segal, Natalia and Servan, Christophe and Wang, Bo and Zhang, Dakun and Crego, Josep and Senellart, Jean},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4722},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {265--270},
 publisher = {Association for Computational Linguistics},
 title = {SYSTRAN Purely Neural MT Engines for WMT2017},
 year = {2017}
}

@inproceedings{W17-4723,
 address = {Copenhagen, Denmark},
 author = {Di Gangi, Mattia Antonino and Bertoldi, Nicola and Federico, Marcello},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4723},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {271--275},
 publisher = {Association for Computational Linguistics},
 title = {FBK{\^a}s Participation to the English-to-German News Translation Task of WMT 2017},
 year = {2017}
}

@inproceedings{W17-4724,
 address = {Copenhagen, Denmark},
 author = {Ding, Shuoyang and Khayrallah, Huda and Koehn, Philipp and Post, Matt and Kumar, Gaurav and Duh, Kevin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4724},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {276--282},
 publisher = {Association for Computational Linguistics},
 title = {The JHU Machine Translation Systems for WMT 2017},
 year = {2017}
}

@inproceedings{W17-4725,
 address = {Copenhagen, Denmark},
 author = {Escolano, Carlos and Costa-juss\`{a}, Marta R. and Fonollosa, Jos\'{e} A. R.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4725},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {283--287},
 publisher = {Association for Computational Linguistics},
 title = {The TALP-UPC Neural Machine Translation System for German/Finnish-English Using the Inverse Direction Model in Rescoring},
 year = {2017}
}

@inproceedings{W17-4726,
 address = {Copenhagen, Denmark},
 author = {Garc\'{i}a-Mart\'{i}nez, Mercedes and Caglayan, Ozan and Aransa, Walid and Bardet, Adrien and Bougares, Fethi and Barrault, Lo\"{i}c},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4726},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {288--295},
 publisher = {Association for Computational Linguistics},
 title = {LIUM Machine Translation Systems for WMT17 News Translation Task},
 year = {2017}
}

@inproceedings{W17-4727,
 address = {Copenhagen, Denmark},
 author = {Gr\"{o}nroos, Stig-Arne and Virpioja, Sami and Kurimo, Mikko},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4727},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {296--302},
 publisher = {Association for Computational Linguistics},
 title = {Extending hybrid word-character neural machine translation with multi-task learning of morphological analysis},
 year = {2017}
}

@inproceedings{W17-4728,
 address = {Copenhagen, Denmark},
 author = {Gwinnup, Jeremy and Anderson, Timothy and Erdmann, Grant and Young, Katherine and Kazi, Michaeel and Salesky, Elizabeth and Thompson, Brian and Taylor, Jonathan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4728},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {303--309},
 publisher = {Association for Computational Linguistics},
 title = {The AFRL-MITLL WMT17 Systems: Old, New, Borrowed, BLEU},
 year = {2017}
}

@inproceedings{W17-4729,
 address = {Copenhagen, Denmark},
 author = {Holtz, Chester and Ke, Chuyang and Gildea, Daniel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4729},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {310--314},
 publisher = {Association for Computational Linguistics},
 title = {University of Rochester WMT 2017 NMT System Submission},
 year = {2017}
}

@inproceedings{W17-4730,
 address = {Copenhagen, Denmark},
 author = {Huck, Matthias and Braune, Fabienne and Fraser, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4730},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {315--322},
 publisher = {Association for Computational Linguistics},
 title = {LMU Munich's Neural Machine Translation Systems for News Articles and Health Information Texts},
 year = {2017}
}

@inproceedings{W17-4731,
 address = {Copenhagen, Denmark},
 author = {Hurskainen, Arvi and Tiedemann, J\"{o}rg},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4731},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {323--329},
 publisher = {Association for Computational Linguistics},
 title = {Rule-based Machine translation from English to Finnish},
 year = {2017}
}

@inproceedings{W17-4732,
 address = {Copenhagen, Denmark},
 author = {Lo, Chi-kiu and Chen, Boxing and Cherry, Colin and Foster, George and Larkin, Samuel and Stewart, Darlene and Kuhn, Roland},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4732},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {330--337},
 publisher = {Association for Computational Linguistics},
 title = {NRC Machine Translation System for WMT 2017},
 year = {2017}
}

@inproceedings{W17-4733,
 address = {Copenhagen, Denmark},
 author = {\"{O}stling, Robert and Scherrer, Yves and Tiedemann, J\"{o}rg and Tang, Gongbo and Nieminen, Tommi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4733},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {338--347},
 publisher = {Association for Computational Linguistics},
 title = {The Helsinki Neural Machine Translation System},
 year = {2017}
}

@inproceedings{W17-4734,
 address = {Copenhagen, Denmark},
 author = {Peter, Jan-Thorsten and Ney, Hermann and Bojar, Ond\v{r}ej and Pham, Ngoc-Quan and Niehues, Jan and Waibel, Alex and Burlot, Franck and Yvon, Fran\c{c}ois and Pinnis, M\={a}rcis and Sics, Valters and Bastings, Joost and Rios, Miguel and Aziz, Wilker and Williams, Philip and Blain, Fr\'{e}d\'{e}ric and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4734},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {348--357},
 publisher = {Association for Computational Linguistics},
 title = {The QT21 Combined Machine Translation System for English to Latvian},
 year = {2017}
}

@inproceedings{W17-4735,
 address = {Copenhagen, Denmark},
 author = {Peter, Jan-Thorsten and Guta, Andreas and Alkhouli, Tamer and Bahar, Parnia and Rosendahl, Jan and Rossenbach, Nick and Gra\c{c}a, Miguel and Ney, Hermann},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4735},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {358--365},
 publisher = {Association for Computational Linguistics},
 title = {The RWTH Aachen University English-German and German-English Machine Translation System for WMT 2017},
 year = {2017}
}

@inproceedings{W17-4736,
 address = {Copenhagen, Denmark},
 author = {Pham, Ngoc-Quan and Niehues, Jan and Ha, Thanh-Le and Cho, Eunah and Sperber, Matthias and Waibel, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4736},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {366--373},
 publisher = {Association for Computational Linguistics},
 title = {The Karlsruhe Institute of Technology Systems for the News Translation Task in WMT 2017},
 year = {2017}
}

@inproceedings{W17-4737,
 address = {Copenhagen, Denmark},
 author = {Pinnis, M\={a}rcis and Kri\v{s}lauks, Rihards and Miks, Toms and Deksne, Daiga and \v{S}ics, Valters},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4737},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {374--381},
 publisher = {Association for Computational Linguistics},
 title = {Tilde's Machine Translation Systems for WMT 2017},
 year = {2017}
}

@inproceedings{W17-4738,
 address = {Copenhagen, Denmark},
 author = {Rikters, Mat\={\i}ss and Amrhein, Chantal and Del, Maksym and Fishel, Mark},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4738},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {382--388},
 publisher = {Association for Computational Linguistics},
 title = {C-3MA: Tartu-Riga-Zurich Translation Systems for WMT17},
 year = {2017}
}

@inproceedings{W17-4739,
 address = {Copenhagen, Denmark},
 author = {Sennrich, Rico and Birch, Alexandra and Currey, Anna and Germann, Ulrich and Haddow, Barry and Heafield, Kenneth and Miceli Barone, Antonio Valerio and Williams, Philip},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4739},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {389--399},
 publisher = {Association for Computational Linguistics},
 title = {The University of Edinburgh's Neural MT Systems for WMT17},
 year = {2017}
}

@inproceedings{W17-4740,
 address = {Copenhagen, Denmark},
 author = {Tan, Zhixing and Wang, Boli and Hu, Jinming and Chen, Yidong and shi, xiaodong},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4740},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {400--404},
 publisher = {Association for Computational Linguistics},
 title = {XMU Neural Machine Translation Systems for WMT 17},
 year = {2017}
}

@inproceedings{W17-4741,
 address = {Copenhagen, Denmark},
 author = {Trieu, Long and Pham, Trung-Tin and Nguyen, Le-Minh},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4741},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {405--409},
 publisher = {Association for Computational Linguistics},
 title = {The JAIST Machine Translation Systems for WMT 17},
 year = {2017}
}

@inproceedings{W17-4742,
 address = {Copenhagen, Denmark},
 author = {Wang, Yuguang and Cheng, Shanbo and Jiang, Liyang and Yang, Jiajun and Chen, Wei and Li, Muze and Shi, Lin and Wang, Yanfeng and Yang, Hongtao},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4742},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {410--415},
 publisher = {Association for Computational Linguistics},
 title = {Sogou Neural Machine Translation Systems for WMT17},
 year = {2017}
}

@inproceedings{W17-4743,
 address = {Copenhagen, Denmark},
 author = {Wolk, Krzysztof and Marasek, Krzysztof},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4743},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {416--421},
 publisher = {Association for Computational Linguistics},
 title = {PJIIT{\^a}s systems for WMT 2017 Conference},
 year = {2017}
}

@inproceedings{W17-4744,
 address = {Copenhagen, Denmark},
 author = {Xu, Jia and Kuang, Yi Zong and Baijoo, Shondell and Lee, Jacob Hyun and Shahzad, Uman and Ahmed, Mir and Lancaster, Meredith and Carlan, Chris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4744},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {422--427},
 publisher = {Association for Computational Linguistics},
 title = {Hunter MT: A Course for Young Researchers in WMT17},
 year = {2017}
}

@inproceedings{W17-4745,
 address = {Copenhagen, Denmark},
 author = {Zhang, Jinchao and Porkaew, Peerachet and Hu, Jiawei and Zhao, Qiuye and Liu, Qun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4745},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {428--431},
 publisher = {Association for Computational Linguistics},
 title = {CASICT-DCU Neural Machine Translation Systems for WMT17},
 year = {2017}
}

@inproceedings{W17-4746,
 address = {Copenhagen, Denmark},
 author = {Caglayan, Ozan and Aransa, Walid and Bardet, Adrien and Garc\'{i}a-Mart\'{i}nez, Mercedes and Bougares, Fethi and Barrault, Lo\"{i}c and Masana, Marc and Herranz, Luis and van de Weijer, Joost},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4746},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {432--439},
 publisher = {Association for Computational Linguistics},
 title = {LIUM-CVC Submissions for WMT17 Multimodal Translation Task},
 year = {2017}
}

@inproceedings{W17-4747,
 address = {Copenhagen, Denmark},
 author = {Calixto, Iacer and Dutta Chowdhury, Koel and Liu, Qun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4747},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {440--444},
 publisher = {Association for Computational Linguistics},
 title = {DCU System Report on the WMT 2017 Multi-modal Machine Translation Task},
 year = {2017}
}

@inproceedings{W17-4748,
 address = {Copenhagen, Denmark},
 author = {Duselis, John and Hutt, Michael and Gwinnup, Jeremy and Davis, James and Sandvick, Joshua},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4748},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {445--449},
 publisher = {Association for Computational Linguistics},
 title = {The AFRL-OSU WMT17 Multimodal Translation System: An Image Processing Approach},
 year = {2017}
}

@inproceedings{W17-4749,
 address = {Copenhagen, Denmark},
 author = {Helcl, Jind\v{r}ich and Libovick\'{y}, Jind\v{r}ich},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4749},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {450--457},
 publisher = {Association for Computational Linguistics},
 title = {CUNI System for the WMT17 Multimodal Translation Task},
 year = {2017}
}

@inproceedings{W17-4750,
 address = {Copenhagen, Denmark},
 author = {Jaffe, Alan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4750},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {458--464},
 publisher = {Association for Computational Linguistics},
 title = {Generating Image Descriptions using Multilingual Data},
 year = {2017}
}

@inproceedings{W17-4751,
 address = {Copenhagen, Denmark},
 author = {Ma, Mingbo and Li, Dapeng and Zhao, Kai and Huang, Liang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4751},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {465--469},
 publisher = {Association for Computational Linguistics},
 title = {OSU Multimodal Machine Translation System Report},
 year = {2017}
}

@inproceedings{W17-4752,
 address = {Copenhagen, Denmark},
 author = {Madhyastha, Pranava Swaroop and Wang, Josiah and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4752},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {470--476},
 publisher = {Association for Computational Linguistics},
 title = {Sheffield MultiMT: Using Object Posterior Predictions for Multimodal Machine Translation},
 year = {2017}
}

@inproceedings{W17-4753,
 address = {Copenhagen, Denmark},
 author = {Zhang, Jingyi and Utiyama, Masao and Sumita, Eiichro and Neubig, Graham and Nakamura, Satoshi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4753},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {477--482},
 publisher = {Association for Computational Linguistics},
 title = {NICT-NAIST System for WMT17 Multimodal Translation Task},
 year = {2017}
}

@inproceedings{W17-4754,
 address = {Copenhagen, Denmark},
 author = {Duma, Mirela-Stefania and Menzel, Wolfgang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4754},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {483--488},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Threshold Detection for Data Selection in Machine Translation},
 year = {2017}
}

@inproceedings{W17-4755,
 address = {Copenhagen, Denmark},
 author = {Bojar, Ond\v{r}ej and Graham, Yvette and Kamran, Amir},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4755},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {489--513},
 publisher = {Association for Computational Linguistics},
 title = {Results of the WMT17 Metrics Shared Task},
 year = {2017}
}

@inproceedings{W17-4756,
 address = {Copenhagen, Denmark},
 author = {Sokolov, Artem and Kreutzer, Julia and Sunderland, Kellen and Danchenko, Pavel and Szymaniak, Witold and F\"{u}rstenau, Hagen and Riezler, Stefan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4756},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {514--524},
 publisher = {Association for Computational Linguistics},
 title = {A Shared Task on Bandit Learning for Machine Translation},
 year = {2017}
}

@inproceedings{W17-4757,
 address = {Copenhagen, Denmark},
 author = {Bojar, Ond\v{r}ej and Helcl, Jind\v{r}ich and Kocmi, Tom and Libovick\'{y}, Jind\v{r}ich and Musil, Tom\'{a}\v{s}},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4757},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {525--533},
 publisher = {Association for Computational Linguistics},
 title = {Results of the WMT17 Neural MT Training Task},
 year = {2017}
}

@inproceedings{W17-4758,
 address = {Copenhagen, Denmark},
 author = {Avramidis, Eleftherios},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4758},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {534--539},
 publisher = {Association for Computational Linguistics},
 title = {Sentence-level quality estimation by predicting HTER as a multi-component metric},
 year = {2017}
}

@inproceedings{W17-4759,
 address = {Copenhagen, Denmark},
 author = {Bi\c{c}ici, Ergun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4759},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {540--544},
 publisher = {Association for Computational Linguistics},
 title = {Predicting Translation Performance with Referential Translation Machines},
 year = {2017}
}

@inproceedings{W17-4760,
 address = {Copenhagen, Denmark},
 author = {Blain, Fr\'{e}d\'{e}ric and Scarton, Carolina and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4760},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {545--550},
 publisher = {Association for Computational Linguistics},
 title = {Bilexical Embeddings for Quality Estimation},
 year = {2017}
}

@inproceedings{W17-4761,
 address = {Copenhagen, Denmark},
 author = {Chen, Zhiming and Tan, Yiming and Zhang, Chenlin and Xiang, Qingyu and Zhang, Lilin and Li, Maoxi and WANG, Mingwen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4761},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {551--555},
 publisher = {Association for Computational Linguistics},
 title = {Improving Machine Translation Quality Estimation with Neural Network Features},
 year = {2017}
}

@inproceedings{W17-4762,
 address = {Copenhagen, Denmark},
 author = {Duma, Melania and Menzel, Wolfgang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4762},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {556--561},
 publisher = {Association for Computational Linguistics},
 title = {UHH Submission to the WMT17 Quality Estimation Shared Task},
 year = {2017}
}

@inproceedings{W17-4763,
 address = {Copenhagen, Denmark},
 author = {Kim, Hyun and Lee, Jong-Hyeok and Na, Seung-Hoon},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4763},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {562--568},
 publisher = {Association for Computational Linguistics},
 title = {Predictor-Estimator using Multilevel Task Learning with Stack Propagation for Neural Quality Estimation},
 year = {2017}
}

@inproceedings{W17-4764,
 address = {Copenhagen, Denmark},
 author = {Martins, Andr\'{e} F. T. and Kepler, Fabio and Monteiro, Jose},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4764},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {569--574},
 publisher = {Association for Computational Linguistics},
 title = {Unbabel's Participation in the WMT17 Translation Quality Estimation Shared Task},
 year = {2017}
}

@inproceedings{W17-4765,
 address = {Copenhagen, Denmark},
 author = {Paetzold, Gustavo and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4765},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {575--581},
 publisher = {Association for Computational Linguistics},
 title = {Feature-Enriched Character-Level Convolutions for Text Regression},
 year = {2017}
}

@inproceedings{W17-4766,
 address = {Copenhagen, Denmark},
 author = {Duma, Melania and Menzel, Wolfgang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4766},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {582--588},
 publisher = {Association for Computational Linguistics},
 title = {UHH Submission to the WMT17 Metrics Shared Task},
 year = {2017}
}

@inproceedings{W17-4767,
 address = {Copenhagen, Denmark},
 author = {Lo, Chi-kiu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4767},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {589--597},
 publisher = {Association for Computational Linguistics},
 title = {MEANT 2.0: Accurate semantic MT evaluation for any output language},
 year = {2017}
}

@inproceedings{W17-4768,
 address = {Copenhagen, Denmark},
 author = {Ma, Qingsong and Graham, Yvette and Wang, Shugen and Liu, Qun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4768},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {598--603},
 publisher = {Association for Computational Linguistics},
 title = {Blend: a Novel Combined MT Metric Based on Direct Assessment {\^a} CASICT-DCU submission to WMT17 Metrics Task},
 year = {2017}
}

@inproceedings{W17-4769,
 address = {Copenhagen, Denmark},
 author = {Mare\v{c}ek, David and Bojar, Ond\v{r}ej and H\"{u}bsch, Ond\v{r}ej and Rosa, Rudolf and Varis, Dusan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4769},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {604--611},
 publisher = {Association for Computational Linguistics},
 title = {CUNI Experiments for WMT17 Metrics Task},
 year = {2017}
}

@inproceedings{W17-4770,
 address = {Copenhagen, Denmark},
 author = {Popovi\'{c}, Maja},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4770},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {612--618},
 publisher = {Association for Computational Linguistics},
 title = {chrF++: words helping character n-grams},
 year = {2017}
}

@inproceedings{W17-4771,
 address = {Copenhagen, Denmark},
 author = {T\"{a}ttar, Andre and Fishel, Mark},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4771},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {619--622},
 publisher = {Association for Computational Linguistics},
 title = {bleu2vec: the Painfully Familiar Metric on Continuous Vector Space Steroids},
 year = {2017}
}

@inproceedings{W17-4772,
 address = {Copenhagen, Denmark},
 author = {Berard, Alexandre and Besacier, Laurent and Pietquin, Olivier},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4772},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {623--629},
 publisher = {Association for Computational Linguistics},
 title = {LIG-CRIStAL Submission for the WMT 2017 Automatic Post-Editing Task},
 year = {2017}
}

@inproceedings{W17-4773,
 address = {Copenhagen, Denmark},
 author = {Chatterjee, Rajen and Farajian, M. Amin and Negri, Matteo and Turchi, Marco and Srivastava, Ankit and Pal, Santanu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4773},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {630--638},
 publisher = {Association for Computational Linguistics},
 title = {Multi-source Neural Automatic Post-Editing: FBK{\^a}s participation in the WMT 2017 APE shared task},
 year = {2017}
}

@inproceedings{W17-4774,
 address = {Copenhagen, Denmark},
 author = {Junczys-Dowmunt, Marcin and Junczys-Dowmunt, Marcin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4774},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {639--646},
 publisher = {Association for Computational Linguistics},
 title = {The AMU-UEdin Submission to the WMT 2017 Shared Task on Automatic Post-Editing},
 year = {2017}
}

@inproceedings{W17-4775,
 address = {Copenhagen, Denmark},
 author = {Hokamp, Chris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4775},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {647--654},
 publisher = {Association for Computational Linguistics},
 title = {Ensembling Factored Neural Machine Translation Models for Automatic Post-Editing and Quality Estimation},
 year = {2017}
}

@inproceedings{W17-4776,
 address = {Copenhagen, Denmark},
 author = {Tan, Yiming and Chen, Zhiming and Huang, Liu and Zhang, Lilin and Li, Maoxi and Wang, Mingwen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4776},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {655--660},
 publisher = {Association for Computational Linguistics},
 title = {Neural Post-Editing Based on Quality Estimation},
 year = {2017}
}

@inproceedings{W17-4777,
 address = {Copenhagen, Denmark},
 author = {Varis, Dusan and Bojar, Ond\v{r}ej},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4777},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {661--666},
 publisher = {Association for Computational Linguistics},
 title = {CUNI System for WMT17 Automatic Post-Editing Task},
 year = {2017}
}

@inproceedings{W17-4778,
 address = {Copenhagen, Denmark},
 author = {Sharaf, Amr and Feng, Shi and Nguyen, Khanh and Brantley, Kiante and Daum\'{e} III, Hal},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4778},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {667--673},
 publisher = {Association for Computational Linguistics},
 title = {The UMD Neural Machine Translation Systems at WMT17 Bandit Learning Task},
 year = {2017}
}

@inproceedings{W17-4779,
 address = {Copenhagen, Denmark},
 author = {Wisniewski, Guillaume},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4779},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {674--679},
 publisher = {Association for Computational Linguistics},
 title = {LIMSI Submission for WMT'17 Shared Task on Bandit Learning},
 year = {2017}
}

@inproceedings{W17-4780,
 address = {Copenhagen, Denmark},
 author = {Abdou, Mostafa and Gloncak, Vladan and Bojar, Ond\v{r}ej},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4780},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {680--686},
 publisher = {Association for Computational Linguistics},
 title = {Variable Mini-Batch Sizing and Pre-Trained Embeddings},
 year = {2017}
}

@inproceedings{W17-4781,
 address = {Copenhagen, Denmark},
 author = {Gwinnup, Jeremy and Erdmann, Grant and Young, Katherine},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4781},
 booktitle = {Proceedings of the Second Conference on Machine Translation},
 month = {September},
 pages = {687--691},
 publisher = {Association for Computational Linguistics},
 title = {The AFRL WMT17 Neural Machine Translation Training Task Submission},
 year = {2017}
}

@inproceedings{W17-4801,
 abstract = {We describe the design, the setup, and the evaluation results of the DiscoMT
2017 shared task on cross-lingual pronoun prediction. The task asked
participants to predict a target-language pronoun given a source-language
pronoun in the context of a sentence. We further provided a lemmatized
target-language human-authored translation of the source sentence, and
automatic word alignments between the source sentence words and the
target-language lemmata. The aim of the task was to predict, for each
target-language pronoun placeholder, the word that should replace it from a
small, closed set of classes, using any type of information that can be
extracted from the entire document. We offered four subtasks, each for a
different language pair and translation direction: English-to-French, English-to-German, German-to-English, and Spanish-to-English. Five teams
participated in the shared task, making submissions for all language pairs. The
evaluation results show that most participating teams outperformed two strong
n-gram-based language model-based baseline systems by a sizable margin.},
 address = {Copenhagen, Denmark},
 author = {Lo\'{a}iciga, Sharid and Stymne, Sara and Nakov, Preslav and Hardmeier, Christian and Tiedemann, J\"{o}rg and Cettolo, Mauro and Versley, Yannick},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4801},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {1--16},
 publisher = {Association for Computational Linguistics},
 title = {Findings of the 2017 DiscoMT Shared Task on Cross-lingual Pronoun Prediction},
 year = {2017}
}

@inproceedings{W17-4802,
 abstract = {In this paper, we define and assess a reference-based metric to evaluate the
accuracy of pronoun translation (APT). The metric automatically aligns a
candidate and a reference translation using GIZA++ augmented with specific
heuristics, and then counts the number of identical or different pronouns, with
provision for legitimate variations and omitted pronouns.  All counts are then
combined into one score.  The metric is applied to the results of seven systems
(including the baseline) that participated in the DiscoMT 2015 shared task on
pronoun translation from English to French. The APT metric reaches around
0.993-0.999 Pearson correlation with human judges (depending on the parameters
of APT), while other automatic metrics such as BLEU, METEOR, or those specific
to pronouns used at DiscoMT 2015 reach only 0.972-0.986 Pearson correlation.},
 address = {Copenhagen, Denmark},
 author = {Miculicich Werlen, Lesly and Popescu-Belis, Andrei},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4802},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {17--25},
 publisher = {Association for Computational Linguistics},
 title = {Validation of an Automatic Metric for the Accuracy of Pronoun Translation (APT)},
 year = {2017}
}

@inproceedings{W17-4803,
 abstract = {Although coherence is an important aspect of any text generation system, it has
received little attention in the context of machine translation (MT) so far.
We hypothesize that the quality of document-level translation can be improved
if MT models take into account the semantic relations among sentences during
translation. We integrate the graph-based coherence model proposed by Mesgar
and Strube, (2016) with Docent (Hardmeier et al., 2012, Hardmeier, 2014) a
document-level machine translation system. The application of this graph-based
coherence modeling approach is novel in the context of machine translation. We
evaluate the coherence model and its effects on the quality of the machine
translation. The result of our experiments shows that our coherence model
slightly improves the quality of translation in terms of the average Meteor
score.},
 address = {Copenhagen, Denmark},
 author = {Born, Leo and Mesgar, Mohsen and Strube, Michael},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4803},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {26--35},
 publisher = {Association for Computational Linguistics},
 title = {Using a Graph-based Coherence Model in Document-Level Machine Translation},
 year = {2017}
}

@inproceedings{W17-4804,
 abstract = {We present work on handling XML markup in Statistical Machine Translation
(SMT). The methods we propose can be used to effectively preserve markup (for
instance inline formatting or structure) and to place markup correctly in a
machine-translated segment. We evaluate our approaches with parallel data that
naturally contains markup or where markup was inserted to create synthetic
examples. In our experiments, hybrid reinsertion has proven the most accurate
method to handle markup, while alignment masking and alignment reinsertion
should be regarded as viable alternatives. We provide implementations of all
the methods described and they are freely available as an open-source
framework.},
 address = {Copenhagen, Denmark},
 author = {M\"{u}ller, Mathias},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4804},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {36--46},
 publisher = {Association for Computational Linguistics},
 title = {Treatment of Markup in Statistical Machine Translation},
 year = {2017}
}

@inproceedings{W17-4805,
 abstract = {We describe the Uppsala system for the 2017 DiscoMT shared task on
cross-lingual pronoun prediction. The system is based on a lower layer of
BiLSTMs reading the source and target sentences respectively. Classification is
based on the BiLSTM representation of the source and target positions for the
pronouns. In addition we enrich our system with dependency representations from
an external parser and character representations of the source sentence. We
show that these additions perform well for German and Spanish as source
languages. Our system is competitive and is in first or second place for all
language pairs.},
 address = {Copenhagen, Denmark},
 author = {Stymne, Sara and Lo\'{a}iciga, Sharid and Cap, Fabienne},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4805},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {47--53},
 publisher = {Association for Computational Linguistics},
 title = {A BiLSTM-based System for Cross-lingual Pronoun Prediction},
 year = {2017}
}

@inproceedings{W17-4806,
 abstract = {In this paper we present our systems for the DiscoMT 2017 cross-lingual pronoun
prediction shared task. For all four language pairs, we trained a standard
attention-based neural machine translation system as well as three variants
that incorporate information from the preceding source sentence. We show that
our systems, which are not specifically designed for pronoun prediction and may
be used to generate complete sentence translations, generally achieve
competitive results on this task.},
 address = {Copenhagen, Denmark},
 author = {Jean, S\'{e}bastien and Lauly, Stanislas and Firat, Orhan and Cho, Kyunghyun},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4806},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {54--57},
 publisher = {Association for Computational Linguistics},
 title = {Neural Machine Translation for Cross-Lingual Pronoun Prediction},
 year = {2017}
}

@inproceedings{W17-4807,
 abstract = {This paper describes the UU-Hardmeier system submitted to the DiscoMT
2017 shared task on cross-lingual pronoun prediction. The system is an ensemble
of convolutional neural networks combined with a source-aware n-gram language
model.},
 address = {Copenhagen, Denmark},
 author = {Hardmeier, Christian},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4807},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {58--62},
 publisher = {Association for Computational Linguistics},
 title = {Predicting Pronouns with a Convolutional Network and an N-gram Model},
 year = {2017}
}

@inproceedings{W17-4808,
 abstract = {In this paper we present our system in
the DiscoMT 2017 Shared Task on Crosslingual
Pronoun Prediction. Our entry
builds on our last year{\^a}s success, our system
based on deep recurrent neural networks
outperformed all the other systems
with a clear margin. This year we investigate
whether different pre-trained word
embeddings can be used to improve the
neural systems, and whether the recently
published Gated Convolutions outperform
the Gated Recurrent Units used last year.},
 address = {Copenhagen, Denmark},
 author = {Luotolahti, Juhani and Kanerva, Jenna and Ginter, Filip},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4808},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {63--66},
 publisher = {Association for Computational Linguistics},
 title = {Cross-Lingual Pronoun Prediction with Deep Recurrent Neural Networks v2.0},
 year = {2017}
}

@inproceedings{W17-4809,
 abstract = {Although parallel coreference corpora can
to a high degree support the development
of SMT systems, there are no large-scale
parallel datasets available due to the complexity
of the annotation task and the variability
in annotation schemes. In this
study, we exploit an annotation projection
method to combine the output of two
coreference resolution systems for two
different source languages (English, German)
in order to create an annotated corpus
for a third language (Russian). We
show that our technique is superior to projecting
annotations from a single source
language, and we provide an in-depth
analysis of the projected annotations in order
to assess the perspectives of our approach.},
 address = {Copenhagen, Denmark},
 author = {Grishina, Yulia},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4809},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {67--72},
 publisher = {Association for Computational Linguistics},
 title = {Combining the output of two coreference resolution systems for two source languages to improve annotation projection},
 year = {2017}
}

@inproceedings{W17-4810,
 abstract = {In this paper, we analyse alignment discrepancies  for discourse structures in
English-German parallel data -- sentence pairs, in which discourse structures
in target or source texts have no alignment in the corresponding parallel
sentences. The discourse-related structures are designed in form of linguistic
patterns based on the information delivered by automatic part-of-speech and
dependency annotation. In addition to alignment errors (existing structures
left unaligned), these alignment discrepancies can be caused by language
contrasts or through the phenomena of explicitation and implicitation in the
translation process. We propose a new approach including new type of resources
for corpus-based language contrast analysis and apply it to study and classify
the contrasts found in our English-German parallel corpus. As unaligned
discourse structures may also result in the loss of discourse information in
the MT training data, we hope to deliver information in support of
discourse-aware machine translation (MT).},
 address = {Copenhagen, Denmark},
 author = {Lapshinova-Koltunski, Ekaterina and Hardmeier, Christian},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4810},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {73--81},
 publisher = {Association for Computational Linguistics},
 title = {Discovery of Discourse-Related Language Contrasts through Alignment Discrepancies in English-German Translation},
 year = {2017}
}

@inproceedings{W17-4811,
 abstract = {We investigate the use of extended context in attention-based neural machine
translation. We base our experiments on translated movie subtitles and discuss
the effect of increasing the segments beyond single translation units. We study
the use of extended source language context as well as bilingual context
extensions. The models learn to distinguish between information from different
segments and are surprisingly robust with respect to translation quality. In
this pilot study, we observe interesting cross-sentential attention patterns
that improve textual coherence in translation at least in some selected cases.},
 address = {Copenhagen, Denmark},
 author = {Tiedemann, J\"{o}rg and Scherrer, Yves},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4811},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {82--92},
 publisher = {Association for Computational Linguistics},
 title = {Neural Machine Translation with Extended Context},
 year = {2017}
}

@inproceedings{W17-4812,
 abstract = {Implicit discourse connectives and relations are distributed more widely in
Chinese texts, when translating into English, such connectives are usually
translated explicitly. Towards Chinese-English MT, in this paper we describe
cross-lingual annotation and alignment of dis-course connectives in a parallel
corpus, describing related surveys and findings. We then conduct some
evaluation experiments to testify the translation of implicit connectives and
whether representing implicit connectives explicitly in source language can
improve the final translation performance significantly. Preliminary results
show it has little improvement by just inserting explicit connectives for
implicit relations.},
 address = {Copenhagen, Denmark},
 author = {Li, Hongzheng and Langlais, Philippe and Jin, Yaohong},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4812},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {93--98},
 publisher = {Association for Computational Linguistics},
 title = {Translating Implicit Discourse Connectives Based on Cross-lingual Annotation and Alignment},
 year = {2017}
}

@inproceedings{W17-4813,
 abstract = {Currently under review for EMNLP 2017
The phrase-based Statistical Machine Translation (SMT) approach deals with
sentences in isolation, making it difficult to consider discourse context in
translation. This poses a challenge for ambiguous words that need discourse
knowledge to be correctly translated. We propose a method that benefits from
the semantic similarity in lexical chains to improve SMT output by integrating
it in a document-level decoder. We focus on word embeddings to deal with the
lexical chains, contrary to the traditional approach that uses lexical
resources. Experimental results on German-to-English show that our method
produces correct translations in up to 88% of the changes, improving the
translation in 36%-48% of them over the baseline.},
 address = {Copenhagen, Denmark},
 author = {Mascarell, Laura},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4813},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {99--109},
 publisher = {Association for Computational Linguistics},
 title = {Lexical Chains meet Word Embeddings in Document-level Statistical Machine Translation},
 year = {2017}
}

@inproceedings{W17-4814,
 abstract = {As the quality of Machine Translation (MT) improves, research on improving
discourse in automatic translations becomes more viable. This has resulted in
an increase in the amount of work on discourse in MT. However many of the
existing models and metrics have yet to integrate these insights.
Part of this is due to the evaluation methodology, based as it is largely on
matching to a single reference. At a time when MT is increasingly being
used in a pipeline for other tasks, the semantic element of the translation
process needs to be properly integrated into the task. Moreover, in order to
take MT to another level, it will need to judge output not based on a single
reference translation, but based on notions of fluency and of adequacy --
ideally with reference to the source text.},
 address = {Copenhagen, Denmark},
 author = {Sim Smith, Karin},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-4814},
 booktitle = {Proceedings of the Third Workshop on Discourse in Machine Translation},
 month = {September},
 pages = {110--121},
 publisher = {Association for Computational Linguistics},
 title = {On Integrating Discourse in Machine Translation},
 year = {2017}
}

@inproceedings{W17-4901,
 abstract = {As natural language processing research is growing and largely driven by the
availability of data, we expanded research from news and small-scale dialog
corpora to web and social media. User-generated data and crowdsourcing opened
the door for investigating human language of various styles with more
statistical power and real-world applications. In this position/survey paper, I
will review and discuss seven language styles that I believe to be important
and interesting to study: influential work in the past, challenges at the
present, and potential impact for the future.},
 address = {Copenhagen, Denmark},
 author = {Xu, Wei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4901},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {1--9},
 publisher = {Association for Computational Linguistics},
 title = {From Shakespeare to Twitter: What are Language Styles all about?},
 year = {2017}
}

@inproceedings{W17-4902,
 abstract = {Variations in writing styles are commonly used to adapt the content to a
specific context, audience, or purpose. However, applying stylistic variations
is still by and large a manual process, and there have been little efforts
towards automating it. In this paper we explore automated methods to transform
text from modern English to Shakespearean English using an end to end trainable
neural model with pointers to enable copy action. To tackle limited amount of
parallel data, we pre-train embeddings of words by leveraging external
dictionaries mapping Shakespearean words to modern English words as well as
additional text. Our methods are able to get a BLEU score of 31+, an
improvement of {\^a} 6 points above the strongest baseline. We publicly release
our code to foster further research in this area.},
 address = {Copenhagen, Denmark},
 author = {Jhamtani, Harsh and Gangal, Varun and Hovy, Eduard and Nyberg, Eric},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4902},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {10--19},
 publisher = {Association for Computational Linguistics},
 title = {Shakespearizing Modern Language Using Copy-Enriched Sequence to Sequence Models},
 year = {2017}
}

@inproceedings{W17-4903,
 abstract = {Detecting and analyzing stylistic variation in language is relevant to diverse
Natural Language Processing applications. In this work, we investigate whether
salient dimensions of style variations are embedded in standard distributional
vector spaces of word meaning. We hypothesizes that distances between
embeddings of lexical paraphrases can help isolate style from meaning
variations and help identify latent style dimensions. We conduct a qualitative
analysis of latent style dimensions, and show the effectiveness of identified
style subspaces on a lexical formality prediction task.},
 address = {Copenhagen, Denmark},
 author = {Niu, Xing and Carpuat, Marine},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4903},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {20--27},
 publisher = {Association for Computational Linguistics},
 title = {Discovering Stylistic Variations in Distributional Vector Space Models via Lexical Paraphrases},
 year = {2017}
}

@inproceedings{W17-4904,
 abstract = {Many of the creative and figurative elements that make language
exciting are lost in translation in current natural language
generation engines. In this paper, we explore a method to harvest
templates from positive and negative reviews in the restaurant domain, with the goal of vastly expanding the types of stylistic variation
available to the natural language generator. We learn hyperbolic
adjective patterns that are representative of the strongly-valenced
expressive language commonly used in either positive or negative
reviews.  We then identify and delexicalize entities, and use
heuristics to extract generation templates from review sentences. We
evaluate the learned templates against more traditional review
templates, using subjective measures of convincingness, interestingness, and naturalness. Our results show that the
learned templates score highly on these measures.  Finally, we analyze
the linguistic categories that characterize the learned positive and
negative templates. We plan to use the learned templates to improve the
conversational style of dialogue systems in the
restaurant domain.},
 address = {Copenhagen, Denmark},
 author = {Oraby, Shereen and Homayon, Sheideh and Walker, Marilyn},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4904},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {28--36},
 publisher = {Association for Computational Linguistics},
 title = {Harvesting Creative Templates for Generating Stylistically Varied Restaurant Reviews},
 year = {2017}
}

@inproceedings{W17-4905,
 abstract = {The problem of detecting scientific fraud using machine learning was recently
introduced, with initial, positive results from a model taking into account
various general indicators.
The results seem to suggest that writing style is predictive of scientific
fraud.
We revisit these initial experiments, and show that the leave-one-out testing
procedure they used likely leads to a slight over-estimate of the
predictability, but also that simple models can outperform their proposed model by some margin.
We go on to explore more abstract linguistic features, such as linguistic
complexity and discourse structure, only to obtain negative results.
Upon analyzing our models, we do see some interesting patterns, though:
Scientific fraud, for examples, contains less comparison, as well as different
types of hedging and ways of presenting logical reasoning.},
 address = {Copenhagen, Denmark},
 author = {Braud, Chlo\'{e} and S{\o}gaard, Anders},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4905},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {37--42},
 publisher = {Association for Computational Linguistics},
 title = {Is writing style predictive of scientific fraud?},
 year = {2017}
}

@inproceedings{W17-4906,
 abstract = {Metaphor is one of the most studied and widespread figures of speech and an
essen- tial element of individual style. In this pa- per we look at metaphor
identification in Adjective-Noun pairs. We show that us- ing a single neural
network combined with pre-trained vector embeddings can outper- form the state
of the art in terms of accu- racy. In specific, the approach presented in this
paper is based on two ideas: a) trans- fer learning via using pre-trained
vectors representing adjective noun pairs, and b) a neural network as a model
of composition that predicts a metaphoricity score as out- put. We present
several different architec- tures for our system and evaluate their per-
formances. Variations on dataset size and on the kinds of embeddings are also
inves- tigated. We show considerable improve- ment over the previous approaches
both in terms of accuracy and w.r.t the size of an- notated training data.},
 address = {Copenhagen, Denmark},
 author = {Bizzoni, Yuri and Chatzikyriakidis, Stergios and Ghanimifard, Mehdi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4906},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {43--52},
 publisher = {Association for Computational Linguistics},
 title = {"Deep" Learning : Detecting Metaphoricity in Adjective-Noun Pairs},
 year = {2017}
}

@inproceedings{W17-4907,
 abstract = {We use a convolutional neural network to perform authorship identification on a
very homogeneous dataset of scientific publications. In order to investigate
the effect of domain biases, we obscure words below a certain frequency
threshold, retaining only their POS-tags. This procedure improves test
performance due to better generalization on unseen data. Using our method, we
are able to predict the authors of scientific publications in the same
discipline at levels well above chance.},
 address = {Copenhagen, Denmark},
 author = {Hitschler, Julian and van den Berg, Esther and Rehbein, Ines},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4907},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {53--58},
 publisher = {Association for Computational Linguistics},
 title = {Authorship Attribution with Convolutional Neural Networks and POS-Eliding},
 year = {2017}
}

@inproceedings{W17-4908,
 abstract = {Sociolinguistic research suggests that speakers modulate their language style
in response to their audience. Similar effects have recently been claimed to
occur in the informal written context of Twitter, with users choosing less
region-specific and non-standard vocabulary when addressing larger audiences.
However, these studies have not carefully controlled for the possible confound
of topic: that is, tweets addressed to a broad audience might also tend towards
topics that engender a more formal style. In addition, it is not clear to what
extent previous results generalize to different samples of users. Using
mixed-effects models, we show that audience and topic have independent effects
on the rate of distinctively Scottish usage in two demographically distinct
Twitter user samples. However, not all effects are consistent between the two
groups, underscoring the importance of replicating studies on distinct user
samples before drawing strong conclusions from social media data.},
 address = {Copenhagen, Denmark},
 author = {Shoemark, Philippa and Kirby, James and Goldwater, Sharon},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4908},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {59--68},
 publisher = {Association for Computational Linguistics},
 title = {Topic and audience effects on distinctively Scottish vocabulary usage in Twitter data},
 year = {2017}
}

@inproceedings{W17-4909,
 abstract = {The differences in the frequencies of some parts of speech (POS), particularly
function words, and lexical diversity in male and female speech have been
pointed out in a number of papers. The classifiers using exclusively
context-independent parameters have proved to be highly effective. However, there are still issues that have to be addressed as a lot of studies are
performed for English and the genre and topic of texts is sometimes neglected.
The aim of this paper is to investigate the association between
context-independent parameters of Russian written texts and the gender of their
authors and to design predictive re-gression models. A number of correlations
were found. The obtained data is in good agreement with the results obtained
for other languages. The model based on 5 parameters with the highest
correlation coefficients was designed.},
 address = {Copenhagen, Denmark},
 author = {Litvinova, Tatiana and Seredin, Pavel and Litvinova, Olga and Zagorovskaya, Olga},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4909},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {69--73},
 publisher = {Association for Computational Linguistics},
 title = {Differences in type-token ratio and part-of-speech frequencies in male and female Russian written texts},
 year = {2017}
}

@inproceedings{W17-4910,
 abstract = {While there is wide acknowledgement in NLP of the utility of document
characterization by genre, it is quite difficult to determine a definitive set
of features or even a comprehensive list of
genres. This paper addresses both issues. First, with prototype semantics, we
develop a hierarchical taxonomy of discourse functions. We implement the
taxonomy by developing a new text genre corpus of contemporary German to
perform a text based comparative register analysis.
Second, we extract a host of style features, both deep and shallow, aiming
beyond linguistically motivated features at situational correlates in texts.
The feature sets are used for supervised text genre classification, on which
our models achieve high accuracy.
The combination of the corpus typology and feature sets allows us to
characterize types of communicative purpose in a comparative setup, by
qualitative interpretation of style feature loadings of a regularized
discriminant analysis.
Finally, to determine the dependence of genre on topics (which are arguably the
distinguishing factor of sub-genre), we compare and combine our style models
with Latent Dirichlet Allocation features across different corpus settings with
unstable topics.},
 address = {Copenhagen, Denmark},
 author = {Haider, Thomas and Palmer, Alexis},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4910},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {74--84},
 publisher = {Association for Computational Linguistics},
 title = {Modeling Communicative Purpose with Functional Style: Corpus and Features for German Genre and Register Analysis},
 year = {2017}
}

@inproceedings{W17-4911,
 abstract = {Conversation is a critical component of storytelling, where key information is
often revealed by
what/how a character says it. We focus on the issue of character voice and
build stylistic models with linguistic features related to natural language
generation decisions. Using a dialogue corpus of the television series, The Big
Bang Theory, we apply content analysis to extract relevant linguistic features
to build character-based stylistic models, and we test the model-fit through an
user perceptual experiment with Amazon's Mechanical Turk. The results are
encouraging in that human subjects tend to perceive the generated utterances as
being more similar to the character they are modeled on, than to another random
character.},
 address = {Copenhagen, Denmark},
 author = {Lin, Grace and Walker, Marilyn},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4911},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {85--93},
 publisher = {Association for Computational Linguistics},
 title = {Stylistic Variation in Television Dialogue for Natural Language Generation},
 year = {2017}
}

@inproceedings{W17-4912,
 abstract = {Most work on neural natural language generation (NNLG) focus on controlling the
content of the generated text. We experiment with controling several stylistic
aspects of the generated text, in addition to its content. The method is based
on conditioned RNN language model, where the desired content as well as the
stylistic parameters serve as conditioning contexts.
We demonstrate the approach on the movie reviews domain and show that it is
successful in generating coherent sentences corresponding to the required
linguistic style and content.},
 address = {Copenhagen, Denmark},
 author = {Ficler, Jessica and Goldberg, Yoav},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4912},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {94--104},
 publisher = {Association for Computational Linguistics},
 title = {Controlling Linguistic Style Aspects in Neural Language Generation},
 year = {2017}
}

@inproceedings{W17-4913,
 abstract = {The concept of style is much debated in theoretical as well as empirical terms.
From an empirical perspective, the key question is how to operationalize style
and thus make it accessible for annotation and quantification. In authorship
attribution, many different approaches have successfully resolved this issue at
the cost of linguistic interpretability: The resulting algorithms may be able
to distinguish one language variety from the other, but do not give us much
information on their distinctive linguistic properties. We approach the issue
of interpreting stylistic features by extracting linear and syntactic n-grams
that are distinctive for a language variety. We present a study that
exemplifies this process by a comparison of the German academic languages of
linguistics and literary studies. Overall, our findings show that distinctive
n-grams can be related to linguistic categories. The results suggest that the
style of German literary studies is characterized by nominal structures and the
style of linguistics by verbal ones.},
 address = {Copenhagen, Denmark},
 author = {Andresen, Melanie and Zinsmeister, Heike},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4913},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {105--115},
 publisher = {Association for Computational Linguistics},
 title = {Approximating Style by N-gram-based Annotation},
 year = {2017}
}

@inproceedings{W17-4914,
 abstract = {Recent applications of neural language models have led to an increased interest
in the automatic generation of natural language. However impressive, the
evaluation of neurally generated text has so far remained rather informal and
anecdotal. Here, we present an attempt at the systematic assessment of one
aspect of the quality of neurally generated text. We focus on a specific aspect
of neural language generation: its ability to reproduce authorial writing
styles. Using established models for authorship attribution, we empirically
assess the stylistic qualities of neurally generated text. In comparison to
conventional language models, neural models generate fuzzier text, that is
relatively harder to attribute correctly. Nevertheless, our results also
suggest that neurally generated text offers more valuable perspectives for the
augmentation of training data.},
 address = {Copenhagen, Denmark},
 author = {Manjavacas, Enrique and De Gussem, Jeroen and Daelemans, Walter and Kestemont, Mike},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-4914},
 booktitle = {Proceedings of the Workshop on Stylistic Variation},
 month = {September},
 pages = {116--125},
 publisher = {Association for Computational Linguistics},
 title = {Assessing the Stylistic Properties of Neurally Generated Text in Authorship Attribution},
 year = {2017}
}

@inproceedings{W17-5001,
 abstract = {Question difficulty estimates guide test creation, but are too costly for
small-scale testing. We empirically verify that Bloom's Taxonomy, a standard
tool for difficulty estimation during question creation, reliably predicts
question difficulty observed after testing in a short-answer corpus. We also
find that difficulty is mirrored in the amount of variation in student answers, which can be computed before grading.
We show that question difficulty and its approximations are useful for
\textit{automated grading}, allowing us to identify the optimal feature set for
grading each question even in an unseen-question setting.},
 address = {Copenhagen, Denmark},
 author = {Pado, Ulrike},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5001},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Question Difficulty -- How to Estimate Without Norming, How to Use for Automated Grading},
 year = {2017}
}

@inproceedings{W17-5002,
 abstract = {For medical students, virtual patient dialogue systems can provide useful
training opportunities without the cost of employing actors to portray
standardized patients.              This work utilizes word- and
character-based convolutional neural networks (CNNs) for question
identification in a virtual
patient dialogue system, outperforming a strong word- and character-based
logistic regression baseline.  While the CNNs perform well given sufficient
training data, the best system performance is ultimately achieved by combining
CNNs with a hand-crafted pattern matching system that is robust to label
sparsity, providing a 10% boost in system accuracy and an error reduction of
47% as compared to the pattern-matching system alone.},
 address = {Copenhagen, Denmark},
 author = {Jin, Lifeng and White, Michael and Jaffe, Evan and Zimmerman, Laura and Danforth, Douglas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5002},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {11--21},
 publisher = {Association for Computational Linguistics},
 title = {Combining CNNs and Pattern Matching for Question Interpretation in a Virtual Patient Dialogue System},
 year = {2017}
}

@inproceedings{W17-5003,
 abstract = {This paper is a preliminary report on using text complexity measurement in the
service of a new educational application. We describe a reading intervention
where a child takes turns reading a book aloud with a virtual reading partner.
Our ultimate goal is to provide meaningful feedback to the parent or the
teacher by continuously tracking the child's improvement in reading fluency. We
show that this would not be a simple endeavor, due to an intricate relationship
between text complexity from the point of view of comprehension and reading
rate.},
 address = {Copenhagen, Denmark},
 author = {Beigman Klebanov, Beata and Loukina, Anastassia and Sabatini, John and O'Reilly, Tenaha},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5003},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {22--32},
 publisher = {Association for Computational Linguistics},
 title = {Continuous fluency tracking and the challenges of varying text complexity},
 year = {2017}
}

@inproceedings{W17-5004,
 abstract = {We investigate the utility of different auxiliary objectives and training
strategies within a neural sequence labeling approach to error detection in
learner writing.
Auxiliary costs provide the model with additional linguistic information, allowing it to learn general-purpose compositional features that can then be
exploited for other objectives.
Our experiments show that a joint learning approach trained with parallel
labels on in-domain data improves performance over the previous best error
detection system.
While the resulting model has the same number of parameters, the additional
objectives allow it to be optimised more efficiently and achieve better
performance.},
 address = {Copenhagen, Denmark},
 author = {Rei, Marek and Yannakoudakis, Helen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5004},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {33--43},
 publisher = {Association for Computational Linguistics},
 title = {Auxiliary Objectives for Neural Error Detection Models},
 year = {2017}
}

@inproceedings{W17-5005,
 abstract = {The use of linked data within language-learning applications is an open
research question. A research prototype is presented that applies linked-data
principles to store linguistic annotation generated from language-learning
content using a variety of NLP tools. The result is a database that links
learning content, linguistic annotation and open-source resources, on top of
which a diverse range of tools for language-learning applications can be built.},
 address = {Copenhagen, Denmark},
 author = {Loughnane, Robyn and McCurdy, Kate and Kolb, Peter and Selent, Stefan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5005},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {44--51},
 publisher = {Association for Computational Linguistics},
 title = {Linked Data for Language-Learning Applications},
 year = {2017}
}

@inproceedings{W17-5006,
 abstract = {High quality classroom discussion is important to student development, enhancing
abilities to express claims, reason about other students{\^a} claims, and retain
information for longer periods of time. Previous small-scale studies have shown
that one indicator of classroom discussion quality is specificity. In this
paper we tackle the problem of predicting specificity for classroom
discussions. We propose several methods and feature sets capable of
outperforming the state of the art in specificity prediction. Additionally, we
provide a set of meaningful, interpretable features that can be used to analyze
classroom discussions at a pedagogical level.},
 address = {Copenhagen, Denmark},
 author = {Lugini, Luca and Litman, Diane},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5006},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {52--61},
 publisher = {Association for Computational Linguistics},
 title = {Predicting Specificity in Classroom Discussion},
 year = {2017}
}

@inproceedings{W17-5007,
 abstract = {Native Language Identification (NLI) is the task of automatically identifying
the native language (L1) of an individual based on their language production in
a learned language. It is typically framed as a classification task where the
set of L1s is known a priori. Two previous shared tasks on NLI have been
organized where the aim was to identify the L1 of learners of English based on
essays (2013) and spoken responses (2016) they provided during a standardized
assessment of academic English proficiency. The 2017 shared task combines the
inputs from the two prior tasks for the first time. There are three tracks: NLI
on the essay only, NLI on the spoken response only (based on a transcription of
the response and i-vector acoustic features), and NLI using both responses. We
believe this makes for a more interesting shared task while building on the
methods and results from the previous two shared tasks. In this paper, we
report the results of the shared task. A total of 19 teams competed across the
three different sub-tasks. The fusion track showed that combining the written
and spoken responses provides a large boost in prediction accuracy. Multiple
classifier systems (e.g. ensembles and meta-classifiers) were the most
effective in all tasks, with most based on traditional classifiers (e.g. SVMs)
with lexical/syntactic features.},
 address = {Copenhagen, Denmark},
 author = {Malmasi, Shervin and Evanini, Keelan and Cahill, Aoife and Tetreault, Joel and Pugh, Robert and Hamill, Christopher and Napolitano, Diane and Qian, Yao},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5007},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {62--75},
 publisher = {Association for Computational Linguistics},
 title = {A Report on the 2017 Native Language Identification Shared Task},
 year = {2017}
}

@inproceedings{W17-5008,
 abstract = {This study provides a detailed analysis of evaluation of English pronoun
reference questions which are created automatically by machine. Pronoun
reference questions are multiple choice questions that ask test takers to
choose an antecedent of a target pronoun in a reading passage from four
options. The evaluation was performed from two perspectives: the perspective of
English teachers and that of English learners. Item analysis suggests that
machine-generated questions achieve comparable quality with human-made
questions. Correlation analysis revealed a strong correlation between the
scores of machine-generated questions and that of human-made questions.},
 address = {Copenhagen, Denmark},
 author = {Satria, Arief Yudha and Tokunaga, Takenobu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5008},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {76--85},
 publisher = {Association for Computational Linguistics},
 title = {Evaluation of Automatically Generated Pronoun Reference Questions},
 year = {2017}
}

@inproceedings{W17-5009,
 abstract = {Public speakings play important roles in schools and work places and properly
using humor contributes to effective presentations. For the purpose of
automatically evaluating speakers' humor usage, we build a presentation corpus
containing humorous utterances based on TED talks. Compared to previous data
resources supporting humor recognition research, ours has several advantages, including (a) both positive and negative instances coming from a homogeneous
data set, (b) containing a large number of speakers, and (c) being open.
Focusing on using lexical cues for humor recognition, we systematically compare
a newly emerging text classification method based on Convolutional Neural
Networks (CNNs) with a well-established conventional method using linguistic
knowledge. The advantages of the CNN method are both getting higher detection
accuracies and being able to learn essential features automatically.},
 address = {Copenhagen, Denmark},
 author = {Chen, Lei and Lee, Chong Min},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5009},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {86--90},
 publisher = {Association for Computational Linguistics},
 title = {Predicting Audience's Laughter During Presentations Using Convolutional Neural Network},
 year = {2017}
}

@inproceedings{W17-5010,
 abstract = {We present crowdsourced collection of error annotations for transcriptions of
spoken learner English. Our emphasis in data collection is on fluency
corrections, a more complete correction than has traditionally been aimed for
in grammatical error correction research (GEC). Fluency corrections require
improvements to the text, taking discourse and utterance level semantics into
account: the result is a more naturalistic, holistic version of the original.
We propose that this shifted emphasis be reflected in a new name for the task:
'holistic error correction' (HEC). We analyse crowdworker behaviour in HEC and
conclude that the method is useful with certain amendments for future work.},
 address = {Copenhagen, Denmark},
 author = {Caines, Andrew and Flint, Emma and Buttery, Paula},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5010},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {91--100},
 publisher = {Association for Computational Linguistics},
 title = {Collecting fluency corrections for spoken learner English},
 year = {2017}
}

@inproceedings{W17-5011,
 abstract = {Writing is a challenge, especially for at-risk students who may lack the
prerequisite writing skills required to persist in U.S. 4-year postsecondary
(college) institutions. Educators teaching postsecondary courses requiring
writing could benefit from a better understanding of writing achievement and
its role in postsecondary success. In this paper, novel exploratory work
examined how automated writing evaluation (AWE) can inform our understanding of
the relationship between postsecondary writing skill and broader success
outcomes. An exploratory study was conducted using test-taker essays from a
standardized writing assessment of postsecondary student learning outcomes.
Findings showed that for the essays, AWE features were found to be predictors
of broader outcomes measures: college success and learning outcomes measures.
Study findings illustrate AWE{\^a}s potential to support educational analytics --
i.e., relationships between writing skill and broader outcomes -- taking a
step toward moving AWE beyond writing assessment and instructional use cases.},
 address = {Copenhagen, Denmark},
 author = {Burstein, Jill and McCaffrey, Dan and Beigman Klebanov, Beata and Ling, Guangming},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5011},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {101--108},
 publisher = {Association for Computational Linguistics},
 title = {Exploring Relationships Between Writing \& Broader Outcomes With Automated Writing Evaluation},
 year = {2017}
}

@inproceedings{W17-5012,
 abstract = {Characterizing the content of a technical document in terms of its learning
utility can be useful for applications related to education, such as generating
reading lists from large collections of documents. We refer to this learning
utility as the ``pedagogical value'' of the document to the learner. While
pedagogical value is an important concept that has been studied extensively
within the education domain, there has been little work exploring it from a
computational, i.e., natural language processing (NLP), perspective. To allow a
computational exploration of this concept, we introduce the notion of
``pedagogical roles'' of documents (e.g., Tutorial and Survey) as an
intermediary component for the study of pedagogical value. Given the lack of
available corpora for our exploration, we create the first annotated corpus of
pedagogical roles and use it to test baseline techniques for automatic
prediction of such roles.},
 address = {Copenhagen, Denmark},
 author = {Sheng, Emily and Natarajan, Prem and Gordon, Jonathan and Burns, Gully},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5012},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {109--120},
 publisher = {Association for Computational Linguistics},
 title = {An Investigation into the Pedagogical Features of Documents},
 year = {2017}
}

@inproceedings{W17-5013,
 abstract = {Given the lack of large user-evaluated corpora in disability-related NLP
research (e.g. text simplification or readability assessment for people with
cognitive disabilities), the question of choosing suitable training data for
NLP models is not straightforward. The use of large generic corpora may be
problematic because such data may not reflect the needs of the target
population. The use of the available user-evaluated corpora may be problematic
because these datasets are not large enough to be used as training data. In
this paper we explore a third approach, in which a large generic corpus is
combined with a smaller population-specific corpus to train a classifier which
is
evaluated using two sets of unseen user-evaluated data. One of these sets, the
ASD Comprehension corpus, is developed for the purposes of this study and made
freely available. We explore the effects of the size and type of the training
data used on the performance of the classifiers, and the effects of the type of
the unseen test datasets on the classification performance.},
 address = {Copenhagen, Denmark},
 author = {Yaneva, Victoria and Orasan, Constantin and Evans, Richard and Rohanian, Omid},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5013},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {121--132},
 publisher = {Association for Computational Linguistics},
 title = {Combining Multiple Corpora for Readability Assessment for People with Cognitive Disabilities},
 year = {2017}
}

@inproceedings{W17-5014,
 abstract = {Flashcard systems are effective tools for learning words but have their
limitations in teaching word usage. To overcome this problem, we propose a
novel flashcard system that
shows a new example sentence on each repetition. This extension requires
high-quality example sentences, automatically extracted from a huge corpus. To
do this, we use a Determinantal Point Process which scales well to large data
and allows to naturally represent sentence similarity and quality as features.
Our human evaluation experiment on Japanese language indicates that the
proposed method successfully extracted high-quality example sentences.},
 address = {Copenhagen, Denmark},
 author = {Tolmachev, Arseny and Kurohashi, Sadao},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5014},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {133--142},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Extraction of High-Quality Example Sentences for Word Learning Using a Determinantal Point Process},
 year = {2017}
}

@inproceedings{W17-5015,
 abstract = {This paper reports the first study on automatic generation of distractors for
fill-in-the-blank items for learning Chinese vocabulary.  We investigate the
quality of distractors generated by a number of criteria, including
part-of-speech, difficulty level, spelling, word co-occurrence and semantic
similarity.  Evaluations show that a semantic similarity measure, based on the
word2vec model, yields distractors that are significantly more plausible than
those generated by baseline methods.},
 address = {Copenhagen, Denmark},
 author = {Jiang, Shu and Lee, John},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5015},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {143--148},
 publisher = {Association for Computational Linguistics},
 title = {Distractor Generation for Chinese Fill-in-the-blank Items},
 year = {2017}
}

@inproceedings{W17-5016,
 abstract = {We propose a novel word embedding pre-training approach that exploits writing
errors in learners' scripts. We compare our method to previous models that tune
the embeddings based on script scores and the discrimination between correct
and corrupt word contexts in addition to the generic commonly-used embeddings
pre-trained on large corpora. The comparison is achieved by using the
aforementioned models to bootstrap a neural network that learns to predict a
holistic score for scripts. Furthermore, we investigate augmenting our model
with error corrections and monitor the impact on performance. Our results show
that our error-oriented approach outperforms other comparable ones which is
further demonstrated when training on more data. Additionally, extending the
model with corrections provides further performance gains when data sparsity is
an issue.},
 address = {Copenhagen, Denmark},
 author = {Farag, Youmna and Rei, Marek and Briscoe, Ted},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5016},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {149--158},
 publisher = {Association for Computational Linguistics},
 title = {An Error-Oriented Approach to Word Embedding Pre-Training},
 year = {2017}
}

@inproceedings{W17-5017,
 abstract = {Neural approaches to automated essay scoring have recently shown
state-of-the-art performance. The automated essay scoring task typically
involves a broad notion of writing quality that encompasses content, grammar, organization, and conventions. This differs from the short answer content
scoring task, which focuses on content accuracy. The inputs to neural essay
scoring models -- ngrams and embeddings -- are arguably well-suited to evaluate
content in short answer scoring tasks. We investigate how several basic neural
approaches similar to those used for automated essay scoring perform on short
answer scoring. We show that neural architectures can outperform a strong
non-neural baseline, but performance and optimal parameter settings vary across
the more diverse types of prompts typical of short answer scoring.},
 address = {Copenhagen, Denmark},
 author = {Riordan, Brian and Horbach, Andrea and Cahill, Aoife and Zesch, Torsten and Lee, Chong Min},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5017},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {159--168},
 publisher = {Association for Computational Linguistics},
 title = {Investigating neural architectures for short answer scoring},
 year = {2017}
}

@inproceedings{W17-5018,
 abstract = {This paper is concerned with the task of automatically assessing the written
proficiency level of non-native (L2) learners of English.
Drawing on previous research on automated L2 writing assessment following the
Common European Framework of Reference for Languages (CEFR), we investigate the
possibilities and difficulties of deriving the CEFR level from short answers to
open-ended questions, which has not yet been subjected to numerous studies up
to date.
The object of our study is twofold: to examine the intricacy involved with both
human and automated CEFR-based grading of short answers.
On the one hand, we describe the compilation of a learner corpus of short
answers graded with CEFR levels by three certified Cambridge examiners.
We mainly observe that, although the shortness of the answers is reported as
undermining a clear-cut evaluation, the length of the answer does not
necessarily correlate with inter-examiner disagreement.
On the other hand, we explore the development of a soft-voting system for the
automated CEFR-based grading of short answers and draw tentative conclusions
about its use in a computer-assisted testing (CAT) setting.},
 address = {Copenhagen, Denmark},
 author = {Tack, Ana\"{i}s and Fran\c{c}ois, Thomas and Roekhaut, Sophie and Fairon, C\'{e}drick},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5018},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {169--179},
 publisher = {Association for Computational Linguistics},
 title = {Human and Automated CEFR-based Grading of Short Answers},
 year = {2017}
}

@inproceedings{W17-5019,
 abstract = {The field of grammatical error correction (GEC) has made tremendous bounds in
the last ten years, but new questions and obstacles are revealing themselves.
In this position paper, we discuss the issues that need to be addressed and
provide recommendations for the field to continue to make progress, and propose
a new shared task. We invite suggestions and critiques from the audience to
make the new shared task a community-driven venture.},
 address = {Copenhagen, Denmark},
 author = {Sakaguchi, Keisuke and Napoles, Courtney and Tetreault, Joel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5019},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {180--187},
 publisher = {Association for Computational Linguistics},
 title = {GEC into the future: Where are we going and how do we get there?},
 year = {2017}
}

@inproceedings{W17-5020,
 abstract = {Automated methods for essay scoring have made great progress in recent years, achieving accuracies very close to human annotators.
However, a known weakness of such automated scorers is not taking into account
the semantic relevance of the submitted text.
While there is existing work on detecting answer relevance given a textual
prompt, very little previous research has been done to incorporate visual
writing prompts.
We propose a neural architecture and several extensions for detecting off-topic
responses to visual prompts and evaluate it on a dataset of texts written by
language learners.},
 address = {Copenhagen, Denmark},
 author = {Rei, Marek},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5020},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {188--197},
 publisher = {Association for Computational Linguistics},
 title = {Detecting Off-topic Responses to Visual Prompts},
 year = {2017}
}

@inproceedings{W17-5021,
 abstract = {We summarize the involvement of our CEMI team in the ''NLI Shared Task 2017'', which deals with both textual and speech input data. We submitted the results
achieved by using three different system architectures; each of them combines
multiple supervised learning models trained on various feature sets. As
expected, better results are achieved with the systems that use both the
textual data and the spoken responses. Combining the input data of two
different modalities led to a rather dramatic improvement in classification
performance.
Our best performing method is based on a set of feed-forward neural networks
whose hidden-layer outputs are combined together using a softmax layer. We
achieved a macro-averaged F1 score of 0.9257 on the evaluation (unseen) test
set and our team placed first in the main task together with other three teams.},
 address = {Copenhagen, Denmark},
 author = {Ircing, Pavel and Svec, Jan and Zajic, Zbynek and Hladka, Barbora and Holub, Martin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5021},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {198--209},
 publisher = {Association for Computational Linguistics},
 title = {Combining Textual and Speech Features in the NLI Task Using State-of-the-Art Machine Learning Techniques},
 year = {2017}
}

@inproceedings{W17-5022,
 abstract = {Native language identification (NLI) is the task of determining an author's
native language, based on a piece of his/her writing in a second language. In
recent years, NLI has received much attention due to its challenging nature and
its applications in language pedagogy and forensic linguistics. We participated
in the NLI2017 shared task under the name UT-DSP. In our effort to implement a
method for native language identification, we made use of a fusion of character
and word N-grams, and achieved an optimal F1-Score of 77.64\%, using both essay
and speech transcription datasets.},
 address = {Copenhagen, Denmark},
 author = {Mohammadi, Elham and Veisi, Hadi and Amini, Hessam},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5022},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {210--216},
 publisher = {Association for Computational Linguistics},
 title = {Native Language Identification Using a Mixture of Character and Word N-grams},
 year = {2017}
}

@inproceedings{W17-5023,
 abstract = {Our team{\^a}Uvic-NLP{\^a}explored and evaluated a variety of lexical features for
Native Language Identification (NLI) within the framework of ensemble methods.
Using a subset of the highest performing features, we train Support Vector
Machines (SVM) and Fully Connected Neural Networks (FCNN) as base classifiers, and test different methods for combining their outputs. Restricting our scope
to the closed essay track in the NLI Shared Task 2017, we find that our best
SVM ensemble achieves an F1 score of 0.8730 on the test set.},
 address = {Copenhagen, Denmark},
 author = {Chan, Sophia and Honari Jahromi, Maryam and Benetti, Benjamin and Lakhani, Aazim and Fyshe, Alona},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5023},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {217--223},
 publisher = {Association for Computational Linguistics},
 title = {Ensemble Methods for Native Language Identification},
 year = {2017}
}

@inproceedings{W17-5024,
 abstract = {We describe a machine learning approach for the 2017 shared task on Native
Language Identification (NLI). The proposed approach combines several kernels
using multiple kernel learning. While most of our kernels are based on
character p-grams (also known as n-grams) extracted from essays or speech
transcripts, we also use a kernel based on i-vectors, a low-dimensional
representation of audio recordings, provided by the shared task organizers. For
the learning stage, we choose Kernel Discriminant Analysis (KDA) over Kernel
Ridge Regression (KRR), because the former classifier obtains better results
than the latter one on the development set. In our previous work, we have used
a similar machine learning approach to achieve state-of-the-art NLI results.
The goal of this paper is to demonstrate that our shallow and simple approach
based on string kernels (with minor improvements) can pass the test of time and
reach state-of-the-art performance in the 2017 NLI shared task, despite the
recent advances in natural language processing. We participated in all three
tracks, in which the competitors were allowed to use only the essays (essay
track), only the speech transcripts (speech track), or both (fusion track).
Using only the data provided by the organizers for training our models, we have
reached a macro F1 score of 86.95% in the closed essay track, a macro F1 score
of 87.55% in the closed speech track, and a macro F1 score of 93.19% in the
closed fusion track. With these scores, our team (UnibucKernel) ranked in the
first group of teams in all three tracks, while attaining the best scores in
the speech and the fusion tracks.},
 address = {Copenhagen, Denmark},
 author = {Ionescu, Radu Tudor and Popescu, Marius},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5024},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {224--234},
 publisher = {Association for Computational Linguistics},
 title = {Can string kernels pass the test of time in Native Language Identification?},
 year = {2017}
}

@inproceedings{W17-5025,
 abstract = {We present the RUG-SU team's submission at the Native Language Identification
Shared Task 2017.
We combine several approaches into an ensemble, based on spelling error
features, a simple neural network using word representations, a deep residual
network using word and character features, and a system based on a recurrent
neural network.
Our best system is an ensemble of neural networks, reaching an F1 score of
0.8323.
Although our system is not the highest ranking one, we do outperform the
baseline by far.},
 address = {Copenhagen, Denmark},
 author = {Bjerva, Johannes and Grigonyte, Gintare and \"{O}stling, Robert and Plank, Barbara},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5025},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {235--239},
 publisher = {Association for Computational Linguistics},
 title = {Neural Networks and Spelling Features for Native Language Identification},
 year = {2017}
}

@inproceedings{W17-5026,
 abstract = {We report on our experiments with N-gram and embedding based feature
representations for Native Language Identification (NLI) as a part of the NLI
Shared Task 2017 (team name: NLI-ISU). Our best performing system on the test
set for written essays had a macro F1 of 0.8264 and was based on word uni, bi
and trigram features. We explored n-grams covering word, character, POS and
word-POS mixed representations for this task. For embedding based feature
representations, we employed both word and document embeddings. We had a
relatively poor performance with all embedding representations compared to
n-grams, which could be because of the fact that embeddings capture semantic
similarities whereas L1 differences are more stylistic in nature.},
 address = {Copenhagen, Denmark},
 author = {Vajjala, Sowmya and Banerjee, Sagnik},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5026},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {240--248},
 publisher = {Association for Computational Linguistics},
 title = {A study of N-gram and Embedding Representations for Native Language Identification},
 year = {2017}
}

@inproceedings{W17-5027,
 abstract = {This paper describes the systems submitted by GadjahMada team to the Native
Language Identification (NLI) Shared Task 2017. Our models used a continuous
representation of character n-grams which are learned jointly with feed-forward
neural network classifier. Character n-grams have been proved to be effective
for style-based identification tasks including NLI. Results on the test set
demonstrate that the proposed model performs very well on essay and fusion
tracks by obtaining more than 0.8 on both F-macro score and accuracy.},
 address = {Copenhagen, Denmark},
 author = {Sari, Yunita and Rifqi Fatchurrahman, Muhammad and Dwiastuti, Meisyarah},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5027},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {249--254},
 publisher = {Association for Computational Linguistics},
 title = {A Shallow Neural Network for Native Language Identification with Character N-grams},
 year = {2017}
}

@inproceedings{W17-5028,
 abstract = {This paper describes our results at the NLI shared task 2017.  We participated
in essays, speech, and fusion task that uses text, speech, and i-vectors for
the task of identifying the native language of the given input. In the essay
track, a linear SVM system using word bigrams and character 7-grams performed
the best. In the speech track, an LDA classifier based only on i-vectors
performed better than a combination system using text features from speech
transcriptions and i-vectors. In the fusion task, we experimented with systems
that used combination of i-vectors with higher order n-grams features, combination of i-vectors with word unigrams, a mean probability ensemble, and a
stacked ensemble system. Our finding is that word unigrams in combination with
i-vectors achieve higher score than systems trained with larger number of
\emph{n}-gram features.  Our best-performing systems achieved F1-scores of
87.16%, 83.33% and 91.75% on the essay track, the speech track and the fusion
track respectively.},
 address = {Copenhagen, Denmark},
 author = {Rama, Taraka and \c{C}\"{o}ltekin, \c{C}a\u{g}r{\"A}$\pm$},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5028},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {255--260},
 publisher = {Association for Computational Linguistics},
 title = {Fewer features perform well at Native Language Identification task},
 year = {2017}
}

@inproceedings{W17-5029,
 abstract = {Learners need to find suitable documents to read and prioritize them in an
appropriate order. We present a method of automatically generating reading
lists, selecting documents based on their pedagogical value to the learner and
ordering them using the structure of concepts in the domain. Resulting reading
lists related to computational linguistics were evaluated by advanced learners
and judged to be near the quality of those generated by domain experts. We
provide an open-source implementation of our method to enable future work on
reading list generation.},
 address = {Copenhagen, Denmark},
 author = {Gordon, Jonathan and Aguilar, Stephen and Sheng, Emily and Burns, Gully},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5029},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {261--270},
 publisher = {Association for Computational Linguistics},
 title = {Structured Generation of Technical Reading Lists},
 year = {2017}
}

@inproceedings{W17-5030,
 abstract = {Eye tracking studies from the past few decades have shaped the way we think
of word complexity and cognitive load: words that are long, rare and ambiguous
are more difficult to read. However, online processing techniques have been
scarcely applied to investigating the reading difficulties of people with
autism and what vocabulary is challenging for them. We present parallel gaze
data obtained from adult readers with autism and a control group of
neurotypical readers and show that the former required higher cognitive
effort to comprehend the texts as evidenced by three gaze-based measures. We
divide all words into four classes based on their viewing times for both groups
and investigate the relationship between longer viewing times and word length, word frequency, and four cognitively-based measures (word concreteness, familiarity, age of acquisition and imagability).},
 address = {Copenhagen, Denmark},
 author = {\v{S}tajner, Sanja and Yaneva, Victoria and Mitkov, Ruslan and Ponzetto, Simone Paolo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5030},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {271--281},
 publisher = {Association for Computational Linguistics},
 title = {Effects of Lexical Properties on Viewing Time per Word in Autistic and Neurotypical Readers},
 year = {2017}
}

@inproceedings{W17-5031,
 abstract = {We present a very simple model for text quality assessment based on a deep
convolutional neural network, where the only supervision required is one corpus
of user-generated text of varying quality, and one contrasting text corpus of
consistently high quality. Our model is able to provide local quality
assessments in different parts of a text, which allows visual feedback about
where potentially problematic parts of the text are located, as well as a way
to evaluate which textual features are captured by our model. We evaluate our
method on two corpora: a large corpus of manually graded student essays and a
longitudinal corpus of language learner written production, and find that the
text quality metric learned by our model is a fairly strong predictor of both
essay grade and learner proficiency level.},
 address = {Copenhagen, Denmark},
 author = {\"{O}stling, Robert and Grigonyte, Gintare},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5031},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {282--286},
 publisher = {Association for Computational Linguistics},
 title = {Transparent text quality assessment with convolutional neural networks},
 year = {2017}
}

@inproceedings{W17-5032,
 abstract = {Shortage of available training data is holding back progress in the area of
automated error detection.
This paper investigates two alternative methods for artificially generating
writing errors, in order to create additional resources.
We propose treating error generation as a machine translation task, where
grammatically correct text is translated to contain errors.
In addition, we explore a system for extracting textual patterns from an
annotated corpus, which can then be used to insert errors into grammatically
correct sentences.
Our experiments show that the inclusion of artificially generated errors
significantly improves error detection accuracy on both FCE and CoNLL 2014
datasets.},
 address = {Copenhagen, Denmark},
 author = {Rei, Marek and Felice, Mariano and Yuan, Zheng and Briscoe, Ted},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5032},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {287--292},
 publisher = {Association for Computational Linguistics},
 title = {Artificial Error Generation with Machine Translation and Syntactic Patterns},
 year = {2017}
}

@inproceedings{W17-5033,
 abstract = {Using methods of statistical analysis, we investigate how semantic knowledge is
acquired in English as a second language and evaluate the pace of development
across a number of predicate types and content word combinations, as well as
across the levels of language proficiency and native languages. Our exploratory
study helps identify the most problematic areas for language learners with
different backgrounds and at different stages of learning.},
 address = {Copenhagen, Denmark},
 author = {Kochmar, Ekaterina and Shutova, Ekaterina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5033},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {293--302},
 publisher = {Association for Computational Linguistics},
 title = {Modelling semantic acquisition in second language learning},
 year = {2017}
}

@inproceedings{W17-5034,
 abstract = {Ontologies provide a structured representation of concepts and the
relationships which connect them. This work investigates how a pre-existing
educational Biology ontology can be used to generate useful practice questions
for students by using the connectivity structure in a novel way. It also
introduces a novel way to generate multiple-choice distractors from the
ontology, and compares this to a baseline of using embedding representations of
nodes. An assessment by an experienced science teacher shows a significant
advantage over a baseline when using the ontology for distractor generation. A
subsequent study with three science teachers on the results of a modified
question generation algorithm finds significant improvements. An in-depth
analysis of the teachers{\^a} comments yields useful insights for any researcher
working on automated question generation for educational applications.},
 address = {Copenhagen, Denmark},
 author = {Stasaski, Katherine and Hearst, Marti A.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5034},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {303--312},
 publisher = {Association for Computational Linguistics},
 title = {Multiple Choice Question Generation Utilizing An Ontology},
 year = {2017}
}

@inproceedings{W17-5035,
 abstract = {The paper presents first results of an ongoing project on text
simplification focusing on linguistic metaphors. Based on an analysis
of a parallel corpus of news text professionally simplified for
different grade levels, we identify six types of simplification
choices falling into two broad categories: preserving metaphors or
dropping them. An annotation study on almost 300 source sentences with
metaphors (grade level 12) and their simplified counterparts (grade~4)
is conducted. The results show that most metaphors are preserved and
when they are dropped, the semantic content tends to be preserved
rather than dropped, however, it is reworded without metaphorical
language. In general, some of the expected tendencies in complexity
reduction, measured with psycholinguistic variables linked to metaphor
comprehension, are observed, suggesting good prospect for machine
learning-based metaphor simplification.},
 address = {Copenhagen, Denmark},
 author = {Wolska, Magdalena and Clausen, Yulia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5035},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {313--318},
 publisher = {Association for Computational Linguistics},
 title = {Simplifying metaphorical language for young readers: A corpus study on news text},
 year = {2017}
}

@inproceedings{W17-5036,
 abstract = {Knowledge of the association between assessment questions and the skills
required to solve them is necessary for analysis of student learning. This
association, often represented as a Q-matrix, is either hand-labeled by domain
experts or learned as latent variables given a large student response data set.
As a means of automating the match to formal standards, this paper uses neural
text classification methods, leveraging the language in the standards documents
to identify online text for a proxy training task. Experiments involve
identifying the topic and crosscutting concepts of middle school science
questions leveraging multi-task training. Results show that it is possible to
automatically build a Q-matrix without student response data and using a modest
number of hand-labeled questions.},
 address = {Copenhagen, Denmark},
 author = {Nadeem, Farah and Ostendorf, Mari},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5036},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {319--326},
 publisher = {Association for Computational Linguistics},
 title = {Language Based Mapping of Science Assessment Items to Skills},
 year = {2017}
}

@inproceedings{W17-5037,
 abstract = {We build a grammatical error correction (GEC) system primarily based on the
state-of-the-art statistical machine translation (SMT) approach, using
task-specific features and tuning, and further enhance it with the modeling
power of neural network joint models. The SMT-based system is weak in
generalizing beyond patterns seen during training and lacks granularity below
the word level. To address this issue, we incorporate a character-level SMT
component targeting the misspelled words that the original SMT-based system
fails to correct. Our final system achieves 53.14% F 0.5 score on the benchmark
CoNLL-2014 test set, an improvement of 3.62% F 0.5 over the best previous
published score.},
 address = {Copenhagen, Denmark},
 author = {Chollampatt, Shamil and Ng, Hwee Tou},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5037},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {327--333},
 publisher = {Association for Computational Linguistics},
 title = {Connecting the Dots: Towards Human-Level Grammatical Error Correction},
 year = {2017}
}

@inproceedings{W17-5038,
 abstract = {In Foreign Language Teaching and Learning (FLTL), questions are systematically
used to assess the learner{\^a}s understanding of a text. Computational
linguistic approaches have been developed to generate such questions
automatically given a text (e.g., Heilman, 2011). In this paper, we want to
broaden the perspective on the different functions questions can play in FLTL
and discuss how automatic question generation can support the different uses.
Complementing the focus on meaning and comprehension, we want to highlight the
fact that questions can also be used to make learners notice form aspects of
the linguistic system and their interpretation. Automatically generating
questions that target linguistic forms and grammatical categories in a text in
essence supports incidental focus-on-form (Loewen, 2005) in a meaning-focused
reading task. We discuss two types of questions serving this purpose, how they
can be generated automatically; and we report on a crowd-sourcing evaluation
comparing automatically generated to manually written questions targeting
particle verbs, a challenging linguistic form for learners of English.},
 address = {Copenhagen, Denmark},
 author = {Chinkina, Maria and Meurers, Detmar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5038},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {334--344},
 publisher = {Association for Computational Linguistics},
 title = {Question Generation for Language Learning: From ensuring texts are read to supporting learning},
 year = {2017}
}

@inproceedings{W17-5039,
 abstract = {n this work we adapt machine translation (MT) to grammatical error correction, identifying how components of the statistical MT pipeline can be modified for
this task and analyzing how each modification impacts system performance. We
evaluate the contribution of each of these components with standard evaluation
metrics and automatically characterize the morphological and lexical
transformations made in system output. Our model rivals the current state of
the art using a fraction of the training data.},
 address = {Copenhagen, Denmark},
 author = {Napoles, Courtney and Callison-Burch, Chris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5039},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {345--356},
 publisher = {Association for Computational Linguistics},
 title = {Systematically Adapting Machine Translation for Grammatical Error Correction},
 year = {2017}
}

@inproceedings{W17-5040,
 abstract = {Automatic essay scoring is nowadays successfully used even in high-stakes
tests, but this is mainly limited to holistic scoring of learner essays.
We present a new dataset of essays written by highly proficient German native
speakers that is scored using a fine-grained rubric with the goal to provide
detailed feedback.
Our experiments with two state-of-the-art scoring systems (a neural and a
SVM-based one)                                show a large drop in performance
compared to
existing
datasets.
This demonstrates the need for such datasets that allow to guide research on
more elaborate essay scoring methods.},
 address = {Copenhagen, Denmark},
 author = {Horbach, Andrea and Scholten-Akoun, Dirk and Ding, Yuning and Zesch, Torsten},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5040},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {357--366},
 publisher = {Association for Computational Linguistics},
 title = {Fine-grained essay scoring of a complex writing task for native speakers},
 year = {2017}
}

@inproceedings{W17-5041,
 abstract = {We describe the submissions entered by the National Research Council
Canada in the NLI-2017 evaluation. We mainly explored the use of
voting, and various ways to optimize the choice and number of voting
systems.  We also explored the use of features that rely on no
linguistic preprocessing. Long ngrams of characters obtained from raw
text turned out to yield the best performance on all textual input
(written essays and speech transcripts). Voting ensembles turned out
to produce small performance gains, with little difference between the
various optimization strategies we tried. Our top systems achieved
accuracies of 87% on the \essay\ track, 84% on the
\speech\ track, and close to 92% by combining essays, speech and
i-vectors in the \fusion\ track.},
 address = {Copenhagen, Denmark},
 author = {Goutte, Cyril and L\'{e}ger, Serge},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5041},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {367--373},
 publisher = {Association for Computational Linguistics},
 title = {Exploring Optimal Voting in Native Language Identification},
 year = {2017}
}

@inproceedings{W17-5042,
 abstract = {We present the CIC-FBK system, which took part in the Native Language
Identification (NLI) Shared Task 2017. Our approach combines features commonly
used in previous NLI research, i.e., word n-grams, lemma n-grams, part-of-speech n-grams, and function words, with recently introduced character
n-grams from misspelled words, and features that are novel in this task, such
as typed character n-grams, and syntactic n-grams of words and of syntactic
relation tags. We use log-entropy weighting scheme and perform classification
using the Support Vector Machines (SVM) algorithm. Our system achieved 0.8808
macro-averaged F1-score and shared the 1st rank in the NLI Shared Task 2017
scoring.},
 address = {Copenhagen, Denmark},
 author = {Markov, Ilia and Chen, Lingzhen and Strapparava, Carlo and Sidorov, Grigori},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5042},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {374--381},
 publisher = {Association for Computational Linguistics},
 title = {CIC-FBK Approach to Native Language Identification},
 year = {2017}
}

@inproceedings{W17-5043,
 abstract = {In this paper, we explore the performance of a linear SVM trained on language
independent character features for the NLI Shared Task 2017. Our basic system
(GRONINGEN) achieves the best performance (87.56 F1-score) on the evaluation
set using only 1-9 character n-grams as features. We compare this against
several ensemble and meta-classifiers in order to examine how the linear system
fares when combined with other, especially non-linear classifiers. Special
emphasis is placed on the topic bias that exists by virtue of the assessment
essay prompt distribution.},
 address = {Copenhagen, Denmark},
 author = {Kulmizev, Artur and Blankers, Bo and Bjerva, Johannes and Nissim, Malvina and van Noord, Gertjan and Plank, Barbara and Wieling, Martijn},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5043},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {382--389},
 publisher = {Association for Computational Linguistics},
 title = {The Power of Character N-grams in Native Language Identification},
 year = {2017}
}

@inproceedings{W17-5044,
 abstract = {This paper reports our contribution (team WLZ) to the NLI Shared Task 2017
(essay track). We first extract lexical and syntactic features from the essays, perform feature weighting and selection, and train linear support vector
machine (SVM) classifiers each on an individual feature type. The output of
base classifiers, as probabilities for each class, are then fed into a
multilayer perceptron to predict the native language of the author. We also
report the performance of each feature type, as well as the best features of a
type. Our system achieves an accuracy of 86.55%, which is among the best
performing systems of this shared task.},
 address = {Copenhagen, Denmark},
 author = {Li, Wen and Zou, Liang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5044},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {390--397},
 publisher = {Association for Computational Linguistics},
 title = {Classifier Stacking for Native Language Identification},
 year = {2017}
}

@inproceedings{W17-5045,
 abstract = {This paper presents an ensemble system combining the output of multiple SVM
classifiers to native language identification (NLI). The system was submitted
to the NLI Shared Task 2017 fusion track which featured students essays and
spoken responses in form of audio transcriptions and iVectors by non-native
English speakers of eleven native languages. Our system competed in the
challenge under the team name ZCD and was based on an ensemble of SVM
classifiers trained on character n-grams achieving 83.58% accuracy and ranking
3rd in the shared task.},
 address = {Copenhagen, Denmark},
 author = {Zampieri, Marcos and Ciobanu, Alina Maria and Dinu, Liviu P.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5045},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {398--404},
 publisher = {Association for Computational Linguistics},
 title = {Native Language Identification on Text and Speech},
 year = {2017}
}

@inproceedings{W17-5046,
 abstract = {In this paper, we discuss the results of the IUCL system in the NLI Shared Task
2017. For our system, we explore a variety of phonetic algorithms to generate
features for Native Language Identification. These features are contrasted with
one of the most successful type of features in NLI, character n-grams. We find
that although phonetic features do not perform as well as character n-grams
alone, they do increase overall F1 score when used together with character
n-grams.},
 address = {Copenhagen, Denmark},
 author = {Smiley, Charese and K\"{u}bler, Sandra},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5046},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {405--412},
 publisher = {Association for Computational Linguistics},
 title = {Native Language Identification using Phonetic Algorithms},
 year = {2017}
}

@inproceedings{W17-5047,
 abstract = {This paper proposes a deep-learning based native-language identification (NLI)
using a latent semantic analysis (LSA) as a participant (ETRI-SLP) of the NLI
Shared Task 2017 where the NLI Shared Task 2017 aims to detect the native
language of an essay or speech response of a standardized assessment of English
proficiency for academic purposes. To this end, we use the six unit forms of a
text data such as character 4/5/6-grams and word 1/2/3-grams. For each unit
form of text data, we convert it into a count-based vector, extract a 2000-rank
LSA feature, and perform a linear discriminant analysis (LDA) based dimension
reduction. From the count-based vector or the LSA-LDA feature, we also obtain
the output prediction values of a support vector machine (SVM) based
classifier, the output prediction values of a deep neural network (DNN) based
classifier, and the bottleneck values of a DNN based classifier. In order to
incorporate the various kinds of text-based features and a speech-based
i-vector feature, we design two DNN based ensemble classifiers for late fusion
and early fusion, respectively. From the NLI experiments, the F1 (macro) scores
are obtained as 0.8601, 0.8664, and 0.9220 for the essay track, the speech
track, and the fusion track, respectively. The proposed method has comparable
performance to the top-ranked teams for the speech and fusion tracks, although
it has slightly lower performance for the essay track.},
 address = {Copenhagen, Denmark},
 author = {Oh, Yoo Rhee and Jeon, Hyung-Bae and Song, Hwa Jeon and Lee, Yun-Kyung and Park, Jeon-Gue and Lee, Yun-Keun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5047},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {413--422},
 publisher = {Association for Computational Linguistics},
 title = {A deep-learning based native-language classification by using a latent semantic analysis for the NLI Shared Task 2017},
 year = {2017}
}

@inproceedings{W17-5048,
 abstract = {In this paper we describe the approaches we explored for the 2017 Native
Language Identification shared task. We focused on simple word and sub-word
units avoiding heavy use of hand-crafted features. Following recent trends, we
explored linear and neural networks models to attempt to compensate for the
lack of rich feature use. Initial efforts yielded f1-scores of 82.39% and
83.77% in the development and test sets of the fusion track, and were
officially submitted to the task as team L2F. After the task was closed, we
carried on further experiments and relied on a late fusion strategy for
combining our simple proposed approaches with modifications of the baselines
provided by the task. As expected, the i-vectors based sub-system dominates the
performance of the system combinations, and results in the major contributor to
our achieved scores. Our best combined system achieves 90.1% and 90.2% f1-score
in the development and test sets of the fusion track, respectively.},
 address = {Copenhagen, Denmark},
 author = {Kepler, Fabio and Astudillo, Ram\'{o}n and Abad, Alberto},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5048},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {423--429},
 publisher = {Association for Computational Linguistics},
 title = {Fusion of Simple Models for Native Language Identification},
 year = {2017}
}

@inproceedings{W17-5049,
 abstract = {In this paper, we describe the approach of the ItaliaNLP Lab team to native
language identification and discuss the results we submitted as participants to
the essay track of NLI Shared Task 2017. We introduce for the first time a
2-stacked sentence-document architecture for native language identification
that is able to exploit both local sentence information and a wide set of
general-purpose features qualifying the lexical and grammatical structure of
the whole document. When evaluated on the official test set, our
sentence-document stacked architecture obtained the best result among all the
participants of the essay track with an F1 score of 0.8818.},
 address = {Copenhagen, Denmark},
 author = {Cimino, Andrea and Dell'Orletta, Felice},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5049},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {430--437},
 publisher = {Association for Computational Linguistics},
 title = {Stacked Sentence-Document Classifier Approach for Improving Native Language Identification},
 year = {2017}
}

@inproceedings{W17-5050,
 abstract = {We show that text readability prediction improves significantly from hard
parameter sharing with models predicting first pass duration, total fixation
duration and regression duration. Specifically, we induce multi-task Multilayer
Perceptrons and Logistic Regression models over sentence representations that
capture various aggregate statistics, from two different text readability
corpora for English, as well as the Dundee eye-tracking corpus. Our approach
leads to significant improvements over Single task learning and over previous
systems. In addition, our improvements are consistent across train sample
sizes, making our approach especially applicable to small datasets.},
 address = {Copenhagen, Denmark},
 author = {Gonzalez-Gardu\~{n}o, Ana Valeria and S{\o}gaard, Anders},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5050},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {438--443},
 publisher = {Association for Computational Linguistics},
 title = {Using Gaze to Predict Text Readability},
 year = {2017}
}

@inproceedings{W17-5051,
 abstract = {NLP applications for learners often rely on annotated learner corpora. Thereby, it is important that the annotations are both meaningful for the task, and
consistent and reliable. We present a new longitudinal L1 learner corpus for
German (handwritten texts collected in grade 2--4), which is transcribed and
annotated with a target hypothesis that strictly only corrects orthographic
errors, and is thereby tailored to research and tool development for
orthographic issues in primary school. While for most corpora, transcription
and target hypothesis are not evaluated, we conducted a detailed
inter-annotator agreement study for both tasks. Although we achieved high
agreement, our discussion of cases of disagreement shows that even with
detailed guidelines, annotators differ here and there for different reasons, which should also be considered when working with transcriptions and target
hypotheses of other corpora, especially if no explicit guidelines for their
construction are known.},
 address = {Copenhagen, Denmark},
 author = {Laarmann-Quante, Ronja and Ortmann, Katrin and Ehlert, Anna and Vogel, Maurice and Dipper, Stefanie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5051},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {444--456},
 publisher = {Association for Computational Linguistics},
 title = {Annotating Orthographic Target Hypotheses in a German L1 Learner Corpus},
 year = {2017}
}

@inproceedings{W17-5052,
 abstract = {We explore various supervised learning strategies for automated scoring of
content knowledge for a large corpus of 130 different content-based questions
spanning four subject areas (Science, Math, English Language Arts, and Social
Studies) and containing over 230,000 responses scored by human raters. Based on
our analyses, we provide specific recommendations for content scoring. These
are based on patterns observed across multiple questions and assessments and
are, therefore, likely to generalize to other scenarios and prove useful to the
community as automated content scoring becomes more popular in schools and
classrooms.},
 address = {Copenhagen, Denmark},
 author = {Madnani, Nitin and Loukina, Anastassia and Cahill, Aoife},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5052},
 booktitle = {Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {September},
 pages = {457--467},
 publisher = {Association for Computational Linguistics},
 title = {A Large Scale Quantitative Exploration of Modeling Strategies for Content Scoring},
 year = {2017}
}

@inproceedings{W17-5101,
 abstract = {In this paper we present the dataset of 200,000+ political arguments produced
in the local phase of the 2016 Chilean constitutional process. We describe the
human processing of this data by the government officials, and the manual
tagging of arguments performed by members of our research group. Afterwards we
focus on classification tasks that mimic the human processes, comparing linear
methods with neural network architectures. The experiments show that some of
the manual tasks are suitable for automatization. In particular, the best
methods achieve a 90% top-5 accuracy in a multi-class classification of
arguments, and 65% macro-averaged F1-score for tagging arguments according to a
three-part argumentation model.},
 address = {Copenhagen, Denmark},
 author = {Fierro, Constanza and Fuentes, Claudio and P\'{e}rez, Jorge and Quezada, Mauricio},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5101},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {200K+ Crowdsourced Political Arguments for a New Chilean Constitution},
 year = {2017}
}

@inproceedings{W17-5102,
 abstract = {Argumentative text has been analyzed both theoretically and computationally in
terms of argumentative structure that consists of argument components (e.g., claims, premises) and their argumentative relations (e.g., support, attack).
Less emphasis has been placed on analyzing the semantic types of argument
components. We propose a two-tiered annotation scheme to label claims and
premises and their semantic types in an online persuasive forum, Change My
View, with the long-term goal of understanding what makes a message persuasive.
Premises are annotated with the three types of persuasive modes: ethos, logos, pathos, while claims are labeled as interpretation, evaluation, agreement, or
disagreement, the latter two designed to account for the dialogical nature of
our corpus.
We aim to answer three questions: 1) can humans reliably annotate the semantic
types of argument components?
2) are types of premises/claims positioned in recurrent orders?
and 3) are certain types of claims and/or premises more likely to appear in
persuasive messages than in non-persuasive messages?},
 address = {Copenhagen, Denmark},
 author = {Hidey, Christopher and Musi, Elena and Hwang, Alyssa and Muresan, Smaranda and McKeown, Kathy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5102},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {11--21},
 publisher = {Association for Computational Linguistics},
 title = {Analyzing the Semantic Types of Claims and Premises in an Online Persuasive Forum},
 year = {2017}
}

@inproceedings{W17-5103,
 abstract = {We propose a method for the annotation of Japanese civil judgment documents, with the purpose of creating flexible summaries of these. The first step, described in the current paper, concerns content selection, i.e., the question
of which material should be extracted initially for the summary. In particular, we utilize the hierarchical argument structure of the judgment documents. Our
main contributions are a) the design of an annotation scheme that stresses the
connection between legal points (called issue topics) and argument structure, b) an adaptation of rhetorical status to suit the Japanese legal system and c)
the definition of a linked argument structure based on legal sub-arguments. In
this paper, we report agreement between two annotators on several aspects of
the overall task.},
 address = {Copenhagen, Denmark},
 author = {Yamada, Hiroaki and Teufel, Simone and Tokunaga, Takenobu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5103},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {22--31},
 publisher = {Association for Computational Linguistics},
 title = {Annotation of argument structure in Japanese legal documents},
 year = {2017}
}

@inproceedings{W17-5104,
 abstract = {Stance classification is a core component in on-demand argument construction
pipelines. Previous work on claim stance classification relied on background
knowledge such as manually-composed sentiment lexicons. We show that both
accuracy and coverage can be significantly improved through automatic expansion
of the initial lexicon. We also developed a set of contextual features that
further improves the state-of-the-art for this task.},
 address = {Copenhagen, Denmark},
 author = {Bar-Haim, Roy and Edelstein, Lilach and Jochim, Charles and Slonim, Noam},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5104},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {32--38},
 publisher = {Association for Computational Linguistics},
 title = {Improving Claim Stance Classification with Lexical Knowledge Expansion and Context Utilization},
 year = {2017}
}

@inproceedings{W17-5105,
 abstract = {This paper presents a method of extracting argumentative structure from natural
language text. The approach presented is based on the way in which we
understand an argument being made, not just from the words said, but from
existing contextual knowledge and understanding of the broader issues. We
leverage high-precision, low-recall techniques in order to automatically build
a large corpus of inferential statements related to the text's topic. These
statements are then used to produce a matrix representing the inferential
relationship between different aspects of the topic. From this matrix, we are
able to determine connectedness and directionality of inference between
statements in the original text. By following this approach, we obtain results
that compare favourably to those of other similar techniques to classify
premise-conclusion pairs (with results 22 points above baseline), but without
the requirement of large volumes of annotated, domain specific data.},
 address = {Copenhagen, Denmark},
 author = {Lawrence, John and Reed, Chris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5105},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {39--48},
 publisher = {Association for Computational Linguistics},
 title = {Mining Argumentative Structure from Natural Language text using Automatically Generated Premise-Conclusion Topic Models},
 year = {2017}
}

@inproceedings{W17-5106,
 abstract = {Computational argumentation is expected to play a critical role in the future
of web search. To make this happen, many search-related questions must be
revisited, such as how people query for arguments, how to mine arguments from
the web, or how to rank them. In this paper, we develop an argument search
framework for studying these and further questions. The framework allows for
the composition of approaches to acquiring, mining, assessing, indexing, querying, retrieving, ranking, and presenting arguments while relying on
standard infrastructure and interfaces. Based on the framework, we build a
prototype search engine, called args, that relies on an initial, freely
accessible index of nearly 300k arguments crawled from reliable web resources.
The framework and the argument search engine are intended as an environment for
collaborative research on computational argumentation and its practical
evaluation.},
 address = {Copenhagen, Denmark},
 author = {Wachsmuth, Henning and Potthast, Martin and Al Khatib, Khalid and Ajjour, Yamen and Puschmann, Jana and Qu, Jiani and Dorsch, Jonas and Morari, Viorel and Bevendorff, Janek and Stein, Benno},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5106},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {49--59},
 publisher = {Association for Computational Linguistics},
 title = {Building an Argument Search Engine for the Web},
 year = {2017}
}

@inproceedings{W17-5107,
 abstract = {In this paper, we address the problem of argument relation classification where
argument units are from different texts. We design a joint inference method for
the task by modeling argument relation classification and stance classification
jointly. We show that our joint model improves the results over several strong
baselines.},
 address = {Copenhagen, Denmark},
 author = {Hou, Yufang and Jochim, Charles},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5107},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {60--66},
 publisher = {Association for Computational Linguistics},
 title = {Argument Relation Classification Using a Joint Inference Model},
 year = {2017}
}

@inproceedings{W17-5108,
 abstract = {Argumentative corpora are costly to create and are available in only few
languages with English dominating the area. In this paper we release the first
publicly available Mandarin argumentative corpus. The corpus is created by
exploiting the idea of comparable corpora from Statistical Machine Translation.
We use existing corpora in English and manually map the claims and premises to
comparable corpora in Mandarin. We also implement a simple solution to automate
this approach with the view of creating argumentative corpora in other
less-resourced languages. In this way we introduce a new task of multi-lingual
argument mapping that can be evaluated using our English-Mandarin argumentative
corpus. The preliminary results of our automatic argument mapper mirror the
simplicity of our approach, but provide a baseline for further improvements.},
 address = {Copenhagen, Denmark},
 author = {Aker, Ahmet and Zhang, Huangpan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5108},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {67--72},
 publisher = {Association for Computational Linguistics},
 title = {Projection of Argumentative Corpora from Source to Target Languages},
 year = {2017}
}

@inproceedings{W17-5109,
 abstract = {This paper describes a pilot study to evaluate human analysts{\^a} ability to
identify the argumentation scheme and premises of an argument having an
implicit conclusion.  In preparation for the study, argumentation scheme
definitions were crafted for genetics research articles.  The schemes were
defined in semantic terms, following a proposal to use semantic rules to mine
arguments in that literature.},
 address = {Copenhagen, Denmark},
 author = {Green, Nancy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5109},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {73--78},
 publisher = {Association for Computational Linguistics},
 title = {Manual Identification of Arguments with Implicit Conclusions Using Semantic Rules for Argument Mining},
 year = {2017}
}

@inproceedings{W17-5110,
 abstract = {Automatic claim detection is a fundamental
argument mining task that aims to automatically
mine claims regarding a topic
of consideration. Previous works on mining
argumentative content have assumed
that a set of relevant documents is given in
advance. Here, we present a first corpus--
wide claim detection framework, that can
be directly applied to massive corpora.
Using simple and intuitive empirical observations, we derive a claim sentence
query by which we are able to directly retrieve
sentences in which the prior probability
to include topic-relevant claims is
greatly enhanced. Next, we employ simple
heuristics to rank the sentences, leading
to an unsupervised corpus--wide claim detection
system, with precision that outperforms
previously reported results on the
task of claim detection given relevant documents
and labeled data.},
 address = {Copenhagen, Denmark},
 author = {Levy, Ran and Gretz, Shai and Sznajder, Benjamin and Hummel, Shay and Aharonov, Ranit and Slonim, Noam},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5110},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {79--84},
 publisher = {Association for Computational Linguistics},
 title = {Unsupervised corpus--wide claim detection},
 year = {2017}
}

@inproceedings{W17-5111,
 abstract = {This short paper presents a first implementation of a knowledge-driven
argument mining approach. The major processing steps and language resources of
the system are surveyed. An indicative evaluation outlines challenges and
improvement directions.},
 address = {Copenhagen, Denmark},
 author = {Saint-Dizier, Patrick},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5111},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {85--90},
 publisher = {Association for Computational Linguistics},
 title = {Using Question-Answering Techniques to Implement a Knowledge-Driven Argument Mining Approach},
 year = {2017}
}

@inproceedings{W17-5112,
 abstract = {This paper offers a comparative analysis of the performance of different
supervised machine learning methods and feature sets on argument mining tasks.
Specifically, we address the tasks of extracting argumentative segments from
texts and predicting the structure between those segments. Eight classifiers
and different combinations of six feature types reported in previous work are
evaluated. The results indicate that overall best performing features are the
structural ones. Although the performance of classifiers varies depending on
the feature combinations and corpora used for training and testing, Random
Forest seems to be among the best performing classifiers. These results build a
basis for further development of argument mining techniques and can guide an
implementation of argument mining into different applications such as argument
based search.},
 address = {Copenhagen, Denmark},
 author = {Aker, Ahmet and Sliwa, Alfred and Ma, Yuan and Lui, Ruishen and Borad, Niravkumar and Ziyaei, Seyedeh and Ghobadi, Mina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5112},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {91--96},
 publisher = {Association for Computational Linguistics},
 title = {What works and what does not: Classifier and feature analysis for argument mining},
 year = {2017}
}

@inproceedings{W17-5113,
 abstract = {In this paper we present a new unsupervised approach, {\^a}Attraction to
Topics{\^a} --
A2T , for the detection of argumentative units, a sub-task of argument mining.
Motivated by the importance of topic identification in manual annotation, we
examine whether topic modeling can be used for performing unsupervised
detection of argumentative sentences, and to what extend topic modeling can be
used to classify sentences as claims and premises.
Preliminary evaluation results suggest that topic information can be
successfully used for the detection of argumentative sentences, at least for
corpora used for evaluation.
Our approach has been evaluated on two English corpora, the first of which
contains 90 persuasive essays, while the second is a collection of 340
documents from user generated content.},
 address = {Copenhagen, Denmark},
 author = {Ferrara, Alfio and Montanelli, Stefano and Petasis, Georgios},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5113},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {97--107},
 publisher = {Association for Computational Linguistics},
 title = {Unsupervised Detection of Argumentative Units though Topic Modeling Techniques},
 year = {2017}
}

@inproceedings{W17-5114,
 abstract = {In this paper we consider the insights that can be gained by considering large
scale argument networks and the complex interactions between their constituent
propositions. We investigate metrics for analysing properties of these
networks, illustrating these using a corpus of arguments taken from the 2016 US
Presidential Debates. We present techniques for determining these features
directly from natural language text and show that there is a strong correlation
between these automatically identified features and the argumentative structure
contained within the text. Finally, we combine these metrics with argument
mining techniques and show how the identification of argumentative relations
can be improved by considering the larger context in which they occur.},
 address = {Copenhagen, Denmark},
 author = {Lawrence, John and Reed, Chris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5114},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {108--117},
 publisher = {Association for Computational Linguistics},
 title = {Using Complex Argumentative Interactions to Reconstruct the Argumentative Structure of Large-Scale Debates},
 year = {2017}
}

@inproceedings{W17-5115,
 abstract = {The segmentation of an argumentative text into argument units and their
non-argumentative counterparts is the first step in identifying the
argumentative structure of the text. Despite its importance for argument
mining, unit segmentation has been approached only sporadically so far. This
paper studies the major parameters of unit segmentation systematically. We
explore the effectiveness of various features, when capturing words separately, along with their neighbors, or even along with the entire text. Each such
context is reflected by one machine learning model that we evaluate within and
across three domains of texts. Among the models, our new deep learning approach
capturing the entire text turns out best within all domains, with an F-score of
up to 88.54. While structural features generalize best across domains, the
domain transfer remains hard, which points to major challenges of unit
segmentation.},
 address = {Copenhagen, Denmark},
 author = {Ajjour, Yamen and Chen, Wei-Fan and Kiesel, Johannes and Wachsmuth, Henning and Stein, Benno},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5115},
 booktitle = {Proceedings of the 4th Workshop on Argument Mining},
 month = {September},
 pages = {118--128},
 publisher = {Association for Computational Linguistics},
 title = {Unit Segmentation of Argumentative Texts},
 year = {2017}
}

@inproceedings{W17-5201,
 abstract = {Sarcasm is a form of verbal irony that is intended to express contempt or
ridicule. Often quoted as a challenge to sentiment analysis, sarcasm involves
use of words of positive or no polarity to convey negative sentiment.
Incongruity has been observed to be at the heart of sarcasm understanding in
humans. Our work in sarcasm detection identifies different forms of incongruity
and employs different machine learning techniques to capture them. This talk
will describe the approach, datasets and challenges in sarcasm detection using
different forms of incongruity.
We identify two forms of incongruity: incongruity which can be understood based
on the target text and common background knowledge, and incongruity which can
be understood based on the target text and additional, specific context. The
former involves use of sentiment-based features, word embeddings, and topic
models. The latter involves creation of author's historical context based on
their historical data, and creation of conversational context for sarcasm
detection of dialogue.},
 address = {Copenhagen, Denmark},
 author = {Joshi, Aditya},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5201},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {1},
 publisher = {Association for Computational Linguistics},
 title = {Detecting Sarcasm Using Different Forms Of Incongruity},
 year = {2017}
}

@inproceedings{W17-5202,
 abstract = {There has been a good amount of progress in sentiment analysis over
the past 10 years, including the proposal of new methods and the
creation of benchmark datasets. In some papers, however, there is a
tendency to compare models only on one or two datasets, either
because of time restraints or because the model is tailored to a
specific task. Accordingly, it is hard to understand how well a
certain model generalizes across different tasks and datasets. In
this paper, we contribute to this situation by comparing several
models on six different benchmarks, which belong to different
domains and additionally have different levels of granularity
(binary, 3-class, 4-class and 5-class). We show that Bi-LSTMs
perform well across datasets and that both LSTMs and Bi-LSTMs are
particularly good at fine-grained sentiment tasks (\ie, with more
than two classes). Incorporating sentiment information
into word embeddings during training gives good results for datasets
that are lexically similar to the training data. With our
experiments, we contribute to a better understanding of the
performance of different model architectures on different data
sets. Consequently, we detect
novel state-of-the-art results on the \textit{SenTube} datasets.},
 address = {Copenhagen, Denmark},
 author = {Barnes, Jeremy and Klinger, Roman and Schulte im Walde, Sabine},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5202},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {2--12},
 publisher = {Association for Computational Linguistics},
 title = {Assessing State-of-the-Art Sentiment Models on State-of-the-Art Sentiment Datasets},
 year = {2017}
}

@inproceedings{W17-5203,
 abstract = {There is a rich variety of data sets for sentiment analysis
(viz.,~polarity and subjectivity classification). For the more
challenging task of detecting discrete emotions following the
definitions of Ekman and Plutchik, however, there are much fewer
data sets, and notably no resources for the social media
domain. This paper contributes to closing this gap by extending the
\textit{SemEval 2016 stance and sentiment dataset} with emotion
annotation. We (a) analyse annotation reliability and annotation
merging; (b) investigate the relation between emotion annotation and
the other annotation layers (stance, sentiment); (c) report
modelling results as a baseline for future work.},
 address = {Copenhagen, Denmark},
 author = {Schuff, Hendrik and Barnes, Jeremy and Mohme, Julian and Pad\'{o}, Sebastian and Klinger, Roman},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5203},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {13--23},
 publisher = {Association for Computational Linguistics},
 title = {Annotation, Modelling and Analysis of Fine-Grained Emotions on a Stance and Sentiment Detection Corpus},
 year = {2017}
}

@inproceedings{W17-5204,
 abstract = {Social media are used by an increasing number of political actors. A
small subset of these is interested in pursuing extremist motives
such as mobilization, recruiting or radicalization activities. In
order to counteract these trends, online providers and state
institutions reinforce their monitoring efforts, mostly relying on
manual workflows. We propose a machine learning approach
to support manual attempts towards identifying right-wing extremist
content in German Twitter profiles. Based on a fine-grained
conceptualization of right-wing extremism, we frame the task as
ranking each individual profile on a continuum spanning different
degrees of right-wing extremism, based on a nearest neighbour
approach. A quantitative evaluation reveals that our ranking model
yields robust performance (up to 0.81 F$\_1$ score) when being used
for predicting discrete class labels. At the same time, the model
provides plausible continuous ranking scores for a small
sample of borderline cases at the division of right-wing extremism
and New Right political movements.},
 address = {Copenhagen, Denmark},
 author = {Hartung, Matthias and Klinger, Roman and Schmidtke, Franziska and Vogel, Lars},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5204},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {24--33},
 publisher = {Association for Computational Linguistics},
 title = {Ranking Right-Wing Extremist Social Media Profiles by Similarity to Democratic and Extremist Groups},
 year = {2017}
}

@inproceedings{W17-5205,
 abstract = {We present the first shared task on detecting the intensity of emotion felt by
the speaker of a tweet. We create the first datasets of tweets annotated for
anger, fear, joy, and sadness intensities using a technique called best--worst
scaling (BWS). We show that the annotations lead to reliable fine-grained
intensity scores (rankings of tweets by intensity). The data was partitioned
into training, development, and test sets for the competition. Twenty-two
teams participated in the shared task, with the best system obtaining a Pearson
correlation of 0.747 with the gold intensity scores. We summarize the machine
learning setups, resources, and tools used by the participating teams, with a
focus on the techniques and resources that are particularly useful for the
task. The emotion intensity dataset and the shared task are helping improve our
understanding of how we convey more or less intense emotions through language.},
 address = {Copenhagen, Denmark},
 author = {Mohammad, Saif and Bravo-Marquez, Felipe},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5205},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {34--49},
 publisher = {Association for Computational Linguistics},
 title = {WASSA-2017 Shared Task on Emotion Intensity},
 year = {2017}
}

@inproceedings{W17-5206,
 abstract = {Our submission to the WASSA-2017 shared task on the prediction of emotion
intensity in tweets is a supervised learning method with extended lexicons of
affective norms. We combine three main information sources in a random forrest
regressor, namely (1), manually created resources, (2) automatically extended
lexicons, and (3) the output of a neural network (CNN-LSTM) for sentence
regression. All three feature sets perform similarly well in isolation ({\^a} .67
macro average Pearson correlation). The combination achieves .72 on the
official test set (ranked 2nd out of 22 participants). Our analysis reveals
that performance is increased by providing cross-emotional intensity
predictions. The
automatic extension of lexicon features benefit from domain specific
embeddings.
Complementary ratings for affective norms increase the impact of lexicon
features. Our resources (ratings for 1.6 million twitter specific words) and
our implementation is publicly available at
http://www.ims.uni-stuttgart.de/data/ims\_emoint.},
 address = {Copenhagen, Denmark},
 author = {K\"{o}per, Maximilian and Kim, Evgeny and Klinger, Roman},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5206},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {50--57},
 publisher = {Association for Computational Linguistics},
 title = {IMS at EmoInt-2017: Emotion Intensity Prediction with Affective Norms, Automatically Extended Resources and Deep Learning},
 year = {2017}
}

@inproceedings{W17-5207,
 abstract = {The paper describes the best performing system for EmoInt - a shared task to
predict the intensity of emotions in tweets. Intensity is a real valued score, between 0 and 1. The emotions are classified as - anger, fear, joy and sadness.
We apply three different deep neural network based models, which approach the
problem from essentially different directions. Our final performance quantified
by an average pearson correlation score of 74.7 and an average spearman
correlation score of 73.5 is obtained using an ensemble of the three models. We
outperform the baseline model of the shared task by 9.9\% and 9.4\% pearson and
spearman correlation scores respectively.},
 address = {Copenhagen, Denmark},
 author = {Goel, Pranav and Kulshreshtha, Devang and Jain, Prayas and Shukla, Kaushal Kumar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5207},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {58--65},
 publisher = {Association for Computational Linguistics},
 title = {Prayas at EmoInt 2017: An Ensemble of Deep Neural Architectures for Emotion Intensity Prediction in Tweets},
 year = {2017}
}

@inproceedings{W17-5208,
 abstract = {Mining arguments from natural language texts, parsing argumentative structures, and assessing argument quality are among the recent challeng-es tackled in
computational argumentation. While advanced deep learning models provide
state-of-the-art performance in many of these tasks, much attention is also
paid to the underly-ing fundamental questions. How are arguments expressed in
natural language across genres and domains? What is the essence of an
argument's claim? Can we reliably annotate convincingness of an argument? How
can we approach logic and common-sense reasoning in argumentation? This talk
highlights some recent advances in computa-tional argumentation and shows why
researchers must be both "surfers" and "scuba divers".},
 address = {Copenhagen, Denmark},
 author = {Gurevych, Iryna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5208},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {66},
 publisher = {Association for Computational Linguistics},
 title = {Latest News in Computational Argumentation: Surfing on the Deep Learning Wave, Scuba Diving in the Abyss of Fundamental Questions},
 year = {2017}
}

@inproceedings{W17-5209,
 abstract = {Lexicon-based methods using syntactic rules for polarity classification rely on
parsers that are dependent on the language and on  treebank guidelines. Thus, rules are also dependent and require adaptation, especially in multilingual
scenarios. We tackle this challenge in the context of the Iberian Peninsula, releasing the first symbolic syntax-based Iberian system with rules shared
across five official languages: Basque, Catalan, Galician, Portuguese and
Spanish. The model is made available.},
 address = {Copenhagen, Denmark},
 author = {Vilares, David and Garcia, Marcos and Alonso, Miguel A. and G\'{o}mez-Rodr\'{i}guez, Carlos},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5209},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {67--73},
 publisher = {Association for Computational Linguistics},
 title = {Towards Syntactic Iberian Polarity Classification},
 year = {2017}
}

@inproceedings{W17-5210,
 abstract = {Claims are the building blocks of arguments and the reasons underpinning
opinions, thus analyzing claims is important for both argumentation mining and
opinion mining. We propose a framework for representing claims as
microstructures, which express the beliefs, judgments, and policies about the
relations between domain-specific concepts. In a proof-of-concept study, we
manually build microstructures for over 800 claims extracted from an online
debate. We test the so-obtained microstructures on the task of claim stance
classification, achieving considerable improvements over text-based baselines.
Author{1}{Affiliation}},
 address = {Copenhagen, Denmark},
 author = {Boltuzic, Filip and \v{S}najder, Jan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5210},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {74--80},
 publisher = {Association for Computational Linguistics},
 title = {Toward Stance Classification Based on Claim Microstructures},
 year = {2017}
}

@inproceedings{W17-5211,
 abstract = {Different theories posit different sources for feelings of well-being and
happiness.  Appraisal theory grounds our emotional responses in our goals and
desires and their fulfillment, or lack of fulfillment. Self-Determination
theory posits that the basis for well-being rests on our assessments of our
competence, autonomy and social connection. And surveys that measure happiness
empirically note that people require their basic needs to be met for food and
shelter, but beyond that tend to be happiest when socializing, eating or having
sex. We analyze a corpus of private micro-blogs from a well-being application
called Echo, where users label each written post about daily events with a
happiness score between 1 and 9.  Our goal is to ground the linguistic
descriptions of events that users experience in theories of well-being and
happiness, and then examine the extent to which different theoretical accounts
can explain the variance in the happiness scores.  We show that recurrent event
types, such as obligation and
incompetence, which affect people's feelings of well-being are not captured in
current lexical or semantic resources.},
 address = {Copenhagen, Denmark},
 author = {Wu, Jiaqi and Walker, Marilyn and Anand, Pranav and Whittaker, Steve},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5211},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {81--91},
 publisher = {Association for Computational Linguistics},
 title = {Linguistic Reflexes of Well-Being and Happiness in Echo},
 year = {2017}
}

@inproceedings{W17-5212,
 abstract = {Consumer spending is an important macroeconomic indicator that is used by
policy-makers to judge the health of an economy. In this paper we present a
novel method for predicting future consumer spending from social media data. In
contrast to previous work that largely relied on sentiment analysis, the
proposed method models consumer spending from purchase intentions found on
social media. Our experiments with time series analysis models and
machine-learning regression models reveal utility of this data for making
short-term forecasts of consumer spending: for three- and seven-day horizons, prediction variables derived from social media help to improve forecast
accuracy by 11% to 18% for all the three models, in comparison to models that
used only autoregressive predictors.},
 address = {Copenhagen, Denmark},
 author = {Pekar, Viktor and Binner, Jane},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5212},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {92--101},
 publisher = {Association for Computational Linguistics},
 title = {Forecasting Consumer Spending from Purchase Intentions Expressed on Social Media},
 year = {2017}
}

@inproceedings{W17-5213,
 abstract = {Video reviews are the natural evolution of written product reviews. In this
paper we target this phenomenon and introduce the first dataset created from
closed captions of YouTube product review videos as well as a new attention-RNN
model for aspect extraction and joint aspect extraction and sentiment
classification. Our model provides state-of-the-art performance on aspect
extraction without requiring the usage of hand-crafted features on the SemEval
ABSA corpus, while it outperforms the baseline on the joint task. In our
dataset, the attention-RNN model outperforms the baseline for both tasks, but
we observe important performance drops for all models in comparison to SemEval.
These results, as well as further experiments on domain adaptation for aspect
extraction, suggest that differences between speech and written text, which
have been discussed extensively in the literature, also extend to the domain of
product reviews, where they are relevant for fine-grained opinion mining.},
 address = {Copenhagen, Denmark},
 author = {Marrese-Taylor, Edison and Balazs, Jorge and Matsuo, Yutaka},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5213},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {102--111},
 publisher = {Association for Computational Linguistics},
 title = {Mining fine-grained opinions on closed captions of YouTube videos with an attention-RNN},
 year = {2017}
}

@inproceedings{W17-5214,
 abstract = {Emotions can be triggered by various factors. According to the Appraisal
Theories (De Rivera, 1977; Frijda, 1986; Ortony et al., 1988; Johnson-Laird and
Oatley, 1989) emotions are elicited and differentiated on the basis of the
cognitive evaluation of the personal significance of a situation, object or
event based on {\^a}appraisal criteria{\^a} (intrinsic characteristics of objects
and events, significance of events to individual needs and goals, individual{\^a}s ability to cope with the consequences of the event, compatibility of event with social or personal standards, norms and values).
These differences in values can trigger reactions such as anger, disgust
(contempt), sadness, etc., because these behaviors are evaluated by the public
as being incompatible with their social/personal standards, norms or values.
Such arguments are frequently present both in mainstream media, as well as
social media, building a society-wide view, attitude and emotional reaction
towards refugees/immigrants. In this demo, I will talk about experiments to
annotate and detect factual arguments that are linked to human
needs/motivations from text and in consequence trigger emotion in the media
audience and propose a new task for next year's WASSA.},
 address = {Copenhagen, Denmark},
 author = {Balahur, Alexandra},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5214},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {112},
 publisher = {Association for Computational Linguistics},
 title = {Understanding human values and their emotional effect},
 year = {2017}
}

@inproceedings{W17-5215,
 abstract = {In this work, we present a first attempt to investigate multi-emoji expressions
and whether they behave similarly to multiword expressions in terms of
non-compositionality. We focus on the combination of the frog and the hot
beverage emoji, but also show some preliminary results for other
non-compositional emoji combinations. We use off-the-shelf sentiment analysers
as well as manual classifications to approach the compositionality of these
emoji combinations.},
 address = {Copenhagen, Denmark},
 author = {Padilla L\'{o}pez, Rebeca and Cap, Fabienne},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5215},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {113--117},
 publisher = {Association for Computational Linguistics},
 title = {Did you ever read about Frogs drinking Coffee? Investigating the Compositionality of Multi-Emoji Expressions},
 year = {2017}
}

@inproceedings{W17-5216,
 abstract = {In this paper we present an annotated corpus created with the aim of analyzing
the
informative behaviour of emoji -- an issue of importance for sentiment
analysis and
natural language processing. The corpus consists of 2475 tweets all containing
at
least one emoji, which has been annotated using one of the three possible
classes: Redundant, Non Redundant, and Non Redundant + POS. We explain how the
corpus
was collected, describe the annotation procedure and the interface developed
for the task. We provide an analysis of the corpus, considering also possible
predictive features, discuss the problematic aspects of the annotation, and
suggest future improvements.},
 address = {Copenhagen, Denmark},
 author = {Donato, Giulia and Paggio, Patrizia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5216},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {118--126},
 publisher = {Association for Computational Linguistics},
 title = {Investigating Redundancy in Emoji Use: Study on a Twitter Based Corpus},
 year = {2017}
}

@inproceedings{W17-5217,
 abstract = {Patients turn to Online Health Communities not only for information on specific
conditions but also for emotional support. Previous research has indicated that
the progression of emotional status can be studied through the linguistic
patterns of an individual's posts.  We analyze a real-world dataset from the
Mental Health section of HealthBoards.com. Estimated from the word usages in
their posts, we find that the emotional progress across patients vary widely.
We study the problem of predicting a patient's emotional status in the future
from her past posts and we propose a Recurrent Neural Network (RNN) based
architecture to address it.  We find that the future emotional status can be
predicted with reasonable accuracy given her historical posts and participation
features. Our evaluation results demonstrate the efficacy of our proposed
architecture, by outperforming state-of-the-art approaches with over 0.13
reduction in Mean Absolute Error.},
 address = {Copenhagen, Denmark},
 author = {Halder, Kishaloy and Poddar, Lahari and Kan, Min-Yen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5217},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {127--135},
 publisher = {Association for Computational Linguistics},
 title = {Modeling Temporal Progression of Emotional Status in Mental Health Forum: A Recurrent Neural Net Approach},
 year = {2017}
}

@inproceedings{W17-5218,
 abstract = {This paper presents an integrated ABSA pipeline for Dutch that has been
developed and tested on qualitative user feedback coming from three domains:
retail, banking and human resources. The two latter domains provide
service-oriented data, which has not been investigated before in ABSA. By
performing in-domain and cross-domain experiments the validity of our approach
was investigated. We show promising results for the three ABSA subtasks, aspect
term extraction, aspect category classification and aspect polarity
classification.},
 address = {Copenhagen, Denmark},
 author = {De Clercq, Orphee and Lefever, Els and Jacobs, Gilles and Carpels, Tijl and Hoste, Veronique},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5218},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {136--142},
 publisher = {Association for Computational Linguistics},
 title = {Towards an integrated pipeline for aspect-based sentiment analysis in various domains},
 year = {2017}
}

@inproceedings{W17-5219,
 abstract = {As a discipline of Natural Language Processing, Sentiment Analysis is used to
extract and analyze subjective information present in natural language data.
The task of Sentiment Analysis has acquired wide commercial uses including
social media monitoring tasks, survey responses, review systems, etc. Languages
like English have several resources which aid in the task of Sentiment
Analysis. SentiWordNet and Subjectivity WordList are examples of such tools and
resources. With more data being available in native vernacular, language-specific SentiWordNet(s) have become essential. For resource poor
languages, creating such SentiWordNet(s) is a difficult task to achieve. One
solution is to use available resources in English and translate the final
source lexicon to target lexicon via machine translation. Machine translation
systems for the English-Odia language pair have not yet been developed. In this
paper, we discuss a method to create a SentiWordNet for Odia, which is
resource-poor, by only using resources which are currently available for Indian
languages. The lexicon created, would serve as a tool for Sentiment Analysis
related task specific to Odia data.},
 address = {Copenhagen, Denmark},
 author = {Mohanty, Gaurav and Kannan, Abishek and Mamidi, Radhika},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5219},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {143--148},
 publisher = {Association for Computational Linguistics},
 title = {Building a SentiWordNet for Odia},
 year = {2017}
}

@inproceedings{W17-5220,
 abstract = {With the advent of word embeddings, lexicons are no longer fully utilized for
sentiment analysis although they still provide important features in the
traditional setting. This paper introduces a novel approach to sentiment
analysis that integrates lexicon embeddings and an attention mechanism into
Convolutional Neural Networks. Our approach performs separate convolutions for
word and lexicon embeddings and provides a global view of the document using
attention. Our models are experimented on both the SemEval'16 Task 4 dataset
and the Stanford Sentiment Treebank and show comparative or better results
against the existing state-of-the-art systems. Our analysis shows that lexicon
embeddings allow building high-performing models with much smaller word
embeddings, and the attention mechanism effectively dims out noisy words for
sentiment analysis.},
 address = {Copenhagen, Denmark},
 author = {Shin, Bonggun and Lee, Timothy and Choi, Jinho D.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5220},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {149--158},
 publisher = {Association for Computational Linguistics},
 title = {Lexicon Integrated CNN Models with Attention for Sentiment Analysis},
 year = {2017}
}

@inproceedings{W17-5221,
 abstract = {Recently, a technique called Layer-wise
Relevance Propagation (LRP) was shown
to deliver insightful explanations in the
form of input space relevances for un-
derstanding feed-forward neural network
classification decisions. In the present
work, we extend the usage of LRP to
recurrent neural networks. We propose
a specific propagation rule applicable to
multiplicative connections as they arise
in recurrent network architectures such
as LSTMs and GRUs. We apply our
technique to a word-based bi-directional
LSTM model on a five-class sentiment
prediction task, and evaluate the result-
ing LRP relevances both qualitatively and
quantitatively, obtaining better results than
a gradient-based related method which
was used in previous work.},
 address = {Copenhagen, Denmark},
 author = {Arras, Leila and Montavon, Gr\'{e}goire and M\"{u}ller, Klaus-Robert and Samek, Wojciech},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5221},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {159--168},
 publisher = {Association for Computational Linguistics},
 title = {Explaining Recurrent Neural Network Predictions in Sentiment Analysis},
 year = {2017}
}

@inproceedings{W17-5222,
 abstract = {The WASSA 2017 EmoInt shared task has
the goal to predict emotion intensity values
of tweet messages. Given the text of
a tweet and its emotion category (anger, joy, fear, and sadness), the participants
were asked to build a system that assigns
emotion intensity values. Emotion intensity
estimation is a challenging problem
given the short length of the tweets, the
noisy structure of the text and the lack
of annotated data. To solve this problem, we developed an ensemble of two neural
models, processing input on the character.
and word-level with a lexicon-driven
system. The correlation scores across all
four emotions are averaged to determine
the bottom-line competition metric, and
our system ranks place forth in full intensity
range and third in 0.5-1 range of intensity
among 23 systems at the time of
writing (June 2017).},
 address = {Copenhagen, Denmark},
 author = {Lakomkin, Egor and Bothe, Chandrakant and Wermter, Stefan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5222},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {169--174},
 publisher = {Association for Computational Linguistics},
 title = {GradAscent at EmoInt-2017: Character and Word Level Recurrent Neural Network Models for Tweet Emotion Intensity Detection},
 year = {2017}
}

@inproceedings{W17-5223,
 abstract = {This paper describes the entry NUIG in the WASSA 2017 (8th Workshop on
Computational Approaches to Subjectivity, Sentiment \& Social Media Analysis)
shared task on emotion recognition.
The NUIG system used an SVR (SVM regression) and BLSTM ensemble, utilizing
primarily n-grams (for SVR features) and tweet word embeddings (for BLSTM
features). Experiments were carried out on several other candidate features, some of which were added to the SVR model.
Parameter selection for the SVR model was run as a grid search whilst
parameters for the BLSTM model were selected through a non-exhaustive ad-hoc
search.},
 address = {Copenhagen, Denmark},
 author = {Andryushechkin, Vladimir and Wood, Ian and O' Neill, James},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5223},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {175--179},
 publisher = {Association for Computational Linguistics},
 title = {NUIG at EmoInt-2017: BiLSTM and SVR Ensemble to Detect Emotion Intensity},
 year = {2017}
}

@inproceedings{W17-5224,
 abstract = {Aspect Term Extraction (ATE) identifies opinionated aspect terms in texts and
is one of the tasks in the SemEval Aspect Based Sentiment Analysis (ABSA)
contest. The small amount of available datasets for supervised ATE and the
costly human annotation for aspect term labelling give rise to the need for
unsupervised ATE. In this paper, we introduce an architecture that achieves
top-ranking performance for supervised ATE. Moreover, it can be used
efficiently as feature extractor and classifier for unsupervised ATE. Our
second contribution is a method to automatically construct datasets for ATE. We
train a classifier on our automatically labelled datasets and evaluate it on
the human annotated SemEval ABSA test sets. Compared to a strong rule-based
baseline, we obtain a dramatically higher F-score and attain precision values
above 80%. Our unsupervised method beats the supervised ABSA baseline from
SemEval, while preserving high precision scores.},
 address = {Copenhagen, Denmark},
 author = {Giannakopoulos, Athanasios and Musat, Claudiu and Hossmann, Andreea and Baeriswyl, Michael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5224},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {180--188},
 publisher = {Association for Computational Linguistics},
 title = {Unsupervised Aspect Term Extraction with B-LSTM \& CRF using Automatically Labelled Datasets},
 year = {2017}
}

@inproceedings{W17-5225,
 abstract = {Linguistic Inquiry and Word Count (LIWC) is a rich dictionary that map words
into several psychological categories such as Affective, Social, Cognitive, Perceptual and Biological processes. In this work, we have used LIWC
psycholinguistic categories to train regression models and predict emotion
intensity in tweets for the EmoInt-2017 task. Results show that LIWC features
may boost emotion intensity prediction on the basis of a low dimension set.},
 address = {Copenhagen, Denmark},
 author = {Santos, Henrique and Vieira, Renata},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5225},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {189--192},
 publisher = {Association for Computational Linguistics},
 title = {PLN-PUCRS at EmoInt-2017: Psycholinguistic features for emotion intensity prediction in tweets},
 year = {2017}
}

@inproceedings{W17-5226,
 abstract = {This paper describes our approach to the Emotion Intensity shared task. A
parallel
architecture of Convolutional Neural Network (CNN) and Long short term memory
networks (LSTM) alongwith two sets of features are extracted which aid the
network
in judging emotion intensity. Experiments on different models and various
features
sets are described and analysis on results has also been presented.},
 address = {Copenhagen, Denmark},
 author = {Meisheri, Hardik and Saha, Rupsa and Sinha, Priyanka and Dey, Lipika},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5226},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {193--199},
 publisher = {Association for Computational Linguistics},
 title = {Textmining at EmoInt-2017: A Deep Learning Approach to Sentiment Intensity Scoring of English Tweets},
 year = {2017}
}

@inproceedings{W17-5227,
 abstract = {In this paper, we present a system that uses a convolutional neural network
with long short-term memory (CNN-LSTM) model to complete the task. The CNN-LSTM
model has two combined parts: CNN extracts local n-gram features within tweets
and LSTM composes the features to capture long-distance dependency across
tweets. Additionally, we used other three models (CNN, LSTM, BiLSTM) as
baseline algorithms. Our introduced model showed good performance in the
experimental results.},
 address = {Copenhagen, Denmark},
 author = {Zhang, You and Yuan, Hang and Wang, Jin and Zhang, Xuejie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5227},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {200--204},
 publisher = {Association for Computational Linguistics},
 title = {YNU-HPCC at EmoInt-2017: Using a CNN-LSTM Model for Sentiment Intensity Prediction},
 year = {2017}
}

@inproceedings{W17-5228,
 abstract = {The paper describes experiments on estimating emotion intensity in tweets
using a generalized regressor system. The system combines various independent
feature extractors, trains them on general regressors and finally combines
the best performing models to create an ensemble. The pro- posed system stood
3rd out of 22 systems in leaderboard of WASSA-2017 Shared Task on Emotion
Intensity.},
 address = {Copenhagen, Denmark},
 author = {Duppada, Venkatesh and Hiray, Sushant},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5228},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {205--211},
 publisher = {Association for Computational Linguistics},
 title = {Seernet at EmoInt-2017: Tweet Emotion Intensity Estimator},
 year = {2017}
}

@inproceedings{W17-5229,
 abstract = {This paper describes the system that we submitted as part of our participation
in the shared task on Emotion Intensity (EmoInt-2017). We propose a Long short
term memory (LSTM) based architecture cascaded with Support Vector Regressor
(SVR) for intensity prediction. We also employ Particle Swarm Optimization
(PSO) based feature selection algorithm for obtaining an optimized feature set
for training and evaluation. System evaluation shows interesting results on the
four emotion datasets i.e. anger, fear, joy and sadness. In comparison to the
other participating teams our system was ranked 5th in the competition.},
 address = {Copenhagen, Denmark},
 author = {Akhtar, Md Shad and Sawant, Palaash and Ekbal, Asif and Pawar, Jyoti and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5229},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {212--218},
 publisher = {Association for Computational Linguistics},
 title = {IITP at EmoInt-2017: Measuring Intensity of Emotions using Sentence Embeddings and Optimized Features},
 year = {2017}
}

@inproceedings{W17-5230,
 abstract = {In this paper, we describe a method to predict emotion intensity in tweets.
Our approach is an ensemble of three regression methods. The first method uses
content-based features (hashtags, emoticons, elongated words, etc.). The second
method considers word n-grams and character n-grams for training. The final
method uses lexicons, word embeddings, word n-grams, character n-grams for
training the model. An ensemble of these three methods gives better performance
than individual methods. We applied our method on WASSA emotion dataset.
Achieved results are as follows: average Pearson correlation is 0.706, average
Spearman correlation is 0.696, average Pearson correlation for gold scores in
range 0.5 to 1 is 0.539, and average Spearman correlation for gold scores in
range 0.5 to 1 is 0.514.},
 address = {Copenhagen, Denmark},
 author = {Madisetty, Sreekanth and Desarkar, Maunendra Sankar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5230},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {219--224},
 publisher = {Association for Computational Linguistics},
 title = {NSEmo at EmoInt-2017: An Ensemble to Predict Emotion Intensity in Tweets},
 year = {2017}
}

@inproceedings{W17-5231,
 abstract = {In this paper we describe Tecnolengua Group's participation in the shared task
on emotion intensity at WASSA 2017. We used the Lingmotif tool and a new, complementary tool, Lingmotif Learn, which we developed for this occasion. We
based our intensity predictions for the four test datasets entirely on
Lingmotif's TSS (text sentiment score) feature. We also developed mechanisms
for dealing with the idiosyncrasies of Twitter text. Results were comparatively
poor, but the experience meant a good opportunity for us to identify issues in
our score calculation for short texts, a genre for which the Lingmotif tool was
not originally designed.},
 address = {Copenhagen, Denmark},
 author = {Moreno-Ortiz, Antonio},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5231},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {225--232},
 publisher = {Association for Computational Linguistics},
 title = {Tecnolengua Lingmotif at EmoInt-2017: A lexicon-based approach},
 year = {2017}
}

@inproceedings{W17-5232,
 abstract = {In this paper we describe a deep learning system that has been designed and
built for the WASSA 2017 Emotion Intensity Shared Task. We introduce a
representation learning approach based on inner attention on top of an RNN.
Results show that our model offers good capabilities and is able to
successfully identify emotion-bearing words to predict intensity without
leveraging on lexicons, obtaining the 13t place among 22 shared task
competitors.},
 address = {Copenhagen, Denmark},
 author = {Marrese-Taylor, Edison and Matsuo, Yutaka},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5232},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {233--237},
 publisher = {Association for Computational Linguistics},
 title = {EmoAtt at EmoInt-2017: Inner attention sentence embedding for Emotion Intensity},
 year = {2017}
}

@inproceedings{W17-5233,
 abstract = {The EmoInt-2017 task aims to determine a continuous numerical value
representing the intensity to which an emotion is expressed in a tweet.
Compared to classification tasks that identify 1 among n emotions for a tweet, the present task can provide more fine-grained (real-valued) sentiment
analysis. This paper presents a system that uses a bi-directional LSTM-CNN
model to complete the competition task. Combining bi-directional LSTM and CNN, the prediction process considers both global information in a tweet and local
important information. The proposed method ranked sixth among twenty-one teams
in terms of Pearson Correlation Coefficient.},
 address = {Copenhagen, Denmark},
 author = {He, Yuanye and Yu, Liang-Chih and Lai, K. Robert and Liu, Weiyi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5233},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {238--242},
 publisher = {Association for Computational Linguistics},
 title = {YZU-NLP at EmoInt-2017: Determining Emotion Intensity Using a Bi-directional LSTM-CNN Model},
 year = {2017}
}

@inproceedings{W17-5234,
 abstract = {In this paper, we present a novel ensemble learning architecture for emotion
intensity analysis, particularly a novel framework of ensemble method. The
ensemble method has two stages and each stage includes several single machine
learning models. In stage1, we employ both linear and nonlinear regression
models to obtain a more diverse emotion intensity representation. In stage2, we
use two regression models including linear regression and XGBoost. The result
of stage1 serves as the input of stage2, so the two different type models
(linear and non-linear) in stage2 can describe the input in two opposite
aspects. We also added a method for analyzing and splitting multi-words
hashtags and appending them to the emotion intensity corpus before feeding it
to our model. Our model achieves 0.571 Pearson-measure for the average of four
emotions.},
 address = {Copenhagen, Denmark},
 author = {Jiang, Song and Han, Xiaotian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5234},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {243--248},
 publisher = {Association for Computational Linguistics},
 title = {DMGroup at EmoInt-2017: Emotion Intensity Using Ensemble Method},
 year = {2017}
}

@inproceedings{W17-5235,
 abstract = {This paper describes the UWaterloo affect prediction system developed for
EmoInt-2017. We delve into our feature selection approach for affect intensity, affect presence, sentiment intensity and sentiment presence lexica alongside
pre-trained word embeddings, which are utilized to extract emotion intensity
signals from tweets in an ensemble learning approach. The system employs
emotion specific model training, and utilizes distinct models for each of the
emotion corpora in isolation. Our system utilizes gradient boosted regression
as the primary learning technique to predict the final emotion intensities.},
 address = {Copenhagen, Denmark},
 author = {John, Vineet and Vechtomova, Olga},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5235},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {249--254},
 publisher = {Association for Computational Linguistics},
 title = {UWat-Emote at EmoInt-2017: Emotion Intensity Detection using Affect Clues, Sentiment Polarity and Word Embeddings},
 year = {2017}
}

@inproceedings{W17-5236,
 abstract = {This paper presents the combined LIPN-UAM participation in the WASSA 2017
Shared Task on Emotion Intensity. In particular, the paper provides some
highlights on the Tweetaneuse system that was presented to the shared task. We
combined lexicon-based features with sentence-level vector representations to
implement a random forest regressor.},
 address = {Copenhagen, Denmark},
 author = {Buscaldi, Davide and Priego, Belem},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5236},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {255--258},
 publisher = {Association for Computational Linguistics},
 title = {LIPN-UAM at EmoInt-2017:Combination of Lexicon-based features and Sentence-level Vector Representations for Emotion Intensity Determination},
 year = {2017}
}

@inproceedings{W17-5237,
 abstract = {This working note presents the methodology used in deepCybErNet submission to
the shared task on Emotion Intensities in Tweets (EmoInt) WASSA-2017. The goal
of the task is to predict a real valued score in the range [0-1] for a
particular tweet with an emotion type. To do this, we used Bag-of-Words and
embedding based on recurrent network architecture. We have developed two
systems and experiments are conducted on the Emotion Intensity shared Task 1
data base at WASSA- 2017. A system which uses word embedding based on recurrent
network architecture has achieved highest 5 fold cross-validation accuracy.
This has used embedding with recurrent network to extract optimal features at
tweet level and logistic regression for prediction. These methods are highly
language independent and experimental results shows that the proposed methods
are apt for predicting a real valued score in than range [0-1] for a given
tweet with its emotion type.},
 address = {Copenhagen, Denmark},
 author = {R, Vinayakumar and b, premjith and s, sachin kumar and kp, soman and Poornachandran, Prabaharan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5237},
 booktitle = {Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {September},
 pages = {259--263},
 publisher = {Association for Computational Linguistics},
 title = {deepCybErNet at EmoInt-2017: Deep Emotion Intensities in Tweets},
 year = {2017}
}

@inproceedings{W17-5301,
 abstract = {This paper presents the results of the RepEval 2017 Shared Task, which
evaluated neural network sentence representation learning models on the
Multi-Genre Natural Language Inference corpus (MultiNLI) recently introduced by
Williams et al. (2017). All of the five participating teams beat the
bidirectional LSTM (BiLSTM) and continuous bag of words baselines reported in
Williams et al. The best single model used stacked BiLSTMs with residual
connections to extract sentence features and reached 74.5% accuracy on the
genre-matched test set. Surprisingly, the results of the competition were
fairly consistent across the genre-matched and genre-mismatched test sets, and
across subsets of the test data representing a variety of linguistic phenomena, suggesting that all of the submitted systems learned reasonably
domain-independent representations for sentence meaning.},
 address = {Copenhagen, Denmark},
 author = {Nangia, Nikita and Williams, Adina and Lazaridou, Angeliki and Bowman, Samuel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5301},
 booktitle = {Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP},
 month = {September},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {The RepEval 2017 Shared Task: Multi-Genre Natural Language Inference with Sentence Representations},
 year = {2017}
}

@inproceedings{W17-5302,
 abstract = {In this paper, we propose an alternative evaluating metric for word analogy
questions (A to B is as C to D) in word vector evaluation. Different from the
traditional method which predicts the fourth word by the given three, we
measure the similarity directly on the "relations" of two pairs of given words, just as shifting the relation vectors into a new analogy space. Cosine and
Euclidean distances are then calculated as measurements. Observation and
experiments shows the proposed analogy space evaluation could offer a more
comprehensive evaluating result on word vectors with word analogy questions.
Meanwhile, computational complexity are remarkably reduced by avoiding
traversing the vocabulary.},
 address = {Copenhagen, Denmark},
 author = {Che, Xiaoyin and Ring, Nico and Raschkowski, Willi and Yang, Haojin and Meinel, Christoph},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5302},
 booktitle = {Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP},
 month = {September},
 pages = {11--15},
 publisher = {Association for Computational Linguistics},
 title = {Traversal-Free Word Vector Evaluation in Analogy Space},
 year = {2017}
}

@inproceedings{W17-5303,
 abstract = {We introduce the cross-match test - an exact, distribution free, high-dimensional hypothesis test as an intrinsic evaluation metric for word
embeddings. We show that cross-match is an effective means of measuring the
distributional similarity between different vector representations and of
evaluating the statistical significance of different vector embedding models.
Additionally, we find that cross-match can be used to provide a quantitative
measure of linguistic similarity for selecting bridge languages for machine
translation. We demonstrate that the results of the hypothesis test align with
our expectations and note that the framework of two sample hypothesis testing
is not limited to word embeddings and can be extended to all vector
representations.},
 address = {Copenhagen, Denmark},
 author = {Gurnani, Nishant},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5303},
 booktitle = {Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP},
 month = {September},
 pages = {16--20},
 publisher = {Association for Computational Linguistics},
 title = {Hypothesis Testing based Intrinsic Evaluation of Word Embeddings},
 year = {2017}
}

@inproceedings{W17-5304,
 abstract = {This work presents a framework for word similarity evaluation grounded on
cognitive sciences experimental data. Word pair similarities are compared to
reaction times of subjects in large scale lexical decision and naming tasks
under semantic priming. Results show that GloVe embeddings lead to
significantly higher correlation with experimental measurements than other
controlled and off-the-shelf embeddings, and that the choice of a training
corpus is less important than that of the algorithm. Comparison of rankings
with other datasets shows that the cognitive phenomenon covers more aspects
than simply word relatedness or similarity.},
 address = {Copenhagen, Denmark},
 author = {Auguste, Jeremy and Rey, Arnaud and Favre, Benoit},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5304},
 booktitle = {Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP},
 month = {September},
 pages = {21--26},
 publisher = {Association for Computational Linguistics},
 title = {Evaluation of word embeddings against cognitive processes: primed reaction times in lexical decision and naming tasks},
 year = {2017}
}

@inproceedings{W17-5305,
 abstract = {Acquiring language provides a ubiquitous mode of communication, across humans
and robots. To this effect, distributional representations of words based on
co-occurrence statistics, have provided significant advancements ranging across
machine translation to comprehension. In this paper, we study the suitability
of using general purpose word-embeddings for language learning in robots. We
propose using text-based games as a proxy to evaluating word embedding on real
robots. Based in a risk-reward setting, we review the effectiveness of the
embeddings in navigating tasks in fantasy games, as an approximation to their
performance on more complex scenarios, like language assisted robot navigation.},
 address = {Copenhagen, Denmark},
 author = {Gulati, Anmol and Agrawal, Kumar Krishna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5305},
 booktitle = {Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP},
 month = {September},
 pages = {27--30},
 publisher = {Association for Computational Linguistics},
 title = {Playing with Embeddings : Evaluating embeddings for Robot Language Learning through MUD Games},
 year = {2017}
}

@inproceedings{W17-5306,
 abstract = {In this paper, we investigate the application of machine learning techniques
and word embeddings to the task of Recognizing Textual Entailment (RTE) in
Social Media. We look at a manually labeled dataset consisting of user
generated short texts posted on Twitter (tweets) and related to four recent
media events (the Charlie Hebdo shooting, the Ottawa shooting, the Sydney
Siege, and the German Wings crash) and test to what extent neural techniques
and embeddings are able to distinguish between tweets that entail or contradict
each other or that claim unrelated things. We obtain comparable results to the
state of the art in a train-test setting, but we show that, due to the noisy
aspect of the data, results plummet in an evaluation strategy crafted to better
simulate a real-life train-test scenario.},
 address = {Copenhagen, Denmark},
 author = {\c{S}ulea, Octavia-Maria},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5306},
 booktitle = {Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP},
 month = {September},
 pages = {31--35},
 publisher = {Association for Computational Linguistics},
 title = {Recognizing Textual Entailment in Twitter Using Word Embeddings},
 year = {2017}
}

@inproceedings{W17-5307,
 abstract = {The RepEval 2017 Shared Task aims to evaluate natural language understanding
models for sentence representation, in which a sentence is represented as a
fixed-length vector with neural networks and the quality of the representation
is tested with a natural language inference task. This paper describes our
system (alpha) that is ranked among the top in the Shared Task, on both the
in-domain test set (obtaining a 74.9% accuracy) and on the cross-domain test
set (also attaining a 74.9% accuracy), demonstrating that the model generalizes
well to the cross-domain data. Our model is equipped with intra-sentence
gated-attention composition which helps achieve a better performance. In
addition to submitting our model to the Shared Task, we have also tested it on
the Stanford Natural Language Inference (SNLI) dataset. We obtain an accuracy
of 85.5%, which is the best reported result on SNLI when cross-sentence
attention is not allowed, the same condition enforced in RepEval 2017.},
 address = {Copenhagen, Denmark},
 author = {Chen, Qian and Zhu, Xiaodan and Ling, Zhen-Hua and Wei, Si and Jiang, Hui and Inkpen, Diana},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5307},
 booktitle = {Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP},
 month = {September},
 pages = {36--40},
 publisher = {Association for Computational Linguistics},
 title = {Recurrent Neural Network-Based Sentence Encoder with Gated Attention for Natural Language Inference},
 year = {2017}
}

@inproceedings{W17-5308,
 abstract = {We present a simple sequential sentence encoder for multi-domain natural
language inference. Our encoder is based on stacked bidirectional LSTM-RNNs
with shortcut connections and fine-tuning of word embeddings. The overall
supervised model uses the above encoder to encode two input sentences into two
vectors, and then uses a classifier over the vector combination to label the
relationship between these two sentences as that of entailment, contradiction, or neural. Our Shortcut-Stacked sentence encoders achieve strong improvements
over existing encoders on matched and mismatched multi-domain natural language
inference (top single-model result in the EMNLP RepEval 2017 Shared Task
(Nangia et al., 2017)). Moreover, they achieve the new state-of-the-art
encoding result on the original SNLI dataset (Bowman et al., 2015).},
 address = {Copenhagen, Denmark},
 author = {Nie, Yixin and Bansal, Mohit},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5308},
 booktitle = {Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP},
 month = {September},
 pages = {41--45},
 publisher = {Association for Computational Linguistics},
 title = {Shortcut-Stacked Sentence Encoders for Multi-Domain Inference},
 year = {2017}
}

@inproceedings{W17-5309,
 abstract = {Natural language inference (NLI) is a central problem in language
understanding. End-to-end artificial neural networks have reached
state-of-the-art  performance in NLI field recently. In this paper, we propose
Character-level Intra Attention Network (CIAN) for the NLI task. In our model, we use the character-level convolutional network to replace the standard word
embedding layer, and we use the intra attention to capture the intra-sentence
semantics. The proposed CIAN model provides improved results based on a newly
published MNLI corpus.},
 address = {Copenhagen, Denmark},
 author = {Yang, Han and Costa-juss\`{a}, Marta R. and Fonollosa, Jos\'{e} A. R.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5309},
 booktitle = {Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP},
 month = {September},
 pages = {46--50},
 publisher = {Association for Computational Linguistics},
 title = {Character-level Intra Attention Network for Natural Language Inference},
 year = {2017}
}

@inproceedings{W17-5310,
 abstract = {In this paper we present the model used by the team Rivercorners for the 2017
RepEval shared task. First, our model separately encodes a pair of sentences
into variable-length representations by using a bidirectional LSTM. Later, it
creates fixed-length raw representations by means of simple aggregation
functions, which are then refined using an attention mechanism. Finally it
combines the refined representations of both sentences into a single vector to
be used for classification. With this model we obtained test accuracies of
72.057% and 72.055% in the matched and mismatched evaluation tracks
respectively, outperforming the LSTM baseline, and obtaining performances
similar to a model that relies on shared information between sentences (ESIM).
When using an ensemble both accuracies increased to 72.247% and 72.827%
respectively.},
 address = {Copenhagen, Denmark},
 author = {Balazs, Jorge and Marrese-Taylor, Edison and Loyola, Pablo and Matsuo, Yutaka},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5310},
 booktitle = {Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP},
 month = {September},
 pages = {51--55},
 publisher = {Association for Computational Linguistics},
 title = {Refining Raw Sentence Representations for Textual Entailment Recognition via Attention},
 year = {2017}
}

@inproceedings{W17-5311,
 abstract = {System using BiLSTM and max pooling. Embedding is enhanced by POS, character
and dependency info.},
 address = {Copenhagen, Denmark},
 author = {Vu, Hoa},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5311},
 booktitle = {Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP},
 month = {September},
 pages = {56--60},
 publisher = {Association for Computational Linguistics},
 title = {LCT-MALTA's Submission to RepEval 2017 Shared Task},
 year = {2017}
}

@inproceedings{W17-5401,
 abstract = {This paper presents a summary of the first Workshop on Building Linguistically
Generalizable Natural Language Processing Systems, and the associated Build It
Break It, The Language Edition shared task. The goal of this workshop was to
bring together researchers in NLP and linguistics with a carefully designed
shared task aimed at testing the generalizability of NLP systems beyond the
distributions of their training data. We describe the motivation, setup, and
participation of the shared task, provide discussion of some highlighted
results, and discuss lessons learned.},
 address = {Copenhagen, Denmark},
 author = {Ettinger, Allyson and Rao, Sudha and Daum\'{e} III, Hal and Bender, Emily M.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5401},
 booktitle = {Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems},
 month = {September},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Towards Linguistically Generalizable NLP Systems: A Workshop and Shared Task},
 year = {2017}
}

@inproceedings{W17-5402,
 abstract = {We report results on benchmarking Open Information Extraction (OIE) systems
using RelVis, a toolkit for benchmarking Open Information Extraction systems.
Our comprehensive benchmark contains three data sets from the news domain and
one data set from Wikipedia with overall 4522 labeled sentences and 11243
binary or n-ary OIE relations.
In our analysis on these data sets we compared the performance of four popular
OIE systems, ClausIE, OpenIE 4.2, Stanford OpenIE and PredPatt.
In addition, we evaluated the impact of five common error classes on a subset
of 749 n-ary tuples.
From our deep analysis we unreveal important research directions for a next
generation on OIE systems.},
 address = {Copenhagen, Denmark},
 author = {Schneider, Rudolf and Oberhauser, Tom and Klatt, Tobias and Gers, Felix A. and L\"{o}ser, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5402},
 booktitle = {Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems},
 month = {September},
 pages = {11--18},
 publisher = {Association for Computational Linguistics},
 title = {Analysing Errors of Open Information Extraction Systems},
 year = {2017}
}

@inproceedings{W17-5403,
 abstract = {Grapheme-to-phoneme conversion (g2p) is necessary for text-to-speech and
automatic speech recognition systems. Most g2p systems are monolingual: they
require language-specific data or handcrafting of rules. Such systems are
difficult to extend to low resource languages, for which data and handcrafted
rules are not available. As an alternative, we present a neural
sequence-to-sequence approach to g2p which is trained on
spelling--pronunciation pairs in hundreds of languages. The system shares a
single encoder and decoder across all languages, allowing it to utilize the
intrinsic similarities between different writing systems. We show an 11%
improvement in phoneme error rate over an approach based on adapting
high-resource monolingual g2p models to low-resource languages. Our model is
also much more compact relative to previous approaches.},
 address = {Copenhagen, Denmark},
 author = {Peters, Ben and Dehdari, Jon and van Genabith, Josef},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5403},
 booktitle = {Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems},
 month = {September},
 pages = {19--26},
 publisher = {Association for Computational Linguistics},
 title = {Massively Multilingual Neural Grapheme-to-Phoneme Conversion},
 year = {2017}
}

@inproceedings{W17-5404,
 abstract = {This paper describes our submission to the sentiment analysis sub-task of
``Build It, Break It: The Language Edition (BIBI)'', on both the builder and
breaker sides.
As a builder, we use convolutional neural nets, trained on both phrase and
sentence data.
As a breaker, we use Q-learning to learn minimal change pairs, and apply a
token substitution method automatically.
We analyse the results to gauge the robustness of NLP systems.},
 address = {Copenhagen, Denmark},
 author = {Li, Yitong and Cohn, Trevor and Baldwin, Timothy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5404},
 booktitle = {Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems},
 month = {September},
 pages = {27--32},
 publisher = {Association for Computational Linguistics},
 title = {BIBI System Description: Building with CNNs and Breaking with Deep Reinforcement Learning},
 year = {2017}
}

@inproceedings{W17-5405,
 abstract = {This paper describes our {\^a}breaker{\^a} submission to the 2017 EMNLP {\^a}Build It
Break It{\^a} shared task on sentiment analysis. In order to cause the
{\^a}builder{\^a} systems to make incorrect predictions, we edited items in the
blind test data according to linguistically interpretable strategies that allow
us to assess the ease with which the builder systems learn various components
of linguistic structure. On the whole, our submitted pairs break all systems at
a high rate (72.6%), indicating that sentiment analysis as an NLP task may
still have a lot of ground to cover. Of the breaker strategies that we
consider, we find our semantic and pragmatic manipulations to pose the most
substantial difficulties for the builder systems.},
 address = {Copenhagen, Denmark},
 author = {Mahler, Taylor and Cheung, Willy and Elsner, Micha and King, David and de Marneffe, Marie-Catherine and Shain, Cory and Stevens-Guille, Symon and White, Michael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5405},
 booktitle = {Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems},
 month = {September},
 pages = {33--39},
 publisher = {Association for Computational Linguistics},
 title = {Breaking NLP: Using Morphosyntax, Semantics, Pragmatics and World Knowledge to Fool Sentiment Analysis Systems},
 year = {2017}
}

@inproceedings{W17-5406,
 abstract = {Lexical Simplification is the task of reducing the lexical complexity of
textual documents  by replacing difficult words with easier to read (or
understand) expressions while preserving the original meaning. The development
of robust pipelined multilingual architectures able to adapt to new languages
is of paramount importance in lexical simplification.  This paper describes and
evaluates a  modular hybrid linguistic-statistical Lexical Simplifier that
deals with the four major Ibero-Romance Languages: Spanish, Portuguese, Catalan, and Galician. The architecture of the system is the same for the four
languages addressed, only the language resources used during simplification are
language specific.},
 address = {Copenhagen, Denmark},
 author = {Ferr\'{e}s, Daniel and Saggion, Horacio and G\'{o}mez Guinovart, Xavier},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5406},
 booktitle = {Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems},
 month = {September},
 pages = {40--47},
 publisher = {Association for Computational Linguistics},
 title = {An Adaptable Lexical Simplification Architecture for Major Ibero-Romance Languages},
 year = {2017}
}

@inproceedings{W17-5407,
 abstract = {This paper challenges a cross-genre document retrieval task, where the queries
are in formal writing and the target documents are in conversational writing.
In this task, a query, is a sentence extracted from either a summary or a plot
of an episode in a TV show, and the target document consists of transcripts
from the corresponding episode.
To establish a strong baseline, we employ the current state-of-the-art search
engine to perform document retrieval on the dataset collected for this work.
We then introduce a structure reranking approach to improve the initial ranking
by utilizing syntactic and semantic structures generated by NLP tools.
Our evaluation shows an improvement of more than 4% when the structure
reranking is applied, which is very promising.},
 address = {Copenhagen, Denmark},
 author = {Jurczyk, Tomasz and Choi, Jinho D.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5407},
 booktitle = {Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems},
 month = {September},
 pages = {48--53},
 publisher = {Association for Computational Linguistics},
 title = {Cross-genre Document Retrieval: Matching between Conversational and Formal Writings},
 year = {2017}
}

@inproceedings{W17-5408,
 abstract = {Sentiment analysis deals with the task of determining the polarity of a
document or sentence and has received a lot of attention in recent years for
the English language. With the rapid growth of social media these days, a lot
of data is available in regional languages besides English. Telugu is one such
regional language with abundant data available in social media, but it{\^a}s hard
to find a labelled data of sentences for Telugu Sentiment Analysis. In this
paper, we describe an effort to build a gold-standard annotated corpus of
Telugu sentences to support Telugu Sentiment Analysis. The corpus, named ACTSA
(Annotated Corpus for Telugu Sentiment Analysis) has a collection of Telugu
sentences taken from different sources which were then pre-processed and
manually annotated by native Telugu speakers using our annotation guidelines.
In total, we have annotated 5457 sentences, which makes our corpus the largest
resource currently available. The corpus and the annotation guidelines are made
publicly available.},
 address = {Copenhagen, Denmark},
 author = {Mukku, Sandeep Sricharan and Mamidi, Radhika},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5408},
 booktitle = {Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems},
 month = {September},
 pages = {54--58},
 publisher = {Association for Computational Linguistics},
 title = {ACTSA: Annotated Corpus for Telugu Sentiment Analysis},
 year = {2017}
}

@inproceedings{W17-5409,
 abstract = {This paper describes a builder entry, named {\^a}strawman{\^a}, to the
sentence-level sentiment analysis task of the {\^a}Build It, Break It{\^a} shared
task of the First Workshop
on Building Linguistically Generalizable NLP Systems. The goal of a builder is
to provide an automated sentiment analyzer that would serve as a target for
breakers whose goal is to find pairs of minimally-differing sentences that
break the analyzer.},
 address = {Copenhagen, Denmark},
 author = {Cho, Kyunghyun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5409},
 booktitle = {Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems},
 month = {September},
 pages = {59--60},
 publisher = {Association for Computational Linguistics},
 title = {Strawman: An Ensemble of Deep Bag-of-Ngrams for Sentiment Analysis},
 year = {2017}
}

@inproceedings{W17-5410,
 abstract = {The current paper covers several strategies we used to `break' predictions of
sentiment analysis systems participating in the BLGNLP2017 workshop.
Specifically, we identify difficulties of participating systems in
understanding modals, subjective judgments, world-knowledge based references
and certain differences in syntax and perspective.},
 address = {Copenhagen, Denmark},
 author = {Stali\={u}naite, Ieva and Bonfil, Ben},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5410},
 booktitle = {Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems},
 month = {September},
 pages = {61--64},
 publisher = {Association for Computational Linguistics},
 title = {Breaking Sentiment Analysis of Movie Reviews},
 year = {2017}
}

@inproceedings{W17-5501,
 abstract = {In this paper, we present an approach to exploit phrase tables generated by
statistical machine translation in order to map French discourse connectives to
discourse relations. Using this approach, we created DisCoRel, a lexicon of
French discourse connectives and their PDTB relations. When evaluated against
LEXCONN, DisCoRel achieves a recall of 0.81 and an Average Precision of 0.68
for the Concession and Condition relations.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Laali, Majid and Kosseim, Leila},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5501},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {1--6},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Mapping of French Discourse Connectives to PDTB Discourse Relations},
 year = {2017}
}

@inproceedings{W17-5502,
 abstract = {Full text discourse parsing relies on texts comprehensively annotated with
discourse relations.
To this end, we address a significant gap in the inter-sentential discourse
relations annotated in the Penn Discourse Treebank (PDTB), namely the class of
cross-paragraph implicit relations, which account for 30% of inter-sentential
relations in the corpus. We present our annotation study to explore the
incidence rate of adjacent vs. non-adjacent implicit relations in
cross-paragraph contexts, and the relative degree of difficulty in annotating
them. Our experiments show a high incidence of non-adjacent relations that are
difficult to annotate reliably, suggesting the practicality of backing off from
their annotation to reduce noise for corpus-based studies. Our resulting
guidelines follow the PDTB adjacency constraint for implicits while employing
an underspecified representation of non-adjacent implicits, and yield 62%
inter-annotator agreement on this task.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Prasad, Rashmi and Forbes-Riley, Katherine and Lee, Alan},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5502},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {7--16},
 publisher = {Association for Computational Linguistics},
 title = {Towards Full Text Shallow Discourse Relation Annotation: Experiments with Cross-Paragraph Implicit Relations in the PDTB},
 year = {2017}
}

@inproceedings{W17-5503,
 abstract = {We  test state of the art dialogue systems  for their behaviour in response to
user-initiated sub-dialogues, i.e. interactions where a system question is
responded to with a question or request from the user, who thus initiates a
sub-dialogue. We look  at sub-dialogues both within a single app (where the
sub-dialogue concerns another topic in the original domain) and across apps
(where the sub-dialogue concerns a different domain). The overall conclusion of
the tests is that none of the systems can be said to deal appropriately with
user-initiated sub-dialogues.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Larsson, Staffan},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5503},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {17--22},
 publisher = {Association for Computational Linguistics},
 title = {User-initiated Sub-dialogues in State-of-the-art Dialogue Systems},
 year = {2017}
}

@inproceedings{W17-5504,
 abstract = {We present a multimodal dialogue system that allows doctors to interact with a
medical decision support system in virtual reality (VR). We integrate an
interactive visualization of patient records and radiology image data, as well
as therapy predictions. Therapy predictions are computed in real-time using a
deep learning model.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Prange, Alexander and Chikobava, Margarita and Poller, Peter and Barz, Michael and Sonntag, Daniel},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5504},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {23--26},
 publisher = {Association for Computational Linguistics},
 title = {A Multimodal Dialogue System for Medical Decision Support inside Virtual Reality},
 year = {2017}
}

@inproceedings{W17-5505,
 abstract = {Generative encoder-decoder models offer great promise in developing
domain-general dialog systems. However, they have mainly been applied to
open-domain conversations. This paper presents a practical and novel framework
for building task-oriented dialog systems based on encoder-decoder models. This
framework enables encoder-decoder models to accomplish slot-value independent
decision-making and interact with external databases. Moreover, this paper
shows the flexibility of the proposed method by interleaving chatting
capability with a slot-filling system for better out-of-domain recovery. The
models were trained on both real-user data from a bus information system and
human-human chat data. Results show that the proposed framework achieves good
performance in both offline evaluation metrics and in task success rate with
human users.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Zhao, Tiancheng and Lu, Allen and Lee, Kyusong and Eskenazi, Maxine},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5505},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {27--36},
 publisher = {Association for Computational Linguistics},
 title = {Generative Encoder-Decoder Models for Task-Oriented Spoken Dialog Systems with Chatting Capability},
 year = {2017}
}

@inproceedings{W17-5506,
 abstract = {Neural task-oriented dialogue systems often struggle to smoothly interface with
a knowledge base. In this work, we seek to address this problem by proposing a
new neural dialogue agent that is able to effectively sustain grounded, multi-domain discourse through a novel key-value retrieval mechanism. The model
is end-to-end differentiable and does not need to explicitly model dialogue
state or belief trackers. We also release a new dataset of 3,031 dialogues that
are grounded through underlying knowledge bases and span three distinct tasks
in the in-car personal assistant space: calendar scheduling, weather
information retrieval, and point-of-interest navigation. Our architecture is
simultaneously trained on data from all domains and significantly outperforms a
competitive rule-based system and other existing neural dialogue architectures
on the provided domains according to both automatic and human evaluation
metrics.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Eric, Mihail and Krishnan, Lakshmi and Charette, Francois and Manning, Christopher D.},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5506},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {37--49},
 publisher = {Association for Computational Linguistics},
 title = {Key-Value Retrieval Networks for Task-Oriented Dialogue},
 year = {2017}
}

@inproceedings{W17-5507,
 abstract = {We address the problem of acquiring the ontological categories of unknown terms
through implicit confirmation in dialogues. We develop an approach that makes
implicit confirmation requests with an unknown term's predicted category. Our
approach does not degrade user experience with repetitive explicit
confirmations, but the system has difficulty determining if information in the
confirmation request can be correctly acquired. To overcome this challenge, we
propose a method for determining whether or not the predicted category is
correct, which is included in an implicit confirmation request. Our method
exploits multiple user responses to implicit confirmation requests containing
the same ontological category. Experimental results revealed that the proposed
method exhibited a higher precision rate for determining the correctly
predicted categories than when only single user responses were considered.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Ono, Kohei and Takeda, Ryu and Nichols, Eric and Nakano, Mikio and Komatani, Kazunori},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5507},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {50--59},
 publisher = {Association for Computational Linguistics},
 title = {Lexical Acquisition through Implicit Confirmations over Multiple Dialogues},
 year = {2017}
}

@inproceedings{W17-5508,
 abstract = {Recursive autoencoders (RAEs) for compositionality of a vector space model were
applied to utterance intent classification of a smartphone-based
Japanese-language spoken dialogue system. Though the RAEs express a nonlinear
operation on the vectors of child nodes, the operation is considered to be
different intrinsically depending on types of child nodes. To relax the
difference, a data-driven untying of autoencoders (AEs) is proposed. The
experimental result of the utterance intent classification showed an improved
accuracy with the proposed method compared with the basic tied RAE and untied
RAE based on a manual rule.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Kato, Tsuneo and Nagai, Atsushi and Noda, Naoki and Sumitomo, Ryosuke and Wu, Jianming and Yamamoto, Seiichi},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5508},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {60--64},
 publisher = {Association for Computational Linguistics},
 title = {Utterance Intent Classification of a Spoken Dialogue System with Efficiently Untied Recursive Autoencoders},
 year = {2017}
}

@inproceedings{W17-5509,
 abstract = {Reinforcement learning is widely used for dialogue policy optimization where
the reward function often consists of more than one component, e.g., the
dialogue success and the dialogue length. In this work, we propose a structured
method for finding a good balance between these components by searching for the
optimal reward component weighting. To render this search feasible, we use
multi-objective reinforcement learning to significantly reduce the number of
training dialogues required. We apply our proposed method to find optimized
component weights for six domains and compare them to a default baseline.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Ultes, Stefan and Budzianowski, Pawe{\l} and Casanueva, I\~{n}igo and Mrk\v{s}i\'{c}, Nikola and Rojas Barahona, Lina M. and Su, Pei-Hao and Wen, Tsung-Hsien and Gasic, Milica and Young, Steve},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5509},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {65--70},
 publisher = {Association for Computational Linguistics},
 title = {Reward-Balancing for Statistical Spoken Dialogue Systems using Multi-objective Reinforcement Learning},
 year = {2017}
}

@inproceedings{W17-5510,
 abstract = {This work aims at characterising verbal alignment processes for improving
virtual agent communicative capabilities. We propose computationally
inexpensive measures of verbal alignment based on expression repetition in
dyadic textual dialogues. Using these measures, we present a contrastive study
between Human-Human and Human-Agent dialogues on a negotiation task. We exhibit
quantitative differences in the strength and orientation of verbal alignment
showing the ability of our approach to characterise important aspects of verbal
alignment.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Dubuisson Duplessis, Guillaume and Clavel, Chlo\'{e} and Landragin, Fr\'{e}d\'{e}ric},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5510},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {71--81},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Measures to Characterise Verbal Alignment in Human-Agent Interaction},
 year = {2017}
}

@inproceedings{W17-5511,
 abstract = {This is a demonstration of interactive teaching for practical end-to-end dialog
systems driven by a recurrent neural network.  In this approach, a developer
teaches the network by interacting with the system and providing on-the-spot
corrections.  Once a system is deployed, a developer can also correct mistakes
in logged dialogs.  This demonstration shows both of these teaching methods
applied to dialog systems in three domains: pizza ordering, restaurant
information, and weather forecasts.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Williams, Jason D and Liden, Lars},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5511},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {82--85},
 publisher = {Association for Computational Linguistics},
 title = {Demonstration of interactive teaching for end-to-end dialog control with hybrid code networks},
 year = {2017}
}

@inproceedings{W17-5512,
 abstract = {Human conversation is inherently complex, often spanning many different
topics/domains. This makes policy learning for dialogue systems very
challenging. Standard flat reinforcement learning methods do not provide an
efficient framework for modelling such dialogues. In this paper, we focus on
the under-explored problem of multi-domain dialogue management. First, we
propose a new method for hierarchical reinforcement learning using the
option framework. Next, we show that the proposed architecture learns
faster and arrives at a better policy than the existing flat ones do. Moreover, we show how pretrained policies can be adapted to more complex systems with an
additional set of new actions. In doing that, we show that our approach has the
potential to facilitate policy optimisation for more sophisticated multi-domain
dialogue systems.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Budzianowski, Pawe{\l} and Ultes, Stefan and Su, Pei-Hao and Mrk\v{s}i\'{c}, Nikola and Wen, Tsung-Hsien and Casanueva, I\~{n}igo and Rojas Barahona, Lina M. and Gasic, Milica},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5512},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {86--92},
 publisher = {Association for Computational Linguistics},
 title = {Sub-domain Modelling for Dialogue Management with Hierarchical Reinforcement Learning},
 year = {2017}
}

@inproceedings{W17-5513,
 abstract = {We propose a software architecture designed to ease the implementation of
dialogue systems. The Modular Architecture for Conversational Agents (MACA)
uses a plug-n-play style that allows quick prototyping, thereby facilitating
the development of new techniques and the reproduction of previous work. The
architecture separates the domain of the conversation from the agent's dialogue
strategy, and as such can be easily extended to multiple domains. MACA provides
tools to host dialogue agents on Amazon Mechanical Turk (mTurk) for data
collection and allows processing of other sources of training data. The current
version of the framework already incorporates several domains and existing
dialogue strategies from the recent literature.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Truong, Hoai Phuoc and Parthasarathi, Prasanna and Pineau, Joelle},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5513},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {93--102},
 publisher = {Association for Computational Linguistics},
 title = {MACA: A Modular Architecture for Conversational Agents},
 year = {2017}
}

@inproceedings{W17-5514,
 abstract = {Spoken Language Understanding (SLU) is a key component of goal oriented
dialogue systems that would parse user utterances into semantic frame
representations. Traditionally SLU does not utilize the dialogue history beyond
the previous system turn and contextual ambiguities are resolved by the
downstream components. In this paper, we explore novel approaches for modeling
dialogue context in a recurrent neural network (RNN) based language
understanding system. We propose the Sequential Dialogue Encoder Network, that
allows encoding context from the dialogue history in chronological order. We
compare the performance of our proposed architecture with two context models, one that uses just the previous turn context and another that encodes dialogue
context in a memory network, but loses the order of utterances in the dialogue
history. Experiments with a multi-domain dialogue dataset demonstrate that the
proposed architecture results in reduced semantic frame error rates.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Bapna, Ankur and Tur, Gokhan and Hakkani-Tur, Dilek and Heck, Larry},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5514},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {103--114},
 publisher = {Association for Computational Linguistics},
 title = {Sequential Dialogue Context Modeling for Spoken Language Understanding},
 year = {2017}
}

@inproceedings{W17-5515,
 abstract = {Conversational agents offer users a natural-language interface to accomplish
tasks, entertain themselves, or access information. Informational dialogue is
particularly challenging in that the agent has to hold a conversation on an
open topic, and to achieve a reasonable coverage it generally needs to digest
and present unstructured information from textual sources. Making responses
based on such sources sound natural and fit appropriately into the conversation
context is a topic of ongoing research, one of the key issues of which is
preventing the agent's responses from sounding repetitive. Targeting this
issue, we propose a new task, known as redundancy localization, which aims to
pinpoint semantic overlap between text passages. To help address it
systematically, we formalize the task, prepare a public dataset with
fine-grained redundancy labels, and propose a model utilizing a weak training
signal defined over the results of a passage-retrieval system on web texts. The
proposed model demonstrates superior performance compared to a state-of-the-art
entailment model and yields encouraging results when applied to a real-world
dialogue.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Krause, Sebastian and Kozhevnikov, Mikhail and Malmi, Eric and Pighin, Daniele},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5515},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {115--126},
 publisher = {Association for Computational Linguistics},
 title = {Redundancy Localization for the Conversationalization of Unstructured Responses},
 year = {2017}
}

@inproceedings{W17-5516,
 abstract = {Attentive listening systems are designed to let people, especially senior
people, keep talking to maintain communication ability and mental health.  This
paper addresses key components of an attentive listening system which
encourages users to talk smoothly. First, we introduce continuous prediction of
end-of-utterances and generation of backchannels, rather than generating
backchannels after end-point detection of utterances. This improves subjective
evaluations of backchannels.  Second, we propose an effective statement
response mechanism which detects focus words and responds in the form of a
question or partial repeat.  This can be applied to any statement.  Moreover, a
flexible turn-taking mechanism is designed which uses backchannels or fillers
when the turn-switch is ambiguous.  These techniques are integrated into a
humanoid robot to conduct attentive listening. We test the feasibility of the
system in a pilot experiment and show that it can produce coherent dialogues
during conversation.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Lala, Divesh and Milhorat, Pierrick and Inoue, Koji and Ishida, Masanari and Takanashi, Katsuya and Kawahara, Tatsuya},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5516},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {127--136},
 publisher = {Association for Computational Linguistics},
 title = {Attentive listening system with backchanneling, response generation and flexible turn-taking},
 year = {2017}
}

@inproceedings{W17-5517,
 abstract = {Recent spoken dialog systems are moving away from command and control towards a
more intuitive and natural style of interaction. In order to choose an
appropriate system design which allows the system to deal with naturally spoken
user input, a definition of what exactly constitutes naturalness in user input
is important. In this paper, we examine how different user groups naturally
speak to an automotive spoken dialog system (SDS). We conduct a user study in
which we collect freely spoken user utterances for a wide range of use cases in
German. By means of a comparative study of the utterances from the study with
interpersonal utterances, we provide criteria what constitutes naturalness in
the user input of an state-of-the-art automotive SDS.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Braunger, Patricia and Maier, Wolfgang},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5517},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {137--146},
 publisher = {Association for Computational Linguistics},
 title = {Natural Language Input for In-Car Spoken Dialog Systems: How Natural is Natural?},
 year = {2017}
}

@inproceedings{W17-5518,
 abstract = {Deep reinforcement learning (RL) methods have significant potential for
dialogue policy optimisation. However, they suffer from a poor performance in
the early stages of learning. This is especially problematic for on-line
learning with real users. Two approaches are introduced to tackle this problem.
Firstly, to speed up the learning process, two sample-efficient neural networks
algorithms: trust region actor-critic with experience replay (TRACER)  and
episodic natural actor-critic with experience replay (eNACER) are presented.
For TRACER, the trust region helps to control the learning step size and avoid
catastrophic model changes. For eNACER, the natural gradient identifies the
steepest ascent direction in policy space to speed up the convergence. Both
models employ off-policy learning with experience replay to improve
sample-efficiency. Secondly, to mitigate the cold start issue, a corpus of
demonstration data is utilised to pre-train the models prior to on-line
reinforcement learning. Combining these two approaches, we demonstrate a
practical approach to learn deep RL-based dialogue policies and demonstrate
their effectiveness in a task-oriented information seeking domain.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Su, Pei-Hao and Budzianowski, Pawe{\l} and Ultes, Stefan and Gasic, Milica and Young, Steve},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5518},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {147--157},
 publisher = {Association for Computational Linguistics},
 title = {Sample-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management},
 year = {2017}
}

@inproceedings{W17-5519,
 abstract = {We train a char2char model on the E2E NLG Challenge data, by exploiting
{\^a}out-of-the-box{\^a} the recently released tfseq2seq framework, using some of
the standard options offered by this tool. With minimal effort, and in
particular without delexicalization, tokenization or lowercasing, the obtained
raw predictions, according to a small scale human evaluation, are excellent on
the linguistic side and quite reasonable on the adequacy side, the primary
downside being the possible omissions of semantic material. However, in a
significant number of cases (more than 70%), a perfect solution can be found in
the top-20 predictions, indicating promising directions for solving the
remaining issues.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Agarwal, Shubham and Dymetman, Marc},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5519},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {158--163},
 publisher = {Association for Computational Linguistics},
 title = {A surprisingly effective out-of-the-box char2char model on the E2E NLG Challenge dataset},
 year = {2017}
}

@inproceedings{W17-5520,
 abstract = {For estimating the Interaction Quality (IQ) in Spoken Dialogue Systems (SDS), the dialogue history is of significant importance. Previous works included this
information manually in the form of precomputed temporal features into the
classification process. Here, we employ a deep learning architecture based on
Long Short-Term Memories (LSTM) to extract this information automatically from
the data, thus estimating IQ solely by using current exchange features. We show
that it is thereby possible to achieve competitive results as in a scenario
where manually optimized temporal features have been included.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Rach, Niklas and Minker, Wolfgang and Ultes, Stefan},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5520},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {164--169},
 publisher = {Association for Computational Linguistics},
 title = {Interaction Quality Estimation Using Long Short-Term Memories},
 year = {2017}
}

@inproceedings{W17-5521,
 abstract = {DialPort collects user data for connected spoken dialog systems. At present six
systems are linked to a central portal that directs the user to the applicable
system and suggests systems that the user may be interested in. User data has
started to flow into the system.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Lee, Kyusong and Zhao, Tiancheng and Du, Yulun and Cai, Edward and Lu, Allen and Pincus, Eli and Traum, David and Ultes, Stefan and Rojas Barahona, Lina M. and Gasic, Milica and Young, Steve and Eskenazi, Maxine},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5521},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {170--173},
 publisher = {Association for Computational Linguistics},
 title = {DialPort, Gone Live: An Update After A Year of Development},
 year = {2017}
}

@inproceedings{W17-5522,
 abstract = {Conversational interfaces recently gained a lot of attention. One of the
reasons for the current hype is the fact that chatbots (one particularly
popular form of conversational interfaces)
nowadays can be created without any programming knowledge, thanks to different
toolkits and so-called Natural Language Understanding (NLU) services. While
these NLU services are already widely used in both, industry and science, so
far, they have not been analysed systematically. In this paper, we present a
method to evaluate the classification performance of NLU services. Moreover, we
present two new corpora, one consisting of annotated questions and one
consisting of annotated questions with the corresponding answers. Based on
these corpora, we conduct an evaluation of some of the most popular NLU
services. Thereby we want to enable both, researchers and companies to make
more educated decisions about which service they should use.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Braun, Daniel and Hernandez-Mendez, Adrian and Matthes, Florian and Langen, Manfred},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5522},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {174--185},
 publisher = {Association for Computational Linguistics},
 title = {Evaluating Natural Language Understanding Services for Conversational Question Answering Systems},
 year = {2017}
}

@inproceedings{W17-5523,
 abstract = {Computational models for sarcasm detection have often relied on the content of
utterances in isolation. However, speaker's sarcastic intent is not always
obvious without additional context. Focusing on social media discussions, we
investigate two issues: (1) does modeling of conversation context help in
sarcasm detection and (2) can we understand what part of conversation context
triggered the sarcastic reply. To address the first issue, we investigate
several types of Long Short-Term Memory (LSTM) networks that can model both the
conversation context and the sarcastic response. We show that the conditional
LSTM network (Rockt\"{a}schel et al. 2015) and LSTM networks with sentence level
attention on context and response outperform the LSTM model that reads only the
response. To address the second issue, we present a qualitative analysis of
attention weights produced by the LSTM models with attention and discuss the
results compared with human performance on the task.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Ghosh, Debanjan and Richard Fabbri, Alexander and Muresan, Smaranda},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5523},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {186--196},
 publisher = {Association for Computational Linguistics},
 title = {The Role of Conversation Context for Sarcasm Detection in Online Interactions},
 year = {2017}
}

@inproceedings{W17-5524,
 abstract = {We present VOILA: an optimised, multi- modal dialogue agent for interactive
learning of visually grounded word meanings from a human user. VOILA is: (1)
able to learn new visual categories interactively from users from scratch; (2)
trained on real human-human dialogues in the same domain, and so is able to
conduct natural spontaneous dialogue; (3) optimised to find the most effective
trade-off between the accuracy of the visual categories it learns and the cost
it incurs to users. VOILA is deployed on Furhat, a human-like, multi-modal
robot head with back-projection of the face, and a graphical virtual character.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Yu, Yanchao and Eshghi, Arash and Lemon, Oliver},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5524},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {197--200},
 publisher = {Association for Computational Linguistics},
 title = {VOILA: An Optimised Dialogue System for Interactively Learning Visually-Grounded Word Meanings (Demonstration System)},
 year = {2017}
}

@inproceedings{W17-5525,
 abstract = {This paper describes the E2E data, a new dataset for training end-to-end, data-driven natural language generation systems in the restaurant domain, which
is ten times bigger than existing, frequently used datasets in this area. The
E2E dataset poses new challenges: (1) its human reference texts show more
lexical richness and syntactic variation, including discourse phenomena; (2)
generating from this set requires content selection. As such, learning from
this dataset promises more natural, varied and less template-like system
utterances. We also establish a baseline on this dataset, which illustrates
some of the difficulties associated with this data.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Novikova, Jekaterina and Du\v{s}ek, Ond\v{r}ej and Rieser, Verena},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5525},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {201--206},
 publisher = {Association for Computational Linguistics},
 title = {The E2E Dataset: New Challenges For End-to-End Generation},
 year = {2017}
}

@inproceedings{W17-5526,
 abstract = {This paper proposes a new dataset, Frames, composed of 1369 human-human
dialogues with an average of 15 turns per dialogue. This corpus contains
goal-oriented dialogues between users who are given some constraints to book a
trip and assistants who search a database to find appropriate trips. The users
exhibit complex decision-making behaviour which involve comparing trips, exploring different options, and selecting among the trips that were discussed
during the dialogue. To drive research on dialogue systems towards handling
such behaviour, we have annotated and released the dataset and we propose in
this paper a task called frame tracking. This task consists of keeping track of
different semantic frames throughout each dialogue. We propose a rule-based
baseline and analyse the frame tracking task through this baseline.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {El Asri, Layla and Schulz, Hannes and Sharma, Shikhar and Zumer, Jeremie and Harris, Justin and Fine, Emery and Mehrotra, Rahul and Suleman, Kaheer},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5526},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {207--219},
 publisher = {Association for Computational Linguistics},
 title = {Frames: a corpus for adding memory to goal-oriented dialogue systems},
 year = {2017}
}

@inproceedings{W17-5527,
 abstract = {Previous models of turn-taking have mostly been trained for specific
turn-taking decisions, such as discriminating between turn shifts and turn
retention in pauses. In this paper, we present a predictive, continuous model
of turn-taking using Long Short-Term Memory (LSTM) Recurrent Neural Networks
(RNN). The model is trained on human-human dialogue data to predict upcoming
speech activity in a future time window. We show how this general model can be
applied to two different tasks that it was not specifically trained for. First, to predict whether a turn-shift will occur or not in pauses, where the model
achieves a better performance than human observers, and better than results
achieved with more traditional models. Second, to make a prediction at speech
onset whether the utterance will be a short backchannel or a longer utterance.
Finally, we show how the hidden layer in the network can be used as a feature
vector for turn-taking decisions in a human-robot interaction scenario.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Skantze, Gabriel},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5527},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {220--230},
 publisher = {Association for Computational Linguistics},
 title = {Towards a General, Continuous Model of Turn-taking in Spoken Dialogue using LSTM Recurrent Neural Networks},
 year = {2017}
}

@inproceedings{W17-5528,
 abstract = {Natural language generation (NLG) is an important component in spoken dialogue
systems. This paper presents a model called Encoder-Aggregator-Decoder which is
an extension of an Recurrent Neural Network based Encoder-Decoder architecture.
The proposed Semantic Aggregator consists of two components: an Aligner and a
Refiner. The Aligner is a conventional attention calculated over the encoded
input information, while the Refiner is another attention or gating mechanism
stacked over the attentive Aligner in order to further select and aggregate the
semantic elements. The proposed model can be jointly trained both sentence
planning and surface realization to produce natural language utterances.
The model was extensively assessed on four different NLG domains, in which the
experimental results showed that the proposed generator consistently
outperforms the previous methods on all the NLG domains.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Tran, Van-Khanh and Nguyen, Le-Minh and Tojo, Satoshi},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5528},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {231--240},
 publisher = {Association for Computational Linguistics},
 title = {Neural-based Natural Language Generation in Dialogue using RNN Encoder-Decoder with Semantic Aggregation},
 year = {2017}
}

@inproceedings{W17-5529,
 abstract = {A common convention in graphical user interfaces is to indicate a "wait
state", for example while a program is preparing a response, through a changed
cursor state or a progress bar. What should the analogue be in a spoken
conversational system?
To address this question, we set up an experiment in which a human information
provider (IP) was given their information only in a delayed and incremental
manner, which systematically created situations where the IP had the turn but
could not provide task-related information.
Our data analysis shows that 1) IPs bridge the gap until they can provide
information by re-purposing a whole variety of task- and grounding-related
communicative actions (e.g. echoing the user's request, signaling
understanding, asserting partially relevant information), rather than being
silent or explicitly asking for time (e.g. "please wait"), and that 2) IPs
combined these actions productively to ensure an ongoing conversation. These
results, we argue, indicate that natural conversational interfaces should also
be able to manage their time flexibly using a variety of conversational
resources.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {L\'{o}pez Gambino, Soledad and Zarrie{\ss}, Sina and Schlangen, David},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5529},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {241--246},
 publisher = {Association for Computational Linguistics},
 title = {Beyond On-hold Messages: Conversational Time-buying in Task-oriented Dialogue},
 year = {2017}
}

@inproceedings{W17-5530,
 abstract = {We explore context representation learning methods in neural-based models for
dialog act classification. We propose and compare extensively different methods
which combine recurrent neural network architectures and attention mechanisms
(AMs) at different context levels. Our experimental results on two benchmark
datasets show consistent improvements compared to the models without
contextual information and reveal that the most suitable AM in the architecture
depends on the nature of the dataset.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Ortega, Daniel and Vu, Ngoc Thang},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5530},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {247--252},
 publisher = {Association for Computational Linguistics},
 title = {Neural-based Context Representation Learning for Dialog Act Classification},
 year = {2017}
}

@inproceedings{W17-5531,
 abstract = {In goal-driven dialogue systems, success is often defined based on a structured
definition of the goal. This requires that the dialogue system be constrained
to handle a specific class of goals and that there be a mechanism to measure
success with respect to that goal. However, in many human-human dialogues the
diversity of goals makes it infeasible to define success in such a way. To
address this scenario, we consider the task of automatically predicting success
in goal-driven human-human dialogues using only the information communicated
between participants in the form of text. We build a dataset from
stackoverflow.com which consists of exchanges between two users in the
technical domain where ground-truth success labels are available. We then
propose a turn-based hierarchical neural network model that can be used to
predict success without requiring a structured goal definition. We show this
model outperforms rule-based heuristics and other baselines as it is able to
detect patterns over the course of a dialogue and capture notions such as
gratitude.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Noseworthy, Michael and Cheung, Jackie Chi Kit and Pineau, Joelle},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5531},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {253--262},
 publisher = {Association for Computational Linguistics},
 title = {Predicting Success in Goal-Driven Human-Human Dialogues},
 year = {2017}
}

@inproceedings{W17-5532,
 abstract = {We define and motivate the problem of summarizing partial email threads. This
problem introduces the challenge of generating reference summaries for partial
threads when human annotation is only available for the threads as a whole, particularly when the human-selected sentences are not uniformly distributed
within the threads. We propose an oracular algorithm for generating these
reference summaries with arbitrary length, and we are making the resulting
dataset publicly available. In addition, we apply a recent unsupervised method
based on Bayesian Surprise that incorporates background knowledge into partial
thread summarization, extend it with conversational features, and modify the
mechanism by which it handles redundancy. Experiments with our method indicate
improved performance over the baseline for shorter partial threads; and our
results suggest that the potential benefits of background knowledge to partial
thread summarization should be further investigated with larger datasets.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Johnson, Jordon and Masrani, Vaden and Carenini, Giuseppe and Ng, Raymond},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5532},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {263--272},
 publisher = {Association for Computational Linguistics},
 title = {Generating and Evaluating Summaries for Partial Email Threads: Conversational Bayesian Surprise and Silver Standards},
 year = {2017}
}

@inproceedings{W17-5533,
 abstract = {We present the flexdiam dialogue management architecture, which was developed
in a series of projects dedicated to tailoring spoken interaction to the needs
of users with cognitive impairments in an everyday assistive domain, using a
multimodal front-end.
This hybrid DM architecture affords incremental processing of uncertain input, a flexible, mixed-initiative information grounding process that can be adapted
to users' cognitive capacities and interactive idiosyncrasies, and generic
mechanisms that foster transitions in the joint discourse state that
are understandable and controllable by those users, in order to effect a robust
interaction for users with varying capacities.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Yaghoubzadeh, Ramin and Kopp, Stefan},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5533},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {273--283},
 publisher = {Association for Computational Linguistics},
 title = {Enabling robust and fluid spoken dialogue with cognitively impaired users},
 year = {2017}
}

@inproceedings{W17-5534,
 abstract = {We investigate

the
potential
of
adversarial
evaluation
methods for
open-domain
dialogue generation systems, comparing the performance of a discriminative
agent to that of humans on the same task. Our results show that the task is
hard, both for automated models and humans, but that a discriminative agent can
learn patterns that lead to above-chance performance.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Bruni, Elia and Fernandez, Raquel},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5534},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {284--288},
 publisher = {Association for Computational Linguistics},
 title = {Adversarial evaluation for open-domain dialogue generation},
 year = {2017}
}

@inproceedings{W17-5535,
 abstract = {Discourse Parsing and Sentiment Analysis are two fundamental tasks in Natural
Language Processing that have been shown to be mutually beneficial. In this
work, we design and compare two Neural Based models for jointly learning both
tasks. In the proposed approach, we first create a vector representation for
all the text segments in the input sentence. Next, we apply three different
Recursive Neural Net models: one for discourse structure prediction, one for
discourse relation prediction and one for sentiment analysis. Finally, we
combine these Neural Nets in two different joint models: Multi-tasking and
Pre-training. Our results on two standard corpora indicate that both methods
result in improvements in each task but Multi-tasking has a bigger impact than
Pre-training. Specifically for Discourse Parsing, we see improvements in the
prediction of the set of contrastive relations.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Nejat, Bita and Carenini, Giuseppe and Ng, Raymond},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5535},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {289--298},
 publisher = {Association for Computational Linguistics},
 title = {Exploring Joint Neural Model for Sentence Level Discourse Parsing and Sentiment Analysis},
 year = {2017}
}

@inproceedings{W17-5536,
 abstract = {Intelligent assistants (IAs) such as Siri and Cortana conversationally interact
with users and execute a wide range of actions (e.g., searching the Web, setting alarms, and chatting). IAs can support these actions through the
combination of various components such as automatic speech recognition, natural
language understanding, and language generation. However, the complexity of
these components hinders developers from determining which component causes an
error. To remove this hindrance, we focus on reformulation, which is a useful
signal of user dissatisfaction, and propose a method to predict the
reformulation causes. We evaluate the method using the user logs of a
commercial IA. The experimental results have demonstrated that features
designed to detect the error of a specific component improve the performance of
reformulation cause detection.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Sano, Shumpei and Kaji, Nobuhiro and Sassano, Manabu},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5536},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {299--309},
 publisher = {Association for Computational Linguistics},
 title = {Predicting Causes of Reformulation in Intelligent Assistants},
 year = {2017}
}

@inproceedings{W17-5537,
 abstract = {Effective models of social dialog must understand a broad range of
rhetorical and figurative devices. Rhetorical questions (RQs)
are a type of figurative language whose aim is to achieve a pragmatic
goal, such as structuring an argument, being persuasive, emphasizing a point, or being ironic. While there are computational models for other forms of
figurative language, rhetorical questions have received little
attention to date.  We expand a small dataset from previous work, presenting a
corpus of 10,270 RQs from debate forums and Twitter that represent different
discourse functions. We show that we can clearly distinguish between RQs and
sincere questions (0.76 F1). We then show that RQs can be used both
sarcastically and non-sarcastically, observing that non-sarcastic (other) uses
of RQs are frequently argumentative in forums, and persuasive in tweets. We
present experiments to distinguish between these uses of RQs using SVM and LSTM
models that represent linguistic features and post-level context, achieving
results as high as 0.76 F1 for "sarcastic" and 0.77 F1 for "other" in forums, and 0.83 F1 for both "sarcastic" and "other" in tweets. We supplement our
quantitative experiments with an in-depth characterization of the linguistic
variation in RQs.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Oraby, Shereen and Harrison, Vrindavan and Misra, Amita and Riloff, Ellen and Walker, Marilyn},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5537},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {310--319},
 publisher = {Association for Computational Linguistics},
 title = {Are you serious?: Rhetorical Questions and Sarcasm in Social Media Dialog},
 year = {2017}
}

@inproceedings{W17-5538,
 abstract = {In this paper, we present a novel and highly effective method for induction and
application of metaphor frame templates as a step toward detecting metaphor in
extended discourse. We infer implicit facets of a given metaphor frame using a
semi-supervised bootstrapping approach on an unlabeled corpus. Our model
applies this frame facet information to metaphor detection, and achieves the
state-of-the-art performance on a social media dataset when building upon other
proven features in a nonlinear machine learning model. In addition, we
illustrate the mechanism through which the frame and topic information enable
the more accurate metaphor detection.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Jang, Hyeju and Maki, Keith and Hovy, Eduard and Rose, Carolyn},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5538},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {320--330},
 publisher = {Association for Computational Linguistics},
 title = {Finding Structure in Figurative Language: Metaphor Detection with Topic-based Frames},
 year = {2017}
}

@inproceedings{W17-5539,
 abstract = {We apply Reinforcement Learning (RL) to the problem of incremental dialogue
policy learning in the context of a fast-paced dialogue game. We compare the
policy learned by RL with a high-performance baseline policy which has been
shown to perform very efficiently (nearly as well as humans) in this dialogue
game. The RL policy outperforms the baseline policy in offline simulations
(based on real user data). We provide a detailed comparison of the RL policy
and the baseline policy, including information about how much effort and time
it took to develop each one of them. We also highlight the cases where the RL
policy performs better, and show that understanding the RL policy can provide
valuable insights which can inform the creation of an even better rule-based
policy.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Manuvinakurike, Ramesh and DeVault, David and Georgila, Kallirroi},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5539},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {331--341},
 publisher = {Association for Computational Linguistics},
 title = {Using Reinforcement Learning to Model Incrementality in a Fast-Paced Dialogue Game},
 year = {2017}
}

@inproceedings{W17-5540,
 abstract = {To understand narrative, humans draw inferences about the underlying relations
between narrative events.  Cognitive theories of narrative understanding define
these inferences as four different types of causality, that include pairs of
events A, B where A physically causes B (X drop, X break), to pairs of events
where A causes emotional state B (Y saw X, Y felt fear). Previous work on
learning narrative relations from text has either focused on "strict"
physical causality, or has been vague about what relation is being learned.
This paper learns pairs of causal events from a corpus of film scene
descriptions which are action rich and tend to be told in chronological order.
We show that event pairs induced using our methods are of high quality and are
judged to have a stronger causal relation than event pairs from Rel-Grams.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Hu, Zhichao and Walker, Marilyn},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5540},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {342--351},
 publisher = {Association for Computational Linguistics},
 title = {Inferring Narrative Causality between Event Pairs in Films},
 year = {2017}
}

@inproceedings{W17-5541,
 abstract = {We analyze deployment of an interactive dialogue system in an environment where
deep technical expertise might not be readily available. The initial version
was created using a collection of research tools.
We summarize a number of challenges with its deployment at two museums and
describe a new system that simplifies the installation and user interface;
reduces reliance on 3rd-party software; and provides a robust data collection
mechanism.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Leuski, Anton and Artstein, Ron},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5541},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {352--355},
 publisher = {Association for Computational Linguistics},
 title = {Lessons in Dialogue System Deployment},
 year = {2017}
}

@inproceedings{W17-5542,
 abstract = {We demonstrate an information navigation system for sightseeing domains that
has
a dialogue interface for discovering user interests for tourist activities.
The system discovers interests of a user with focus detection on user
utterances, and  proactively presents related information to the discovered user interest.
A partially observable Markov decision process (POMDP)-based dialogue manager, which is extended with user focus states, controls the behavior of the system to provide information with several
dialogue
acts for providing information.
We transferred the belief-update function and the policy of the manager from
other system
trained on a different domain to show the generality of defined dialogue acts
for
our information navigation system.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Yoshino, Koichiro and Suzuki, Yu and Nakamura, Satoshi},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5542},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {356--359},
 publisher = {Association for Computational Linguistics},
 title = {Information Navigation System with Discovering User Interests},
 year = {2017}
}

@inproceedings{W17-5543,
 abstract = {Many genres of natural language text are narratively structured, a testament to
our predilection for organizing our experiences as narratives. There is broad
consensus that understanding a narrative requires identifying and tracking the
goals and desires of the characters and their narrative outcomes. However, to
date, there has been limited work on computational models for this problem. We
introduce a new dataset, DesireDB, which includes gold-standard labels for
identifying statements of desire, textual evidence for desire fulfillment, and
annotations for whether the stated desire is fulfilled given the evidence in
the narrative context. We report experiments on tracking desire fulfillment
using
different methods, and show that LSTM Skip-Thought model achieves F-measure
of 0.7 on our corpus.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Rahimtoroghi, Elahe and Wu, Jiaqi and Wang, Ruimin and Anand, Pranav and Walker, Marilyn},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5543},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {360--369},
 publisher = {Association for Computational Linguistics},
 title = {Modelling Protagonist Goals and Desires in First-Person Narrative},
 year = {2017}
}

@inproceedings{W17-5544,
 abstract = {We present the implementation of an autonomous chatbot, SHIHbot, deployed on
Facebook, which answers a wide variety of sexual health questions on HIV/AIDS.
The chatbot's response database is com-piled from professional medical and
public health resources in order to provide reliable information to users. The
system's backend is NPCEditor, a response selection platform trained on linked
questions and answers; to our knowledge this is the first retrieval-based
chatbot deployed on a large public social network.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Brixey, Jacqueline and Hoegen, Rens and Lan, Wei and Rusow, Joshua and Singla, Karan and Yin, Xusen and Artstein, Ron and Leuski, Anton},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5544},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {370--373},
 publisher = {Association for Computational Linguistics},
 title = {SHIHbot: A Facebook chatbot for Sexual Health Information on HIV/AIDS},
 year = {2017}
}

@inproceedings{W17-5545,
 abstract = {Building dialogue interfaces for real-world scenarios often entails training
semantic parsers starting from zero examples. How can we build datasets that
better capture the variety of ways users might phrase their queries, and what
queries are actually realistic?  \newcite{Wang2015BuildingAS} proposed a method
to build semantic parsing datasets by generating canonical utterances using a
grammar and having crowdworkers paraphrase them into natural wording. A
limitation of this approach is that it induces bias towards using similar
language as the canonical utterances.  In this work, we present a methodology
that elicits meaningful and lexically diverse queries from users for semantic
parsing tasks. Starting from a seed lexicon and a generative grammar, we pair
logical forms with mixed text-image representations and ask crowdworkers to
paraphrase and confirm the plausibility of the queries that they generated. We
use this method to build a semantic parsing dataset from scratch for a dialog
agent in a smart-home simulation. We find evidence that this dataset, which we
have named SmartHome, is demonstrably more lexically diverse and difficult to
parse than existing domain-specific semantic parsing datasets.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Ravichander, Abhilasha and Manzini, Thomas and Grabmair, Matthias and Neubig, Graham and Francis, Jonathan and Nyberg, Eric},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5545},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {374--383},
 publisher = {Association for Computational Linguistics},
 title = {How Would You Say It? Eliciting Lexically Diverse Dialogue for Supervised Semantic Parsing},
 year = {2017}
}

@inproceedings{W17-5546,
 abstract = {Neural conversational models require substantial amounts of dialogue data to
estimate their parameters and are therefore usually learned on large corpora
such as chat forums or movie subtitles. These corpora are, however, often
challenging to work with, notably due to their frequent lack of turn
segmentation and the presence of multiple references external to the dialogue
itself. This paper shows that these challenges can be mitigated by adding a
weighting model into the architecture. The weighting model, which is itself
estimated from dialogue data, associates each training example to a numerical
weight that reflects its intrinsic quality for dialogue modelling. At training
time, these sample weights are included into the empirical loss to be
minimised. Evaluation results on retrieval-based models trained on movie and TV
subtitles demonstrate that the inclusion of such a weighting model improves the
model performance on unsupervised metrics.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {Lison, Pierre and Bibauw, Serge},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5546},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {384--394},
 publisher = {Association for Computational Linguistics},
 title = {Not All Dialogues are Created Equal: Instance Weighting for Neural Conversational Models},
 year = {2017}
}

@inproceedings{W17-5547,
 abstract = {This article describes a model of other-initiated self-repair for a chatbot
that helps to practice conversation in a foreign language. The model was
developed using a corpus of instant messaging conversations between German
native and non-native speakers. Conversation Analysis helped to create
computational models from a small number of examples. The model has been
validated in an AIML-based chatbot. Unlike typical retrieval-based dialogue
systems, the explanations are generated at run-time from a linguistic database.},
 address = {Saarbr{\~A}¼cken, Germany},
 author = {H\"{o}hn, Sviatlana},
 bdsk-url-1 = {http://aclweb.org/anthology/W17-5547},
 booktitle = {Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue},
 month = {August},
 pages = {395--405},
 publisher = {Association for Computational Linguistics},
 title = {A data-driven model of explanations for a chatbot that helps to practice conversation in a foreign language},
 year = {2017}
}

@inproceedings{W17-5601,
 abstract = {We propose a novel method to bootstrap the construction of parallel corpora for
new pairs of structurally different languages.
We do so by combining the use of a pivot language and self-training.
A pivot language enables the use of existing translation models to bootstrap
the alignment and a self-training procedure enables to achieve better
alignment, both at the document and sentence level.
We also propose several evaluation methods for the resulting alignment.},
 address = {Taipei, Taiwan},
 author = {Park, Jungyeul and Dugast, Loic and Hong, Jeen-Pyo and Shin, Chang-Uk and Cha, Jeong-Won},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5601},
 booktitle = {Proceedings of the First Workshop on Curation and Applications of Parallel and Comparable Corpora},
 month = {November},
 pages = {1--10},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Building a Better Bitext for Structurally Different Languages through Self-training},
 year = {2017}
}

@inproceedings{W17-5602,
 abstract = {Integrating Natural Language Processing (NLP) and computer vision is a
promising effort.
However, the applicability of these methods directly depends on the
availability
of a specific multimodal data that includes images and texts.
In this paper, we present a collection of a Multimodal corpus of comparable
texts and their images in 9 languages
from the web news articles of Euronews website.
This corpus has found widespread use in the NLP community in Multilingual and
multimodal tasks.
Here, we focus on its acquisition of the images and text data and their
multilingual alignment.},
 address = {Taipei, Taiwan},
 author = {Afli, Haithem and Lohar, Pintu and Way, Andy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5602},
 booktitle = {Proceedings of the First Workshop on Curation and Applications of Parallel and Comparable Corpora},
 month = {November},
 pages = {11--15},
 publisher = {Asian Federation of Natural Language Processing},
 title = {MultiNews: A Web collection of an Aligned Multimodal and Multilingual Corpus},
 year = {2017}
}

@inproceedings{W17-5603,
 abstract = {Learning phrase representations has been widely explored in many Natural
Language Processing tasks (e.g., Sentiment Analysis, Machine Translation) and
has shown promising improvements. Previous studies either learn
non-compositional phrase representations with general word embedding learning
techniques or learn compositional phrase representations based on syntactic
structures, which either require huge amounts of human annotations or cannot be
easily generalized to all phrases. In this work, we propose to take advantage
of large-scaled paraphrase database and present a pairwise-GRU framework to
generate compositional phrase representations. Our framework can be re-used to
generate representations for any phrases. Experimental results show that our
framework achieves state-of-the-art results on several phrase similarity tasks.},
 address = {Taipei, Taiwan},
 author = {zhou, zhihao and Huang, Lifu and Ji, Heng},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5603},
 booktitle = {Proceedings of the First Workshop on Curation and Applications of Parallel and Comparable Corpora},
 month = {November},
 pages = {16--23},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Learning Phrase Embeddings from Paraphrases with GRUs},
 year = {2017}
}

@inproceedings{W17-5701,
 abstract = {This paper presents the results of the shared tasks from the 4th workshop on
Asian translation (WAT2017) including J<->E, J<->C scientific paper translation
subtasks, C<->J, K<->J, E<->J patent translation subtasks, H<->E mixed domain
subtasks, J<->E newswire subtasks and J<->E recipe subtasks. For the WAT2017, 12 institutions participated in the shared tasks. About 300 translation results
have been submitted to the automatic evaluation server, and selected
submissions were manually evaluated.},
 address = {Taipei, Taiwan},
 author = {Nakazawa, Toshiaki and Higashiyama, Shohei and Ding, Chenchen and Mino, Hideya and Goto, Isao and Kazawa, Hideto and Oda, Yusuke and Neubig, Graham and Kurohashi, Sadao},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5701},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {1--54},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Overview of the 4th Workshop on Asian Translation},
 year = {2017}
}

@inproceedings{W17-5702,
 abstract = {We propose {\em prefix constraints}, a novel method to enforce
constraints on target sentences in neural machine translation. It
places a sequence of special tokens at the beginning of target
sentence (target prefix), while side constraints
\cite{sennrich2016controlling} places a special token at the end of
source sentence (source suffix). Prefix constraints can be predicted
from source sentence jointly with target sentence, while side
constraints must be provided by the user or predicted by some other
methods. In both methods, special tokens are designed to encode
arbitrary features on target-side or metatextual information. We
show that prefix constraints are more flexible than side constraints
and can be used to control the behavior of neural machine
translation, in terms of output length, bidirectional decoding, domain adaptation, and unaligned target word generation.},
 address = {Taipei, Taiwan},
 author = {Takeno, Shunsuke and Nagata, Masaaki and Yamamoto, Kazuhide},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5702},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {55--63},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Controlling Target Features in Neural Machine Translation via Prefix Constraints},
 year = {2017}
}

@inproceedings{W17-5703,
 abstract = {Neural machine translation (NMT) produces sentences that are more fluent than
those produced by statistical machine translation (SMT). However, NMT has a
very high computational cost because of the high dimensionality of the output
layer. Generally, NMT restricts the size of vocabulary, which results in
infrequent words being treated as out-of-vocabulary (OOV) and degrades the
performance of the translation. In evaluation, we achieved a statistically
significant BLEU score improvement of 0.55-0.77 over the baselines including
the state-of-the-art method.},
 address = {Taipei, Taiwan},
 author = {Sekizawa, Yuuki and Kajiwara, Tomoyuki and Komachi, Mamoru},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5703},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {64--69},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Improving Japanese-to-English Neural Machine Translation by Paraphrasing the Target Language},
 year = {2017}
}

@inproceedings{W17-5704,
 abstract = {Large-scale parallel corpora are indispensable to train highly accurate machine
translators.
However, manually constructed large-scale parallel corpora are not freely
available in many language pairs.
In previous studies, training data have been expanded using a pseudo-parallel
corpus obtained using machine translation of the monolingual corpus in the
target language.
However, in low-resource language pairs in which only low-accuracy machine
translation systems can be used, translation quality is reduces when a
pseudo-parallel corpus is used naively.
To improve machine translation performance with low-resource language pairs, we
propose a method to expand the training data effectively via filtering the
pseudo-parallel corpus using a quality estimation based on back-translation.
As a result of experiments with three language pairs using small, medium, and
large parallel corpora, language pairs with fewer training data filtered out
more sentence pairs and improved BLEU scores more significantly.},
 address = {Taipei, Taiwan},
 author = {Imankulova, Aizhan and Sato, Takayuki and Komachi, Mamoru},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5704},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {70--78},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Improving Low-Resource Neural Machine Translation with Filtered Pseudo-Parallel Corpus},
 year = {2017}
}

@inproceedings{W17-5705,
 abstract = {Aiming at facilitating the research on quality estimation (QE) and
automatic post-editing (APE) of machine translation (MT) outputs, especially for those among Asian languages, we have created new
datasets for Japanese to English, Chinese, and Korean translations.
As the source text, actual utterances in Japanese were extracted from the
log data of our speech translation service.  MT outputs were then given by
phrase-based
statistical MT systems.  Finally, human evaluators were employed to
grade the quality of MT outputs and to post-edit them.
This paper describes the characteristics of the created datasets and
reports on our benchmarking experiments on word-level QE, sentence-level QE, and APE conducted using the created datasets.},
 address = {Taipei, Taiwan},
 author = {Fujita, Atsushi and Sumita, Eiichiro},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5705},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {79--88},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Japanese to English/Chinese/Korean Datasets for Translation Quality Estimation and Automatic Post-Editing},
 year = {2017}
}

@inproceedings{W17-5706,
 abstract = {In this year, we participated in four translation subtasks at WAT 2017.
Our model structure is quite simple but we used it with well-tuned
hyper-parameters, leading to a significant improvement compared to the previous
state-of-the-art system.
We also tried to make use of the unreliable part of the provided parallel
corpus by back-translating and making a synthetic corpus.
Our submitted system achieved the new state-of-the-art performance in terms of
the BLEU score, as well as human evaluation.},
 address = {Taipei, Taiwan},
 author = {Morishita, Makoto and Suzuki, Jun and Nagata, Masaaki},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5706},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {89--94},
 publisher = {Asian Federation of Natural Language Processing},
 title = {NTT Neural Machine Translation Systems at WAT 2017},
 year = {2017}
}

@inproceedings{W17-5707,
 abstract = {This paper describes the Neural Machine Translation systems of Xiamen
University for the shared translation tasks of WAT 2017. Our systems are based
on the Encoder-Decoder framework with attention. We participated in three
subtasks. We experimented subword segmentation, synthetic training data and
model ensembling. Experiments show that all these methods can give substantial
improvements.},
 address = {Taipei, Taiwan},
 author = {Wang, Boli and Tan, Zhixing and Hu, Jinming and Chen, Yidong and shi, xiaodong},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5707},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {95--98},
 publisher = {Asian Federation of Natural Language Processing},
 title = {XMU Neural Machine Translation Systems for WAT 2017},
 year = {2017}
}

@inproceedings{W17-5708,
 abstract = {In this paper, we describe the team UT-IIS's system and results for the WAT
2017 translation tasks. We further investigated several tricks including a
novel technique for initializing embedding layers using only the parallel
corpus, which increased the BLEU score by 1.28, found a practical large batch
size of 256, and gained insights regarding hyperparameter settings. Ultimately, our system obtained a better result than the state-of-the-art system of WAT
2016. Our code is available on https://github.com/nem6ishi/wat17.},
 address = {Taipei, Taiwan},
 author = {Neishi, Masato and Sakuma, Jin and Tohda, Satoshi and Ishiwatari, Shonosuke and Yoshinaga, Naoki and Toyoda, Masashi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5708},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {99--109},
 publisher = {Asian Federation of Natural Language Processing},
 title = {A Bag of Useful Tricks for Practical Neural Machine Translation: Embedding Layer Initialization and Large Batch Size},
 year = {2017}
}

@inproceedings{W17-5709,
 abstract = {Neural machine translation (NMT) cannot handle a larger vocabulary
because the training complexity and decoding complexity proportionally
increase with the number of target words. This problem becomes even
more serious when translating patent documents, which contain many
technical terms that are observed infrequently.  Long et al.(2017)
proposed to select phrases that contain out-of-vocabulary words using
the statistical approach of branching entropy.  The selected phrases
are then replaced with tokens during training and post-translated by
the phrase translation table of SMT.  In this paper, we apply the
method proposed by Long et al. (2017) to the WAT 2017 Japanese-Chinese
and Japanese-English patent datasets.
Evaluation on
Japanese-to-Chinese, Chinese-to-Japanese, Japanese-to-English and
English-to-Japanese patent sentence translation proved the
effectiveness of phrases selected with branching entropy, where the NMT
model of Long et al.(2017) achieves a substantial improvement over a
baseline NMT model without the technique proposed by Long et al.(2017).},
 address = {Taipei, Taiwan},
 author = {Long, Zi and Kimura, Ryuichiro and Utsuro, Takehito and Mitsuhashi, Tomoharu and Yamamoto, Mikio},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5709},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {110--118},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Patent NMT integrated with Large Vocabulary Phrase Translation by SMT at WAT 2017},
 year = {2017}
}

@inproceedings{W17-5710,
 abstract = {System architecture, experimental settings and experimental results of the EHR
team for the WAT2017 tasks are described. We participate in three tasks:
JPCen-ja, JPCzh-ja and JPCko-ja. Although the basic architecture of our system
is NMT, reranking technique is conducted using SMT results. One of the major
drawback of NMT is under-translation and over-translation. On the other hand, SMT infrequently makes such translations. So, using reranking of n-best NMT
outputs by the SMT output, discarding such translations can be expected. We can
improve BLEU score from 46.03 to 47.08 by this technique in JPCzh-ja task.},
 address = {Taipei, Taiwan},
 author = {Ehara, Terumasa},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5710},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {119--126},
 publisher = {Asian Federation of Natural Language Processing},
 title = {SMT reranked NMT},
 year = {2017}
}

@inproceedings{W17-5711,
 abstract = {In this paper, we describe the NICT-2 neural machine translation system
evaluated at WAT2017.  This system uses multiple models as an ensemble and
combines models with opposite decoding directions by reranking (called
bi-directional reranking).
In our experimental results on small data sets, the translation quality
improved when the number of models was increased to 32 in total and did not
saturate.  In the experiments on large data sets, improvements of 1.59-3.32
BLEU points were achieved when six-model ensembles were combined by the
bi-directional reranking.},
 address = {Taipei, Taiwan},
 author = {Imamura, Kenji and Sumita, Eiichiro},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5711},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {127--134},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Ensemble and Reranking: Using Multiple Models in the NICT-2 Neural Machine Translation System at WAT2017},
 year = {2017}
}

@inproceedings{W17-5712,
 abstract = {This paper describes the details about the NAIST-NICT machine translation
system for WAT2017 English-Japanese Scientific Paper Translation Task. The
system consists of a language-independent tokenizer and an attentional
encoder-decoder style neural machine translation model. According to the
official results, our system achieves higher translation accuracy than any
systems submitted previous campaigns despite simple model architecture.},
 address = {Taipei, Taiwan},
 author = {Oda, Yusuke and Sudoh, Katsuhito and Nakamura, Satoshi and Utiyama, Masao and Sumita, Eiichiro},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5712},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {135--139},
 publisher = {Asian Federation of Natural Language Processing},
 title = {A Simple and Strong Baseline: NAIST-NICT Neural Machine Translation System for WAT2017 English-Japanese Translation Task},
 year = {2017}
}

@inproceedings{W17-5713,
 abstract = {Japio participates in patent subtasks (JPC-EJ/JE/CJ/KJ) with phrase-based
statistical machine translation (SMT) and neural machine translation (NMT)
systems which are trained with its own patent corpora in addition to the
subtask corpora provided by organizers of WAT2017.  In EJ and CJ subtasks, SMT
and NMT systems whose sizes of training corpora are about 50 million and 10
million sentence pairs respectively achieved comparable scores for automatic
evaluations, but NMT systems were superior to SMT systems for both official and
in-house human evaluations.},
 address = {Taipei, Taiwan},
 author = {Kinoshita, Satoshi and Oshio, Tadaaki and Mitsuhashi, Tomoharu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5713},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {140--145},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Comparison of SMT and NMT trained with large Patent Corpora: Japio at WAT2017},
 year = {2017}
}

@inproceedings{W17-5714,
 abstract = {We describe here our approaches and results on the WAT 2017 shared translation
tasks. Following our good results with Neural Machine Translation in the
previous shared task, we continue this approach this year, with incremental
improvements in models and training methods. We focused on the ASPEC dataset
and could improve the state-of-the-art results for Chinese-to-Japanese and
Japanese-to-Chinese translations.},
 address = {Taipei, Taiwan},
 author = {Cromieres, Fabien and Dabre, Raj and Nakazawa, Toshiaki and Kurohashi, Sadao},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5714},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {146--153},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Kyoto University Participation to WAT 2017},
 year = {2017}
}

@inproceedings{W17-5715,
 abstract = {The paper presents this year's CUNI submissions to the WAT 2017 Translation
Task focusing on the Japanese-English translation, namely Scientific papers
subtask, Patents subtask and Newswire subtask. We compare two neural network
architectures, the standard sequence-to-sequence with attention (Seq2Seq) and
an
architecture using convolutional sentence encoder (FBConv2Seq), both
implemented in the NMT framework Neural Monkey that we currently participate in
developing.
We also compare various types of preprocessing of the source Japanese sentences
and their impact on the overall results. Furthermore, we include the results of
our
experiments with out-of-domain data obtained by combining the corpora provided
for each
subtask.},
 address = {Taipei, Taiwan},
 author = {Kocmi, Tom and Vari\v{s}, Du\v{s}an and Bojar, Ond\v{r}ej},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5715},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {154--159},
 publisher = {Asian Federation of Natural Language Processing},
 title = {CUNI NMT System for WAT 2017 Translation Tasks},
 year = {2017}
}

@inproceedings{W17-5716,
 abstract = {In this paper, we describe our neural machine translation (NMT) system, which
is based on the attention-based NMT and uses long short-term memories (LSTM) as
RNN. We implemented beam search and ensemble decoding in the NMT system. The
system was tested on the 4th Workshop on Asian Translation (WAT 2017) shared
tasks. In our experiments, we participated in the scientific paper subtasks and
attempted Japanese-English, English-Japanese, and Japanese-Chinese translation
tasks. The experimental results showed that implementation of beam search and
ensemble decoding can effectively improve the translation quality.},
 address = {Taipei, Taiwan},
 author = {Matsumura, Yukio and Komachi, Mamoru},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5716},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {160--166},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Tokyo Metropolitan University Neural Machine Translation System for WAT 2017},
 year = {2017}
}

@inproceedings{W17-5717,
 abstract = {In this paper, we empirically compare
the two encoder-decoder neural machine
translation architectures: convolutional se-
quence to sequence model (ConvS2S) and
recurrent sequence to sequence model
(RNNS2S) for English-Hindi language
pair as part of IIT Bombay{\^a}s submission
to WAT2017 shared task. We report the
results for both English-Hindi and Hindi-
English direction of language pair.},
 address = {Taipei, Taiwan},
 author = {Singh, Sandhya and Panjwani, Ritesh and Kunchukuttan, Anoop and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5717},
 booktitle = {Proceedings of the 4th Workshop on Asian Translation (WAT2017)},
 month = {November},
 pages = {167--170},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Comparing Recurrent and Convolutional Architectures for English-Hindi Neural Machine Translation},
 year = {2017}
}

@inproceedings{W17-5801,
 abstract = {A classifier for automatic detection of stance towards vaccination in online
forums was trained and evaluated. Debate posts from six discussion threads on
the British parental website Mumsnet were manually annotated for stance
'against' or 'for' vaccination, or as 'undecided'.  A support vector machine, trained to detect the three classes, achieved a macro F-score of 0.44, while a
macro F-score of 0.62 was obtained by the same type of classifier on the binary
classification task of distinguishing stance 'against' vaccination from stance
'for' vaccination. These results show that vaccine stance detection in online
forums is a difficult task, at least for the type of model investigated and for
the relatively small training corpus that was used. Future work will therefore
include an expansion of the training data and an evaluation of other types of
classifiers and features.},
 address = {Taipei, Taiwan},
 author = {Skeppstedt, Maria and Kerren, Andreas and Stede, Manfred},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5801},
 booktitle = {Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 (DDDSM-2017)},
 month = {November},
 pages = {1--8},
 publisher = {Association for Computational Linguistics},
 title = {Automatic detection of stance towards vaccination in online discussion forums},
 year = {2017}
}

@inproceedings{W17-5802,
 abstract = {We develop a computational model to
discover the potential causes of depression
by analysing the topics in a usergenerated
text. We show the most prominent
causes, and how these causes evolve
over time. Also, we highlight the differences
in causes between students with low
and high neuroticism. Our studies demonstrate
that the topics reveal valuable clues
about the causes contributing to depressed
mood. Identifying causes can have a significant
impact on improving the quality of
depression care; thereby providing greater
insights into a patient{\^a}s state for pertinent
treatment recommendations. Hence, this
study significantly expands the ability to
discover the potential factors that trigger
depression, making it possible to increase
the efficiency of depression treatment.},
 address = {Taipei, Taiwan},
 author = {Abd Yusof, Noor Fazilla and Lin, Chenghua and Guerin, Frank},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5802},
 booktitle = {Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 (DDDSM-2017)},
 month = {November},
 pages = {9--17},
 publisher = {Association for Computational Linguistics},
 title = {Analysing the Causes of Depressed Mood from Depression Vulnerable Individuals},
 year = {2017}
}

@inproceedings{W17-5803,
 abstract = {To date, various Twitter-based event detection systems have been proposed.
Most of their targets, however, share common characteristics. They are seasonal
or global events such as earthquakes and flu pandemics.
In contrast, this study targets unseasonal and local disease events.
Our system investigates the frequencies of disease-related words such as
"nausea","chill",and "diarrhea" and estimates the number of patients using
regression of these word frequencies.
Experiments conducted using Japanese 47 areas from January 2017 to April 2017
revealed that the detection of small and unseasonal event is extremely
difficult (overall performance: 0.13).
However, we found that the event scale and the detection performance show high
correlation in the specified cases (in the phase of patient increasing or
decreasing).
The results also suggest that when 150 and more patients appear in a high
population area, we can expect that our social sensors detect this outbreak.
Based on these results, we can infer that social sensors can reliably detect
unseasonal and local disease events under certain conditions, just as they can
for seasonal or global events.},
 address = {Taipei, Taiwan},
 author = {Takeuchi, Ryo and ISO, Hayate and Ito, Kaoru and Wakamiya, Shoko and Aramaki, Eiji},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5803},
 booktitle = {Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 (DDDSM-2017)},
 month = {November},
 pages = {18--25},
 publisher = {Association for Computational Linguistics},
 title = {Multivariate Linear Regression of Symptoms-related Tweets for Infectious Gastroenteritis Scale Estimation},
 year = {2017}
}

@inproceedings{W17-5804,
 abstract = {The increasing popularity of social media lead users to share enormous
information on the internet. This information has various application like, it
can be used to develop models to understand or predict user behavior on social
media platforms. For example, few online retailers have studied the shopping
patterns to predict shopper{\^a}s pregnancy stage. Another interesting
application is to use the social media platforms to analyze users{\^a}
health-related information. In this study, we developed a tree kernel-based
model to classify tweets conveying pregnancy related information using this
corpus. The developed pregnancy classification model achieved an accuracy of
0.847 and an F-score of 0.565. A new corpus from popular social media platform
Twitter was developed for the purpose of this study.  In future, we would like
to improve this corpus by reducing noise such as retweets.},
 address = {Taipei, Taiwan},
 author = {Huang, Yi-Jie and Su, Chu Hsien and Chang, Yi-Chun and Ting, Tseng-Hsin and Fu, Tzu-Yuan and Wang, Rou-Min and Dai, Hong-Jie and Chang, Yung-Chun and Jonnagaddala, Jitendra and Hsu, Wen-Lian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5804},
 booktitle = {Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 (DDDSM-2017)},
 month = {November},
 pages = {26--32},
 publisher = {Association for Computational Linguistics},
 title = {Incorporating Dependency Trees Improve Identification of Pregnant Women on Social Media Platforms},
 year = {2017}
}

@inproceedings{W17-5805,
 abstract = {Traditional disease surveillance systems depend on outpatient reporting and
virological test results released by hospitals. These data have valid and
accurate information about emerging outbreaks but it{\^a}s often not timely. In
recent years the exponential growth of users getting connected to social media
provides immense knowledge about epidemics by sharing related information.
Social media can now flag more immediate concerns related to out-breaks in real
time. In this paper we apply the long short-term memory recurrent neural
net-work (RNN) architecture to classify tweets conveyed influenza-related
information and compare its performance with baseline algorithms including
support vector machine (SVM), decision tree, naive Bayes, simple logistics, and
naive Bayes multinomial. The developed RNN model achieved an F-score of 0.845
on the MedWeb task test set, which outperforms the F-score of SVM without
applying the synthetic minority oversampling technique by 0.08. The F-score of
the RNN model is within 1% of the highest score achieved by SVM with
oversampling technique.},
 address = {Taipei, Taiwan},
 author = {Wang, Chen-Kai and Singh, Onkar and Tang, Zhao-Li and Dai, Hong-Jie},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5805},
 booktitle = {Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 (DDDSM-2017)},
 month = {November},
 pages = {33--38},
 publisher = {Association for Computational Linguistics},
 title = {Using a Recurrent Neural Network Model for Classification of Tweets Conveyed Influenza-related Information},
 year = {2017}
}

@inproceedings{W17-5806,
 abstract = {Effective response to infectious diseases
outbreaks relies on the rapid and
early detection of those outbreaks. Invalidated, yet timely and openly available
digital information can be used for
the early detection of outbreaks. Public
health surveillance authorities can exploit
these early warnings to plan and
co-ordinate rapid surveillance and
emergency response programs. In
2016, a digital disease detection competition
named ZikaHack was
launched. The objective of the competition
was for multidisciplinary teams
to design, develop and demonstrate innovative
digital disease detection solutions
to retrospectively detect the 2015-
16 Brazilian Zika virus outbreak earlier
than traditional surveillance methods.
In this paper, an overview of the ZikaHack
competition is provided. The
challenges and lessons learned in organizing
this competition are also discussed
for use by other researchers interested
in organizing similar competitions.},
 address = {Taipei, Taiwan},
 author = {Adam, Dillon C and Jonnagaddala, Jitendra and Han-Chen, Daniel and Batongbacal, Sean and Almeida, Luan and Zhu, Jing Z and Yang, Jenny J and Mundekkat, Jumail M and Badman, Steven and Chughtai, Abrar and MacIntyre, C Raina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5806},
 booktitle = {Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 (DDDSM-2017)},
 month = {November},
 pages = {39--46},
 publisher = {Association for Computational Linguistics},
 title = {ZikaHack 2016: A digital disease detection competition},
 year = {2017}
}

@inproceedings{W17-5807,
 abstract = {Biomedical Named Entity (NE) recognition is a core technique for various works
in the biomedical domain. In previous studies, using machine learning algorithm
shows better performance than dictionary-based and rule-based approaches
because there are too many terminological variations of biomedical NEs and new
biomedical NEs are constantly generated. To achieve the high performance with a
machine-learning algorithm, good-quality corpora are required. However, it is
difficult to obtain the good-quality corpora because an-notating a biomedical
corpus for ma-chine-learning is extremely time-consuming and costly. In
addition, most previous corpora are insufficient for high-level tasks because
they cannot cover various domains. Therefore, we propose a method for
generating a large amount of machine-labeled data that covers various domains.
To generate a large amount of machine-labeled data, firstly we generate an
initial machine-labeled data by using a chunker and MetaMap. The chunker is
developed to extract only biomedical NEs with manually annotated data. MetaMap
is used to annotate the category of bio-medical NE. Then we apply the
self-training approach to bootstrap the performance of initial machine-labeled
data. In our experiments, the biomedical NE recognition system that is trained
with our proposed machine-labeled data achieves much high performance. As a
result, our system outperforms biomedical NE recognition system that using
MetaMap only with 26.03%p improvements on F1-score.},
 address = {Taipei, Taiwan},
 author = {Kim, Juae and Kwon, Sunjae and Ko, Youngjoong and Seo, Jungyun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5807},
 booktitle = {Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 (DDDSM-2017)},
 month = {November},
 pages = {47--51},
 publisher = {Association for Computational Linguistics},
 title = {A Method to Generate a Machine-Labeled Data for Biomedical Named Entity Recognition with Various Sub-Domains},
 year = {2017}
}

@inproceedings{W17-5808,
 abstract = {The study of drug-drug interaction (DDI) is important in the drug discovering.
Both PubMed and DrugBank are rich resources to retrieve DDI information which
is usually represented in plain text. Automatically extracting DDI pairs from
text improves the quality of drug discov-ering. In this paper, we presented a
study that focuses on the DDI classification. We normalized the drug names, and
developed both sentence-level and corpus-level features for DDI classification.
A classifier ensemble approach is used for the unbalance DDI labels problem.
Our approach achieved an F-score of 65.4% on SemEval 2013 DDI test set. The
experimental results also show the effects of proposed corpus-level features in
the DDI task.},
 address = {Taipei, Taiwan},
 author = {Tu, Jing Cyun and Lai, Po-Ting and Tsai, Richard Tzong-Han},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5808},
 booktitle = {Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 (DDDSM-2017)},
 month = {November},
 pages = {52--56},
 publisher = {Association for Computational Linguistics},
 title = {Enhancing Drug-Drug Interaction Classification with Corpus-level Feature and Classifier Ensemble},
 year = {2017}
}

@inproceedings{W17-5809,
 abstract = {In this work, we introduce a novel feature engineering approach named
{\^a}algebraic invariance{\^a} to identify discriminative patterns for learning
relation pair features for the chemical-disease relation (CDR) task of
BioCreative V. Our method exploits the existing structural similarity of the
key concepts of relation descriptions from the CDR corpus to generate robust
linguistic patterns for SVM tree kernel-based learning. Preprocessing of the
training data classifies the entity pairs as either related or unrelated to
build instance types for both inter-sentential and intra-sentential scenarios.
An invariant function is proposed to process and optimally cluster similar
patterns for both positive and negative instances. The learning model for CDR
pairs is based on the SVM tree kernel approach, which generates feature trees
and vectors and is modeled on suit- able invariance based patterns, bringing
brevity, precision and context to the identifier features. Results demonstrate
that our method outperformed other compared approaches, achieved a high recall
rate of 85.08%, and averaged an F1- score of 54.34% without the use of any
additional knowledge bases.},
 address = {Taipei, Taiwan},
 author = {Warikoo, Neha and Chang, Yung-Chun and Hsu, Wen-Lian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5809},
 booktitle = {Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 (DDDSM-2017)},
 month = {November},
 pages = {57--64},
 publisher = {Association for Computational Linguistics},
 title = {Chemical-Induced Disease Detection Using Invariance-based Pattern Learning Model},
 year = {2017}
}

@inproceedings{W17-5901,
 abstract = {This paper describes the creation of a new annotated learner corpus. The aim is
to use this corpus to develop an automated system for corrective feedback on
students{\^a} writing. With this system, students will be able to receive timely
feedback on language errors before they submit their assignments for grading. A
corpus of assignments submitted by first year engineering students was
compiled, and a new error tag set for the NTU Corpus of Learner English
(NTUCLE) was developed based on that of the NUS Corpus of Learner English
(NUCLE), as well as marking rubrics used at NTU. After a description of the
corpus, error tag set and annotation process, the paper presents the results of
the annotation exercise as well as follow up actions. The final error tag set, which is significantly larger than that for the NUCLE error categories, is then
presented before a brief conclusion summarising our experience and future
plans.},
 address = {Taipei, Taiwan},
 author = {Winder, Roger Vivek Placidus and MacKinnon, Joseph and Li, Shu Yun and Lin, Benedict Christopher Tzer Liang and Heah, Carmel Lee Hah and Morgado da Costa, Lu\'{i}s and Kuribayashi, Takayuki and Bond, Francis},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5901},
 booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
 month = {December},
 pages = {1--11},
 publisher = {Asian Federation of Natural Language Processing},
 title = {NTUCLE: Developing a Corpus of Learner English to Provide Writing Support for Engineering Students},
 year = {2017}
}

@inproceedings{W17-5902,
 abstract = {We present a pilot study on parsing non-native texts written by learners of
Czech. We performed experiments that have shown that at least  high-level
syntactic functions, like subject, predicate, and object, can be assigned based
on a parser trained on standard native language.},
 address = {Taipei, Taiwan},
 author = {Hana, Jirka and Hladka, Barbora},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5902},
 booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
 month = {December},
 pages = {12--16},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Understanding Non-Native Writings: Can a Parser Help?},
 year = {2017}
}

@inproceedings{W17-5903,
 abstract = {Fill-in-the-blank items are a common form of exercise in computer-assisted
language learning systems.  To automatically generate an effective item, the
system must be able to select a high-quality carrier sentence that illustrates
the usage of the target word.  Previous approaches for carrier sentence
selection have considered sentence length, vocabulary difficulty, the position
of the target word and the presence of finite verbs.  This paper investigates
the utility of word co-occurrence statistics and lexical similarity as
selection criteria.  In an evaluation on generating fill-in-the-blank items for
learning Chinese as a foreign language, we show that these two criteria can
improve carrier sentence quality.},
 address = {Taipei, Taiwan},
 author = {Jiang, Shu and Lee, John},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5903},
 booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
 month = {December},
 pages = {17--22},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Carrier Sentence Selection for Fill-in-the-blank Items},
 year = {2017}
}

@inproceedings{W17-5904,
 abstract = {In today's technology driven digital era, education domain is undergoing a
transformation from traditional approaches to more learner controlled and
flexible methods of learning. This transformation has opened the new avenues
for interdisciplinary research in the field of educational technology and
natural language processing in developing quality digital aids for learning and
teaching. The tool presented here - Hindi Shabhadamitra, developed using Hindi
Wordnet for Hindi language learning, is one such e-learning tool. It has been
developed as a teaching and learning aid suitable for formal school based
curriculum and informal setup for self learning users. Besides vocabulary, it
also provides word based grammar along with images and pronunciation for better
learning and retention. This aid demonstrates that how a rich lexical resource
like wordnet can be systematically remodeled for practical usage in the
educational domain.},
 address = {Taipei, Taiwan},
 author = {Redkar, Hanumant and Singh, Sandhya and Somasundaram, Meenakshi and Gorasia, Dhara and Kulkarni, Malhar and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5904},
 booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
 month = {December},
 pages = {23--28},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Hindi Shabdamitra: A Wordnet based E-Learning Tool for Language Learning and Teaching},
 year = {2017}
}

@inproceedings{W17-5905,
 abstract = {This paper provides an overview along with our findings of the Chinese Spelling
Check shared task at NLPTEA 2017. The goal of this task is to develop a
computer-assisted system to automatically diagnose typing errors in traditional
Chinese sentences written by students. We defined six types of errors which
belong to two categories. Given a sentence, the system should detect where the
errors are, and for each detected error determine its type and provide
correction suggestions. We designed, constructed, and released a benchmark
dataset for this task.},
 address = {Taipei, Taiwan},
 author = {Fung, Gabriel and Debosschere, Maxime and Wang, Dingmin and Li, Bo and Zhu, Jia and Wong, Kam-Fai},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5905},
 booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
 month = {December},
 pages = {29--34},
 publisher = {Asian Federation of Natural Language Processing},
 title = {NLPTEA 2017 Shared Task -- Chinese Spelling Check},
 year = {2017}
}

@inproceedings{W17-5906,
 abstract = {This paper presents a Chinese spelling check approach based on language models
combined with string match algorithm to treat the problems resulted from the
influence caused by Cantonese mother tone. N-grams first used to detecting the
probability of sentence constructed by the writers, a string matching algorithm
called      Knuth-Morris-Pratt (KMP) Algorithm  is used to detect and correct
the error. According to the experimental results, the proposed approach can
detect the error and provide the corresponding correction.},
 address = {Taipei, Taiwan},
 author = {Yeh, Jui-Feng and Chang, Li-Ting and Liu, Chan-Yi and Hsu, Tsung-Wei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5906},
 booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
 month = {December},
 pages = {35--38},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Chinese Spelling Check based on N-gram and String Matching Algorithm},
 year = {2017}
}

@inproceedings{W17-5907,
 abstract = {Detection and correction of Chinese grammatical errors have been two of major
challenges for Chinese automatic grammatical error diagnosis.This paper
presents an N-gram model for automatic detection and correction of Chinese
grammatical errors in NLPTEA 2017 task. The experiment results show that the
proposed method is good at correction of Chinese grammatical errors.},
 address = {Taipei, Taiwan},
 author = {Zhao, Jianbo and Liu, Hao and Bao, Zuyi and Bai, Xiaopeng and Li, Si and Lin, Zhiqing},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5907},
 booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
 month = {December},
 pages = {39--44},
 publisher = {Asian Federation of Natural Language Processing},
 title = {N-gram Model for Chinese Grammatical Error Diagnosis},
 year = {2017}
}

@inproceedings{W17-5908,
 abstract = {Spelling errors occur frequently in educational settings, but their influence
on automatic scoring is largely unknown.
We therefore investigate the influence of spelling errors on content scoring
performance using the example of the ASAP corpus.
We conduct an annotation study on the nature of spelling errors in the ASAP
dataset and utilize these finding in machine learning experiments that measure
the influence of spelling errors on automatic content scoring. Our main finding
is that scoring methods using both token and character n-gram features are
robust against spelling errors up to the error frequency in ASAP.},
 address = {Taipei, Taiwan},
 author = {Horbach, Andrea and Ding, Yuning and Zesch, Torsten},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5908},
 booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
 month = {December},
 pages = {45--53},
 publisher = {Asian Federation of Natural Language Processing},
 title = {The Influence of Spelling Errors on Content Scoring Performance},
 year = {2017}
}

@inproceedings{W17-5909,
 abstract = {Part-of-speech (POS) tagging and chunking have been used in tasks targeting
learner English;
however, to the best our knowledge, few studies have evaluated their
performance and no studies have revealed the causes of POS-tagging/chunking
errors in detail.
Therefore, we investigate performance and analyze the causes of failure. We
focus on spelling errors that occur frequently in learner English.
We demonstrate that spelling errors reduced POS-tagging performance by 0.23\%
owing to spelling errors, and that a spell checker is not necessary for
POS-tagging/chunking of learner English.},
 address = {Taipei, Taiwan},
 author = {Mizumoto, Tomoya and Nagata, Ryo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5909},
 booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
 month = {December},
 pages = {54--58},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Analyzing the Impact of Spelling Errors on POS-Tagging and Chunking in Learner English},
 year = {2017}
}

@inproceedings{W17-5910,
 abstract = {This paper revisits the problem of complex word identification (CWI) following
up the SemEval CWI shared task. We use ensemble classifiers to investigate how
well computational methods can discriminate between complex and non-complex
words. Furthermore, we analyze the classification performance to understand
what makes lexical complexity challenging. Our findings show that most systems
performed poorly on the SemEval CWI dataset, and one of the reasons for that is
the way in which human annotation was performed.},
 address = {Taipei, Taiwan},
 author = {Zampieri, Marcos and Malmasi, Shervin and Paetzold, Gustavo and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5910},
 booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
 month = {December},
 pages = {59--63},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Complex Word Identification: Challenges in Data Annotation and System Performance},
 year = {2017}
}

@inproceedings{W17-5911,
 abstract = {Sentence retrieval is an important NLP application for English as a Second
Language (ESL) learners.
ESL learners are familiar with web search engines, but generic web search
results may not be adequate for composing documents in a specific domain.
However, if we build our own search system specialized to a domain, it may be
subject to the data sparseness problem.
Recently proposed word2vec partially addresses the data sparseness problem, but
fails to extract sentences relevant to queries owing to the modeling of the
latent intent of the query.
Thus, we propose a method of retrieving example sentences using kernel
embeddings and N-gram windows.
This method implicitly models latent intent of query and sentences, and
alleviates the problem of noisy alignment.
Our results show that our method achieved higher precision in sentence
retrieval for ESL in the domain of a university press release corpus, as
compared to a previous unsupervised method used for a semantic textual
similarity task.},
 address = {Taipei, Taiwan},
 author = {Shioda, Kent and Komachi, Mamoru and Ikeya, Rue and Mochihashi, Daichi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5911},
 booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
 month = {December},
 pages = {64--68},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Suggesting Sentences for ESL using Kernel Embeddings},
 year = {2017}
}

@inproceedings{W17-5912,
 abstract = {Event timeline serves as the basic structure of history, and it is used as a
disposition of key phenomena in studying history as a subject in secondary
school. In order to enable a student to understand a historical phenomenon as a
series of connected events, we present a system for automatic event timeline
generation from history textbooks. Additionally, we propose Message Sequence
Chart (MSC) and time-map based visualization techniques to visualize an event
timeline. We also identify key computational challenges in developing natural
language processing based applications for history textbooks.},
 address = {Taipei, Taiwan},
 author = {Bedi, Harsimran and Patil, Sangameshwar and Hingmire, Swapnil and Palshikar, Girish},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-5912},
 booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
 month = {December},
 pages = {69--77},
 publisher = {Asian Federation of Natural Language Processing},
 title = {Event Timeline Generation from History Textbooks},
 year = {2017}
}

@inproceedings{W17-6001,
 abstract = {For practical chatbots, one of the essential factor for improving user
experience is the capability of customizing the talking style of the agents, that is, to make chatbots provide responses meeting users' preference on
language styles, topics, etc. To address this issue, this paper proposes to
incorporate linguistic biases, which implicitly involved in the conversation
corpora generated by human groups in the Social Network Services (SNS), into
the encoder-decoder based response generator. By attaching a specially designed
neural component to dynamically control the impact of linguistic biases in
response generation, a Group Linguistic Bias Aware Neural Response Generation
(GLBA-NRG) model is eventually presented. The experimental results on the
dataset from the Chinese SNS show that the proposed architecture outperforms
the current response generating models by producing both meaningful and vivid
responses with customized styles.},
 address = {Taiwan},
 author = {Wang, Jianan and Wang, Xin and Li, Fang and Xu, Zhen and Wang, Zhuoran and Wang, Baoxun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6001},
 booktitle = {Proceedings of the 9th SIGHAN Workshop on Chinese Language Processing},
 month = {December},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Group Linguistic Bias Aware Neural Response Generation},
 year = {2017}
}

@inproceedings{W17-6002,
 abstract = {For Chinese word segmentation, the large-scale annotated corpora mainly focus
on newswire and only a handful of annotated data is available in other domains
such as patents and literature. Considering the limited amount of annotated
target domain data, it is a challenge for segmenters to learn domain-specific
information while avoid getting over-fitted at the same time. In this paper, we
propose a neural regularized domain adaptation method for Chinese word
segmentation. The teacher networks trained in source domain are employed to
regularize the training process of the student network by preserving the
general knowledge. In the experiments, our neural regularized domain adaptation
method achieves a better performance comparing to previous methods.},
 address = {Taiwan},
 author = {Bao, Zuyi and Li, Si and XU, Weiran and GAO, Sheng},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6002},
 booktitle = {Proceedings of the 9th SIGHAN Workshop on Chinese Language Processing},
 month = {December},
 pages = {11--20},
 publisher = {Association for Computational Linguistics},
 title = {Neural Regularized Domain Adaptation for Chinese Word Segmentation},
 year = {2017}
}

@inproceedings{W17-6003,
 abstract = {Sub-character components of Chinese characters carry important semantic
information, and recent studies have shown that utilizing this information can
improve performance on core semantic tasks. In this paper, we hypothesize that
in addition to semantic information, sub-character components may also carry
emotional information, and that utilizing it should improve performance on
sentiment analysis tasks. We conduct a series of experiments on four Chinese
sentiment data sets and show that we can significantly improve the performance
in various tasks over that of a character-level embeddings baseline. We then
focus on qualitatively assessing multiple examples and trying to explain how
the sub-character components affect the results in each case.},
 address = {Taiwan},
 author = {Benajiba, Yassine and Biran, Or and Weng, Zhiliang and Zhang, Yong and Sun, Jin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6003},
 booktitle = {Proceedings of the 9th SIGHAN Workshop on Chinese Language Processing},
 month = {December},
 pages = {21--29},
 publisher = {Association for Computational Linguistics},
 title = {The Sentimental Value of Chinese Sub-Character Components},
 year = {2017}
}

@inproceedings{W17-6004,
 abstract = {Answer extraction is the most important part of a chinese web-based question
answering system. In order to enhance the robustness and adaptability of answer
extraction to new domains and eliminate the influence of the incomplete and
noisy search snippets, we propose two new answer exraction methods. We utilize
text patterns to generate Part-of-Speech (POS) patterns. In addition, a method
is proposed to construct a POS tree by using these POS patterns. The POS tree
is useful to candidate answer extraction of web-based question answering. To
retrieve a efficient POS tree, the similarities between questions are used to
select the question-answer pairs whose questions are similar to the unanswered
question. Then, the POS tree is improved based on these question-answer pairs.
In order to rank these candidate answers, the weights of the leaf nodes of the
POS tree are calculated using a heuristic method. Moreover, the Genetic
Algorithm (GA) is used to train the weights. The experimental results of
10-fold crossvalidation show that the weighted POS tree trained by GA can
improve the accu-
racy of answer extraction.},
 address = {Taiwan},
 author = {Li, Shuihua and Zhang, Xiaoming and Li, Zhoujun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6004},
 booktitle = {Proceedings of the 9th SIGHAN Workshop on Chinese Language Processing},
 month = {December},
 pages = {30--36},
 publisher = {Association for Computational Linguistics},
 title = {Chinese Answer Extraction Based on POS Tree and Genetic Algorithm},
 year = {2017}
}

@inproceedings{W17-6005,
 abstract = {Terms extensively exist in specific domains, and term translation plays a
critical role in domain-specific machine translation (MT) tasks. However, it's
a challenging task to translate them correctly for the huge number of
pre-existing terms and the endless new terms. To achieve better term
translation quality, it is necessary to inject external term knowledge into the
underlying MT system. Fortunately, there are plenty of term translation
knowledge in parenthetical sentences on the Internet. In this paper, we propose
a simple, straightforward and effective framework to improve term translation
by learning from parenthetical sentences. This framework includes: (1) a
focused web crawler; (2) a parenthetical sentence filter, acquiring
parenthetical sentences including bilingual term pairs; (3) a term translation
knowledge extractor, extracting bilingual term translation candidates; (4) a
probability learner, generating the term translation table for MT decoders. The
extensive experiments demonstrate that our proposed framework significantly
improves the translation quality of terms and sentences.},
 address = {Taiwan},
 author = {Huang, Guoping and Zhang, Jiajun and Zhou, Yu and Zong, Chengqing},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6005},
 booktitle = {Proceedings of the 9th SIGHAN Workshop on Chinese Language Processing},
 month = {December},
 pages = {37--45},
 publisher = {Association for Computational Linguistics},
 title = {Learning from Parenthetical Sentences for Term Translation in Machine Translation},
 year = {2017}
}

@inproceedings{W17-6201,
 address = {Ume\r{a}, Sweden},
 author = {Koller, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6201},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {A Feature Structure Algebra for FTAG},
 year = {2017}
}

@inproceedings{W17-6202,
 address = {Ume\r{a}, Sweden},
 author = {Fowlie, Meaghan and Koller, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6202},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {11--20},
 publisher = {Association for Computational Linguistics},
 title = {Parsing Minimalist Languages with Interpreted Regular Tree Grammars},
 year = {2017}
}

@inproceedings{W17-6203,
 address = {Ume\r{a}, Sweden},
 author = {Burkhardt, Benjamin and Lichte, Timm and Kallmeyer, Laura},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6203},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {21--30},
 publisher = {Association for Computational Linguistics},
 title = {Depictives in English: An LTAG Approach},
 year = {2017}
}

@inproceedings{W17-6204,
 address = {Ume\r{a}, Sweden},
 author = {Aggazzotti, Cristina and Shieber, Stuart M.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6204},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {31--42},
 publisher = {Association for Computational Linguistics},
 title = {Reflexives and Reciprocals in Synchronous Tree Adjoining Grammar},
 year = {2017}
}

@inproceedings{W17-6205,
 address = {Ume\r{a}, Sweden},
 author = {Han, Chung-hye and Sarkar, Anoop},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6205},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {43--52},
 publisher = {Association for Computational Linguistics},
 title = {Coordination in TAG without the Conjoin Operation},
 year = {2017}
}

@inproceedings{W17-6206,
 address = {Ume\r{a}, Sweden},
 author = {Storoshenko, Dennis Ryan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6206},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {53--60},
 publisher = {Association for Computational Linguistics},
 title = {Scope, Time, and Predicate Restriction in Blackfoot using MC-STAG},
 year = {2017}
}

@inproceedings{W17-6207,
 address = {Ume\r{a}, Sweden},
 author = {Kallmeyer, Laura and Osswald, Rainer},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6207},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {61--70},
 publisher = {Association for Computational Linguistics},
 title = {Combining Predicate-Argument Structure and Operator Projection: Clause Structure in Role and Reference Grammar},
 year = {2017}
}

@inproceedings{W17-6208,
 address = {Ume\r{a}, Sweden},
 author = {White, Michael and Charlow, Simon and Needle, Jordan and Bumford, Dylan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6208},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {71--83},
 publisher = {Association for Computational Linguistics},
 title = {Parsing with Dynamic Continuized CCG},
 year = {2017}
}

@inproceedings{W17-6209,
 address = {Ume\r{a}, Sweden},
 author = {Waszczuk, Jakub and Savary, Agata and Parmentier, Yannick},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6209},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {84--93},
 publisher = {Association for Computational Linguistics},
 title = {Multiword Expression-Aware A$*$ TAG Parsing Revisited},
 year = {2017}
}

@inproceedings{W17-6210,
 address = {Ume\r{a}, Sweden},
 author = {Berglund, Martin and Bj\"{o}rklund, Henrik and Drewes, Frank},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6210},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {94--101},
 publisher = {Association for Computational Linguistics},
 title = {Single-Rooted DAGs in Regular DAG Languages: Parikh Image and Path Languages},
 year = {2017}
}

@inproceedings{W17-6211,
 address = {Ume\r{a}, Sweden},
 author = {Drewes, Frank and Jonsson, Anna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6211},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {102--111},
 publisher = {Association for Computational Linguistics},
 title = {Contextual Hyperedge Replacement Grammars for Abstract Meaning Representations},
 year = {2017}
}

@inproceedings{W17-6212,
 address = {Ume\r{a}, Sweden},
 author = {Corro, Caio and Le Roux, Joseph},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6212},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {112--121},
 publisher = {Association for Computational Linguistics},
 title = {Transforming Dependency Structures to LTAG Derivation Trees},
 year = {2017}
}

@inproceedings{W17-6213,
 address = {Ume\r{a}, Sweden},
 author = {Friedman, Dan and Kasai, Jungo and McCoy, R. Thomas and Frank, Robert and Davis, Forrest and Rambow, Owen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6213},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {122--131},
 publisher = {Association for Computational Linguistics},
 title = {Linguistically Rich Vector Representations of Supertags for TAG Parsing},
 year = {2017}
}

@inproceedings{W17-6214,
 address = {Ume\r{a}, Sweden},
 author = {Xu, Pauli and Frank, Robert and Kasai, Jungo and Rambow, Owen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6214},
 booktitle = {Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms},
 month = {September},
 pages = {132--141},
 publisher = {Association for Computational Linguistics},
 title = {TAG Parser Evaluation using Textual Entailments},
 year = {2017}
}

@inproceedings{W17-6301,
 abstract = {This paper presents a joint model for morphological and
dependency analysis based on automatically acquired lexical
knowledge. This model takes advantage of rich lexical knowledge to
simultaneously resolve word segmentation, POS, and
dependency ambiguities. In our experiments on Japanese, we show the
effectiveness of our joint
model over conventional pipeline models.},
 address = {Pisa, Italy},
 author = {Kawahara, Daisuke and Hayashibe, Yuta and Morita, Hajime and Kurohashi, Sadao},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6301},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Automatically Acquired Lexical Knowledge Improves Japanese Joint Morphological and Dependency Analysis},
 year = {2017}
}

@inproceedings{W17-6302,
 abstract = {In this paper, we present an approach to improve the accuracy of a strong
transition-based dependency parser by exploiting dependency language models
that are extracted from a large parsed corpus. We integrated a small number of
features based on the dependency language models into the parser. To
demonstrate the effectiveness of the proposed approach, we evaluate our parser
on standard English and Chinese data where the base parser could achieve
competitive accuracy scores. Our enhanced parser achieved state-of-the-art
accuracy on Chinese data and competitive results on English data. We gained a
large absolute improvement of one point (UAS) on Chinese and 0.5
points for English.},
 address = {Pisa, Italy},
 author = {Yu, Juntao and Bohnet, Bernd},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6302},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {11--17},
 publisher = {Association for Computational Linguistics},
 title = {Dependency Language Models for Transition-based Dependency Parsing},
 year = {2017}
}

@inproceedings{W17-6303,
 abstract = {We present a systematic analysis of lexicalized vs. delexicalized parsing in
low-resource scenarios, and propose a methodology to choose one method over
another under certain conditions. We create a set of simulation experiments on
41 languages and apply our findings to 9 low-resource languages. Experimental
results show that our methodology chooses the best approach in 8 out of 9
cases.},
 address = {Pisa, Italy},
 author = {Falenska, Agnieszka and \c{C}etino\u{g}lu, \"{O}zlem},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6303},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {18--24},
 publisher = {Association for Computational Linguistics},
 title = {Lexicalized vs. Delexicalized Parsing in Low-Resource Scenarios},
 year = {2017}
}

@inproceedings{W17-6304,
 abstract = {Neural part-of-speech tagging has achieved competitive results with the
incorporation of character-based and pre-trained word embeddings. In this
paper, we show that a state-of-the-art bi-LSTM tagger can benefit from using
information from morphosyntactic lexicons as additional input. The tagger, trained on several dozen languages, shows a consistent, average improvement
when using lexical information, even when also using character-based
embeddings, thus showing the complementarity of the different sources of
lexical information. The improvements are particularly important for the
smaller datasets.},
 address = {Pisa, Italy},
 author = {Sagot, Beno\^{i}t and Mart\'{i}nez Alonso, H\'{e}ctor},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6304},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {25--31},
 publisher = {Association for Computational Linguistics},
 title = {Improving neural tagging with lexical information},
 year = {2017}
}

@inproceedings{W17-6305,
 abstract = {We present a low-rank multi-linear model for the task of solving prepositional
phrase attachment ambiguity (PP task). Our model exploits tensor products of
word embeddings, capturing all possible conjunctions of latent embeddings. Our
results on a wide range of datasets and task settings show that tensor products
are the best compositional operation and that a relatively simple multi-linear
model that uses only word embeddings of lexical features can outperform more
complex non-linear architectures that exploit the same information. Our
proposed model gives the current best reported performance on an out-of-domain
evaluation and performs competively on out-of-domain dependency parsing
datasets.},
 address = {Pisa, Italy},
 author = {Madhyastha, Pranava Swaroop and Carreras, Xavier and Quattoni, Ariadna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6305},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {32--43},
 publisher = {Association for Computational Linguistics},
 title = {Prepositional Phrase Attachment over Word Embedding Products},
 year = {2017}
}

@inproceedings{W17-6306,
 abstract = {This opinion paper proposes the use of parallel treebank as learner corpus.  We
show how an L1-L2 parallel treebank --- i.e., parse trees of non-native
sentences, aligned to the parse trees of their target hypotheses --- can
facilitate retrieval of sentences with specific learner errors.  We argue for
its benefits, in terms of corpus re-use and interoperability, over a
conventional learner corpus annotated with error tags.                    As a proof
of
concept, we conduct a case study on word-order errors made by learners of Chinese as a
foreign language.  We report precision and recall in retrieving a range of
word-order error categories from L1-L2 tree pairs annotated in the Universal
Dependency framework.},
 address = {Pisa, Italy},
 author = {Lee, John and Li, Keying and Leung, Herman},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6306},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {44--49},
 publisher = {Association for Computational Linguistics},
 title = {L1-L2 Parallel Dependency Treebank as Learner Corpus},
 year = {2017}
}

@inproceedings{W17-6307,
 abstract = {This paper applies parsing technology to the task of syntactic simplification
of English sentences, focusing on the identification of text spans that can be
removed from a complex sentence.  We report the most comprehensive evaluation
to-date on this task, using a dataset of sentences that exhibit simplification
based on coordination, subordination, punctuation/parataxis, adjectival
clauses, participial phrases, and appositive phrases.  We train a decision tree
with features derived from text span length, POS tags and dependency relations, and show that it significantly outperforms a parser-only baseline.},
 address = {Pisa, Italy},
 author = {Lee, John and Don, J. Buddhika K. Pathirage},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6307},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {50--55},
 publisher = {Association for Computational Linguistics},
 title = {Splitting Complex English Sentences},
 year = {2017}
}

@inproceedings{W17-6308,
 abstract = {In applying word-based dependency parsing such as Universal Dependencies (UD)
to Japanese, the uncertainty of word segmentation emerges for defining
a word unit of the dependencies.
We introduce the following  hierarchical word structures to
dependency parsing in Japanese:
morphological units (a short unit word, SUW) and
syntactic units (a long unit word, LUW).
An SUW can be used to segment a sentence consistently, while it is too short to represent syntactic construction.
An LUW is a unit including functional multiwords and
LUW-based analysis facilitates the capturing of syntactic structure
and makes parsing results more precise than SUW-based analysis.
This paper describes the results of a feasibility study on
the ability and the effectiveness of parsing methods
based on hierarchical word structure (LUW chunking$+$parsing)
in comparison to single layer word structure (SUW parsing).
We also show joint analysis of LUW-chunking and dependency parsing
improves the performance of identifying predicate-argument structures, while there is not much difference between overall results of them. not much
difference between overall results of them.},
 address = {Pisa, Italy},
 author = {Tanaka, Takaaki and Hayashi, Katsuhiko and Nagata, Masaaki},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6308},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {56--60},
 publisher = {Association for Computational Linguistics},
 title = {Hierarchical Word Structure-based Parsing: A Feasibility Study on UD-style Dependency Parsing in Japanese},
 year = {2017}
}

@inproceedings{W17-6309,
 abstract = {We investigate the problem of parsing conversational data of
morphologically-rich languages such as Hindi where argument scrambling occurs
frequently. We evaluate a state-of-the-art non-linear transition-based parsing
system on a new dataset containing 506 dependency trees for sentences from
Bollywood (Hindi) movie scripts and Twitter posts of Hindi monolingual
speakers. We show that a dependency parser trained on a newswire treebank is
strongly biased towards the canonical structures and degrades when applied to
conversational data. Inspired by Transformational Generative Grammar (Chomsky, 1965), we mitigate the sampling bias by generating all theoretically possible
alternative word orders of a clause from the existing (kernel) structures in
the treebank. Training our parser on canonical and transformed structures
improves performance on conversational data by around 9% LAS over the baseline
newswire parser.},
 address = {Pisa, Italy},
 author = {Bhat, Riyaz A. and Bhat, Irshad and Sharma, Dipti},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6309},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {61--66},
 publisher = {Association for Computational Linguistics},
 title = {Leveraging Newswire Treebanks for Parsing Conversational Data with Argument Scrambling},
 year = {2017}
}

@inproceedings{W17-6310,
 abstract = {Syntactic annotation is costly and not available for the vast majority of the
world's languages. We show that sometimes we can do away with less labeled data
by exploiting more readily available forms of mark-up. Specifically, we revisit
an idea from Valentin Spitkovsky's work (2010), namely that hyperlinks
typically bracket syntactic constituents or chunks. We strengthen his results
by showing that not only can hyperlinks help in low resource scenarios, exemplified here by Quechua, but learning from hyperlinks can also improve
state-of-the-art NLP models for English newswire. We also present out-of-domain
evaluation on English Ontonotes 4.0.},
 address = {Pisa, Italy},
 author = {S{\o}gaard, Anders},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6310},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {67--71},
 publisher = {Association for Computational Linguistics},
 title = {Using hyperlinks to improve multilingual partial parsers},
 year = {2017}
}

@inproceedings{W17-6311,
 abstract = {PP-attachments are an important source of errors in parsing natural language.
We propose in this article to use data coming from a multimodal corpus, combining textual, visual and conceptual information, as well as a correction
strategy, to propose alternative attachments in the output of a parser.},
 address = {Pisa, Italy},
 author = {Delecraz, Sebastien and Nasr, Alexis and Bechet, Frederic and Favre, Benoit},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6311},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {72--77},
 publisher = {Association for Computational Linguistics},
 title = {Correcting prepositional phrase attachments using multimodal corpora},
 year = {2017}
}

@inproceedings{W17-6312,
 abstract = {Deep dependency parsing can be cast as the search for maximum acyclic subgraphs
in weighted digraphs. Because this search problem is intractable in the general
case, we consider its restriction to the class of 1-endpoint-crossing (1ec)
graphs, which has high coverage on standard data sets. Our main contribution is
a characterization of 1ec graphs as a subclass of the graphs with pagenumber at
most 3. Building on this we show how to extend an existing parsing algorithm
for 1-endpoint-crossing trees to the full class. While the runtime complexity
of the extended algorithm is polynomial in the length of the input sentence, it
features a large constant, which poses a challenge for practical
implementations.},
 address = {Pisa, Italy},
 author = {Kurtz, Robin and Kuhlmann, Marco},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6312},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {78--87},
 publisher = {Association for Computational Linguistics},
 title = {Exploiting Structure in Parsing to 1-Endpoint-Crossing Graphs},
 year = {2017}
}

@inproceedings{W17-6313,
 abstract = {We present a new transition system with word reordering for unrestricted non-
projective dependency parsing. Our system is based on decomposed arc-eager
rather than arc-standard, which allows more flexible ambiguity resolution
between a local projective and non-local crossing attachment. In our experiment
on Universal Dependencies 2.0, we find our parser outperforms the ordinary
swap-based parser particularly on languages with a large amount of
non-projectivity.},
 address = {Pisa, Italy},
 author = {Kohita, Ryosuke and Noji, Hiroshi and Matsumoto, Yuji},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6313},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {88--98},
 publisher = {Association for Computational Linguistics},
 title = {Effective Online Reordering with Arc-Eager Transitions},
 year = {2017}
}

@inproceedings{W17-6314,
 abstract = {In this paper, we extend the arc-hybrid system for transition-based parsing
with a swap transition that enables reordering of the words and construction of
non-projective trees. Although this extension breaks the arc-decomposability of
the transition system, we show how the existing dynamic oracle for this system
can be modified and combined with a static oracle only for the swap transition.
Experiments on 5 languages show that the new system gives competitive accuracy
and is significantly better than a system trained with a purely static oracle.},
 address = {Pisa, Italy},
 author = {de Lhoneux, Miryam and Stymne, Sara and Nivre, Joakim},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6314},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {99--104},
 publisher = {Association for Computational Linguistics},
 title = {Arc-Hybrid Non-Projective Dependency Parsing with a Static-Dynamic Oracle},
 year = {2017}
}

@inproceedings{W17-6315,
 abstract = {Encoder-decoder neural networks have been used for many NLP tasks, such as
neural machine translation. They have also been applied to constituent parsing
by using bracketed tree structures as a target language, translating input
sentences into syntactic trees. A more commonly used method to linearize
syntactic trees is the shift-reduce system, which uses a sequence of
transition-actions to build trees. We empirically investigate the effectiveness
of applying the encoder-decoder network to transition-based parsing. On
standard benchmarks, our system gives comparable results to the stack LSTM
parser for dependency parsing, and significantly better results compared to the
aforementioned parser for constituent parsing, which uses bracketed tree
formats.},
 address = {Pisa, Italy},
 author = {Liu, Jiangming and Zhang, Yue},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6315},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {105--114},
 publisher = {Association for Computational Linguistics},
 title = {Encoder-Decoder Shift-Reduce Syntactic Parsing},
 year = {2017}
}

@inproceedings{W17-6316,
 abstract = {We present a neural transition-based parser for spinal trees, a dependency
representation of
constituent trees. The parser uses Stack-LSTMs that compose constituent nodes
with
dependency-based derivations. In experiments, we show that this model adapts to
different
styles of dependency relations, but this choice has little effect for
predicting constituent
structure, suggesting that LSTMs induce useful states by themselves.},
 address = {Pisa, Italy},
 author = {Ballesteros, Miguel and Carreras, Xavier},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6316},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {115--121},
 publisher = {Association for Computational Linguistics},
 title = {Arc-Standard Spinal Parsing with Stack-LSTMs},
 year = {2017}
}

@inproceedings{W17-6317,
 abstract = {We generalize coarse-to-fine parsing to grammar formalisms that are more
expressive than PCFGs and/or describe languages of trees or graphs. We evaluate
our algorithm on PCFG, PTAG, and graph parsing. While we achieve the expected
performance gains on PCFGs, coarse-to-fine does not help for PTAG and can even
slow down parsing for graphs. We discuss the implications of this finding.},
 address = {Pisa, Italy},
 author = {Teichmann, Christoph and Koller, Alexander and Groschwitz, Jonas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6317},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {122--127},
 publisher = {Association for Computational Linguistics},
 title = {Coarse-To-Fine Parsing for Expressive Grammar Formalisms},
 year = {2017}
}

@inproceedings{W17-6318,
 abstract = {To improve grammatical function labelling for German, we augment the labelling
component of a neural dependency parser with a decision history. We present
different ways to encode the history, using different LSTM architectures, and
show that our models yield significant improvements, resulting in a LAS for
German that is close to the best result from the SPMRL 2014 shared task
(without the reranker).},
 address = {Pisa, Italy},
 author = {Do, Bich-Ngoc and Rehbein, Ines},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W17-6318},
 booktitle = {Proceedings of the 15th International Conference on Parsing Technologies},
 month = {September},
 pages = {128--133},
 publisher = {Association for Computational Linguistics},
 title = {Evaluating LSTM models for grammatical function labelling},
 year = {2017}
}

