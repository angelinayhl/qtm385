@inproceedings{K17-3001,
 abstract = {The Conference on Computational Natural Language Learning (CoNLL) features a
shared task, in which participants train and test their learning systems on the
same data sets. In 2017, the task was devoted to learning dependency parsers
for a large number of languages, in a real-world setting without any
gold-standard annotation on input. All test sets followed a unified annotation
scheme, namely that of Universal Dependencies. In this paper, we define the
task and evaluation methodology, describe how the data sets were prepared, report and analyze the main results, and provide a brief categorization of the
different approaches of the participating systems.},
 address = {Vancouver, Canada},
 author = {Zeman, Daniel  and  Popel, Martin  and  Straka, Milan  and  Hajic, Jan  and  Nivre, Joakim  and  Ginter, Filip  and  Luotolahti, Juhani  and  Pyysalo, Sampo  and  Petrov, Slav  and  Potthast, Martin  and  Tyers, Francis  and  Badmaeva, Elena  and  Gokirmak, Memduh  and  Nedoluzhko, Anna  and  Cinkova, Silvie  and  Hajic jr., Jan  and  Hlavacova, Jaroslava  and  Kettnerov\'{a}, V\'{a}clava  and  Uresova, Zdenka  and  Kanerva, Jenna  and  Ojala, Stina  and  Missil\"{a}, Anna  and  Manning, Christopher D.  and  Schuster, Sebastian  and  Reddy, Siva  and  Taji, Dima  and  Habash, Nizar  and  Leung, Herman  and  de Marneffe, Marie-Catherine  and  Sanguinetti, Manuela  and  Simi, Maria  and  Kanayama, Hiroshi  and  dePaiva, Valeria  and  Droganova, Kira  and  Mart\'{i}nez Alonso, H\'{e}ctor  and  \c{C}\"{o}ltekin, \c{C}a\u{g}rÄ±  and  Sulubacak, Umut  and  Uszkoreit, Hans  and  Macketanz, Vivien  and  Burchardt, Aljoscha  and  Harris, Kim  and  Marheinecke, Katrin  and  Rehm, Georg  and  Kayadelen, Tolga  and  Attia, Mohammed  and  Elkahky, Ali  and  Yu, Zhuoran  and  Pitler, Emily  and  Lertpradit, Saran  and  Mandl, Michael  and  Kirchner, Jesse  and  Alcalde, Hector Fernandez  and  Strnadov\'{a}, Jana  and  Banerjee, Esha  and  Manurung, Ruli  and  Stella, Antonio  and  Shimada, Atsuko  and  Kwak, Sookyoung  and  Mendonca, Gustavo  and  Lando, Tatiana  and  Nitisaroj, Rattima  and  Li, Josie},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {1--19},
 publisher = {Association for Computational Linguistics},
 title = {CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 year = {2017}
}

@inproceedings{K17-3002,
 abstract = {This paper describes the neural dependency parser submitted by Stanford to the
CoNLL 2017 Shared Task on parsing Universal Dependencies. Our system uses
relatively simple LSTM networks to produce part of speech tags and labeled
dependency parses from segmented and tokenized sequences of words. In order to
address the rare word problem that abounds in languages with complex
morphology, we include a character-based word representation that uses an LSTM
to produce embeddings from sequences of characters. Our system was ranked first
according to all five relevant metrics for the system: UPOS tagging (93.09%), XPOS tagging (82.27%), unlabeled attachment score (81.30%), labeled attachment
score (76.30%), and content word labeled attachment score (72.57%).},
 address = {Vancouver, Canada},
 author = {Dozat, Timothy  and  Qi, Peng  and  Manning, Christopher D.},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {20--30},
 publisher = {Association for Computational Linguistics},
 title = {Stanford's Graph-based Neural Dependency Parser at the CoNLL 2017 Shared Task},
 year = {2017}
}

@inproceedings{K17-3003,
 abstract = {We describe our entry, C2L2, to the CoNLL 2017 shared task on parsing Universal
Dependencies from raw text. Our system features an ensemble of three global
parsing paradigms, one graph-based and two transition-based. Each model
leverages character-level bi-directional LSTMs as lexical feature extractors to
encode morphological information. Though relying on baseline tokenizers and
focusing only on parsing, our system ranked second in the official end-to-end
evaluation with a macro-average of 75.00 LAS F1 score over 81 test treebanks.
In addition, we had the top average performance on the four surprise languages
and on the small treebank subset.},
 address = {Vancouver, Canada},
 author = {Shi, Tianze  and  Wu, Felix G.  and  Chen, Xilun  and  Cheng, Yao},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {31--39},
 publisher = {Association for Computational Linguistics},
 title = {Combining Global Models for Parsing Universal Dependencies},
 year = {2017}
}

@inproceedings{K17-3004,
 abstract = {This paper presents the IMS contribution to the CoNLL 2017 Shared Task. In the
preprocessing step we employed a CRF POS/morphological tagger and a neural
tagger predicting supertags. On some languages, we also applied word
segmentation with the CRF tagger and sentence segmentation with a
perceptron-based parser. For parsing we took an ensemble approach by blending
multiple instances of three parsers with very different architectures. Our
system achieved the third place overall and the second place for the surprise
languages.},
 address = {Vancouver, Canada},
 author = {Bj\"{o}rkelund, Anders  and  Falenska, Agnieszka  and  Yu, Xiang  and  Kuhn, Jonas},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {40--51},
 publisher = {Association for Computational Linguistics},
 title = {IMS at the CoNLL 2017 UD Shared Task: CRFs and Perceptrons Meet Neural Networks},
 year = {2017}
}

@inproceedings{K17-3005,
 abstract = {This paper describes our system (HIT-SCIR) for the CoNLL 2017 shared task:
Multilingual Parsing from Raw Text to Universal Dependencies.
Our system includes three pipelined components: \textit{tokenization}, \textit{Part-of-Speech} (POS) \textit{tagging} and \textit{dependency parsing}.
We use character-based bidirectional long short-term memory (LSTM) networks for
both tokenization and POS tagging.
Afterwards, we employ a list-based transition-based algorithm for general
non-projective parsing and present an improved Stack-LSTM-based architecture
for representing each transition state and making predictions.
Furthermore, to parse low/zero-resource languages and cross-domain data, we use
a model transfer approach to make effective use of existing resources.
We demonstrate substantial gains against the UDPipe baseline, with an average
improvement of 3.76% in LAS of all languages. And finally, we rank the 4th
place on the official test sets.},
 address = {Vancouver, Canada},
 author = {Che, Wanxiang  and  Guo, Jiang  and  Wang, Yuxuan  and  Zheng, Bo  and  Zhao, Huaipeng  and  Liu, Yang  and  Teng, Dechuan  and  Liu, Ting},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {52--62},
 publisher = {Association for Computational Linguistics},
 title = {The HIT-SCIR System for End-to-End Parsing of Universal Dependencies},
 year = {2017}
}

@inproceedings{K17-3006,
 abstract = {In this paper, we present our multilingual dependency parser developed for the
CoNLL 2017 UD Shared Task dealing with âMultilingual Parsing from Raw Text to
Universal Dependenciesâ. Our parser extends the monolingual BIST-parser as a
multi-source multilingual trainable parser. Thanks to multilingual word
embeddings and one hot encodings for languages, our system can use both
monolingual and multi-source training. We trained 69 monolingual language
models and 13 multilingual models for the shared task. Our multilingual
approach making use of different resources yield better results than the
monolingual approach for 11 languages. Our system ranked 5
th and achieved 70.93 overall LAS score over the 81 test corpora
(macro-averaged LAS F1 score).},
 address = {Vancouver, Canada},
 author = {Lim, KyungTae  and  Poibeau, Thierry},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {63--70},
 publisher = {Association for Computational Linguistics},
 title = {A System for Multilingual Dependency Parsing based on Bidirectional LSTM Feature Representations},
 year = {2017}
}

@inproceedings{K17-3007,
 abstract = {We describe our submission to the CoNLL 2017 shared task, which exploits the
shared common knowledge of a language across different domains via a domain
adaptation technique.
Our approach is an extension to the recently proposed adversarial training
technique for domain adaptation, which we apply on top of a graph-based neural
dependency parsing model on bidirectional LSTMs.
In our experiments, we find our baseline graph-based parser already outperforms
the official baseline model (UDPipe) by a large margin.
Further, by applying our technique to the treebanks of the same language with
different domains, we observe an additional gain in the performance, in
particular for the domains with less training data.},
 address = {Vancouver, Canada},
 author = {Sato, Motoki  and  Manabe, Hitoshi  and  Noji, Hiroshi  and  Matsumoto, Yuji},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {71--79},
 publisher = {Association for Computational Linguistics},
 title = {Adversarial Training for Cross-Domain Universal Dependency Parsing},
 year = {2017}
}

@inproceedings{K17-3008,
 abstract = {We introduce context embeddings, dense vectors derived from a language model
that represent the left/right context of a word instance, and demonstrate that
context embeddings significantly improve the accuracy of our transition based
parser. Our model consists of a bidirectional LSTM (BiLSTM) based language
model that is pre-trained to predict words in plain text, and a multi-layer
perceptron (MLP) decision model that uses features from the language model to
predict the correct actions for an ArcHybrid transition based parser. We
participated in the CoNLL 2017 UD Shared Task as the ``Ko\c{c} University'' team
and our system was ranked 7th out of 33 systems that parsed 81 treebanks in 49
languages.},
 address = {Vancouver, Canada},
 author = {KÄ±rnap, \"{O}mer  and  \"{O}nder, Berkay Furkan  and  Yuret, Deniz},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {80--87},
 publisher = {Association for Computational Linguistics},
 title = {Parsing with Context Embeddings},
 year = {2017}
}

@inproceedings{K17-3009,
 abstract = {Many natural language processing tasks, including the most advanced ones, routinely start by several basic processing steps -- tokenization and
segmentation, most likely also POS tagging and lemmatization, and commonly
parsing as well. A multilingual pipeline performing these steps can be trained
using the Universal Dependencies project, which contains annotations of the
described tasks for 50 languages in the latest release UD 2.0.
We present an update to UDPipe, a simple-to-use pipeline processing CoNLL-U
version 2.0 files, which performs these tasks for multiple languages without
requiring additional external data.  We provide models for all 50 languages of
UD 2.0, and furthermore, the pipeline can be trained easily using data in
CoNLL-U format.  UDPipe is a standalone application in C++, with bindings
available for Python, Java, C\# and Perl.
In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal
Dependencies, UDPipe was the eight best system, while achieving low running
times and moderately sized models.},
 address = {Vancouver, Canada},
 author = {Straka, Milan  and  Strakov\'{a}, Jana},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {88--99},
 publisher = {Association for Computational Linguistics},
 title = {Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe},
 year = {2017}
}

@inproceedings{K17-3010,
 abstract = {This paper presents our submissions for the CoNLL 2017 UD Shared Task. Our
parser, called UParse, is based on a neural network graph-based dependency
parser. The parser uses features from a bidirectional LSTM to to produce a
distribution over possible heads for each word in the sentence. To allow
transfer learning for low-resource treebanks and surprise languages, we train
several multilingual models for related languages, grouped by their genus and
language families. Out of 33 participants, our system achieves rank 9th in the
main results, with 75.49 UAS and 68.87 LAS F-1 scores (average across 81
treebanks).},
 address = {Vancouver, Canada},
 author = {Vania, Clara  and  Zhang, Xingxing  and  Lopez, Adam},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {100--110},
 publisher = {Association for Computational Linguistics},
 title = {UParse: the Edinburgh system for the CoNLL 2017 UD shared task},
 year = {2017}
}

@inproceedings{K17-3011,
 abstract = {This paper describes the system of the Team Orange-Deski\~{n}, used for the CoNLL
2017 UD Shared Task in
Multilingual Dependency Parsing. We based our approach on an existing open
source tool (BistParser), which we modified in order to produce the required
output. Additionally we added a kind of pseudo-projectivisation. This was
needed since some of the taskâs languages have a high percentage of
non-projective dependency trees. In most cases we also employed word
embeddings. For the 4 surprise languages, the data provided seemed too little
to train on. Thus we decided to use the training data of typologically close
languages instead. Our system achieved a macro-averaged LAS of 68.61% (10th in
the overall ranking) which improved to 69.38% after bug fixes.},
 address = {Vancouver, Canada},
 author = {Heinecke, Johannes  and  Asadullah, Munshi},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {111--118},
 publisher = {Association for Computational Linguistics},
 title = {Multi-Model and Crosslingual Dependency Analysis},
 year = {2017}
}

@inproceedings{K17-3012,
 abstract = {We present the TurkuNLP entry in the CoNLL 2017 Shared Task on Multilingual
Parsing from Raw Text to Universal Dependencies. The system is based on the
UDPipe parser with our focus being in exploring various techniques to pre-train
the word embeddings used by the parser in order to improve its performance
especially on languages with small training sets. The system ranked 11th among
the 33 participants overall, being 8th on the small treebanks, 10th on the
large treebanks, 12th on the parallel test sets, and 26th on the surprise
languages.},
 address = {Vancouver, Canada},
 author = {Kanerva, Jenna  and  Luotolahti, Juhani  and  Ginter, Filip},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {119--125},
 publisher = {Association for Computational Linguistics},
 title = {TurkuNLP: Delexicalized Pre-training of Word Embeddings for Dependency Parsing},
 year = {2017}
}

@inproceedings{K17-3013,
 abstract = {We developed two simple systems for dependency parsing: darc, a
transition-based parser, and mstnn, a graph-based parser. We tested our systems
in the CoNLL 2017 UD Shared Task, with darc being the official system. Darc
ranked 12th among 33 systems, just above the baseline. Mstnn had no official
ranking, but its main score was above the 27th. In this paper, we describe our
two systems, examine their strengths and weaknesses, and discuss the lessons we
learned.},
 address = {Vancouver, Canada},
 author = {Yu, Kuan  and  Sofroniev, Pavel  and  Schill, Erik  and  Hinrichs, Erhard},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {126--133},
 publisher = {Association for Computational Linguistics},
 title = {The parse is darc and full of errors: Universal dependency parsing with transition-based and graph-based algorithms},
 year = {2017}
}

@inproceedings{K17-3014,
 abstract = {We present a novel neural network model that learns POS tagging and graph-based
dependency parsing jointly. Our model uses bidirectional LSTMs to learn feature
representations shared for both POS tagging and dependency parsing tasks, thus
handling the feature-engineering problem. Our extensive experiments, on 19
languages from the Universal Dependencies project, show that our model
outperforms the state-of-the-art neural network-based Stack-propagation model
for joint POS tagging and transition-based dependency parsing, resulting in a
new state of the art. Our code is open-source and available together with
pre-trained models at: https://github.com/ datquocnguyen/jPTDP},
 address = {Vancouver, Canada},
 author = {Nguyen, Dat Quoc  and  Dras, Mark  and  Johnson, Mark},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {134--142},
 publisher = {Association for Computational Linguistics},
 title = {A Novel Neural Network Model for Joint POS Tagging and Graph-based Dependency Parsing},
 year = {2017}
}

@inproceedings{K17-3015,
 abstract = {For this yearâs multilingual dependency parsing shared task, we developed a
pipeline system, which uses a variety of features for each of its components.
Unlike the recent popular deep learning approaches that learn low dimensional
dense features using non-linear classifier, our system uses structured linear
classifiers to learn millions of sparse features. Specifically, we trained a
linear classifier for sentence boundary prediction, linear chain conditional
random fields (CRFs) for tokenization, part-of-speech tagging and morph
analysis. A second order graph based parser learns the tree structure (without
relations), and fa linear tree CRF then assigns relations to the dependencies
in the tree. Our system achieves reason- able performance -- 67.87% official
aver- aged macro F1 score},
 address = {Vancouver, Canada},
 author = {Qian, Xian  and  Liu, Yang},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {143--151},
 publisher = {Association for Computational Linguistics},
 title = {A non-DNN Feature Engineering Approach to Dependency Parsing -- FBAML at CoNLL 2017 Shared Task},
 year = {2017}
}

@inproceedings{K17-3016,
 abstract = {The LyS-FASTPARSE team present BIST-COVINGTON, a neural implementation of the
Covington (2001) algorithm for non-projective dependency parsing. The
bidirectional LSTM approach by Kiperwasser and Goldberg (2016) is used to train
a greedy parser with a dynamic oracle to mitigate error propagation. The model
participated in the CoNLL 2017 UD Shared Task. In spite of not using any
ensemble methods and using the baseline segmentation and PoS tagging, the
parser obtained good results on both macro-average LAS and UAS in the big
treebanks category (55 languages), ranking 7th out of 33 teams. In the all
treebanks category (LAS and UAS) we ranked 16th and 12th. The gap between the
all and big categories is mainly due to the poor performance on four parallel
PUD treebanks, suggesting that some 'suffixed' treebanks (e.g. Spanish-AnCora)
perform poorly on cross-treebank settings, which does not occur with the
corresponding 'unsuffixed' treebank  (e.g. Spanish). By changing that, we
obtain the 11th best LAS among all runs (official and unofficial). The code is
made available at https://github.com/CoNLL-UD-2017/LyS-FASTPARSE},
 address = {Vancouver, Canada},
 author = {Vilares, David  and  G\'{o}mez-Rodr\'{i}guez, Carlos},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {152--162},
 publisher = {Association for Computational Linguistics},
 title = {A non-projective greedy dependency parser with bidirectional LSTMs},
 year = {2017}
}

@inproceedings{K17-3017,
 abstract = {This paper describes LIMSI's submission to the CoNLL 2017 UD Shared Task, which
is focused on small treebanks, and how to improve low-resourced parsing only by
ad hoc combination of multiple views and resources. We present our approach for
low-resourced parsing, together with a detailed analysis of the results for
each test treebank. We also report extensive analysis experiments on model
selection for the PUD treebanks, and on annotation consistency among UD
treebanks.},
 address = {Vancouver, Canada},
 author = {Aufrant, Lauriane  and  Wisniewski, Guillaume  and  Yvon, Fran\c{c}ois},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {163--173},
 publisher = {Association for Computational Linguistics},
 title = {LIMSI$@$CoNLL'17: UD Shared Task},
 year = {2017}
}

@inproceedings{K17-3018,
 abstract = {This paper presents RACAI's approach, experiments and results at CONLL 2017
Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. We
handle raw text and we cover tokenization, sentence splitting, word
segmentation, tagging, lemmatization and parsing. All results are reported
under strict training, development and testing conditions, in which the corpora
provided for the shared tasks is used "as is", without any modifications to the
composition of the train and development sets.},
 address = {Vancouver, Canada},
 author = {Dumitrescu, Stefan Daniel  and  Boro\c{s}, Tiberiu  and  Tufi\c{s}, Dan},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {174--181},
 publisher = {Association for Computational Linguistics},
 title = {RACAI's Natural Language Processing pipeline for Universal Dependencies},
 year = {2017}
}

@inproceedings{K17-3019,
 abstract = {This paper describes our dependency parsing system in CoNLL-2017 shared task on
Multilingual Parsing from Raw Text to Universal Dependencies. We primarily
focus on the low-resource languages (surprise languages). We have developed a
framework to combine multiple treebanks to train parsers for low resource
languages by delexicalization method. We have applied transformation on source
language treebanks based on syntactic features of the low-resource language to
improve performance of the parser. In the official evaluation, our system
achieves an macro-averaged LAS score of 67.61 and 37.16 on the entire blind
test data and the surprise language test data respectively.},
 address = {Vancouver, Canada},
 author = {Das, Ayan  and  Zaffar, Affan  and  Sarkar, Sudeshna},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {182--190},
 publisher = {Association for Computational Linguistics},
 title = {Delexicalized transfer parsing for low-resource languages using transformed and combined treebanks},
 year = {2017}
}

@inproceedings{K17-3020,
 abstract = {This paper describes the system for our participation in the CoNLL 2017 Shared
Task: Multilingual Parsing from Raw Text to Universal Dependencies. In this
work, we design a system based on UDPipe1 for universal dependency parsing, where multilingual transition-based models are trained for different treebanks.
Our system directly takes raw texts as input, performing several intermediate
steps like tokenizing and tagging, and finally generates the corresponding
dependency
trees. For the special surprise languages for this task, we adopt a
delexicalized strategy and predict basing on transfer learning from other
related languages. In the final evaluation of the shared task, our system
achieves a result of 66.53% in macro-averaged LAS F1-score.},
 address = {Vancouver, Canada},
 author = {Wang, Hao  and  Zhao, Hai  and  Zhang, Zhisong},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {191--197},
 publisher = {Association for Computational Linguistics},
 title = {A Transition-based System for Universal Dependency Parsing},
 year = {2017}
}

@inproceedings{K17-3021,
 abstract = {This paper describes UALing's approach to the udst using corpus selection
techniques to reduce training data size.  The methodology is simple: we use
similarity measures to select a corpus from available training data (even from
multiple corpora for surprise languages) and use the resulting corpus to
complete the parsing task.  The training and parsing is done with the baseline
UDPipe system. While our approach
reduces the size of training data significantly, it retains performance within
0.5% of the baseline system. Due to the reduction in training data size, our
system performs faster than the naive, complete corpus method.  Specifically, our system runs in less than 10 minutes, ranking it among the fastest entries
for this task.
Our system is available at https://github.com/CoNLL-UD-2017/UALING.},
 address = {Vancouver, Canada},
 author = {Hornby, Ryan  and  Taylor, Clark  and  Park, Jungyeul},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {198--206},
 publisher = {Association for Computational Linguistics},
 title = {Corpus Selection Approaches for Multilingual Parsing from Raw Text to Universal Dependencies},
 year = {2017}
}

@inproceedings{K17-3022,
 abstract = {We present the Uppsala submission to the CoNLL 2017 shared task on parsing from
raw text to universal dependencies. Our system is a simple pipeline consisting
of two components. The first performs joint word and sentence segmentation on
raw text; the second predicts dependency trees from raw words. The parser
bypasses the need for part-of-speech tagging, but uses word embeddings based on
universal tag distributions. We achieved a macro-averaged LAS F1 of 65.11 in
the official test run, which improved to 70.49 after bug fixes. We obtained the
2nd best result for sentence segmentation with a score of 89.03.},
 address = {Vancouver, Canada},
 author = {de Lhoneux, Miryam  and  Shao, Yan  and  Basirat, Ali  and  Kiperwasser, Eliyahu  and  Stymne, Sara  and  Goldberg, Yoav  and  Nivre, Joakim},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {207--217},
 publisher = {Association for Computational Linguistics},
 title = {From Raw Text to Universal Dependencies - Look, No Tags!},
 year = {2017}
}

@inproceedings{K17-3023,
 abstract = {In this paper we describe the system by METU team for universal dependency
parsing of multilingual text. We use a neural network-based dependency parser
that has a greedy transition approach to dependency parsing. CCG supertags
contain rich structural information that proves useful in certain NLP tasks. We
experiment with CCG supertags as additional features in our experiments. The
neural network parser is trained together with dependencies and simplified CCG
tags as well as other features provided.},
 address = {Vancouver, Canada},
 author = {AkkuÅ, Burak Kerim  and  Azizoglu, Heval  and  Cakici, Ruket},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {218--227},
 publisher = {Association for Computational Linguistics},
 title = {Initial Explorations of CCG Supertagging for Universal Dependency Parsing},
 year = {2017}
}

@inproceedings{K17-3024,
 abstract = {This paper describes the University of Geneva's submission to the CoNLL 2017
shared task Multilingual Parsing from Raw Text to Universal Dependencies
(listed as the CLCL (Geneva) entry).  Our submitted parsing system is the
grandchild of the first transition-based neural network dependency parser, which was the University of Geneva's entry in the CoNLL 2007 multilingual
dependency parsing shared task, with some improvements to speed and
portability.  These results provide a baseline for investigating how far we
have come in the past ten years of work on neural network dependency parsing.},
 address = {Vancouver, Canada},
 author = {Moor, Christophe  and  Merlo, Paola  and  Henderson, James  and  Wang, Haozhou},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {228--236},
 publisher = {Association for Computational Linguistics},
 title = {CLCL (Geneva) DINN Parser: a Neural Network Dependency Parser Ten Years Later},
 year = {2017}
}

@inproceedings{K17-3025,
 abstract = {We present a multilingual dependency parser with a bidirectional-LSTM (BiLSTM)
feature extractor and a multi-layer perceptron (MLP) classifier. We trained our
transition-based projective parser in UD version 2.0 datasets without any
additional data. The parser is fast, lightweight and effective on big
treebanks.
In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal
Dependencies, the official results show that the macro-averaged LAS F1 score of
our system Mengest is 61.33%.},
 address = {Vancouver, Canada},
 author = {Ji, Tao  and  Wu, Yuanbin  and  Lan, Man},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {237--242},
 publisher = {Association for Computational Linguistics},
 title = {A Fast and Lightweight System for Multilingual Dependency Parsing},
 year = {2017}
}

@inproceedings{K17-3026,
 abstract = {We present the ParisNLP entry at the UD CoNLL 2017 parsing shared task. In
addition to the UDpipe models provided, we built our own data-driven
tokenization
models, sentence segmenter and lexicon-based morphological analyzers. All of
these were used with a range of different parsing models (neural or not, feature-rich or not, transition or graph-based, etc.) and the best combination
for each language was selected. Unfortunately, a glitch in the shared taskâs
Matrix led our model selector to run generic, weakly lexicalized models, tailored for surprise languages, instead of our dataset-specific models.
Because of this \#ParsingTragedy, we officially ranked 27th, whereas our real
models finally unofficially ranked 6th.},
 address = {Vancouver, Canada},
 author = {De La Clergerie, Eric  and  Sagot, Beno\^{i}t  and  Seddah, Djam\'{e}},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {243--252},
 publisher = {Association for Computational Linguistics},
 title = {The ParisNLP entry at the ConLL UD Shared Task 2017: A Tale of a \#ParsingTragedy},
 year = {2017}
}

@inproceedings{K17-3027,
 abstract = {We present the Open University's submission to the CoNLL 2017 Shared Task on
multilingual parsing from raw text to Universal Dependencies.
The core of our system is a joint morphological disambiguator and syntactic
parser which accepts morphologically analyzed surface tokens as input and
returns morphologically disambiguated dependency trees as output.
Our parser requires a lattice as input, so we generate morphological analyses
of surface tokens using a data-driven morphological analyzer that derives its
lexicon from the UD training corpora, and we rely on UDPipe for sentence
segmentation and surface-level tokenization. We report our official
macro-average LAS is 56.56. Although our model is not as performant as many
others, it does not make use of neural networks, therefore we do not rely on
word embeddings or any other data source other than the corpora themselves.
In addition, we show the utility of a lexicon-backed morphological analyzer for
the MRL Modern Hebrew. We use our results on Modern Hebrew to argue that the UD
community should define a UD-compatible standard for access to lexical
resources, which we argue is crucial for MRLs and low resource languages in
particular.},
 address = {Vancouver, Canada},
 author = {More, Amir  and  Tsarfaty, Reut},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {253--264},
 publisher = {Association for Computational Linguistics},
 title = {Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to The CoNLL 2017 Shared Task},
 year = {2017}
}

@inproceedings{K17-3028,
 abstract = {This paper presents our system submitted for the CoNLL 2017 Shared Task, ``Multilingual Parsing from Raw Text to Universal Dependencies.'' We ran the
system for all languages with our own fully pipelined components without
relying on re-trained baseline systems. To train the dependency parser, we used
only the universal part-of-speech tags and distance between words, and applied
deterministic rules to assign dependency labels.  The simple and delexicalized
models are suitable for cross-lingual transfer approaches and a universal
language model.  Experimental results show that our model performed well in
some metrics and leads discussion on topics such as contribution of each
component and on syntactic similarities among languages.},
 address = {Vancouver, Canada},
 author = {Kanayama, Hiroshi  and  Muraoka, Masayasu  and  Yoshikawa, Katsumasa},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {265--273},
 publisher = {Association for Computational Linguistics},
 title = {A Semi-universal Pipelined Approach to the CoNLL 2017 UD Shared Task},
 year = {2017}
}

@inproceedings{K17-3029,
 abstract = {This article describes MetaRomance, a rule-based cross-lingual parser for
Romance languages submitted to CoNLL 2017 Shared Task: Multilingual Parsing
from Raw Text to Universal Dependencies. The system is an almost delexicalized
parser which does not need training data to analyze Romance languages. It
contains linguistically motivated rules based on PoS-tag patterns. The rules
included in MetaRomance were developed in about 12 hours by one expert with no
prior knowledge in Universal Dependencies, and can be easily extended using a
transparent formalism. In this paper we compare the performance of MetaRomance
with other supervised systems participating in the competition, paying special
attention to the parsing of different treebanks of the same language. We also
compare our system with a delexicalized parser for Romance languages, and take
advantage of the harmonized annotation of Universal Dependencies to propose a
language ranking based on the syntactic distance each variety has from Romance
languages.},
 address = {Vancouver, Canada},
 author = {Garcia, Marcos  and  Gamallo, Pablo},
 booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
 month = {August},
 pages = {274--282},
 publisher = {Association for Computational Linguistics},
 title = {A rule-based system for cross-lingual parsing of Romance languages with Universal Dependencies},
 year = {2017}
}

