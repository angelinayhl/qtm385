@inproceedings{S17-2001,
 abstract = {Semantic Textual Similarity (STS) measures the meaning similarity of sentences.
Applications include machine translation (MT), summarization, generation, question answering (QA), short answer grading, semantic search, dialog and
conversational systems. The STS shared task is a venue for assessing the
current state-of-the-art. The 2017 task focuses on multilingual and
cross-lingual pairs with one sub-track exploring MT quality estimation (MTQE)
data. The task obtained strong participation from 31 teams, with 17
participating in all  language tracks. We summarize performance and
review a selection of well performing methods. Analysis highlights common
errors, providing insight into the limitations of existing models. To support
ongoing work on semantic representations, the STS Benchmark is introduced
as a new shared training and evaluation set carefully selected from the corpus
of English STS shared task data (2012-2017).},
 address = {Vancouver, Canada},
 author = {Cer, Daniel  and  Diab, Mona  and  Agirre, Eneko  and  Lopez-Gazpio, Inigo  and  Specia, Lucia},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {1--14},
 publisher = {Association for Computational Linguistics},
 title = {SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation},
 year = {2017}
}

@inproceedings{S17-2002,
 abstract = {This paper introduces a new task on Multilingual and Cross-lingual SemanticThis
paper introduces a new task on Multilingual and Cross-lingual Semantic Word
Similarity which measures the semantic similarity of word pairs within and
across five languages: English, Farsi, German, Italian and Spanish. High
quality datasets were manually curated for the five languages with high
inter-annotator agreements (consistently in the 0.9 ballpark). These were used
for semi-automatic construction of ten cross-lingual datasets. 17 teams
participated in the task, submitting 24 systems in subtask 1 and 14 systems in
subtask 2. Results show that systems that combine statistical knowledge from
text corpora, in the form of word embeddings, and external knowledge from
lexical resources are best performers in both subtasks. More information can be
found on the task website: http://alt.qcri.org/semeval2017/task2/},
 address = {Vancouver, Canada},
 author = {Camacho-Collados, Jose  and  Pilehvar, Mohammad Taher  and  Collier, Nigel  and  Navigli, Roberto},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {15--26},
 publisher = {Association for Computational Linguistics},
 title = {SemEval-2017 Task 2: Multilingual and Cross-lingual Semantic Word Similarity},
 year = {2017}
}

@inproceedings{S17-2003,
 abstract = {We describe SemEval--2017 Task 3 on Community Question Answering. This year, we reran the four subtasks from SemEval-2016: (A) Question--Comment Similarity, (B) Question--Question Similarity, (C) Question--External Comment Similarity, and (D) Rerank the correct answers for a new question in Arabic, providing all
the data from 2015 and 2016 for training, and fresh data for testing.
Additionally, we added a new subtask E in order to enable experimentation with
Multi-domain Question Duplicate Detection in a larger-scale scenario, using
StackExchange subforums. A total of 23 teams participated in the task, and
submitted a total of 85 runs (36 primary and 49 contrastive) for subtasks A--D.
Unfortunately, no teams participated in subtask E. A variety of approaches and
features were used by the participating systems to address the different
subtasks. The best systems achieved an official score (MAP) of 88.43, 47.22, 15.46, and 61.16 in subtasks A, B, C, and D, respectively.  These scores are
better than the baselines, especially for subtasks A--C.},
 address = {Vancouver, Canada},
 author = {Nakov, Preslav  and  Hoogeveen, Doris  and  M\`{a}rquez, Llu\'{i}s  and  Moschitti, Alessandro  and  Mubarak, Hamdy  and  Baldwin, Timothy  and  Verspoor, Karin},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {27--48},
 publisher = {Association for Computational Linguistics},
 title = {SemEval-2017 Task 3: Community Question Answering},
 year = {2017}
}

@inproceedings{S17-2004,
 abstract = {This paper describes a new shared task for humor understanding that attempts to
eschew the ubiquitous binary approach to humor detection and focus on
comparative humor ranking instead. The task is based on a new dataset of funny
tweets posted in response to shared hashtags, collected from the `Hashtag Wars'
segment of the TV show $@$midnight. The results are evaluated in two subtasks
that require the participants to generate either the correct pairwise
comparisons of tweets (subtask A), or the correct ranking of the tweets
(subtask B) in terms of how funny they are. 7 teams participated in subtask A, and 5 teams participated in subtask B. The best accuracy in subtask A was
0.675. The best (lowest) rank edit distance for subtask B was 0.872.},
 address = {Vancouver, Canada},
 author = {Potash, Peter  and  Romanov, Alexey  and  Rumshisky, Anna},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {49--57},
 publisher = {Association for Computational Linguistics},
 title = {SemEval-2017 Task 6: #HashtagWars: Learning a Sense of Humor},
 year = {2017}
}

@inproceedings{S17-2005,
 abstract = {A pun is a form of wordplay in which a word suggests two or more meanings by
exploiting polysemy, homonymy, or phonological similarity to another word, for
an intended humorous or rhetorical effect.  Though a recurrent and expected
feature in many discourse types, puns stymie traditional approaches to
computational lexical semantics because they violate their
one-sense-per-context assumption.  This paper describes the first competitive
evaluation for the automatic detection, location, and interpretation of puns.
We describe the motivation for these tasks, the evaluation methods, and the
manually annotated data set.  Finally, we present an overview and discussion of
the participating systems' methodologies, resources, and results.},
 address = {Vancouver, Canada},
 author = {Miller, Tristan  and  Hempelmann, Christian  and  Gurevych, Iryna},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {58--68},
 publisher = {Association for Computational Linguistics},
 title = {SemEval-2017 Task 7: Detection and Interpretation of English Puns},
 year = {2017}
}

@inproceedings{S17-2006,
 abstract = {Media is full of false claims. Even Oxford Dictionaries named âpost-truthâ
as the word of 2016. This makes it more important than ever to build systems
that can identify the veracity of a story, and the nature of the discourse
around it. RumourEval is a SemEval shared task that aims to identify and handle
rumours and reactions to them, in text. We present an annotation scheme, a
large dataset covering multiple topics -- each having their own families of
claims and replies -- and use these to pose two concrete challenges as well as
the results achieved by participants on these challenges.},
 address = {Vancouver, Canada},
 author = {Derczynski, Leon  and  Bontcheva, Kalina  and  Liakata, Maria  and  Procter, Rob  and  Wong Sak Hoi, Geraldine  and  Zubiaga, Arkaitz},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {69--76},
 publisher = {Association for Computational Linguistics},
 title = {SemEval-2017 Task 8: RumourEval: Determining rumour veracity and support for rumours},
 year = {2017}
}

@inproceedings{S17-2007,
 abstract = {This paper presents three systems for semantic textual similarity (STS)
evaluation at SemEval-2017 STS task. One is an unsupervised system and the
other two are supervised systems which simply employ the unsupervised one. All
our systems mainly depend on the (SIS), which is constructed based on the
semantic hierarchical taxonomy in WordNet, to compute non-overlapping
information content (IC) of sentences. Our team ranked 2nd among 31
participating teams by the primary score of Pearson correlation coefficient
(PCC) mean of 7 tracks and achieved the best performance on Track 1 (AR-AR)
dataset.},
 address = {Vancouver, Canada},
 author = {Wu, Hao  and  Huang, Heyan  and  Jian, Ping  and  Guo, Yuhang  and  Su, Chao},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {77--84},
 publisher = {Association for Computational Linguistics},
 title = {BIT at SemEval-2017 Task 1: Using Semantic Information Space to Evaluate Semantic Textual Similarity},
 year = {2017}
}

@inproceedings{S17-2008,
 abstract = {This paper describes Luminoso's participation in SemEval 2017 Task 2, ``Multilingual and Cross-lingual Semantic Word Similarity'', with a system
based on ConceptNet. ConceptNet is an open, multilingual knowledge graph that
focuses on general knowledge that relates the meanings of words and phrases.
Our submission to SemEval was an update of previous work that builds
high-quality, multilingual word embeddings from a combination of ConceptNet and
distributional semantics. Our system took first place in both subtasks. It
ranked first in 4 out of 5 of the separate languages, and also ranked first in
all 10 of the cross-lingual language pairs.},
 address = {Vancouver, Canada},
 author = {Speer, Robert  and  Lowry-Duda, Joanna},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {85--89},
 publisher = {Association for Computational Linguistics},
 title = {ConceptNet at SemEval-2017 Task 2: Extending Word Embeddings with Multilingual Relational Knowledge},
 year = {2017}
}

@inproceedings{S17-2009,
 abstract = {In this paper we present the system for Answer Selection and Ranking in
Community Question Answering, which we build as part of our participation in
SemEval-2017 Task 3. We develop a Support Vector Machine (SVM) based system
that makes use of textual, domain-specific, word-embedding and topic-modeling
features.
In addition, we propose a novel method for dialogue chain identification in
comment threads. Our primary submission won subtask C, outperforming other
systems in all the primary evaluation metrics. We performed well in other
English subtasks, ranking third in subtask A and eighth in subtask B. We also
developed open source toolkits for all the three English subtasks by the name
cQARank [https://github.com/TitasNandi/cQARank].},
 address = {Vancouver, Canada},
 author = {Nandi, Titas  and  Biemann, Chris  and  Yimam, Seid Muhie  and  Gupta, Deepak  and  Kohail, Sarah  and  Ekbal, Asif  and  Bhattacharyya, Pushpak},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {90--97},
 publisher = {Association for Computational Linguistics},
 title = {IIT-UHH at SemEval-2017 Task 3: Exploring Multiple Features for Community Question Answering and Implicit Dialogue Identification},
 year = {2017}
}

@inproceedings{S17-2010,
 abstract = {This paper describes the winning system for SemEval-2017 Task 6: #HashtagWars:
Learning a Sense of Humor. Humor detection has up until now been predominantly
addressed using feature-based approaches. Our system utilizes recurrent deep
learning methods with dense embeddings to predict humorous tweets from the
midnight show #HashtagWars. In order to include both meaning and sound in the
analysis, GloVe embeddings are combined with a novel phonetic representation to
serve as input to an LSTM component. The output is combined with a
character-based CNN model, and an XGBoost component in an ensemble model which
achieves 0.675 accuracy on the evaluation data.},
 address = {Vancouver, Canada},
 author = {Donahue, David  and  Romanov, Alexey  and  Rumshisky, Anna},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {98--102},
 publisher = {Association for Computational Linguistics},
 title = {HumorHawk at SemEval-2017 Task 6: Mixing Meaning and Sound for Humor Recognition},
 year = {2017}
}

@inproceedings{S17-2011,
 abstract = {This paper describes our system, entitled
Idiom Savant, for the 7th Task of the Se-
meval 2017 workshop, âDetection and in-
terpretation of English Punsâ. Our sys-
tem consists of two probabilistic models
for each type of puns using Google n-
gram and Word2Vec. Our system achieved
f-score of calculating, 0.663, and 0.07
in homographic puns and 0.8439, 0.6631, and 0.0806 in heterographic puns in task
1, task 2, and task 3 respectively.},
 address = {Vancouver, Canada},
 author = {Doogan, Samuel  and  Ghosh, Aniruddha  and  Chen, Hanyang  and  Veale, Tony},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {103--108},
 publisher = {Association for Computational Linguistics},
 title = {Idiom Savant at Semeval-2017 Task 7: Detection and Interpretation of English Puns},
 year = {2017}
}

@inproceedings{S17-2012,
 abstract = {We present our submitted systems for Semantic Textual Similarity (STS) Track 4
at SemEval-2017. Given a pair of Spanish-English sentences, each system must
estimate their semantic similarity by a score between 0 and 5. In our
submission, we use syntax-based, dictionary-based, context-based, and MT-based
methods. We also combine these methods in unsupervised and supervised way. Our
best run ranked 1st on track 4a with a correlation of 83.02% with human
annotations.},
 address = {Vancouver, Canada},
 author = {Ferrero, J\'{e}r\'{e}my  and  Besacier, Laurent  and  Schwab, Didier  and  Agn\`{e}s, Fr\'{e}d\'{e}ric},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {109--114},
 publisher = {Association for Computational Linguistics},
 title = {CompiLIG at SemEval-2017 Task 1: Cross-Language Plagiarism Detection Methods for Semantic Textual Similarity},
 year = {2017}
}

@inproceedings{S17-2013,
 abstract = {This paper describes the model UdL we proposed to solve the semantic textual
similarity task of SemEval 2017 workshop. The track we participated in was
estimating the semantics relatedness of a given set of sentence pairs in
English. The best run out of three submitted runs of our model achieved a
Pearson correlation score of 0.8004 compared to a hidden human annotation of
250~pairs. We used random forest ensemble learning to map an expandable set of
extracted pairwise features into a semantic similarity estimated value bounded
between 0 and 5. Most of these features were calculated using word embedding
vectors similarity to align Part of Speech (PoS) and Name Entities (NE) tagged
tokens of each sentence pair. Among other pairwise features, we experimented a
classical tf-idf weighted Bag of Words (BoW) vector model but with
character-based range of n-grams instead of words. This sentence vector
BoW-based feature gave a relatively high importance value percentage in the
feature importances analysis of the ensemble learning.},
 address = {Vancouver, Canada},
 author = {Al-Natsheh, Hussein T.  and  Martinet, Lucie  and  Muhlenbach, Fabrice  and  ZIGHED, Djamel Abdelkader},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {115--119},
 publisher = {Association for Computational Linguistics},
 title = {UdL at SemEval-2017 Task 1: Semantic Textual Similarity Estimation of English Sentence Pairs Using Regression Model over Pairwise Features},
 year = {2017}
}

@inproceedings{S17-2014,
 abstract = {We describe our system (DT Team) submitted at SemEval-2017 Task 1, Semantic
Textual Similarity (STS) challenge for English (Track 5). We developed three
different models with various features including similarity scores calculated
using word and chunk alignments, word/sentence embeddings, and Gaussian Mixture
Model(GMM). The correlation between our systemâs output and the human
judgments were up to 0.8536, which is more than 10% above baseline, and almost
as good as the best performing system which was at 0.8547 correlation (the
difference is just about 0.1%). Also, our system produced leading results when
evaluated with a separate STS benchmark dataset. The word alignment and
sentence embeddings based features were found to be very effective.},
 address = {Vancouver, Canada},
 author = {Maharjan, Nabin  and  Banjade, Rajendra  and  Gautam, Dipesh  and  Tamang, Lasang J.  and  Rus, Vasile},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {120--124},
 publisher = {Association for Computational Linguistics},
 title = {DT\_Team at SemEval-2017 Task 1: Semantic Similarity Using Alignments, Sentence-Level Embeddings and Gaussian Mixture Model Output},
 year = {2017}
}

@inproceedings{S17-2015,
 abstract = {This paper describes FCICU team systems that participated in SemEval-2017
Semantic Textual Similarity task (Task1) for monolingual and cross-lingual
sentence pairs. A sense-based language independent textual similarity approach
is presented, in which a proposed alignment similarity method coupled with new
usage of a semantic network (BabelNet) is used. Additionally, a previously
proposed integration between sense-based and sur-face-based semantic textual
similarity approach is applied together with our proposed approach. For all the
tracks in Task1, Run1 is a string kernel with alignments metric and Run2 is a
sense-based alignment similarity method. The first run is ranked 10th, and the
second is ranked 12th in the primary track, with correlation 0.619 and 0.617
respectively},
 address = {Vancouver, Canada},
 author = {Hassan, Basma  and  AbdelRahman, Samir  and  Bahgat, Reem  and  Farag, Ibrahim},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {125--129},
 publisher = {Association for Computational Linguistics},
 title = {FCICU at SemEval-2017 Task 1: Sense-Based Language Independent Semantic Textual Similarity Approach},
 year = {2017}
}

@inproceedings{S17-2016,
 abstract = {This paper describes our convolutional neural network (CNN) system for Semantic
Textual Similarity (STS) task. We calculated semantic similarity score between
two sentences by comparing their semantic vectors. We generated semantic vector
of every sentence by max pooling every dimension of their word vectors. There
are mainly two trick points in our system. One is that we trained a CNN to
transfer GloVe word vectors to a more proper form for STS task before pooling.
Another is that we trained a fully-connected neural network (FCNN) to transfer
difference of two semantic vectors to probability of every similarity score. We
decided all hyper parameters empirically. In spite of the simplicity of our
neural network system, we achieved a good accuracy and ranked 3rd in primary
track of SemEval 2017.},
 address = {Vancouver, Canada},
 author = {Shao, Yang},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {130--133},
 publisher = {Association for Computational Linguistics},
 title = {HCTI at SemEval-2017 Task 1: Use convolutional neural network to evaluate Semantic Textual Similarity},
 year = {2017}
}

@inproceedings{S17-2017,
 abstract = {This article describes our proposed system  named LIM-LIG. This system is
designed for SemEval 2017 Task1: Semantic  Textual  Similarity (Track1).
LIM-LIG  proposes  an  innovative  enhancement to word embedding-based model
devoted  to    measure                                            the  semantic
similarity
in
Arabic
sentences.
The  main  idea  is  to  exploit    the  word representations  as  vectors  in
a  multidimensional  space    to    capture  the  semantic  and  syntactic
properties  of                                              words.
IDF
weighting
and
Part-of-Speech                                tagging
are
applied  on  the  examined  sentences  to  support    the  identification  of
words  that  are  highly  descriptive  in  each  sentence.  LIM-LIG system
achieves a Pearson's correlation of 0.74633, ranking 2nd among all
participants in the   Arabic monolingual pairs

STS
task
organized
within
the
SemEval 2017 evaluation campaign},
 address = {Vancouver, Canada},
 author = {NAGOUDI, El Moatez Billah  and  Ferrero, J\'{e}r\'{e}my  and  Schwab, Didier},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {134--138},
 publisher = {Association for Computational Linguistics},
 title = {LIM-LIG at SemEval-2017 Task1: Enhancing the Semantic Similarity for Arabic Sentences with Vectors Weighting},
 year = {2017}
}

@inproceedings{S17-2018,
 abstract = {Semantic Textual Similarity (STS) evaluation assesses the degree to which two
parts of texts are similar, based on their semantic evaluation. In this paper, we describe three models submitted to STS SemEval 2017. Given two English parts
of a text, each of proposed methods outputs the assessment of their semantic
similarity.
We propose an approach for computing monolingual semantic textual similarity
based on an ensemble of three distinct methods. Our model consists of recursive
neural network (RNN) text auto-encoders ensemble with supervised a model of
vectorized sentences using reduced part of speech (PoS) weighted word
embeddings as well as unsupervised a method based on word coverage (TakeLab).
Additionally, we enrich our model with additional features that allow
disambiguation of ensemble methods based on their efficiency. We have used
Multi-Layer Perceptron as an ensemble classifier basing on estimations of
trained Gradient Boosting Regressors.
Results of our research proves that using such ensemble leads to a higher
accuracy due to a fact that each member-algorithm tends to specialize in
particular type of sentences. Simple model based on PoS weighted Word2Vec word
embeddings seem to improve performance of more complex RNN based auto-encoders
in the ensemble. In the monolingual English-English STS subtask our Ensemble
based model achieved mean Pearson correlation of .785 compared with human
annotators.},
 address = {Vancouver, Canada},
 author = {\'{S}piewak, Martyna  and  Sobecki, Piotr  and  Kara\'{s}, Daniel},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {139--143},
 publisher = {Association for Computational Linguistics},
 title = {OPI-JSA at SemEval-2017 Task 1: Application of Ensemble learning for computing semantic textual similarity},
 year = {2017}
}

@inproceedings{S17-2019,
 abstract = {This is the Lump team participation at SemEval 2017 Task 1 on Semantic Textual
Similarity. Our supervised model relies on features which are multilingual or
interlingual in nature. We include lexical similarities, cross-language
explicit semantic analysis, internal representations of multilingual neural
networks and interlingual word embeddings. Our representations allow to use
large datasets in language pairs with many instances to better classify
instances in smaller language pairs avoiding the necessity of translating into
a single language. Hence we can deal with all the languages in the task:
Arabic, English, Spanish, and Turkish.},
 address = {Vancouver, Canada},
 author = {Espa\~{n}a-Bonet, Cristina  and  Barr\'{o}n-Cede\~{n}o, Alberto},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {144--149},
 publisher = {Association for Computational Linguistics},
 title = {Lump at SemEval-2017 Task 1: Towards an Interlingua Semantic Similarity},
 year = {2017}
}

@inproceedings{S17-2020,
 abstract = {This paper reports the details of our submissions in the task 1 of SemEval
2017. This task aims at assessing the semantic textual similarity of two
sentences or texts. We submit three unsupervised systems based on word
embeddings. The differences between these runs are the various preprocessing on
evaluation data. The best performance of these systems on the evaluation of
Pearson correlation is 0.6887. Unsurprisingly, results of our runs demonstrate
that data preprocessing, such as tokenization, lemmatization, extraction of
content words and removing stop words, is helpful and plays a significant role
in improving the performance of models.},
 address = {Vancouver, Canada},
 author = {Meng, Fanqing  and  Lu, Wenpeng  and  Zhang, Yuteng  and  Cheng, Jinyong  and  Du, Yuehan  and  Han, Shuwang},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {150--153},
 publisher = {Association for Computational Linguistics},
 title = {QLUT at SemEval-2017 Task 1: Semantic Textual Similarity Based on Word Embeddings},
 year = {2017}
}

@inproceedings{S17-2021,
 abstract = {Shared Task 1 at SemEval-2017 deals with assessing the semantic similarity
between sentences, either in the same or in different languages.
In our system submission, we employ multilingual word representations, in which
similar words in different languages are close to one another.
Using such representations is advantageous, since the increasing amount of
available parallel data allows for the application of such methods to many of
the languages in the world.
Hence, semantic similarity can be inferred even for languages for which no
annotated data exists.
Our system is trained and evaluated on all language pairs included in the
shared task (English, Spanish, Arabic, and Turkish).
Although development results are promising, our system does not yield high
performance on the shared task test sets.},
 address = {Vancouver, Canada},
 author = {Bjerva, Johannes  and  \"{O}stling, Robert},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {154--158},
 publisher = {Association for Computational Linguistics},
 title = {ResSim at SemEval-2017 Task 1: Multilingual Word Representations for Semantic Textual Similarity},
 year = {2017}
}

@inproceedings{S17-2022,
 abstract = {Semantic Textual Similarity (STS) devotes to measuring the degree of
equivalence in the underlying semantic of the sentence pair. We proposed a new
system, ITNLP-AiKF, which applies in the SemEval 2017 Task1 Semantic Textual
Similarity track 5 English monolingual pairs. In our system, rich features are
involved, including Ontology based, word embedding based, Corpus based, Alignment based and Literal based feature. We leveraged the features to predict
sentence pair similarity by a Support Vector Regression (SVR) model. In the
result, a Pearson Correlation of 0.8231 is achieved by our system, which is a
competitive result in the contest of this track.},
 address = {Vancouver, Canada},
 author = {Liu, Wenjie  and  Sun, Chengjie  and  Lin, Lei  and  Liu, Bingquan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {159--163},
 publisher = {Association for Computational Linguistics},
 title = {ITNLP-AiKF at SemEval-2017 Task 1: Rich Features Based SVR for Semantic Textual Similarity Computing},
 year = {2017}
}

@inproceedings{S17-2023,
 abstract = {This paper describes a neural-network model which performed competitively (top
6) at the SemEval 2017 cross-lingual Semantic Textual Similarity (STS) task.
Our system employs an attention-based recurrent neural network model that
optimizes the sentence similarity. In this paper, we describe our participation
in the multilingual STS task which measures similarity across English, Spanish, and Arabic.},
 address = {Vancouver, Canada},
 author = {Zhuang, WenLi  and  Chang, Ernie},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {164--169},
 publisher = {Association for Computational Linguistics},
 title = {Neobility at SemEval-2017 Task 1: An Attention-based Sentence Similarity Model},
 year = {2017}
}

@inproceedings{S17-2024,
 abstract = {This paper describes our unsupervised knowledge-free approach to the
SemEval-2017 Task 1 Competition. The proposed method makes use of Paragraph
Vector for assessing the semantic similarity between pairs of sentences. We
experimented with various dimensions of the vector and three state-of-the-art
similarity metrics. Given a cross-lingual task, we trained models corresponding
to its two languages and combined the models by averaging the similarity
scores. The results of our submitted runs are above the median scores for five
out of seven test sets by means of Pearson Correlation. Moreover, one of our
system runs performed best on the Spanish-English-WMT test set ranking first
out of 53 runs submitted in total by all participants.},
 address = {Vancouver, Canada},
 author = {Duma, Mirela-Stefania  and  Menzel, Wolfgang},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {170--174},
 publisher = {Association for Computational Linguistics},
 title = {SEF$@$UHH at SemEval-2017 Task 1: Unsupervised Knowledge-Free Semantic Textual Similarity via Paragraph Vector},
 year = {2017}
}

@inproceedings{S17-2025,
 abstract = {This paper reports the STS-UHH participation in the SemEval 2017 shared
Task 1 of Semantic Textual Similarity (STS). Overall, we submitted 3 runs
covering
monolingual and cross-lingual STS tracks. Our participation involves two
approaches:
unsupervised approach, which estimates a word alignment-based similarity
score, and supervised approach, which combines dependency graph similarity
and coverage features with lexical similarity measures using regression
methods. We also present a way on ensembling both models. Out of 84 submitted
runs, our team best multi-lingual run has been ranked 12th in overall
performance
with correlation of 0.61, 7th among 31 participating teams.},
 address = {Vancouver, Canada},
 author = {Kohail, Sarah  and  Salama, Amr Rekaby  and  Biemann, Chris},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {175--179},
 publisher = {Association for Computational Linguistics},
 title = {STS-UHH at SemEval-2017 Task 1: Scoring Semantic Textual Similarity Using Supervised and Unsupervised Ensemble},
 year = {2017}
}

@inproceedings{S17-2026,
 abstract = {We describe a modified shared-LSTM network for the Semantic Textual Similarity
(STS) task at SemEval-2017. The network builds on previously explored Siamese
network architectures. We treat max sentence length as an additional
hyperparameter to be tuned (beyond learning rate, regularization, and dropout).
Our results demonstrate that hand-tuning max sentence training length
significantly improves final accuracy. After optimizing hyperparameters, we
train the network on the multilingual semantic similarity task using
pre-translated sentences. We achieved a correlation of 0.4792 for all the
subtasks.  We achieved the fourth highest team correlation for Task 4b, which
was our best relative placement.},
 address = {Vancouver, Canada},
 author = {Barrow, Joe  and  Peskov, Denis},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {180--184},
 publisher = {Association for Computational Linguistics},
 title = {UMDeep at SemEval-2017 Task 1: End-to-End Shared Weight LSTM Model for Semantic Textual Similarity},
 year = {2017}
}

@inproceedings{S17-2027,
 abstract = {This paper describes MITRE's participation in the Semantic Textual Similarity
task (SemEval-2017 Task 1), which evaluated machine learning approaches to the
identification of similar meaning among text snippets in English, Arabic, Spanish, and Turkish. We detail the techniques we explored ranging from simple
bag-of-ngrams classifiers to neural architectures with varied attention and
alignment mechanisms. Linear regression is used to tie the
systems together into an ensemble submitted for evaluation. The resulting
system is capable of matching human similarity ratings of image captions with
correlations of 0.73 to 0.83 in monolingual settings and 0.68 to 0.78 in
cross-lingual conditions, demonstrating the power of relatively simple
approaches.},
 address = {Vancouver, Canada},
 author = {Henderson, John  and  Merkhofer, Elizabeth  and  Strickhart, Laura  and  Zarrella, Guido},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {185--190},
 publisher = {Association for Computational Linguistics},
 title = {MITRE at SemEval-2017 Task 1: Simple Semantic Similarity},
 year = {2017}
}

@inproceedings{S17-2028,
 abstract = {To address semantic similarity on multilingual and cross-lingual sentences, we
firstly translate other foreign languages into English, and then
feed our monolingual English system with various interactive features. Our
system is further supported by combining with deep learning semantic similarity
and our best run achieves the mean Pearson correlation 73.16% in primary
track.},
 address = {Vancouver, Canada},
 author = {Tian, Junfeng  and  Zhou, Zhiheng  and  Lan, Man  and  Wu, Yuanbin},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {191--197},
 publisher = {Association for Computational Linguistics},
 title = {ECNU at SemEval-2017 Task 1: Leverage Kernel-based Traditional NLP features and Neural Networks to Build a Universal Model for Multilingual and Cross-lingual Semantic Textual Similarity},
 year = {2017}
}

@inproceedings{S17-2029,
 abstract = {This paper describes our proposed solution for SemEval 2017 Task 1: Semantic
Textual Similarity. The task aims at measuring the degree of
equivalence between sentences given in English. Performance is evaluated by
computing Pearson Correlation scores between the predicted scores and human
judgements. Our proposed system consists of two subsystems and one regression
model for predicting STS scores. The two subsystems are designed to learn
Paraphrase and Event Embeddings that can take the consideration of paraphrasing
characteristics and sentence structures into our system. The regression model
associates these embeddings to make the final predictions. The experimental
result shows that our system acquires 0.8 of Pearson Correlation Scores in this
task.},
 address = {Vancouver, Canada},
 author = {Lee, I-Ta  and  Goindani, Mahak  and  Li, Chang  and  Jin, Di  and  Johnson, Kristen Marie  and  Zhang, Xiao  and  Pacheco, Maria Leonor  and  Goldwasser, Dan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {198--202},
 publisher = {Association for Computational Linguistics},
 title = {PurdueNLP at SemEval-2017 Task 1: Predicting Semantic Textual Similarity with Paraphrase and Event Embeddings},
 year = {2017}
}

@inproceedings{S17-2030,
 abstract = {We use referential translation machines for predicting the semantic similarity
of text in all STS tasks which contain Arabic, English, Spanish, and Turkish
this year.
RTMs pioneer a language independent approach to semantic similarity and remove
the need to access
any task or domain specific information or resource. RTMs become 6th out of 52
submissions in
Spanish to English STS.
We average prediction scores using weights based on the training performance to
improve the overall performance.},
 address = {Vancouver, Canada},
 author = {Bi\c{c}ici, Ergun},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {203--207},
 publisher = {Association for Computational Linguistics},
 title = {RTM at SemEval-2017 Task 1: Referential Translation Machines for Predicting Semantic Similarity},
 year = {2017}
}

@inproceedings{S17-2031,
 abstract = {In this paper we report our attempt to use, on the one hand, state-of-the-art
neural approaches that are proposed to measure Semantic Textual Similarity
(STS). On the other hand, we propose an unsupervised cross-word alignment
approach, which is linguistically motivated. The neural approaches proposed
herein are divided into two main stages. The first stage deals with
constructing neural word embeddings, the components of sentence embeddings. The
second stage deals with constructing a semantic similarity function relating
pairs of sentence embeddings. Unfortunately our competition results were poor
in all tracks, therefore we concentrated our research to improve them for Track
5 (EN-EN).},
 address = {Vancouver, Canada},
 author = {Arroyo-Fern\'{a}ndez, Ignacio  and  Meza Ruiz, Ivan Vladimir},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {208--212},
 publisher = {Association for Computational Linguistics},
 title = {LIPN-IIMAS at SemEval-2017 Task 1: Subword Embeddings, Attention Recurrent Neural Networks and Cross Word Alignment for Semantic Textual Similarity},
 year = {2017}
}

@inproceedings{S17-2032,
 abstract = {This paper describes our approach to the SemEval-2017 ``Semantic Textual
Similarity'' and ``Multilingual Word Similarity'' tasks. In the former, we test
our approach in both English and Spanish, and use a linguistically-rich set of
features. These move from lexical to semantic features. In particular, we try
to take advantage of the recent Abstract Meaning Representation and SMATCH
measure. Although without state of the art results, we introduce semantic
structures in textual similarity and analyze their impact. Regarding word
similarity, we target the English language and combine WordNet information with
Word Embeddings. Without matching the best systems, our approach proved to be
simple and effective.},
 address = {Vancouver, Canada},
 author = {Fialho, Pedro  and  Patinho Rodrigues, Hugo  and  Coheur, Lu\'{i}sa  and  Quaresma, Paulo},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {213--219},
 publisher = {Association for Computational Linguistics},
 title = {L2F/INESC-ID at SemEval-2017 Tasks 1 and 2: Lexical and semantic features in word and textual similarity},
 year = {2017}
}

@inproceedings{S17-2033,
 abstract = {In this paper, we introduce an approach to combining word embeddings and
machine translation for multilingual semantic word similarity, the task2 of
SemEval-2017. Thanks to the unsupervised transliteration model, our
cross-lingual word embeddings encounter decreased sums of OOVs. Our results are
produced using only monolingual Wikipedia corpora and a limited amount of
sentence-aligned data. Although relatively little resources are utilized, our
system ranked 3rd in the monolingual subtask and can be the 6th in the
cross-lingual subtask.},
 address = {Vancouver, Canada},
 author = {He, Junqing  and  Wu, Long  and  Zhao, Xuemin  and  Yan, Yonghong},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {220--225},
 publisher = {Association for Computational Linguistics},
 title = {HCCL at SemEval-2017 Task 2: Combining Multilingual Word Embeddings and Transliteration Model for Semantic Similarity},
 year = {2017}
}

@inproceedings{S17-2034,
 abstract = {This article describes the distributional strategy submitted by the Citius team
to the SemEval 2017 Task 2. Even though the team participated in two subtasks, namely monolingual and cross-lingual word similarity, the article is mainly
focused on the cross-lingual subtask. Our method uses comparable corpora and
syntactic dependencies to extract count-based and transparent bilingual
distributional contexts. The evaluation of the results show that our method is
competitive with other cross-lingual strategies, even those using aligned and
parallel texts.},
 address = {Vancouver, Canada},
 author = {Gamallo, Pablo},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {226--229},
 publisher = {Association for Computational Linguistics},
 title = {Citius at SemEval-2017 Task 2: Cross-Lingual Similarity from Comparable Corpora and Dependency-Based Contexts},
 year = {2017}
}

@inproceedings{S17-2035,
 abstract = {We have built a simple corpus-based system to estimate words similarity in
multiple languages with a count-based approach. After training on Wikipedia
corpora, our system was evaluated on the multilingual subtask of SemEval-2017
Task 2 and achieved a good level of performance, despite its great simplicity.
Our results tend to demonstrate the power of the distributional approach in
semantic similarity tasks, even without knowledge of the underlying language.
We also show that dimensionality reduction has a considerable impact on the
results.},
 address = {Vancouver, Canada},
 author = {Melka, Josu\'{e}  and  Bernard, Gilles},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {230--234},
 publisher = {Association for Computational Linguistics},
 title = {Jmp8 at SemEval-2017 Task 2: A simple and general distributional approach to estimate word similarity},
 year = {2017}
}

@inproceedings{S17-2036,
 abstract = {This paper shows the details of our system submissions in the task 2 of SemEval
2017. We take part in the subtask 1 of this task, which is an English
monolingual subtask. This task is designed to evaluate the semantic word
similarity of two linguistic items. The results of runs are assessed by
standard Pearson and Spearman correlation, contrast with official gold standard
set. The best performance of our runs is 0.781 (Final). The techniques of our
runs mainly make use of the word embeddings and the knowledge-based method. The
results demonstrate that the combined method is effective for the computation
of word similarity, while the word embeddings and the knowledge-based
technique, respectively, needs more deeply improvement in details.},
 address = {Vancouver, Canada},
 author = {Meng, Fanqing  and  Lu, Wenpeng  and  Zhang, Yuteng  and  Jian, Ping  and  Shi, Shumin  and  Huang, Heyan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {235--238},
 publisher = {Association for Computational Linguistics},
 title = {QLUT at SemEval-2017 Task 2: Word Similarity Based on Word Embedding and Knowledge Base},
 year = {2017}
}

@inproceedings{S17-2037,
 abstract = {The RUFINO team proposed a non-supervised, conceptually-simple and
low-cost approach for addressing the Multilingual and Cross-lingual
Semantic Word Similarity challenge at SemEval 2017. The proposed systems
were cross-lingual extensions of popular monolingual lexical similarity
approaches such as PMI and word2vec. The extensions were possible
by means of a small parallel list of concepts similar to the Swadesh's
list, which we obtained in a semi-automatic way. In spite of its simplicity, our approach showed to be effective obtaining statistically-significant
and consistent results in all datasets proposed for the task. Besides, we provide some research directions for improving this novel and affordable
approach.},
 address = {Vancouver, Canada},
 author = {Jimenez, Sergio  and  Due\~{n}as, George  and  Gaitan, Lorena  and  Segura, Jorge},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {239--244},
 publisher = {Association for Computational Linguistics},
 title = {RUFINO at SemEval-2017 Task 2: Cross-lingual lexical similarity by extending PMI and word embeddings systems with a Swadesh's-like list},
 year = {2017}
}

@inproceedings{S17-2038,
 abstract = {In this paper we report on the participation of the MERALI system to the
SemEval Task 2 Subtask 1. The MERALI system approaches conceptual similarity
through a simple, cognitively inspired, heuristics; it builds on a linguistic
resource, the TTCS-e, that relies on BabelNet, NASARI and ConceptNet. The
linguistic resource in fact contains a novel mixture of common-sense and
encyclopedic knowledge. The obtained results point out that there is ample room
for improvement, so that they are used to elaborate on present limitations and
on future steps.},
 address = {Vancouver, Canada},
 author = {Mensa, Enrico  and  Radicioni, Daniele P.  and  Lieto, Antonio},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {245--249},
 publisher = {Association for Computational Linguistics},
 title = {MERALI at SemEval-2017 Task 2 Subtask 1: a Cognitively Inspired approach},
 year = {2017}
}

@inproceedings{S17-2039,
 abstract = {This paper describes the HHU system that participated in Task 2 of SemEval
2017, Multilingual and Cross-lingual Semantic Word Similarity. We introduce our
unsupervised embedding learning technique and describe how it was employed and
configured to address the problems of monolingual and multilingual word
similarity measurement. This paper reports from empirical evaluations on the
benchmark provided by the task's organizers.},
 address = {Vancouver, Canada},
 author = {QasemiZadeh, Behrang  and  Kallmeyer, Laura},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {250--255},
 publisher = {Association for Computational Linguistics},
 title = {HHU at SemEval-2017 Task 2: Fast Hash-Based Embeddings for Semantic Word Similarity Assessment},
 year = {2017}
}

@inproceedings{S17-2040,
 abstract = {In this paper, we describe our proposed method for measuring semantic
similarity for a given pair of words at SemEval-2017 monolingual semantic word
similarity task. We use a combination of knowledge-based and corpus-based
techniques.
We use FarsNet, the Persian Word Net, besides deep learning techniques to
extract the similarity of words. We evaluated our proposed approach on Persian
(Farsi) test data at SemEval-2017. It outperformed the other participants and
ranked the first in the challenge.},
 address = {Vancouver, Canada},
 author = {Ranjbar, Niloofar  and  Mashhadirajab, Fatemeh  and  Shamsfard, Mehrnoush  and  Hosseini pour, Rayeheh  and  Vahid pour, Aryan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {256--260},
 publisher = {Association for Computational Linguistics},
 title = {Mahtab at SemEval-2017 Task 2: Combination of Corpus-based and Knowledge-based Methods to Measure Semantic Word Similarity},
 year = {2017}
}

@inproceedings{S17-2041,
 abstract = {This paper describes Sew-Embed, our language-independent approach to
multilingual and cross-lingual semantic word similarity as part of the
SemEval-2017 Task 2. We leverage the Wikipedia-based concept representations
developed by Raganato et al. (2016), and propose an embedded augmentation of
their explicit high-dimensional vectors, which we obtain by plugging in an
arbitrary word (or sense) embedding representation, and computing a weighted
average in the continuous vector space. We evaluate Sew-Embed with two
different off-the-shelf embedding representations, and report their
performances across all monolingual and cross-lingual benchmarks available for
the task. Despite its simplicity, especially compared with supervised or overly
tuned approaches, Sew-Embed achieves competitive results in the cross-lingual
setting (3rd best result in the global ranking of subtask 2, score 0.56).},
 address = {Vancouver, Canada},
 author = {Delli Bovi, Claudio  and  Raganato, Alessandro},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {261--266},
 publisher = {Association for Computational Linguistics},
 title = {Sew-Embed at SemEval-2017 Task 2: Language-Independent Concept Representations from a Semantically Enriched Wikipedia},
 year = {2017}
}

@inproceedings{S17-2042,
 abstract = {This paper presents Wild Devsâ participation in the SemEval-2017 Task 2
âMulti-lingual and Cross-lingual Semantic Word Similarityâ, which tries to
automatically measure the semantic similarity between two words. The system was
build using neural networks, having as input a collection of word pairs, whereas the output consists of a list of scores, from 0 to 4, corresponding to
the degree of similarity between the word pairs.},
 address = {Vancouver, Canada},
 author = {Rotari, R\v{a}zvan-Gabriel  and  Hulub, Ionut  and  Oprea, Stefan  and  Plamada-Onofrei, Mihaela  and  Lorent, Alina Beatrice  and  Preisler, Raluca  and  Iftene, Adrian  and  Trandabat, Diana},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {267--270},
 publisher = {Association for Computational Linguistics},
 title = {Wild Devs' at SemEval-2017 Task 2: Using Neural Networks to Discover Word Similarity},
 year = {2017}
}

@inproceedings{S17-2043,
 abstract = {In   this   paper   we                                 present               the

Tren-toTeam  system  which
participated  to  thetask  3  at  SemEval-2017                                (Nakov

et
al.,2017).We
concentrated  our  work  onapplying   Grice   Maxims(used   in

manystate-of-the-art Machine learning applica-tions(Vogel  et  al.,  2013;
Kheirabadiand  Aghagolzadeh,  2012;  Dale  and
Re-iter, 1995;  Franke, 2011))                                to              ranking  an-swers of a question
by answers
relevancy.Particularly, we  created  a                                ranker                    systembased on
relevancy
scores, assigned
by 3main
components:  Named entity recogni-tion,  similarity score,  sentiment
analysis.Our system obtained a comparable resultsto Machine learning systems.},
 address = {Vancouver, Canada},
 author = {Qwaider, Mohammed R. H.  and  Freihat, Abed Alhakim  and  Giunchiglia, Fausto},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {271--274},
 publisher = {Association for Computational Linguistics},
 title = {TrentoTeam at SemEval-2017 Task 3: An application of Grice Maxims in Ranking Community Question Answers},
 year = {2017}
}

@inproceedings{S17-2044,
 abstract = {This paper presents a description of the participation of the UPC-USMBA team in
the SemEval 2017 Task 3, subtask D, Arabic.
Our approach for facing the task is based on a combination of a set of atomic
classifiers. The atomic classifiers include lexical string based, based on
vectorial representations and rulebased.
Several combination approaches have been tried.},
 address = {Vancouver, Canada},
 author = {El Adlouni, Yassine  and  Lahbari, Imane  and  Rodriguez, Horacio  and  Meknassi, Mohammed  and  El Alaoui, Said Ouatik  and  Ennahnahi, Noureddine},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {275--279},
 publisher = {Association for Computational Linguistics},
 title = {UPC-USMBA at SemEval-2017 Task 3: Combining multiple approaches for CQA for Arabic},
 year = {2017}
}

@inproceedings{S17-2045,
 abstract = {This paper presents the system in SemEval-2017 Task 3, Community Question
Answering (CQA). We develop a ranking system that is capable of capturing
semantic relations between text pairs with little word overlap.  In addition to
traditional NLP features, we introduce several neural network based matching
features which enable our system to measure text similarity beyond lexicons.
Our system significantly outperforms baseline methods and holds the second
place in Subtask A and the fifth place in Subtask B, which demonstrates its
efficacy on answer selection and question retrieval.},
 address = {Vancouver, Canada},
 author = {Feng, Wenzheng  and  Wu, Yu  and  Wu, Wei  and  Li, Zhoujun  and  Zhou, Ming},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {280--286},
 publisher = {Association for Computational Linguistics},
 title = {Beihang-MSRA at SemEval-2017 Task 3: A Ranking System with Neural Matching Features for Community Question Answering},
 year = {2017}
}

@inproceedings{S17-2046,
 abstract = {This paper describes our system, dubbed MoRS (Modular Ranking System), pronounced 'Morse', which participated in Task 3 of SemEval-2017.
We used MoRS to perform the Community Question Answering Task 3, which
consisted on reordering a set of comments according to their usefulness in
answering the question in the thread. This was made for a large collection of
questions created by a user community.
As for this challenge we wanted to go back to simple, easy-to-use, and somewhat
forgotten technologies that we think, in the hands of non-expert people, could
be reused in their own data sets. Some of our techniques included the
annotation of text, the retrieval of meta-data for each comment, POS tagging
and Named Entity Recognition, among others. These gave place to syntactical
analysis and semantic measurements. Finally we show and discuss our results and
the context of our approach, which is part of a more comprehensive system in
development, named MoQA.},
 address = {Vancouver, Canada},
 author = {Rodrigues, Miguel J.  and  Couto, Francisco M},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {287--291},
 publisher = {Association for Computational Linguistics},
 title = {MoRS at SemEval-2017 Task 3: Easy to use SVM in Ranking Tasks},
 year = {2017}
}

@inproceedings{S17-2047,
 abstract = {We describe our system for participating in SemEval-2017 Task 3 on Community
Question Answering. Our approach relies on combining a rich set of various
types
of features: semantic and metadata. The most important group turned out to be
the
metadata feature and the semantic vectors trained on QatarLiving data. In the
main
Subtask C, our primary submission was ranked fourth, with a MAP of 13.48 and
accuracy of 97.08. In Subtask A, our primary submission get into the top 50%.},
 address = {Vancouver, Canada},
 author = {Xie, Yufei  and  Wang, Maoquan  and  Ma, Jing  and  Jiang, Jian  and  Lu, Zhao},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {292--298},
 publisher = {Association for Computational Linguistics},
 title = {EICA Team at SemEval-2017 Task 3: Semantic and Metadata-based Features for Community Question Answering},
 year = {2017}
}

@inproceedings{S17-2048,
 abstract = {In this paper we present ThReeNN, a model for Community Question Answering, Task 3, of SemEval-2017. The proposed model exploits both syntactic and
semantic information to build a single and meaningful embedding space. Using a
dependency parser in combination with word embeddings, the model creates
sequences of inputs for a Recurrent Neural Network, which are then used for the
ranking purposes of the Task. The score obtained on the official test data
shows promising results.},
 address = {Vancouver, Canada},
 author = {Attardi, Giuseppe  and  Carta, Antonio  and  Errica, Federico  and  Madotto, Andrea  and  Pannitto, Ludovica},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {299--304},
 publisher = {Association for Computational Linguistics},
 title = {FA3L at SemEval-2017 Task 3: A ThRee Embeddings Recurrent Neural Network for Question Answering},
 year = {2017}
}

@inproceedings{S17-2049,
 abstract = {We describe a method of calculating the similarity of questions in community
QA. Question in cQA are usually very long and there are a lot of useless
information about calculating the similarity of questions. Therefore,we
implement a CNN model based on similar and dissimilar information between
questionâs keywords. We extract the keywords of questions, and then model the
similar and dissimilar information between the keywords, and use the CNN model
to calculate the similarity.},
 address = {Vancouver, Canada},
 author = {Qi, Le  and  Zhang, Yu  and  Liu, Ting},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {305--309},
 publisher = {Association for Computational Linguistics},
 title = {SCIR-QA at SemEval-2017 Task 3: CNN Model Based on Similar and Dissimilar Information between Keywords for Question Similarity},
 year = {2017}
}

@inproceedings{S17-2050,
 abstract = {This paper describes our official entry LearningToQuestion for SemEval 2017
task 3 community question answer, subtask B. The objective is to rerank
questions obtained in web forum as per their similarity to original question.
Our system uses pairwise learning to rank methods on rich set of hand designed
and representation learning features. We use various semantic features that
help our system to achieve promising results on the task. The system achieved
second highest results on official metrics MAP and good results on other search
metrics.},
 address = {Vancouver, Canada},
 author = {Goyal, Naman},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {310--314},
 publisher = {Association for Computational Linguistics},
 title = {LearningToQuestion at SemEval 2017 Task 3: Ranking Similar Questions by Learning to Rank Using Rich Features},
 year = {2017}
}

@inproceedings{S17-2051,
 abstract = {This paper describes the SimBow system submitted at SemEval2017-Task3, for the
question-question similarity subtask B. The proposed approach is a supervised
combination of different unsupervised textual similarities. These textual
similarities rely on the introduction of a relation matrix in the classical
cosine similarity between bag-of-words, so as to get a soft-cosine that takes
into account relations between words. According to the type of relation matrix
embedded in the soft-cosine, semantic or lexical relations can be considered.
Our system ranked first among the official submissions of subtask B.},
 address = {Vancouver, Canada},
 author = {Charlet, Delphine  and  Damnati, Geraldine},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {315--319},
 publisher = {Association for Computational Linguistics},
 title = {SimBow at SemEval-2017 Task 3: Soft-Cosine Semantic Similarity between Questions for Community Question Answering},
 year = {2017}
}

@inproceedings{S17-2052,
 abstract = {We describes deep neural networks frameworks in this paper to address the
community question answering (cQA) ranking task (SemEval-2017 task 3).
Convolutional neural networks and bi-directional long-short term memory
networks are applied in our methods to extract semantic information from
questions and answers (comments). In addition, in order to take the full
advantage of question-comment semantic relevance, we deploy interaction layer
and augmented features before calculating the similarity. The results show that
our methods have the great effectiveness for both subtask A and subtask C.},
 address = {Vancouver, Canada},
 author = {Zhang, Sheng  and  Cheng, Jiajun  and  Wang, Hui  and  Zhang, Xin  and  Li, Pei  and  Ding, Zhaoyun},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {320--325},
 publisher = {Association for Computational Linguistics},
 title = {FuRongWang at SemEval-2017 Task 3: Deep Neural Networks for Selecting Relevant Answers in Community Question Answering},
 year = {2017}
}

@inproceedings{S17-2053,
 abstract = {This paper describes the KeLP system participating in the SemEval-2017
community Question Answering (cQA) task.
The system is a refinement of the kernel-based sentence pair modeling we
proposed for the previous year challenge. It is implemented within the
Kernel-based Learning Platform called KeLP, from which we inherit the team's
name.
Our primary submission ranked first in subtask A, and third in subtasks B and
C, being the only systems appearing in the top-3 ranking for all the English
subtasks. This shows that the proposed framework, which has minor variations
among the three subtasks, is extremely flexible and effective in tackling
learning tasks defined on sentence pairs.},
 address = {Vancouver, Canada},
 author = {Filice, Simone  and  Da San Martino, Giovanni  and  Moschitti, Alessandro},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {326--333},
 publisher = {Association for Computational Linguistics},
 title = {KeLP at SemEval-2017 Task 3: Learning Pairwise Patterns in Community Question Answering},
 year = {2017}
}

@inproceedings{S17-2054,
 abstract = {In this paper we propose a system for reranking
answers for a given question. Our
method builds on a siamese CNN architecture
which is extended by two attention
mechanisms. The approach was evaluated
on the datasets of the SemEval-2017 competition
for Community Question Answering
(cQA), where it achieved 7th place obtaining
a MAP score of 86:24 points on the
Question-Comment Similarity subtask.},
 address = {Vancouver, Canada},
 author = {Deriu, Jan Milan  and  Cieliebak, Mark},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {334--338},
 publisher = {Association for Computational Linguistics},
 title = {SwissAlps at SemEval-2017 Task 3: Attention-based Convolutional Neural Network for Community Question Answering},
 year = {2017}
}

@inproceedings{S17-2055,
 abstract = {In this paper we present the TakeLab-QA entry to SemEval 2017 task 3, which is
a question-comment re-ranking problem. We present a classification based
approach, including two supervised learning models -- Support Vector Machines
(SVM) and Convolutional Neural Networks (CNN). We use features based on
different semantic similarity models (e.g., Latent Dirichlet Allocation), as
well as features based on several types of pre-trained word embeddings.
Moreover, we also use some hand-crafted task-specific features. For training, our system uses no external labeled data apart from that provided by the
organizers. Our primary submission achieves a MAP-score of 81.14 and F1-score
of 66.99 -- ranking us 10th on the SemEval 2017 task 3, subtask A.},
 address = {Vancouver, Canada},
 author = {\v{S}aina, Filip  and  Kukurin, Toni  and  Pulji\'{c}, Lukrecija  and  Karan, Mladen  and  \v{S}najder, Jan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {339--343},
 publisher = {Association for Computational Linguistics},
 title = {TakeLab-QA at SemEval-2017 Task 3: Classification Experiments for Answer Retrieval in Community QA},
 year = {2017}
}

@inproceedings{S17-2056,
 abstract = {This paper describes our submission to SemEval-2017 Task 3 Subtask D, "Question
Answer Ranking in Arabic Community Question Answering". In this work, we
applied a supervised machine learning approach to automatically re-rank a set
of QA pairs according to their relevance to a given question. We employ
features based on latent semantic models, namely WTMF, as well as a set of
lexical features based on string lengths and surface level matching. The
proposed system ranked first out of 3 submissions, with a MAP score of 61.16%.},
 address = {Vancouver, Canada},
 author = {Almarwani, Nada  and  Diab, Mona},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {344--348},
 publisher = {Association for Computational Linguistics},
 title = {GW\_QA at SemEval-2017 Task 3: Question Answer Re-ranking on Arabic Fora},
 year = {2017}
}

@inproceedings{S17-2057,
 abstract = {This paper describes our participation in SemEval-2017 Task 3 on Community
Question  Answering (cQA). The Question Similarity subtask (B) aims to rank  a
set of related questions retrieved by a search engine according to their
similarity to the original question. We adapted our feature-based system for
Recognizing Question Entailment (RQE) to the question similarity task. Tested
on cQA-B-2016 test data, our RQE system outperformed the best system of the
2016 challenge in all measures with 77.47 MAP and 80.57 Accuracy. On cQA-B-2017
test data, performances of all systems dropped by around 30 points. Our primary
system obtained 44.62 MAP, 67.27 Accuracy and 47.25 F1 score. The cQA-B-2017
best system achieved 47.22 MAP and 42.37 F1 score. Our system is ranked sixth
in terms of MAP and third in terms of F1 out of 13 participating teams.},
 address = {Vancouver, Canada},
 author = {Ben Abacha, Asma  and  Demner-Fushman, Dina},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {349--352},
 publisher = {Association for Computational Linguistics},
 title = {NLM\_NIH at SemEval-2017 Task 3: from Question Entailment to Question Similarity for Community Question Answering},
 year = {2017}
}

@inproceedings{S17-2058,
 abstract = {This paper describes a text-ranking system developed by bunji team in
SemEval-2017 Task 3: Community Question Answering, Subtask A and C. The goal of
the task is to re-rank the comments in a question-and-answer forum such that
useful comments for answering the question are ranked high. We proposed a
method that combines neural similarity features and hand-crafted comment
plausibility features, and we modeled inter-comments relationship using
conditional random field. Our approach obtained the fifth place in the Subtask
A and the second place in the Subtask C.},
 address = {Vancouver, Canada},
 author = {Koreeda, Yuta  and  Hashito, Takuya  and  Niwa, Yoshiki  and  Sato, Misa  and  Yanase, Toshihiko  and  Kurotsuchi, Kenzo  and  Yanai, Kohsuke},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {353--359},
 publisher = {Association for Computational Linguistics},
 title = {bunji at SemEval-2017 Task 3: Combination of Neural Similarity Features and Comment Plausibility Features},
 year = {2017}
}

@inproceedings{S17-2059,
 abstract = {In this paper we describe our QU-BIGIR system for the Arabic subtask D of the
SemEval 2017 Task 3. Our approach builds on our participation in the past
version of the same subtask. This year, our system uses different similarity
measures that encodes lexical and semantic pairwise similarity of text pairs.
In addition to well known similarity measures such as cosine similarity, we use
other measures based on the summary statistics of word embedding
representation for a given text. To rank a list of candidate question answer
pairs for a given question, we learn a linear SVM classifier over our
similarity features. Our best resulting run came second in subtask D with a
very competitive performance to the first-ranking system.},
 address = {Vancouver, Canada},
 author = {Torki, Marwan  and  Hasanain, Maram  and  Elsayed, Tamer},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {360--364},
 publisher = {Association for Computational Linguistics},
 title = {QU-BIGIR at SemEval 2017 Task 3: Using Similarity Features for Arabic Community Question Answering Forums},
 year = {2017}
}

@inproceedings{S17-2060,
 abstract = {This paper describes the systems we submitted to the task 3 (Community Ques-
tion Answering) in SemEval 2017 which contains three subtasks on English
corpora, i.e., subtask A: Question-Comment Similarity, subtask B: Question-Question
Similarity, and subtask C: Question-External Comment Similarity. For subtask A, we
combined two different methods to represent question-comment pair, i.e., supervised model using traditional features and Convolutional Neural Network.
For subtask B, we utilized the information of snippets returned from Search
Engine with question subject as query. For subtask C, we ranked the comments by
multiplying the probability of the pair related question comment being Good by
the reciprocal rank of the related question.},
 address = {Vancouver, Canada},
 author = {Wu, Guoshun  and  Sheng, Yixuan  and  Lan, Man  and  Wu, Yuanbin},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {365--369},
 publisher = {Association for Computational Linguistics},
 title = {ECNU at SemEval-2017 Task 3: Using Traditional and Deep Learning Methods to Address Community Question Answering Task},
 year = {2017}
}

@inproceedings{S17-2061,
 abstract = {The majority of core techniques to solve many problems in Community Question
Answering (CQA) task rely on similarity computation. This work focuses on
similarity between two sentences (or questions in subtask B) based on word
embeddings. We exploit words importance levels in sentences or questions for
similarity features, for classification and ranking with machine learning.
Using only 2 types of similarity metric, our proposed method has shown
comparable results with other complex systems. This method on subtask B 2017
dataset is ranked on position 7 out of 13 participants. Evaluation on 2016
dataset is on position 8 of 12, outperforms some complex systems. Further, this
finding is explorable and potential to be used as baseline and extensible for
many tasks in CQA and other textual similarity based system.},
 address = {Vancouver, Canada},
 author = {Agustian, Surya  and  Takamura, Hiroya},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {370--374},
 publisher = {Association for Computational Linguistics},
 title = {UINSUSKA-TiTech at SemEval-2017 Task 3: Exploiting Word Importance Levels for Similarity Features for CQA},
 year = {2017}
}

@inproceedings{S17-2062,
 abstract = {This paper describes our approach to the SemEval-2017 shared task of
determining question-question similarity in a community question-answering
setting (Task 3B). We extracted both syntactic and semantic similarity features
between candidate questions, performed pairwise-preference learning to optimize
for ranking order, and then trained a random forest classifier to predict
whether the candidate questions are paraphrases of each other. This approach
achieved a MAP of 45.7% out of max achievable 67.0% on the test set.},
 address = {Vancouver, Canada},
 author = {Galbraith, Byron  and  Pratap, Bhanu  and  Shank, Daniel},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {375--379},
 publisher = {Association for Computational Linguistics},
 title = {Talla at SemEval-2017 Task 3: Identifying Similar Questions Through Paraphrase Detection},
 year = {2017}
}

@inproceedings{S17-2063,
 abstract = {This paper presents our submission to SemEval-2017 Task 6: #HashtagWars:
Learning a Sense of Humor. There are two subtasks: A. Pairwise Comparison, and
B. Semi-Ranking. Our assumption is that the distribution of humorous and
non-humorous texts in real life language is naturally imbalanced. Using Na\"{i}ve
Bayes Multinomial with standard text-representation features, we approached
Subtask B as a sequence of imbalanced classification problems, and optimized
our system per the macro-average recall. Subtask A was then solved via the
Semi-Ranking results. On the final test, our system was ranked 10th for Subtask
A, and 3rd for Subtask B.},
 address = {Vancouver, Canada},
 author = {Han, Xiwu  and  Toner, Gregory},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {380--384},
 publisher = {Association for Computational Linguistics},
 title = {QUB at SemEval-2017 Task 6: Cascaded Imbalanced Classification for Humor Analysis in Twitter},
 year = {2017}
}

@inproceedings{S17-2064,
 abstract = {This paper describes the Duluth system that participated in SemEval-2017 Task 6
#HashtagWars: Learning a Sense of Humor. The system participated in Subtasks A
and B using N-gram language models, ranking highly in the task evaluation.
This paper discusses the results of our system in the development and
evaluation stages and from two post-evaluation runs.},
 address = {Vancouver, Canada},
 author = {Yan, Xinru  and  Pedersen, Ted},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {385--389},
 publisher = {Association for Computational Linguistics},
 title = {Duluth at SemEval-2017 Task 6: Language Models in Humor Detection},
 year = {2017}
}

@inproceedings{S17-2065,
 abstract = {In this paper we present a deep-learning system that competed at SemEval-2017
Task 6 "#HashtagWars: Learning a Sense of Humor". We participated in
Subtask A, in which the goal was, given two Twitter messages, to identify which
one is funnier. We propose a Siamese architecture with bidirectional Long
Short-Term Memory (LSTM) networks, augmented with an attention mechanism. Our
system works on the token-level, leveraging word embeddings trained on a big
collection of unlabeled Twitter messages. We ranked 2nd in 7 teams. A
post-completion improvement of our model, achieves state-of-the-art results on
#HashtagWars dataset.},
 address = {Vancouver, Canada},
 author = {Baziotis, Christos  and  Pelekis, Nikos  and  Doulkeridis, Christos},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {390--395},
 publisher = {Association for Computational Linguistics},
 title = {DataStories at SemEval-2017 Task 6: Siamese LSTM with Attention for Humorous Text Comparison},
 year = {2017}
}

@inproceedings{S17-2066,
 abstract = {This paper describes our system for humor ranking in tweets within the SemEval
2017 Task 6: #HashtagWars (6A and 6B). For both subtasks, we use an
off-the-shelf gradient boosting model built on a rich set of features, handcrafted to provide the model with the external knowledge needed to better
predict the humor in the text. The features capture various cultural references
and specific humor patterns. Our system ranked 2nd (officially 7th) among 10
submissions on the Subtask A and 2nd among 9 submissions on the Subtask B.},
 address = {Vancouver, Canada},
 author = {Kukova\v{c}ec, Marin  and  Malenica, Juraj  and  Mr\v{s}i\'{c}, Ivan  and  \v{S}ajatovi\'{c}, Antonio  and  Alagi\'{c}, Domagoj  and  \v{S}najder, Jan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {396--400},
 publisher = {Association for Computational Linguistics},
 title = {TakeLab at SemEval-2017 Task 6: #RankingHumorIn4Pages},
 year = {2017}
}

@inproceedings{S17-2067,
 abstract = {This paper explores the role of semantic relatedness features, such as word
associations, in humour recognition. Specifically, we examine the task of
inferring pairwise humour judgments in Twitter hashtag wars. We examine a
variety of word association features derived from University of Southern
Florida Free Association Norms (USF) and the Edinburgh Associative Thesaurus
(EAT) and find that word association-based features outperform Word2Vec
similarity, a popular semantic relatedness measure. Our system achieves an
accuracy of 56.42% using a combination of unigram perplexity, bigram
perplexity, EAT difference (tweet-avg), USF forward (max), EAT difference
(word-avg), USF difference (word-avg), EAT forward (min), USF difference
(tweet-max), and EAT backward (min).},
 address = {Vancouver, Canada},
 author = {Cattle, Andrew  and  Ma, Xiaojuan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {401--406},
 publisher = {Association for Computational Linguistics},
 title = {SRHR at SemEval-2017 Task 6: Word Associations for Humour Recognition},
 year = {2017}
}

@inproceedings{S17-2068,
 abstract = {This paper presents the participation of #WarTeam in Task 6 of SemEval2017 with
a system classifying humor by comparing and ranking tweets. The training data
consists of annotated tweets from the $@$midnight TV show. #WarTeamâs system
uses a neural network (TensorFlow) having inputs from a Na\"{i}ve Bayes humor
classifier and a sentiment analyzer.},
 address = {Vancouver, Canada},
 author = {Fle\c{s}can-Lovin-Arseni, Iuliana Alexandra  and  Turcu, Ramona Andreea  and  Sirbu, Cristina  and  Alexa, Larisa  and  Amarandei, Sandra Maria  and  Herciu, Nichita  and  Scutaru, Constantin  and  Trandabat, Diana  and  Iftene, Adrian},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {407--410},
 publisher = {Association for Computational Linguistics},
 title = {#WarTeam at SemEval-2017 Task 6: Using Neural Networks for Discovering Humorous Tweets},
 year = {2017}
}

@inproceedings{S17-2069,
 abstract = {This paper describes the system devel-oped for SemEval 2017 task 6:
#HashTagWars -Learning a Sense of Hu-mor. Learning to recognize sense of hu-mor
is the important task for language understanding applications. Different set of
features based on frequency of words, structure of tweets and semantics are
used in this system to identify the presence of humor in tweets. Supervised
machine learning approaches, Multilayer percep-tron and Na\"{i}ve Bayes are used
to classify the tweets in to three level of sense of humor. For given Hashtag, the system finds the funniest tweet and predicts the amount of funniness of all
the other tweets. In official submitted runs, we have achieved 0.506 accuracy
using mul-tilayer perceptron in subtask-A and 0.938 distance in subtask-B.
Using Na\"{i}ve bayes in subtask-B, the system achieved 0.949 distance. Apart from
official runs, this system have scored 0.751 accuracy in subtask-A using SVM.
But still there is a wide room for improvement in system.},
 address = {Vancouver, Canada},
 author = {Mahajan, Rutal  and  Zaveri, Mukesh},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {411--415},
 publisher = {Association for Computational Linguistics},
 title = {SVNIT $@$ SemEval 2017 Task-6: Learning a Sense of Humor Using Supervised Approach},
 year = {2017}
}

@inproceedings{S17-2070,
 abstract = {This paper describes the Duluth systems that participated in SemEval-2017 Task
7 : Detection and Interpretation of English Puns. The Duluth systems
participated in all three subtasks, and relied on methods that included word
sense disambiguation and measures of semantic relatedness.},
 address = {Vancouver, Canada},
 author = {Pedersen, Ted},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {416--420},
 publisher = {Association for Computational Linguistics},
 title = {Duluth at SemEval-2017 Task 7 : Puns Upon a Midnight Dreary, Lexical Semantics for the Weak and Weary},
 year = {2017}
}

@inproceedings{S17-2071,
 abstract = {The paper presents a system for locating a pun word. The developed method
calculates a score for each word in a pun, using a number of components, including its Inverse Document Frequency (IDF), Normalized Pointwise Mutual
Information (NPMI) with other words in the pun text, its position in the text, part-of-speech and some syntactic features. The method achieved the best
performance in the Heterographic category and the second best in the
Homographic. Further analysis showed that IDF is the most useful
characteristic, whereas the count of words with which the given word has high
NPMI has a negative effect on performance.},
 address = {Vancouver, Canada},
 author = {Vechtomova, Olga},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {421--425},
 publisher = {Association for Computational Linguistics},
 title = {UWaterloo at SemEval-2017 Task 7: Locating the Pun Using Syntactic Characteristics and Corpus-based Metrics},
 year = {2017}
}

@inproceedings{S17-2072,
 abstract = {The article describes a model of automatic interpretation of English puns, based on Roget{'}s Thesaurus, and its implementation, PunFields. In a pun, the
algorithm discovers two groups of words that belong to two main semantic
fields. The fields become a semantic vector based on which an SVM classifier
learns to recognize puns. A rule-based model is then applied for recognition of
intentionally ambiguous (target) words and their definitions. In SemEval Task 7
PunFields shows a considerably good result in pun classification, but requires
improvement in searching for the target word and its definition.},
 address = {Vancouver, Canada},
 author = {Mikhalkova, Elena  and  Karyakin, Yuri},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {426--431},
 publisher = {Association for Computational Linguistics},
 title = {PunFields at SemEval-2017 Task 7: Employing Roget's Thesaurus in Automatic Pun Recognition and Interpretation},
 year = {2017}
}

@inproceedings{S17-2073,
 abstract = {System description. Implementation of HMM and Cyclic Dependency Network.},
 address = {Vancouver, Canada},
 author = {Pramanick, Aniket  and  Das, Dipankar},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {432--435},
 publisher = {Association for Computational Linguistics},
 title = {JU CSE NLP $@$ SemEval 2017 Task 7: Employing Rules to Detect and Interpret English Puns},
 year = {2017}
}

@inproceedings{S17-2074,
 abstract = {This paper presents a system developed for SemEval-2017 Task 7, Detection and
Interpretation of English Puns consisting of three subtasks; pun detection, pun
location, and pun interpretation, respectively. The system stands on
recognizing a distinctive word which has a high association with the pun in the
given sentence. The intended humorous meaning of pun is identified through the
use of this word. Our official results confirm the potential of this approach.},
 address = {Vancouver, Canada},
 author = {Sevgili, \"{O}zge  and  Ghotbi, Nima  and  Tekir, Selma},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {436--439},
 publisher = {Association for Computational Linguistics},
 title = {N-Hance at SemEval-2017 Task 7: A Computational Approach using Word Association for Puns},
 year = {2017}
}

@inproceedings{S17-2075,
 abstract = {This paper describes the participation of ELiRF-UPV team at task
7 (subtask 2: homographic pun detection and subtask 3: homographic pun
interpretation) of SemEval2017. Our approach is based on the use of word
embeddings to find related words in a sentence and a version of the Lesk
algorithm to establish relationships between synsets.
The results obtained are in line with those obtained by the other participants
and they encourage us to continue working on this problem.},
 address = {Vancouver, Canada},
 author = {Hurtado, Llu\'{i}s-F.  and  Segarra, Encarna  and  Pla, Ferran  and  Carrasco, Pascual  and  Gonz\'{a}lez, Jos\'{e}-\'{A}ngel},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {440--443},
 publisher = {Association for Computational Linguistics},
 title = {ELiRF-UPV at SemEval-2017 Task 7: Pun Detection and Interpretation},
 year = {2017}
}

@inproceedings{S17-2076,
 abstract = {This paper describes our system participating in the SemEval-2017 Task 7, for
the subtasks of homographic pun location and homographic pun interpretation.
For pun interpretation, we use a knowledge-based Word Sense Disambiguation
(WSD) method based on sense embeddings. Pun-based jokes can be divided into two
parts, each containing information about the two distinct senses of the pun. To
exploit this structure we split the context that is input to the WSD system
into two local contexts and find the best sense for each of them. We use the
output of pun interpretation for pun location. As we expect the two meanings of
a pun to be very dissimilar, we compute sense embedding cosine distances for
each sense-pair and select the word that has the highest distance. We describe
experiments on different methods of splitting the context and compare our
method to several baselines. We find evidence supporting our hypotheses and
obtain competitive results for pun interpretation.},
 address = {Vancouver, Canada},
 author = {Oele, Dieke  and  Evang, Kilian},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {444--448},
 publisher = {Association for Computational Linguistics},
 title = {BuzzSaw at SemEval-2017 Task 7: Global vs. Local Context for Interpreting and Locating Homographic English Puns with Sense Embeddings},
 year = {2017}
}

@inproceedings{S17-2077,
 abstract = {In this paper we describe our system created for SemEval-2017 Task 7: Detection
and Interpretation of English Puns. We tackle subtask 1, pun detection, by
leveraging features selected from sentences to design a classifier that can
disambiguate between the presence or absence of a pun. We address subtask 2, pun location, by utilizing a decision flow structure that uses presence or
absence of certain features to decide the next action. The results obtained by
our system are encouraging, considering the simplicity of the system. We
consider this system as a precursor for deeper exploration on efficient feature
selection for pun detection.},
 address = {Vancouver, Canada},
 author = {Vadehra, Ankit},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {449--452},
 publisher = {Association for Computational Linguistics},
 title = {UWAV at SemEval-2017 Task 7: Automated feature-based system for locating puns},
 year = {2017}
}

@inproceedings{S17-2078,
 abstract = {This paper describes our submissions to task 7 in SemEval 2017, i.e., Detection
and Interpretation of English Puns. We participated in the first two subtasks, which are
to detect and locate English puns respectively. For subtask 1, we presented a
supervised system to determine whether or not a sentence contains a pun using
similarity features calculated on sense vectors or cluster center vectors. For
subtask 2, we established an unsupervised system to locate the pun by scoring
each word in the
sentence and we assumed that the word with the smallest score is the pun.},
 address = {Vancouver, Canada},
 author = {Xiu, Yuhuan  and  Lan, Man  and  Wu, Yuanbin},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {453--456},
 publisher = {Association for Computational Linguistics},
 title = {ECNU at SemEval-2017 Task 7: Using Supervised and Unsupervised Methods to Detect and Locate English Puns},
 year = {2017}
}

@inproceedings{S17-2079,
 abstract = {This paper describes our system for detection and interpretation of English
puns. We participated in 2 subtasks related to homographic puns achieve
comparable results for these tasks.
Through the paper we provide detailed description of the approach, as well as
the results obtained in the task.
Our models achieved a F1-score of 77.65% for Subtask 1 and 52.15% for
Subtask 2.},
 address = {Vancouver, Canada},
 author = {Indurthi, Vijayasaradhi  and  Oota, Subba Reddy},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {457--460},
 publisher = {Association for Computational Linguistics},
 title = {Fermi at SemEval-2017 Task 7: Detection and Interpretation of Homographic puns in English Language},
 year = {2017}
}

@inproceedings{S17-2080,
 abstract = {This paper describes our system for subtask-A: SDQC for RumourEval, task-8 of
SemEval 2017. Identifying rumours, especially for breaking news events as they
unfold, is a challenging task due to the absence of sufficient information
about the exact rumour stories circulating on social media. Determining the
stance of Twitter users towards rumourous messages could provide an indirect
way of identifying potential rumours. The proposed approach makes use of topic
independent features from two categories, namely cue features and message
specific features to fit a gradient boosting classifier. With an accuracy of
0.78, our system achieved the second best performance on subtask-A of
RumourEval.},
 address = {Vancouver, Canada},
 author = {Bahuleyan, Hareesh  and  Vechtomova, Olga},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {461--464},
 publisher = {Association for Computational Linguistics},
 title = {UWaterloo at SemEval-2017 Task 8: Detecting Stance towards Rumours with Topic Independent Features},
 year = {2017}
}

@inproceedings{S17-2081,
 abstract = {This paper describes our approach for SemEval-2017 Task 8. We aim at detecting
the stance of tweets and determining the veracity of the given rumor. We
utilize a convolutional neural network for short text categorization using
multiple filter sizes. Our approach beats the baseline classifiers on different
event data with good F1 scores. The best of our submitted runs achieves rank
1st among all scores on subtask B.},
 address = {Vancouver, Canada},
 author = {Chen, Yi-Chin  and  Liu, Zhao-Yang  and  Kao, Hung-Yu},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {465--469},
 publisher = {Association for Computational Linguistics},
 title = {IKM at SemEval-2017 Task 8: Convolutional Neural Networks for stance detection and rumor verification},
 year = {2017}
}

@inproceedings{S17-2082,
 abstract = {Final submission for NileTMRG on RumourEval 2017.},
 address = {Vancouver, Canada},
 author = {Enayet, Omar  and  El-Beltagy, Samhaa R.},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {470--474},
 publisher = {Association for Computational Linguistics},
 title = {NileTMRG at SemEval-2017 Task 8: Determining Rumour and Veracity Support for Rumours on Twitter.},
 year = {2017}
}

@inproceedings{S17-2083,
 abstract = {This paper describes team Turing's submission to SemEval 2017 RumourEval:
Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A). Subtask A addresses the challenge of rumour stance classification, which involves identifying the attitude of Twitter users towards the
truthfulness of the rumour they are discussing. Stance classification is
considered to be an important step towards rumour verification, therefore
performing well in this task is expected to be useful in debunking false
rumours. In this work we classify a set of Twitter posts discussing rumours
into either supporting, denying, questioning or commenting on the underlying
rumours. We propose a LSTM-based sequential model that, through modelling the
conversational structure of tweets, which achieves an accuracy of 0.784 on the
RumourEval test set outperforming all other systems in Subtask A.},
 address = {Vancouver, Canada},
 author = {Kochkina, Elena  and  Liakata, Maria  and  Augenstein, Isabelle},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {475--480},
 publisher = {Association for Computational Linguistics},
 title = {Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-LSTM},
 year = {2017}
}

@inproceedings{S17-2084,
 abstract = {For the competition SemEval-2017 we investigated the possibility of performing
stance classification (support, deny, query or comment) for messages in Twitter
conversation threads related to rumours. Stance classification is interesting
since it can provide a basis for rumour veracity assessment. Our ensemble
classification approach of combining convolutional neural networks with both
automatic rule mining and manually written rules achieved a final accuracy of
74.9% on the competitionâs test data set for Task 8A. To improve
classification we also experimented with data relabeling and using the
grammatical structure of the tweet contents for classification.},
 address = {Vancouver, Canada},
 author = {Garc\'{i}a Lozano, Marianela  and  Lilja, Hanna  and  Tj\"{o}rnhammar, Edward  and  Karasalo, Maja},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {481--485},
 publisher = {Association for Computational Linguistics},
 title = {Mama Edha at SemEval-2017 Task 8: Stance Classification with CNN and Rules},
 year = {2017}
}

@inproceedings{S17-2085,
 abstract = {We describe our submissions for SemEval-2017 Task~8, Determining Rumour
Veracity and Support for Rumours. The Digital Curation Technologies (DKT) team
at the German Research Center for Artificial Intelligence (DFKI) participated
in two subtasks: Subtask A (determining the stance of a message) and Subtask B
(determining veracity of a message, closed variant). In both cases, our
implementation consisted of a Multivariate Logistic Regression (Maximum
Entropy) classifier coupled with hand-written patterns and rules (heuristics)
applied in a post-process cascading fashion. We provide a detailed analysis of
the system performance and report on variants of our systems that were not part
of the official submission.},
 address = {Vancouver, Canada},
 author = {Srivastava, Ankit  and  Rehm, Georg  and  Moreno Schneider, Julian},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {486--490},
 publisher = {Association for Computational Linguistics},
 title = {DFKI-DKT at SemEval-2017 Task 8: Rumour Detection and Classification using Cascading Heuristics},
 year = {2017}
}

@inproceedings{S17-2086,
 abstract = {This paper describes our submissions to task 8 in SemEval 2017, i.e., Determining
rumour veracity and support for rumours. Given a rumoured tweet and a lot of
reply tweets, the subtask A is to label whether these tweets are support, deny, query or comment, and the subtask B aims to predict the veracity (i.e., true, false, and unverified) with a confidence (in range of 0-1) of the given
rumoured tweet. For both subtasks, we adopted supervised machine learning
methods, incorporating rich features. Since training data is imbalanced, we
specifically designed a two-step classifier to address subtask A .},
 address = {Vancouver, Canada},
 author = {Wang, Feixiang  and  Lan, Man  and  Wu, Yuanbin},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {491--496},
 publisher = {Association for Computational Linguistics},
 title = {ECNU at SemEval-2017 Task 8: Rumour Evaluation Using Effective Features and Supervised Ensemble Models},
 year = {2017}
}

@inproceedings{S17-2087,
 abstract = {This paper describes our system participation in the SemEval-2017 Task 8
'RumourEval: Determining rumour veracity and support for rumours'. The
objective of this task was to predict the stance and veracity of the underlying
rumour. We propose a supervised classification approach employing several
lexical, content and twitter specific features for learning. Evaluation shows
promising results for both the problems.},
 address = {Vancouver, Canada},
 author = {Singh, Vikram  and  Narayan, Sunny  and  Akhtar, Md Shad  and  Ekbal, Asif  and  Bhattacharyya, Pushpak},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {497--501},
 publisher = {Association for Computational Linguistics},
 title = {IITP at SemEval-2017 Task 8 : A Supervised Approach for Rumour Evaluation},
 year = {2017}
}

@inproceedings{S17-2088,
 abstract = {This paper describes the fifth year of the Sentiment Analysis in Twitter task.
SemEval-2017 Task 4 continues with a rerun of the subtasks of SemEval-2016 Task
4, which include identifying the overall sentiment of the tweet, sentiment
towards a topic with classification on a two-point and on a five-point ordinal
scale, and quantification of the distribution of sentiment towards a topic
across a number of tweets: again on a two-point and on a five-point ordinal
scale. Compared to 2016, we made two changes: (i) we introduced a new language, Arabic, for all subtasks, and (ii) we made available information from the
profiles of the Twitter users who posted the target tweets. The task continues
to be very popular, with a total of 48 teams participating this year.},
 address = {Vancouver, Canada},
 author = {Rosenthal, Sara  and  Farra, Noura  and  Nakov, Preslav},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {502--518},
 publisher = {Association for Computational Linguistics},
 title = {SemEval-2017 Task 4: Sentiment Analysis in Twitter},
 year = {2017}
}

@inproceedings{S17-2089,
 abstract = {This paper discusses the "Fine-Grained Sentiment Analysis on Financial
Microblogs and News" task as part of SemEval-2017, specifically under the
"Detecting sentiment, humour, and truth" theme. This task contains two tracks, where the first one concerns Microblog messages and the second one covers News
Statements and Headlines. The main goal behind both tracks was to predict the
sentiment score for each of the mentioned companies/stocks. The sentiment
scores for each text instance adopted floating point values in the range of -1
(very negative/bearish) to 1 (very positive/bullish), with 0 designating
neutral sentiment. This task attracted a total of 32 participants, with 25
participating in Track 1 and 29 in Track 2.},
 address = {Vancouver, Canada},
 author = {Cortis, Keith  and  Freitas, Andr\'{e}  and  Daudert, Tobias  and  Huerlimann, Manuela  and  Zarrouk, Manel  and  Handschuh, Siegfried  and  Davis, Brian},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {519--535},
 publisher = {Association for Computational Linguistics},
 title = {SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News},
 year = {2017}
}

@inproceedings{S17-2090,
 abstract = {In this report we summarize the results of the 2017 AMR SemEval shared task.
The task consisted of two separate yet related subtasks. In the parsing
subtask, participants were asked to produce Abstract Meaning Representation
(AMR) (Banarescu et al., 2013) graphs for a set of English sentences in the
biomedical domain. In the generation subtask, participants were asked to
generate English sentences given AMR graphs in the news/forum domain. A total
of five sites participated in the parsing subtask, and four participated in the
generation subtask.
Along with a description of the task and the participants' systems, we show
various score ablations and some sample outputs.},
 address = {Vancouver, Canada},
 author = {May, Jonathan  and  Priyadarshi, Jay},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {536--545},
 publisher = {Association for Computational Linguistics},
 title = {SemEval-2017 Task 9: Abstract Meaning Representation Parsing and Generation},
 year = {2017}
}

@inproceedings{S17-2091,
 abstract = {We describe the SemEval task of extracting keyphrases and relations between
them from scientific documents, which is crucial for understanding which
publications describe which processes, tasks and materials. Although this was a
new task, we had a total of 26 submissions across 3 evaluation scenarios. We
expect the task and the findings reported in this paper to be relevant for
researchers working on understanding scientific content, as well as the broader
knowledge base population and information extraction communities.},
 address = {Vancouver, Canada},
 author = {Augenstein, Isabelle  and  Das, Mrinal  and  Riedel, Sebastian  and  Vikraman, Lakshmi  and  McCallum, Andrew},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {546--555},
 publisher = {Association for Computational Linguistics},
 title = {SemEval 2017 Task 10: ScienceIE - Extracting Keyphrases and Relations from Scientific Publications},
 year = {2017}
}

@inproceedings{S17-2092,
 abstract = {This task proposes a challenge to support the interaction between users and
applications, micro-services and software APIs using natural language. The task
aims for supporting the evaluation and evolution of the discussions surrounding
the natural language processing approaches within the context of end-user
natural language programming, under scenarios of high semantic
heterogeneity/gap.},
 address = {Vancouver, Canada},
 author = {Sales, Juliano  and  Handschuh, Siegfried  and  Freitas, Andr\'{e}},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {556--564},
 publisher = {Association for Computational Linguistics},
 title = {SemEval-2017 Task 11: End-User Development using Natural Language},
 year = {2017}
}

@inproceedings{S17-2093,
 abstract = {Clinical TempEval 2017 aimed to answer the question: how well do systems
trained on annotated timelines for one medical condition (colon cancer) perform
in predicting timelines on another medical condition (brain cancer)? Nine
sub-tasks were included, covering problems in time expression identification, event expression identification and temporal relation identification.
Participant systems were evaluated on clinical and pathology notes from Mayo
Clinic cancer patients, annotated with an extension of TimeML for the clinical
domain. 11 teams participated in the tasks, with the best systems achieving F1
scores above 0.55 for time expressions, above 0.70 for event expressions, and
above 0.40 for temporal relations. Most tasks observed about a 20 point drop
over Clinical TempEval 2016, where systems were trained and evaluated on the
same domain (colon cancer).},
 address = {Vancouver, Canada},
 author = {Bethard, Steven  and  Savova, Guergana  and  Palmer, Martha  and  Pustejovsky, James},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {565--572},
 publisher = {Association for Computational Linguistics},
 title = {SemEval-2017 Task 12: Clinical TempEval},
 year = {2017}
}

@inproceedings{S17-2094,
 abstract = {In this paper we describe our attempt at producing a state-of-the-art Twitter
sentiment classifier using Convolutional Neural Networks (CNNs) and Long Short
Term Memory (LSTMs) networks.  Our system leverages a large amount of unlabeled
data to pre-train word embeddings.  We then use a subset of the unlabeled data
to fine tune the embeddings using distant supervision.                          The
final
CNNs
and
LSTMs are trained on the SemEval-2017 Twitter dataset where the embeddings are
fined tuned again.  To boost performances we ensemble several CNNs and LSTMs
together. Our approach achieved first rank on all of the five English subtasks
amongst 40 teams.},
 address = {Vancouver, Canada},
 author = {Cliche, Mathieu},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {573--580},
 publisher = {Association for Computational Linguistics},
 title = {BB\_twtr at SemEval-2017 Task 4: Twitter Sentiment Analysis with CNNs and LSTMs},
 year = {2017}
}

@inproceedings{S17-2095,
 abstract = {This paper describes our participation in Task 5 track 2 of SemEval 2017 to
predict the sentiment of financial news headlines for a specific company on a
continuous scale between -1 and 1. We tackled the problem using a number of
approaches, utilising a Support Vector Regression (SVR) and a Bidirectional
Long Short-Term Memory (BLSTM). We found an improvement of 4-6% using the LSTM
model over the SVR and came fourth in the track. We report a number of
different evaluations using a finance specific word embedding model and reflect
on the effects of using different evaluation metrics.},
 address = {Vancouver, Canada},
 author = {Moore, Andrew  and  Rayson, Paul},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {581--585},
 publisher = {Association for Computational Linguistics},
 title = {Lancaster A at SemEval-2017 Task 5: Evaluation metrics matter: predicting sentiment from financial news headlines},
 year = {2017}
}

@inproceedings{S17-2096,
 abstract = {This paper describes the submission by the University of Sheffield to the
SemEval 2017 Abstract Meaning Representation Parsing and Generation task
(SemEval 2017 Task 9, Subtask 2). We cast language generation from AMR as a
sequence of actions (e.g., insert/remove/rename edges and nodes) that
progressively transform the AMR  graph into a dependency parse tree. This
transition-based approach relies on the fact that an AMR graph can be
considered structurally similar to a dependency tree, with a focus on content
rather than function words. An added benefit to this approach is the greater
amount of data we can take advantage of to train the parse-to-text linearizer.
Our submitted run on the test data achieved a BLEU score of 3.32 and a
Trueskill score of -22.04 on automatic and human evaluation respectively.},
 address = {Vancouver, Canada},
 author = {Lampouras, Gerasimos  and  Vlachos, Andreas},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {586--591},
 publisher = {Association for Computational Linguistics},
 title = {Sheffield at SemEval-2017 Task 9: Transition-based language generation from AMR.},
 year = {2017}
}

@inproceedings{S17-2097,
 abstract = {This paper describes our submission for
the ScienceIE shared task (SemEval-
2017 Task 10) on entity and relation
extraction from scientific papers. Our
model is based on the end-to-end relation
extraction model of Miwa and Bansal
(2016) with several enhancements such as
semi-supervised learning via neural language
models, character-level encoding, gazetteers extracted from existing knowledge
bases, and model ensembles. Our of-
ficial submission ranked first in end-to-end
entity and relation extraction (scenario 1), and second in the relation-only extraction
(scenario 3).},
 address = {Vancouver, Canada},
 author = {Ammar, Waleed  and  Peters, Matthew  and  Bhagavatula, Chandra  and  Power, Russell},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {592--596},
 publisher = {Association for Computational Linguistics},
 title = {The AI2 system at SemEval-2017 Task 10 (ScienceIE): semi-supervised end-to-end entity and relation extraction},
 year = {2017}
}

@inproceedings{S17-2098,
 abstract = {In this paper we present our participation to SemEval 2017 Task 12. We used a
neural network based approach for entity and temporal relation extraction, and
experimented with two domain adaptation strategies. We achieved competitive
performance for both tasks.},
 address = {Vancouver, Canada},
 author = {Tourille, Julien  and  Ferret, Olivier  and  Tannier, Xavier  and  N\'{e}v\'{e}ol, Aur\'{e}lie},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {597--602},
 publisher = {Association for Computational Linguistics},
 title = {LIMSI-COT at SemEval-2017 Task 12: Neural Architecture for Temporal Information Extraction from Clinical Narratives},
 year = {2017}
}

@inproceedings{S17-2099,
 abstract = {While sentiment analysis in English has achieved significant progress, it
remains a challenging task in Arabic given the rich morphology of the language.
It becomes more challenging when applied to Twitter data that comes with
additional sources of noise including dialects, misspellings, grammatical
mistakes, code switching and the use of non-textual objects to express
sentiments. This paper describes the âOMAMâ systems that we developed as
part of SemEval-2017 task 4. We evaluate English state-of-the-art methods on
Arabic tweets for subtask A. As for the remaining subtasks, we introduce a
topic-based approach that accounts for topic specificities by predicting topics
or domains of upcoming tweets, and then using this information to predict their
sentiment. Results indicate that applying the English state-of-the-art method
to Arabic has achieved solid results without significant enhancements.
Furthermore, the topic-based method ranked 1st in subtasks C and E, and 2nd in
subtask D.},
 address = {Vancouver, Canada},
 author = {Baly, Ramy  and  Badaro, Gilbert  and  Hamdi, Ali  and  Moukalled, Rawan  and  Aoun, Rita  and  El-Khoury, Georges  and  Al Sallab, Ahmad  and  Hajj, Hazem  and  Habash, Nizar  and  Shaban, Khaled  and  El-Hajj, Wassim},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {603--610},
 publisher = {Association for Computational Linguistics},
 title = {OMAM at SemEval-2017 Task 4: Evaluation of English State-of-the-Art Sentiment Analysis Models for Arabic and a New Topic-based Model},
 year = {2017}
}

@inproceedings{S17-2100,
 abstract = {This paper describes our multi-view ensemble approach to SemEval-2017 Task 4 on
Sentiment Analysis in Twitter, specifically, the Message Polarity
Classification subtask for English (subtask A). Our system is a voting
ensemble, where each base classifier is trained in a different feature space.
The first space is a bag-of-words model and has a Linear SVM as base
classifier. The second and third spaces are two different strategies of
combining word embeddings to represent sentences and use a Linear SVM and a
Logistic Regressor as base classifiers. The proposed system was ranked 18th out
of 38 systems considering F1 score and 20th considering recall.},
 address = {Vancouver, Canada},
 author = {Corr\^{e}a J\'{u}nior, Edilson Anselmo  and  Marinho, Vanessa Queiroz  and  dos Santos, Leandro Borges},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {611--615},
 publisher = {Association for Computational Linguistics},
 title = {NILC-USP at SemEval-2017 Task 4: A Multi-view Ensemble for Twitter Sentiment Analysis},
 year = {2017}
}

@inproceedings{S17-2101,
 abstract = {In this paper, we describe our system implementation for sentiment analysis in
Twitter. This system combines two models based on deep neural networks, namely
a convolutional neural network (CNN) and a long short-term memory (LSTM)
recurrent neural network, through interpolation. Distributed representation of
words as vectors are input to the system, and the output is a sentiment class.
The neural network models are trained exclusively with the data sets provided
by the organizers of SemEval-2017 Task 4 Subtask A. Overall, this system has
achieved 0.618 for the average recall rate, 0.587 for the average F1 score, and
0.618 for accuracy.},
 address = {Vancouver, Canada},
 author = {Yang, Tzu-Hsuan  and  Tseng, Tzu-Hsuan  and  Chen, Chia-Ping},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {616--620},
 publisher = {Association for Computational Linguistics},
 title = {deepSA at SemEval-2017 Task 4: Interpolated Deep Neural Networks for Sentiment Analysis in Twitter},
 year = {2017}
}

@inproceedings{S17-2102,
 abstract = {Recently, neural twitter sentiment classification has become one of
state-of-thearts, which relies less feature engineering work compared with
traditional methods. In this paper, we propose a simple and effective ensemble
method to further boost the performances of neural models. We collect several
word embedding sets which are publicly released (often are learned on different
corpus) or constructed by running Skip-gram on released large-scale corpus. We
make an assumption that different word embeddings cover different words and
encode different semantic knowledge, thus using them together can improve the
generalizations and performances of neural models. In the SemEval 2017, our
method ranks 1st in Accuracy, 5th in AverageR. Meanwhile, the additional
comparisons demonstrate the superiority of our model over these ones based
on only one word embedding set. We release our code for the method
duplicability.},
 address = {Vancouver, Canada},
 author = {Yin, Yichun  and  Song, Yangqiu  and  Zhang, Ming},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {621--625},
 publisher = {Association for Computational Linguistics},
 title = {NNEMBs at SemEval-2017 Task 4: Neural Twitter Sentiment Classification: a Simple Ensemble Method with Different Embeddings},
 year = {2017}
}

@inproceedings{S17-2103,
 abstract = {This paper describes a system developed for a shared sentiment analysis task
and its subtasks organized by SemEval-2017. A key feature of our system is the
embedded ability to detect sarcasm in order to enhance the performance of
sentiment classification. We first constructed an
affect-cognition-sociolinguistics sarcasm features model and trained a
SVM-based classifier for detecting sarcastic expressions from general tweets.
For sentiment prediction, we developed CrystalNest-- a two-level cascade
classification system using features combining sarcasm score derived from our
sarcasm classifier, sentiment scores from Alchemy, NRC lexicon, n-grams, word
embedding vectors, and part-of-speech features. We found that the sarcasm
detection derived features consistently benefited key sentiment analysis
evaluation metrics, in different degrees, across four subtasks A-D.},
 address = {Vancouver, Canada},
 author = {Gupta, Raj Kumar  and  Yang, Yinping},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {626--633},
 publisher = {Association for Computational Linguistics},
 title = {CrystalNest at SemEval-2017 Task 4: Using Sarcasm Detection for Enhancing Sentiment Classification and Quantification},
 year = {2017}
}

@inproceedings{S17-2104,
 abstract = {This document describes our participation in SemEval-2017 Task 4: Sentiment
Analysis in Twitter. We have only reported results for subtask B - English, determining the polarity towards a topic on a two point scale (positive or
negative sentiment). Our main contribution is the integration of user
information in the classification process. A SVM model is trained with Word2Vec
vectors from user's tweets extracted from his timeline. The obtained results
show that user-specific classifiers trained on tweets from user timeline can
introduce noise as they are error prone because they are classified by an
imperfect system. This encourages us to explore further integration of user
information for author-based Sentiment Analysis.},
 address = {Vancouver, Canada},
 author = {Jim\'{e}nez-Zafra, Salud Mar\'{i}a  and  Montejo-R\'{a}ez, Arturo  and  Martin, Maite  and  Urena Lopez, L. Alfonso},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {634--639},
 publisher = {Association for Computational Linguistics},
 title = {SINAI at SemEval-2017 Task 4: User based classification},
 year = {2017}
}

@inproceedings{S17-2105,
 abstract = {We present a simple supervised text classification system that combines sparse
and dense vector representations of words, and generalized representations of
words via clusters. The sparse vectors are generated from word n-gram sequences
(1-3). The dense vector representations of words (embeddings) are learned by
training a neural network to predict neighboring words in a large unlabeled
dataset. To classify a text segment, the different representations of it are
concatenated, and the classification is performed using Support Vector Machines
(SVM). Our system is particularly intended for use by non-experts of natural
language processing and machine learning, and, therefore, the system does not
require any manual tuning of parameters or weights. Given a training set, the
system automatically generates the training vectors, optimizes the relevant
hyper-parameters for the SVM classifier, and trains the classification model.
We evaluated this system on the SemEval-2017 English sentiment analysis task.
In terms of average F1-score, our system obtained 8th position out of 39
submissions (F1-score: 0.632, average recall: 0.637, accuracy: 0.646).},
 address = {Vancouver, Canada},
 author = {Sarker, Abeed  and  Gonzalez, Graciela},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {640--643},
 publisher = {Association for Computational Linguistics},
 title = {HLP$@$UPenn at SemEval-2017 Task 4A: A simple, self-optimizing text classification system combining dense and sparse vectors},
 year = {2017}
}

@inproceedings{S17-2106,
 abstract = {This paper describes the system we have used for participating in Subtasks A
(Message Polarity Classification) and B (Topic-Based Message Polarity
Classification according to a two-point scale) of SemEval-2017 Task 4 Sentiment
Analysis in Twitter. We used several features with a sentiment lexicon and NLP
techniques, Maximum Entropy as a classifier for our system.},
 address = {Vancouver, Canada},
 author = {Dovdon, Enkhzol  and  Saias, Jos\'{e}},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {644--647},
 publisher = {Association for Computational Linguistics},
 title = {ej-sa-2017 at SemEval-2017 Task 4: Experiments for Target oriented Sentiment Analysis in Twitter},
 year = {2017}
}

@inproceedings{S17-2107,
 abstract = {In this paper, we describe the participation of the SentiME++ system to the
SemEval 2017 Task 4A "Sentiment Analysis in Twitter" that aims to classify
whether English tweets are of positive, neutral or negative sentiment.
SentiME++ is an ensemble approach to sentiment analysis that leverages stacked
generalization to automatically combine the predictions of five
state-of-the-art sentiment classifiers. SentiME++ achieved officially 61.30%
F1-score, ranking 12th out of 38 participants.},
 address = {Vancouver, Canada},
 author = {Troncy, Raphael  and  Palumbo, Enrico  and  Sygkounas, Efstratios  and  Rizzo, Giuseppe},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {648--652},
 publisher = {Association for Computational Linguistics},
 title = {SentiME++ at SemEval-2017 Task 4: Stacking State-of-the-Art Classifiers to Enhance Sentiment Classification},
 year = {2017}
}

@inproceedings{S17-2108,
 abstract = {This paper describes the Amobee sentiment analysis system, adapted to compete
in SemEval 2017 task 4. The system consists of two parts: a supervised training
of RNN models based on a Twitter sentiment treebank, and the use of feedforward
NN, Naive Bayes and logistic regression classifiers to produce predictions for
the different sub-tasks. The algorithm reached the 3rd place on the 5-label
classification task (sub-task C).},
 address = {Vancouver, Canada},
 author = {Rozental, Alon  and  Fleischer, Daniel},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {653--658},
 publisher = {Association for Computational Linguistics},
 title = {Amobee at SemEval-2017 Task 4: Deep Learning System for Sentiment Detection on Twitter},
 year = {2017}
}

@inproceedings{S17-2109,
 abstract = {This paper describes the TWINA system, with which we participated in
SemEval-2017 Task 4B (Topic Based Message Polarity Classification -- Two point
scale) and 4D (two-point scale Tweet quantification). We implemented ensemble
based Gradient Boost Trees classification method for both the tasks. Our system
could perform well for the task 4D and ranked 13th among 15 teams, for the task
4B our model ranked 23rd position.},
 address = {Vancouver, Canada},
 author = {Laskari, Naveen Kumar  and  Sanampudi, Suresh Kumar},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {659--663},
 publisher = {Association for Computational Linguistics},
 title = {TWINA at SemEval-2017 Task 4: Twitter Sentiment Analysis with Ensemble Gradient Boost Tree Classifier},
 year = {2017}
}

@inproceedings{S17-2110,
 abstract = {In this paper, we present our contribution in SemEval 2017 international
workshop. We have tackled task 4 entitled âSentiment analysis in Twitterâ, specifically subtask 4A-Arabic. We propose two Arabic sentiment classification
models implemented using supervised and unsupervised learning strategies. In
both models, Arabic tweets were preprocessed first then various schemes of
bag-of-N-grams were extracted to be used as features.
The final submission was selected upon the best performance achieved by the
supervised learning-based model. However, the results obtained by the
unsupervised learning-based model are considered promising and evolvable if
more rich lexica are adopted in further work.},
 address = {Vancouver, Canada},
 author = {Mulki, Hala  and  Haddad, Hatem  and  Gridach, Mourad  and  Babao\u{g}lu, Ismail},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {664--669},
 publisher = {Association for Computational Linguistics},
 title = {Tw-StAR at SemEval-2017 Task 4: Sentiment Classification of Arabic Tweets},
 year = {2017}
}

@inproceedings{S17-2111,
 abstract = {We describe a supervised system that uses optimized Condition Random Fields and
lexical features to predict the sentiment of a tweet. The system was submitted
to the English version of all subtasks in SemEval-2017 Task 4.},
 address = {Vancouver, Canada},
 author = {Onyibe, Chukwuyem  and  Habash, Nizar},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {670--674},
 publisher = {Association for Computational Linguistics},
 title = {OMAM at SemEval-2017 Task 4: English Sentiment Analysis with Conditional Random Fields},
 year = {2017}
}

@inproceedings{S17-2112,
 abstract = {In this paper, we describe our submission to SemEval2017 Task 4: Sentiment
Analysis in Twitter. Specifically the proposed system participated both to
tweet polarity classification (two-, three- and five class) and tweet
quantification (two and five-class) tasks.},
 address = {Vancouver, Canada},
 author = {Kolovou, Athanasia  and  Kokkinos, Filippos  and  Fergadis, Aris  and  Papalampidi, Pinelopi  and  Iosif, Elias  and  Malandrakis, Nikolaos  and  Palogiannidi, Elisavet  and  Papageorgiou, Haris  and  Narayanan, Shrikanth  and  Potamianos, Alexandros},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {675--682},
 publisher = {Association for Computational Linguistics},
 title = {Tweester at SemEval-2017 Task 4: Fusion of Semantic-Affective and pairwise classification models for sentiment analysis in Twitter},
 year = {2017}
}

@inproceedings{S17-2113,
 abstract = {In many areas, such as social science, politics or market research, people need
to deal with dataset shifting over time. Distribution drift phenomenon usually
appears in the field of sentiment analysis, when proportions of instances are
changing over time. In this case, the task is to correctly estimate proportions
of each sentiment expressed in the set of documents (quantification task).
Basically, our study was aimed to analyze the effectiveness of a mixture of
quantification technique with one of deep learning architecture. All the
techniques are evaluated using the SemEval-2017 Task4 dataset and source code, mentioned in this paper and available online in the Python programming
language. The results of an application of the quantification techniques are
discussed.},
 address = {Vancouver, Canada},
 author = {Karpov, Nikolay},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {683--688},
 publisher = {Association for Computational Linguistics},
 title = {NRU-HSE at SemEval-2017 Task 4: Tweet Quantification Using Deep Learning Architecture},
 year = {2017}
}

@inproceedings{S17-2114,
 abstract = {A CNN method for sentiment classification task in Task 4A of SemEval 2017 is
presented. To solve the problem of word2vec training word vector slowly, a
method of training word vector by integrating word2vec and Convolutional Neural
Network (CNN) is proposed. This training method not only improves the training
speed of word2vec, but also makes the word vector more effective for the target
task. Furthermore, the word2vec adopts a full connection between the input
layer and the projection layer of the Continuous Bag-of-Words (CBOW) for
acquiring the semantic information of the original sentence.},
 address = {Vancouver, Canada},
 author = {Zhao, Jingjing  and  Yang, Yan  and  Xu, Bing},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {689--693},
 publisher = {Association for Computational Linguistics},
 title = {MI\&T Lab at SemEval-2017 task 4: An Integrated Training Method of Word Vector for Sentiment Classification},
 year = {2017}
}

@inproceedings{S17-2115,
 abstract = {This paper describes SiTAKA, our system that has been used in task 4A, English
and Arabic languages, Sentiment Analysis in Twitter of SemEval2017. The system
proposes the representation of tweets using a novel set of features, which
include a bag of negated words and the information provided by some lexicons.
The polarity of tweets is determined by a classifier based on a Support Vector
Machine. Our system ranks 2nd among 8 systems in the Arabic language tweets and
ranks 8th among 38 systems in the English-language tweets.},
 address = {Vancouver, Canada},
 author = {Jabreel, Mohammed  and  Moreno, Antonio},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {694--699},
 publisher = {Association for Computational Linguistics},
 title = {SiTAKA at SemEval-2017 Task 4: Sentiment Analysis in Twitter Based on a Rich Set of Features},
 year = {2017}
}

@inproceedings{S17-2116,
 abstract = {This paper presents Senti17 system which uses ten convolutional neural networks
(Con- vNet) to assign a sentiment label to a tweet. The network consists of a
convolutional layer followed by a fully-connected layer and a Soft- max on top.
Ten instances of this network are initialized with the same word embeddings  as
inputs but with different initializations for the network weights. We combine
the results of all instances by selecting the sentiment label given by the
majority of the ten voters. This system is ranked fourth in SemEval-2017 Task4
over 38 systems with 67.4% average recall.},
 address = {Vancouver, Canada},
 author = {Hamdan, Hussam},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {700--703},
 publisher = {Association for Computational Linguistics},
 title = {Senti17 at SemEval-2017 Task 4: Ten Convolutional Neural Network Voters for Tweet Polarity Classification},
 year = {2017}
}

@inproceedings{S17-2117,
 abstract = {This report describes our participation to SemEval-2017 Task 4: Sentiment
Analysis in Twitter, specifically in subtasks A, B, and C. The approach for
text sentiment classification is based on a Majority Vote scheme and combined
supervised machine learning methods with classical linguistic resources, including bag-of-words and sentiment lexicon features.},
 address = {Vancouver, Canada},
 author = {Symeonidis, Symeon  and  Effrosynidis, Dimitrios  and  Kordonis, John  and  Arampatzis, Avi},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {704--708},
 publisher = {Association for Computational Linguistics},
 title = {DUTH at SemEval-2017 Task 4: A Voting Classification Approach for Twitter Sentiment Analysis},
 year = {2017}
}

@inproceedings{S17-2118,
 abstract = {The SSN MLRG1 team for Semeval-2017 task 4 has applied Gaussian Process, with
bag of words feature vectors and fixed rule multi-kernel learning, for
sentiment analysis of tweets. Since tweets on the same topic, made at different
times, may exhibit different emotions, their properties such as smoothness and
periodicity also vary with time. Our experiments show that, compared to single
kernel, multiple kernels are effective in learning the simultaneous presence of
multiple properties.},
 address = {Vancouver, Canada},
 author = {S, Angel Deborah  and  Rajendram, S Milton  and  Mirnalinee, T T},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {709--712},
 publisher = {Association for Computational Linguistics},
 title = {SSN\_MLRG1 at SemEval-2017 Task 4: Sentiment Analysis in Twitter Using Multi-Kernel Gaussian Process Classifier},
 year = {2017}
}

@inproceedings{S17-2119,
 abstract = {Sentiment analysis is one of the central issues in Natural Language Processing
and has become more and more important in many fields. Typical sentiment
analysis classifies the sentiment of sentences into several discrete classes
(e.g.,positive or negative). In this paper we describe our deep learning
system(combining GRU and SVM) to solve both two-, three- and five- tweet
polarity classifications. We first trained a gated recurrent neural network
using pre-trained word embeddings, then we extracted features from GRU layer
and input these features into support vector machine to fulfill both the
classification and quantification subtasks. The proposed approach achieved
37th, 19th, and 14rd places in subtasks A, B and C, respectively.},
 address = {Vancouver, Canada},
 author = {Wang, Ming  and  Chu, Biao  and  Liu, Qingxun  and  Zhou, Xiaobing},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {713--717},
 publisher = {Association for Computational Linguistics},
 title = {YNUDLG at SemEval-2017 Task 4: A GRU-SVM Model for Sentiment Classification and Quantification in Twitter},
 year = {2017}
}

@inproceedings{S17-2120,
 abstract = {We present, in this paper, our contribution in SemEval2017 task 4 :
âSentiment Analysis in Twitterâ, subtask A: âMessage Polarity
Classificationâ, for
English and Arabic languages. Our system is based on a list of sentiment seed
words
adapted for tweets. The sentiment relations between seed words and other terms
are captured by cosine similarity between the word embedding representations
(word2vec). These seed words are extracted from datasets of annotated tweets
available online. Our tests, using these seed words, show significant
improvement in results compared to the use of Turney and Littmanâs (2003)
seed words, on polarity classification of tweet messages.},
 address = {Vancouver, Canada},
 author = {Htait, Amal  and  Fournier, S\'{e}bastien  and  Bellot, Patrice},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {718--722},
 publisher = {Association for Computational Linguistics},
 title = {LSIS at SemEval-2017 Task 4: Using Adapted Sentiment Similarity Seed Words For English and Arabic Tweet Polarity Classification},
 year = {2017}
}

@inproceedings{S17-2121,
 abstract = {This paper describes the participation of ELiRF-UPV team at task 4 of
SemEval2017. Our approach is based on the use of convolutional and recurrent
neural networks and the combination of general and specific word embeddings
with polarity lexicons. We participated in all of the proposed subtasks both
for English and Arabic languages using the same system with small variations.},
 address = {Vancouver, Canada},
 author = {Gonz\'{a}lez, Jos\'{e}-\'{A}ngel  and  Pla, Ferran  and  Hurtado, Llu\'{i}s-F.},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {723--727},
 publisher = {Association for Computational Linguistics},
 title = {ELiRF-UPV at SemEval-2017 Task 4: Sentiment Analysis using Deep Learning},
 year = {2017}
}

@inproceedings{S17-2122,
 abstract = {This paper describes the XJSA System submission from XJTU. Our system was
created for SemEval2017 Task 4 -- subtask A which is very popular and
fundamental. The system is based on convolutional neural network and word
embedding. We used two pre-trained word vectors and adopt a dynamic strategy
for k-max pooling.},
 address = {Vancouver, Canada},
 author = {Hao, Yazhou  and  Lan, YangYang  and  Li, Yufei  and  Li, Chen},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {728--731},
 publisher = {Association for Computational Linguistics},
 title = {XJSA at SemEval-2017 Task 4: A Deep System for Sentiment Classification in Twitter},
 year = {2017}
}

@inproceedings{S17-2123,
 abstract = {We propose a sentiment analyzer for the prediction of document-level sentiments
of English micro-blog messages from Twitter. The proposed method is based on
lexicon integrated convolutional neural networks with attention (LCA). Its
performance was evaluated using the datasets provided by SemEval competition
(Task 4). The proposed sentiment analyzer obtained an average F1 of 55.2%, an
average recall of 58.9% and an accuracy of 61.4%.},
 address = {Vancouver, Canada},
 author = {Yoon, Joosung  and  Lyu, Kigon  and  Kim, Hyeoncheol},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {732--736},
 publisher = {Association for Computational Linguistics},
 title = {Adullam at SemEval-2017 Task 4: Sentiment Analyzer Using Lexicon Integrated Convolutional Neural Networks with Attention},
 year = {2017}
}

@inproceedings{S17-2124,
 abstract = {This paper describes our approach for SemEval-2017 Task 4 - Sentiment Analysis
in Twitter (SAT). Its five subtasks are divided into two categories: (1)
sentiment classification, i.e., predicting topic-based tweet sentiment
polarity, and (2) sentiment quantification, that is, estimating the sentiment
distributions of a set of given tweets. We build a convolutional sentence
classification system for the task of SAT. Official results show that the
experimental results of our system are comparative.},
 address = {Vancouver, Canada},
 author = {maoquan, wang  and  Shiyun, Chen  and  yufei, Xie  and  lu, Zhao},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {737--740},
 publisher = {Association for Computational Linguistics},
 title = {EICA at SemEval-2017 Task 4: A Simple Convolutional Neural Network for Topic-based Sentiment Classification},
 year = {2017}
}

@inproceedings{S17-2125,
 abstract = {This paper describes the approach we used for SemEval-2017 Task 4: Sentiment
Analysis in Twitter. Topic-based (target-dependent) sentiment analysis has
become attractive and been used in some applications recently, but it is still
a challenging research task. In our approach, we take the left and right
context of a target into consideration when generating polarity classification
features.  We use two types of word embeddings in our classifiers: the general
word embeddings learned from 200 million tweets, and sentiment-specific word
embeddings learned from 10 million tweets using distance supervision.  We also
incorporate a text feature model in our algorithm. This model produces features
based on text negation, tf.idf weighting scheme, and a Rocchio text
classification method. We participated in four subtasks (B, C, D \& E for
English), all of which are about topic-based message polarity classification.
Our team is ranked \#6 in subtask B, \#3 by MAEu and \#9 by MAEm in subtask C, \#3
using RAE and \#6 using KLD in subtask D, and \#3 in subtask E.},
 address = {Vancouver, Canada},
 author = {Li, Quanzhi  and  Nourbakhsh, Armineh  and  Liu, Xiaomo  and  Fang, Rui  and  Shah, Sameena},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {741--746},
 publisher = {Association for Computational Linguistics},
 title = {funSentiment at SemEval-2017 Task 4: Topic-Based Message Sentiment Classification by Exploiting Word Embeddings, Text Features and Target Contexts},
 year = {2017}
}

@inproceedings{S17-2126,
 abstract = {In this paper we present two deep-learning systems that competed at
SemEval-2017 Task 4 âSentiment Analysis in Twitterâ. We participated in all
subtasks for English tweets, involving message-level and topic-based sentiment
polarity classification and quantification. We use Long Short-Term Memory
(LSTM) networks augmented with two kinds of attention mechanisms, on top of
word embeddings pre-trained on a big collection of Twitter messages. Also, we
present a text processing tool suitable for social network messages, which
performs tokenization, word normalization, segmentation and spell correction.
Moreover, our approach uses no hand-crafted features or sentiment lexicons. We
ranked 1st (tie) in Subtask A, and achieved very competitive results in the
rest of the Subtasks. Both the word embeddings and our text processing tool are
available to the research community.},
 address = {Vancouver, Canada},
 author = {Baziotis, Christos  and  Pelekis, Nikos  and  Doulkeridis, Christos},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {747--754},
 publisher = {Association for Computational Linguistics},
 title = {DataStories at SemEval-2017 Task 4: Deep LSTM with Attention for Message-level and Topic-based Sentiment Analysis},
 year = {2017}
}

@inproceedings{S17-2127,
 abstract = {The paper describes the participation of the team ``TwiSE'' in the SemEval-2017
challenge.
Specifically, I participated at Task 4 entitled ``Sentiment Analysis in
Twitter'' for which I implemented systems for five-point tweet classification
(Subtask C) and five-point tweet quantification (Subtask E) for English tweets.
In the feature extraction steps the systems rely on the vector space model, morpho-syntactic analysis of the tweets and several sentiment lexicons.
The classification step of Subtask C uses a Logistic Regression trained with
the one-versus-rest approach. Another instance of Logistic Regression combined
with the classify-and-count approach is trained for the quantification task of
Subtask E.
In the official leaderboard the system is ranked \textit{5/15} in Subtask C and
\textit{2/12} in Subtask E.},
 address = {Vancouver, Canada},
 author = {Balikas, Georgios},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {755--759},
 publisher = {Association for Computational Linguistics},
 title = {TwiSe at SemEval-2017 Task 4: Five-point Twitter Sentiment Classification and Quantification},
 year = {2017}
}

@inproceedings{S17-2128,
 abstract = {This paper describes the system developed at LIA for the SemEval-2017
evaluation campaign. The goal of Task 4.A was to identify sentiment polarity in
tweets. The system is an ensemble of Deep Neural Network (DNN) models:
Convolutional Neural Network (CNN) and Recurrent Neural Network Long Short-Term
Memory (RNN-LSTM). We initialize the input representation of DNN with different
sets of embeddings trained on large datasets. The ensemble of DNNs are combined
using a score-level fusion approach. The system ranked 2nd at SemEval-2017 and
obtained an average recall of 67.6%.},
 address = {Vancouver, Canada},
 author = {Rouvier, Mickael},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {760--765},
 publisher = {Association for Computational Linguistics},
 title = {LIA at SemEval-2017 Task 4: An Ensemble of Neural Networks for Sentiment Classification},
 year = {2017}
}

@inproceedings{S17-2129,
 abstract = {In this paper, we propose a classifier for
predicting topic-specific sentiments of English
Twitter messages. Our method is
based on a 2-layer CNN.With a distant supervised
phase we leverage a large amount
of weakly-labelled training data. Our system
was evaluated on the data provided
by the SemEval-2017 competition in the
Topic-Based Message Polarity Classification
subtask, where it ranked 4th place.},
 address = {Vancouver, Canada},
 author = {M\"{u}ller, Simon  and  Huonder, Tobias  and  Deriu, Jan  and  Cieliebak, Mark},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {766--770},
 publisher = {Association for Computational Linguistics},
 title = {TopicThunder at SemEval-2017 Task 4: Sentiment Classification Using a Convolutional Neural Network with Distant Supervision},
 year = {2017}
}

@inproceedings{S17-2130,
 abstract = {This paper describes the system used in SemEval-2017 Task 4 (Subtask A):
Message Polarity Classification for both English and Arabic languages. Our
proposed system is an ensemble of two layers, the first one uses our generic
framework for multilingual polarity classification (B4MSA) and the second layer
combines all the decision function values predicted by B4MSA systems using a
non-linear function evolved using a Genetic Programming system, EvoDAG. With
this approach, the best performances reached by our system were macro-recall
0.68 (English) and 0.477 (Arabic) which set us in sixth and fourth positions in
the results table, respectively.},
 address = {Vancouver, Canada},
 author = {Miranda-Jim\'{e}nez, Sabino  and  Graff, Mario  and  Tellez, Eric Sadit  and  Moctezuma, Daniela},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {771--776},
 publisher = {Association for Computational Linguistics},
 title = {INGEOTEC at SemEval 2017 Task 4: A B4MSA Ensemble based on Genetic Programming for Twitter Sentiment Analysis},
 year = {2017}
}

@inproceedings{S17-2131,
 abstract = {This paper describes our approach for SemEval-2017 Task 4: Sentiment Analysis
in Twitter. We have participated in Subtask A: Message Polarity Classification
subtask and  developed two systems. The first system  uses  word embeddings for
feature representation and Support Vector Machine, Random Forest and Naive
Bayes algorithms for classification of Twitter messages into negative, neutral
and positive polarity. The second system is based on Long Short Term Memory
Recurrent Neural Networks and uses word indexes as sequence of inputs for
feature representation.},
 address = {Vancouver, Canada},
 author = {Ayata, Deger  and  Saraclar, Murat  and  Ozgur, Arzucan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {777--783},
 publisher = {Association for Computational Linguistics},
 title = {BUSEM at SemEval-2017 Task 4A Sentiment Analysis with Word Embedding and Long Short Term Memory RNN Approaches},
 year = {2017}
}

@inproceedings{S17-2132,
 abstract = {This paper describes the system we submitted to SemEval-2017 Task 4 (Sentiment
Analysis in Twitter), specifically subtasks A, B, and D. Our main focus was
topic-based message polarity classification on a two-point scale (subtask B).
The system we submitted uses a Support Vector Machine classifier with rich set
of features, ranging from standard to more creative, task-specific features, including a series of rating-based features as well as features that account
for sentimental reminiscence of past topics and deceased famous people. Our
system ranked 14th out of 39 submissions in subtask A, 5th out of 24
submissions in subtask B, and 3rd out of 16 submissions in subtask D.},
 address = {Vancouver, Canada},
 author = {Lozi\'{c}, David  and  \v{S}ari\'{c}, Doria  and  Toki\'{c}, Ivan  and  Medi\'{c}, Zoran  and  \v{S}najder, Jan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {784--789},
 publisher = {Association for Computational Linguistics},
 title = {TakeLab at SemEval-2017 Task 4: Recent Deaths and the Power of Nostalgia in Sentiment Analysis in Twitter},
 year = {2017}
}

@inproceedings{S17-2133,
 abstract = {This paper describes two systems that were used by the NileTMRG for addressing
Arabic Sentiment Analysis as part of SemEval-2017, task 4. NileTMRG
participated in three Arabic related subtasks which are: Subtask A (Message
Polarity Classification), Subtask B (Topic-Based Message Polarity
classification) and Subtask D  (Tweet quantification). For subtask A, we
made use of NUâs sentiment analyzer which we augmented with a scored lexicon.
For subtasks B and D, we used an ensemble of  three different classifiers. The
first classifier was a convolutional neural network that used trained
(word2vec) word embeddings. The second classifier consisted of a  MultiLayer
Perceptron  while the third classifier was a Logistic regression model that
takes the same input as the second classifier. Voting between the three
classifiers was used to determine the final outcome.  In all three Arabic
related tasks in which NileTMRG participated, the team ranked at number one.},
 address = {Vancouver, Canada},
 author = {El-Beltagy, Samhaa R.  and  El kalamawy, Mona  and  Soliman, Abu Bakr},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {790--795},
 publisher = {Association for Computational Linguistics},
 title = {NileTMRG at SemEval-2017 Task 4: Arabic Sentiment Analysis},
 year = {2017}
}

@inproceedings{S17-2134,
 abstract = {In this paper, we propose a multi-channel convolutional neural network-long
short-term memory (CNN-LSTM) model that consists of two parts: multi-channel
CNN and LSTM to analyze the sentiments of short English messages from Twitter.
Un-like a conventional CNN, the proposed model applies a multi-channel strategy
that uses several filters of different length to extract active local n-gram
features in different scales. This information is then sequentially composed
using LSTM. By combining both CNN and LSTM, we can consider both local
information within tweets and long-distance dependency across tweets in the
classification process. Officially released results show that our system
outperforms the baseline algo-rithm.},
 address = {Vancouver, Canada},
 author = {Zhang, Haowei  and  Wang, Jin  and  Zhang, Jixian  and  Zhang, Xuejie},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {796--801},
 publisher = {Association for Computational Linguistics},
 title = {YNU-HPCC at SemEval 2017 Task 4: Using A Multi-Channel CNN-LSTM Model for Sentiment Classification},
 year = {2017}
}

@inproceedings{S17-2135,
 abstract = {This paper describes the submission of
team TSA-INF to SemEval-2017 Task 4
Subtask A. The submitted system is an
ensemble of three varying deep learning
architectures for sentiment analysis. The
core of the architecture is a convolutional
neural network that performs well on text
classification as is. The second subsystem
is a gated recurrent neural network implementation.
Additionally, the third system
integrates opinion lexicons directly into a
convolution neural network architecture.
The resulting ensemble of the three architectures
achieved a top ten ranking with
a macro-averaged recall of 64.3%. Additional
results comparing variations of
the submitted system are not conclusive
enough to determine a best architecture, but serve as a benchmark for further implementations.},
 address = {Vancouver, Canada},
 author = {Deshmane, Amit Ajit  and  Friedrichs, Jasper},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {802--806},
 publisher = {Association for Computational Linguistics},
 title = {TSA-INF at SemEval-2017 Task 4: An Ensemble of Deep Learning Architectures Including Lexicon Features for Twitter Sentiment Analysis},
 year = {2017}
}

@inproceedings{S17-2136,
 abstract = {This paper describes the system submitted to SemEval-2017 Task 4-A Sentiment
Analysis in Twitter developed by the UCSC-NLP team. We studied how
relationships between sense n-grams and sentiment polarities can contribute to
this task, i.e. co-occurrences of WordNet senses in the tweet, and the
polarity. Furthermore, we evaluated the effect of discarding a large set of
features based on char-grams reported in preceding works. Based on these
elements, we developed a SVM system, which exploring SentiWordNet as a polarity
lexicon. It achieves an $F\_1=0.624$ of average. Among $39$ submissions to this
task, we ranked $10th$.},
 address = {Vancouver, Canada},
 author = {Abreu, Jos\'{e}  and  Castro, Iv\'{a}n  and  Mart\'{i}nez, Claudia  and  Oliva, Sebasti\'{a}n  and  Guti\'{e}rrez, Yoan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {807--811},
 publisher = {Association for Computational Linguistics},
 title = {UCSC-NLP at SemEval-2017 Task 4: Sense n-grams for Sentiment Analysis in Twitter},
 year = {2017}
}

@inproceedings{S17-2137,
 abstract = {This paper reports our submission to subtask A of task 4 (Sentiment Analysis in
Twitter, SAT) in SemEval 2017, i.e., Message Polarity Classification. We
investigated several traditional Natural Language Processing (NLP) features, domain specific features and word embedding features together with supervised
machine learning methods to address this task. Officially released results
showed that our system ranked above average.},
 address = {Vancouver, Canada},
 author = {Zhou, Yunxiao  and  Lan, Man  and  Wu, Yuanbin},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {812--816},
 publisher = {Association for Computational Linguistics},
 title = {ECNU at SemEval-2017 Task 4: Evaluating Effective Features on Machine Learning Methods for Twitter Message Polarity Classification},
 year = {2017}
}

@inproceedings{S17-2138,
 abstract = {In this paper, we describe a methodology to infer Bullish or Bearish sentiment
towards companies/brands. More specifically, our approach leverages affective
lexica and word embeddings in combination with convolutional neural networks to
infer the sentiment of financial news headlines towards a target company. Such
architecture was used and evaluated in the context of the SemEval 2017
challenge (task 5, subtask 2), in which it obtained the best performance.},
 address = {Vancouver, Canada},
 author = {Mansar, Youness  and  Gatti, Lorenzo  and  Ferradans, Sira  and  Guerini, Marco  and  Staiano, Jacopo},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {817--822},
 publisher = {Association for Computational Linguistics},
 title = {Fortia-FBK at SemEval-2017 Task 5: Bullish or Bearish? Inferring Sentiment towards Brands from Financial News Headlines},
 year = {2017}
}

@inproceedings{S17-2139,
 abstract = {The system developed by the SSN\_MLRG1 team for Semeval-2017 task 5 on
fine-grained sentiment analysis uses Multiple Kernel Gaussian Process for
identifying the optimistic and pessimistic sentiments associated with companies
and stocks. Since the comments made at different times about the same companies
and stocks may display different emotions, their properties such as smoothness
and periodicity may vary. Our experiments show that while single kernel
Gaussian Process can learn certain properties well, Multiple Kernel Gaussian
Process are effective in learning the presence of different properties
simultaneously.},
 address = {Vancouver, Canada},
 author = {S, Angel Deborah  and  Rajendram, S Milton  and  Mirnalinee, T T},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {823--826},
 publisher = {Association for Computational Linguistics},
 title = {SSN\_MLRG1 at SemEval-2017 Task 5: Fine-Grained Sentiment Analysis Using Multiple Kernel Gaussian Process Regression Model},
 year = {2017}
}

@inproceedings{S17-2140,
 abstract = {This paper presents the details of our system
IBA-Sys that participated in SemEval
Task: Fine-grained sentiment analysis on
Financial Microblogs and News. Our system
participated in both tracks. For microblogs
track, a supervised learning approach
was adopted and the regressor was
trained using XgBoost regression algorithm
on lexicon features. For news headlines
track, an ensemble of regressors was
used to predict sentiment score. One regressor
was trained using TF-IDF features
and another was trained using the n-gram
features. The source code is available at
Github 1.},
 address = {Vancouver, Canada},
 author = {Nasim, Zarmeen},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {827--831},
 publisher = {Association for Computational Linguistics},
 title = {IBA-Sys at SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News},
 year = {2017}
}

@inproceedings{S17-2141,
 abstract = {In this Paper a system for solving SemEval-2017 Task 5 is presented. This task
is divided into two tracks where the sentiment of microblog messages and news
headlines has to be predicted. Since two submissions were allowed, two
different machine learning methods were developed to solve this task, a support
vector machine approach and a recurrent neural network approach. To feed in
data for these approaches, different feature extraction methods are used, mainly word representations and lexica. The best submissions for both tracks
are provided by the recurrent neural network which achieves a F1-score of 0.729
in track 1 and 0.702 in track 2.},
 address = {Vancouver, Canada},
 author = {Cabanski, Tobias  and  Romberg, Julia  and  Conrad, Stefan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {832--836},
 publisher = {Association for Computational Linguistics},
 title = {HHU at SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Data using Machine Learning Methods},
 year = {2017}
}

@inproceedings{S17-2142,
 abstract = {This paper describes a supervised solution for detecting the polarity scores of
tweets or headline news in the financial domain, submitted to the SemEval 2017
Fine-Grained Sentiment Analysis on Financial Microblogs and News Task. The
premise is that it is possible to understand market reaction over a company
stock by measuring the positive/negative sentiment contained in the financial
tweets and news headlines, where polarity is measured in a continuous scale
ranging from -1.0 (very bearish) to 1.0 (very bullish). Our system receives as
input the textual content of tweets or news headlines, together with their ids, stock cashtag or name of target company, and the polarity score gold standard
for the training dataset. Our solution retrieves features from these text
instances using n-gram, hashtags, sentiment score calculated by a external APIs
and others features to train a regression model capable to detect continuous
score of these sentiments with precision.},
 address = {Vancouver, Canada},
 author = {Zini, Tiago  and  Becker, Karin  and  Dias, Marcelo},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {837--841},
 publisher = {Association for Computational Linguistics},
 title = {INF-UFRGS at SemEval-2017 Task 5: A Supervised Identification of Sentiment Score in Tweets and Headlines},
 year = {2017}
}

@inproceedings{S17-2143,
 abstract = {Task 5 of SemEval-2017 involves fine-grained sentiment analysis on financial
microblogs and news.  Our solution for determining the sentiment score extends
an earlier convolutional neural network for sentiment analysis in several ways.
We explicitly encode a focus on a particular company, we apply a data
augmentation   scheme, and use a larger data collection to complement the small
training data provided by the task organizers.                          The best
results
were
achieved
by training a model on an external dataset and then tuning it using the
provided training dataset.},
 address = {Vancouver, Canada},
 author = {Pivovarova, Lidia  and  Escoter, Lloren\c{c}  and  Klami, Arto  and  Yangarber, Roman},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {842--846},
 publisher = {Association for Computational Linguistics},
 title = {HCS at SemEval-2017 Task 5: Polarity detection in business news using convolutional neural networks},
 year = {2017}
}

@inproceedings{S17-2144,
 abstract = {Short length, multi-targets, target relation-ship, monetary expressions, and
outside reference are characteristics of financial tweets. This paper proposes
methods to extract target spans from a tweet and its referencing web page.
Total 15 publicly available sentiment dictionaries and one sentiment dictionary
constructed from training set, containing sentiment scores in binary or real
numbers, are used to compute the sentiment scores of text spans. Moreover, the
correlation coeffi-cients of the price return between any two stocks are
learned with the price data from Bloomberg. They are used to capture the
relationships between the interesting tar-get and other stocks mentioned in a
tweet. The best result of our method in both sub-task are 56.68% and 55.43%, evaluated by evaluation method 2.},
 address = {Vancouver, Canada},
 author = {Chen, Chung-Chi  and  Huang, Hen-Hsen  and  Chen, Hsin-Hsi},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {847--851},
 publisher = {Association for Computational Linguistics},
 title = {NLG301 at SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News},
 year = {2017}
}

@inproceedings{S17-2145,
 abstract = {This paper describes the approach we used for SemEval-2017 Task 5: Fine-Grained
Sentiment Analysis on Financial Microblogs. We use three types of word
embeddings in our algorithm: word embeddings learned from 200 million tweets, sentiment-specific word embeddings learned from 10 million tweets using
distance supervision, and word embeddings learned from 20 million StockTwits
messages.  In our approach, we also take the left and right context of the
target company into consideration when generating polarity prediction features.
All the features generated from different word embeddings and contexts are
integrated together to train our algorithm},
 address = {Vancouver, Canada},
 author = {Li, Quanzhi  and  Shah, Sameena  and  Nourbakhsh, Armineh  and  Fang, Rui  and  Liu, Xiaomo},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {852--856},
 publisher = {Association for Computational Linguistics},
 title = {funSentiment at SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs Using Word Vectors Built from StockTwits and Twitter},
 year = {2017}
}

@inproceedings{S17-2146,
 abstract = {Sentiment analysis is the process of identifying the opinion expressed in text.
Recently it has been used to study behavioral finance, and in particular the
effect of opinions and emotions on economic or financial decisions.
SemEval-2017 task 5 focuses on the financial market as the do- main for
sentiment analysis of text; specifically, task 5, subtask 1 focuses on
financial tweets about stock symbols. In this paper, we describe a machine
learning classifier for binary classification of financial tweets. We used
natural language processing techniques and the random forest algorithm to train
our model, and tuned it for the training dataset of Task 5, subtask 1. Our
system achieves the 7th rank on the leaderboard of the task.},
 address = {Vancouver, Canada},
 author = {Tabari, Narges  and  Seyeditabari, Armin  and  Zadrozny, Wlodek},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {857--860},
 publisher = {Association for Computational Linguistics},
 title = {SentiHeros at SemEval-2017 Task 5: An application of Sentiment Analysis on Financial Tweets},
 year = {2017}
}

@inproceedings{S17-2147,
 abstract = {We present the system developed by the team DUTH for the participation in
Semeval-2017 task 5 - Fine-Grained Sentiment Analysis on Financial Microblogs
and News, in subtasks A and B. Our approach to determine the sentiment of
Microblog Messages and News Statements \& Headlines is based on linguistic
preprocessing, feature engineering, and supervised machine learning techniques.
To train our model, we used Neural Network Regression, Linear Regression, Boosted Decision Tree Regression and Decision Forrest Regression classifiers to
forecast sentiment scores. At the end, we present an error measure, so as to
improve the performance about forecasting methods of the
system.},
 address = {Vancouver, Canada},
 author = {Symeonidis, Symeon  and  Kordonis, John  and  Effrosynidis, Dimitrios  and  Arampatzis, Avi},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {861--865},
 publisher = {Association for Computational Linguistics},
 title = {DUTH at SemEval-2017 Task 5: Sentiment Predictability in Financial Microblogging and News Articles},
 year = {2017}
}

@inproceedings{S17-2148,
 abstract = {This paper describes our system for fine-grained sentiment scoring of news
headlines submitted to SemEval 2017 task 5--subtask 2. Our system uses a
feature-light method that consists of a Support Vector Regression (SVR) with
various kernels and word vectors as features. Our best-performing submission
scored 3rd on the task out of 29 teams and 4th out of 45 submissions with a
cosine score of 0.733.},
 address = {Vancouver, Canada},
 author = {Rotim, Leon  and  Tutek, Martin  and  \v{S}najder, Jan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {866--871},
 publisher = {Association for Computational Linguistics},
 title = {TakeLab at SemEval-2017 Task 5: Linear aggregation of word embeddings for fine-grained sentiment analysis of financial news},
 year = {2017}
}

@inproceedings{S17-2149,
 abstract = {This paper discusses the approach taken by the UWaterloo team to arrive at a
solution for the Fine-Grained Sentiment Analysis problem posed by Task 5 of
SemEval 2017. The paper describes the document vectorization and sentiment
score prediction techniques used, as well as the design and implementation
decisions taken while building the system for this task. The system uses text
vectorization models, such as N-gram, TF-IDF and paragraph embeddings, coupled
with regression model variants to predict the sentiment scores. Amongst the
methods examined, unigrams and bigrams coupled with simple linear regression
obtained the best baseline accuracy. The paper also explores data augmentation
methods to supplement the training dataset. This system was designed for
Subtask 2 (News Statements and Headlines).},
 address = {Vancouver, Canada},
 author = {John, Vineet  and  Vechtomova, Olga},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {872--876},
 publisher = {Association for Computational Linguistics},
 title = {UW-FinSent at SemEval-2017 Task 5: Sentiment Analysis on Financial News Headlines using Training Dataset Augmentation},
 year = {2017}
}

@inproceedings{S17-2150,
 abstract = {In this paper, we present our systems for the âSemEval-2017 Task-5 on Fine-
Grained Sentiment Analysis on Financial Microblogs and Newsâ. In our system, we combined hand-engineered lexical, sentiment and metadata features, the
representations learned from Convolutional Neural Networks (CNN) and
Bidirectional Gated Recurrent Unit (Bi-GRU) with Attention model applied on
top. With this architecture we obtained weighted cosine similarity scores of
0.72 and 0.74 for subtask-1 and subtask-2, respectively. Using the official
scoring system, our system ranked the second place for subtask-2 and eighth
place for the subtask-1. It ranked first for both of the subtasks by the scores
achieved by an alternate scoring system.},
 address = {Vancouver, Canada},
 author = {Kar, Sudipta  and  Maharjan, Suraj  and  Solorio, Thamar},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {877--882},
 publisher = {Association for Computational Linguistics},
 title = {RiTUAL-UH at SemEval-2017 Task 5: Sentiment Analysis on Financial Data Using Neural Networks},
 year = {2017}
}

@inproceedings{S17-2151,
 abstract = {This paper describes our submission to Task 5 of SemEval 2017, Fine-Grained
Sentiment Analysis on Financial Microblogs and News, where we limit ourselves
to performing sentiment analysis on news headlines only (track 2). The approach
presented in this paper uses a Support Vector Machine to do the required
regression, and besides unigrams and a sentiment tool, we use various
ontology-based features. To this end we created a domain ontology that models
various concepts from the financial domain. This allows us to model the
sentiment of actions depending on which entity they are affecting (e.g., 'decreasing debt' is positive, but 'decreasing profit' is negative). The
presented approach yielded a cosine distance of 0.6810 on the official test
data, resulting in the 12th position.},
 address = {Vancouver, Canada},
 author = {Schouten, Kim  and  Frasincar, Flavius  and  de Jong, Franciska},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {883--887},
 publisher = {Association for Computational Linguistics},
 title = {COMMIT at SemEval-2017 Task 5: Ontology-based Method for Sentiment Analysis of Financial Headlines},
 year = {2017}
}

@inproceedings{S17-2152,
 abstract = {This paper describes our systems submitted to the Fine-Grained Sentiment
Analysis on Financial Microblogs and News task (i.e., Task 5) in SemEval-2017.
This task includes two subtasks in microblogs and news headline domain
respectively. To settle this problem, we extract four types of effective
features, including linguistic features, sentiment lexicon features, domain-specific features and word embedding features. Then we employ these
features to construct models by using ensemble regression algorithms. Our
submissions rank 1st and rank 5th in subtask 1 and subtask 2 respectively.},
 address = {Vancouver, Canada},
 author = {Jiang, Mengxiao  and  Lan, Man  and  Wu, Yuanbin},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {888--893},
 publisher = {Association for Computational Linguistics},
 title = {ECNU at SemEval-2017 Task 5: An Ensemble of Regression Algorithms with Effective Features for Fine-Grained Sentiment Analysis in Financial Domain},
 year = {2017}
}

@inproceedings{S17-2153,
 abstract = {This paper reports team IITPB's participation in the SemEval 2017 Task 5 on
`Fine-grained sentiment analysis on financial microblogs and news'. We
developed 2 systems for the two tracks. One system was based on an ensemble of
Support Vector Classifier and Logistic Regression. This system relied on
Distributional Thesaurus (DT), word embeddings and lexicon features to predict
a floating sentiment value between -1 and +1. The other system was based on
Support Vector Regression using word embeddings, lexicon features, and PMI
scores as features. The system was ranked 5th in track 1 and 8th in track 2.},
 address = {Vancouver, Canada},
 author = {Kumar, Abhishek  and  Sethi, Abhishek  and  Akhtar, Md Shad  and  Ekbal, Asif  and  Biemann, Chris  and  Bhattacharyya, Pushpak},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {894--898},
 publisher = {Association for Computational Linguistics},
 title = {IITPB at SemEval-2017 Task 5: Sentiment Prediction in Financial Text},
 year = {2017}
}

@inproceedings{S17-2154,
 abstract = {In this  paper we propose an ensemble based model which combines state of the
art deep learning sentiment analysis algorithms like Convolution Neural Network
(CNN) and Long Short Term Memory (LSTM) along with feature based models to
identify optimistic or pessimistic sentiments associated with companies and
stocks in financial texts. We build our system to participate in a competition
organized by Semantic Evaluation 2017 International Workshop. We combined
predictions from various models using an artificial neural network to determine
the opinion towards an entity in (a) Microblog Messages and (b) News Headlines
data. Our models achieved a cosine similarity score of 0.751 and 0.697 for the
above two tracks giving us the rank of 2nd and 7th best team respectively.},
 address = {Vancouver, Canada},
 author = {Ghosal, Deepanway  and  Bhatnagar, Shobhit  and  Akhtar, Md Shad  and  Ekbal, Asif  and  Bhattacharyya, Pushpak},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {899--903},
 publisher = {Association for Computational Linguistics},
 title = {IITP at SemEval-2017 Task 5: An Ensemble of Deep Learning and Feature Based Models for Financial Sentiment Analysis},
 year = {2017}
}

@inproceedings{S17-2155,
 abstract = {This paper presents the approach developed at the Faculty of Engineering of
University of Porto, to participate in SemEval 2017, Task 5: Fine-grained
Sentiment Analysis on Financial Microblogs and News.
The task consisted in predicting a real continuous variable from -1.0 to +1.0
representing the polarity and intensity of sentiment concerning
companies/stocks mentioned in short texts. We modeled the task as a regression
analysis problem and combined traditional techniques such as pre-processing
short texts, bag-of-words representations and lexical-based features with
enhanced financial specific bag-of-embeddings. We used an external collection
of tweets and news headlines mentioning companies/stocks from S\&P 500 to
create financial word embeddings which are able to capture domain-specific
syntactic and semantic similarities. The resulting approach obtained a cosine
similarity score of 0.69 in sub-task 5.1 - Microblogs and 0.68 in sub-task 5.2
- News Headlines.},
 address = {Vancouver, Canada},
 author = {Saleiro, Pedro  and  Mendes Rodrigues, Eduarda  and  Soares, Carlos  and  Oliveira, Eug\'{e}nio},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {904--908},
 publisher = {Association for Computational Linguistics},
 title = {FEUP at SemEval-2017 Task 5: Predicting Sentiment Polarity and Intensity with Financial Word Embeddings},
 year = {2017}
}

@inproceedings{S17-2156,
 abstract = {This paper describes the improvements that we have applied on CAMR baseline
parser (Wang et al., 2016) at Task 8 of SemEval-2016. Our objective is to
increase the performance of CAMR when parsing sentences from scientific
articles, especially articles of biology domain more accurately. To achieve
this goal, we built two wrapper layers for CAMR. The first layer, which covers
the input data, will normalize, add necessary information to the input
sentences to make the input dependency parser and the aligner better handle
reference citations, scientific figures, formulas, etc. The second layer, which
covers the output data, will modify and standardize output data based on a list
of scientific concept fixing patterns. This will help CAMR better handle
biological concepts which are not in the training dataset. Finally, after
applying our approach, CAMR has scored 0.65 F-score on the test set of
Biomedical training data and 0.61 F-score on the official blind test dataset.},
 address = {Vancouver, Canada},
 author = {Nguyen, Khoa  and  Nguyen, Dang},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {909--913},
 publisher = {Association for Computational Linguistics},
 title = {UIT-DANGNT-CLNLP at SemEval-2017 Task 9: Building Scientific Concept Fixing Patterns for Improving CAMR},
 year = {2017}
}

@inproceedings{S17-2157,
 abstract = {We present a neural encoder-decoder AMR parser that extends an attention-based
model by predicting the alignment between graph nodes and sentence tokens
explicitly with a pointer mechanism. Candidate lemmas are predicted as a
pre-processing step so that the lemmas of lexical concepts, as well as constant
strings, are factored out of the graph linearization and recovered through the
predicted alignments. The approach does not rely on syntactic parses or
extensive external resources. Our parser obtained 59% Smatch on the SemEval
test set.},
 address = {Vancouver, Canada},
 author = {Buys, Jan  and  Blunsom, Phil},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {914--919},
 publisher = {Association for Computational Linguistics},
 title = {Oxford at SemEval-2017 Task 9: Neural AMR Parsing with Pointer-Augmented Attention},
 year = {2017}
}

@inproceedings{S17-2158,
 abstract = {We present the contribution of Universitat Pompeu Fabra's NLP group to the
SemEval Task 9.2 (AMR-to-English Generation). The proposed generation pipeline
comprises: (i) a series of rule-based graph-transducers for the
syntacticization of the input graphs and the resolution of morphological
agreements, and (ii) an off-the-shelf statistical linearization component.},
 address = {Vancouver, Canada},
 author = {Mille, Simon  and  Carlini, Roberto  and  Burga, Alicia  and  Wanner, Leo},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {920--923},
 publisher = {Association for Computational Linguistics},
 title = {FORGe at SemEval-2017 Task 9: Deep sentence generation based on a sequence of graph transducers},
 year = {2017}
}

@inproceedings{S17-2159,
 abstract = {By addressing both text-to-AMR parsing and AMR-to-text generation, SemEval-2017
Task 9 established AMR as a powerful semantic interlingua. We strengthen the
interlingual aspect of AMR by applying the multilingual Grammatical Framework
(GF) for AMR-to-text generation. Our current rule-based GF approach completely
covered only 12.3% of the test AMRs, therefore we combined it with
state-of-the-art JAMR Generator to see if the combination increases or
decreases the overall performance. The combined system achieved the automatic
BLEU score of 18.82 and the human Trueskill score of 107.2, to be compared to
the plain JAMR Generator results. As for AMR parsing, we added NER extensions
to our SemEval-2016 general-domain AMR parser to handle the biomedical genre, rich in organic compound names, achieving Smatch F1=54.0%.},
 address = {Vancouver, Canada},
 author = {Gruzitis, Normunds  and  Gosko, Didzis  and  Barzdins, Guntis},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {924--928},
 publisher = {Association for Computational Linguistics},
 title = {RIGOTRIO at SemEval-2017 Task 9: Combining Machine Learning and Grammar Engineering for AMR Parsing and Generation},
 year = {2017}
}

@inproceedings{S17-2160,
 abstract = {We evaluate a semantic parser based on a character-based sequence-to-sequence
model in the context of the SemEval-2017 shared task on semantic parsing for
AMRs. With data augmentation, super characters, and POS-tagging we gain major
improvements in performance compared to a baseline character-level model.
Although we improve on previous character-based neural semantic parsing models, the overall accuracy is still lower than a state-of-the-art AMR parser. An
ensemble combining our neural semantic parser with an existing, traditional
parser, yields a small gain in performance.},
 address = {Vancouver, Canada},
 author = {van Noord, Rik  and  Bos, Johan},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {929--933},
 publisher = {Association for Computational Linguistics},
 title = {The Meaning Factory at SemEval-2017 Task 9: Producing AMRs with Neural Semantic Parsing},
 year = {2017}
}

@inproceedings{S17-2161,
 abstract = {This paper presents a system that participated in SemEval 2017 Task 10 (subtask
A and subtask B): Extracting Keyphrases and Relations from Scientific
Publications (Augenstein et al., 2017). Our proposed approach utilizes external
knowledge to enrich feature representation of candidate keyphrase, including
Wikipedia, IEEE taxonomy and pre-trained word embeddings etc. Ensemble of
unsupervised models, random forest and linear models are used for candidate
keyphrase ranking and keyphrase type classification. Our system achieves the
3rd place in subtask A and 4th place in subtask B.},
 address = {Vancouver, Canada},
 author = {Wang, Liang  and  Li, Sujian},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {934--937},
 publisher = {Association for Computational Linguistics},
 title = {PKU\_ICL at SemEval-2017 Task 10: Keyphrase Extraction with Model Ensemble and External Knowledge},
 year = {2017}
}

@inproceedings{S17-2162,
 abstract = {We present NTNU's systems for Task A (prediction of keyphrases) and Task B
(labelling as Material, Process or Task) at SemEval 2017 Task 10: Extracting
Keyphrases and Relations from Scientific Publications.
Our approach relies on supervised machine
learning using Conditional Random Fields. Our system yields a micro F-score of
0.34 for Tasks A and B combined on the test data. For Task C (relation
extraction), we relied on an independently developed system described in.
For the full Scenario 1 (including relations), our approach
reaches a micro F-score of 0.33 (5th place). Here we describe our systems, report results and discuss errors.},
 address = {Vancouver, Canada},
 author = {Marsi, Erwin  and  Sikdar, Utpal Kumar  and  Marco, Cristina  and  Barik, Biswanath  and  S{\ae}tre, Rune},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {938--941},
 publisher = {Association for Computational Linguistics},
 title = {NTNU-1$@$ScienceIE at SemEval-2017 Task 10: Identifying and Labelling Keyphrases with Conditional Random Fields},
 year = {2017}
}

@inproceedings{S17-2163,
 abstract = {This paper describes our approach to the SemEval 2017 Task 10: Extracting
Keyphrases and Relations from Scientific Publications, specifically to Subtask
(B): Classification of identified keyphrases. We explored three different deep
learning approaches: a character-level convolutional neural network (CNN), a
stacked learner with an MLP meta-classifier, and an attention based Bi-LSTM.
From these approaches, we created an ensemble of differently
hyper-parameterized systems, achieving a micro-$F\_1$-score of 0.63 on the test
data. Our approach ranks 2nd (score of 1st placed system: 0.64) out of four
according to this official score. However, we erroneously trained 2 out of 3
neural nets (the stacker and the CNN) on only roughly 15% of the full data, namely, the original development set. When trained on the full data
(training$+$development), our ensemble has a micro-$F\_{1}$-score of 0.69. Our
code is available from https://github.com/UKPLab/semeval2017-scienceie.},
 address = {Vancouver, Canada},
 author = {Eger, Steffen  and  Do Dinh, Erik-L\^{a}n  and  Kuznetsov, Ilia  and  Kiaeeha, Masoud  and  Gurevych, Iryna},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {942--946},
 publisher = {Association for Computational Linguistics},
 title = {EELECTION at SemEval-2017 Task 10: Ensemble of nEural Learners for kEyphrase ClassificaTION},
 year = {2017}
}

@inproceedings{S17-2164,
 abstract = {This paper describes the system presented by the LABDA group at SemEval 2017
Task 10 ScienceIE, specifically for the subtasks of identification and
classification of keyphrases from scientific articles.
For the task of identification, we use the BANNER tool, a named entity
recognition system, which
is based on conditional random fields (CRF) and has obtained successful
results in the biomedical domain. To classify keyphrases, we study the UMLS
semantic network and propose a possible linking between the keyphrase types and
the UMLS semantic groups. Based on this semantic linking, we create a
dictionary for each keyphrase type. Then, a feature indicating if a token is
found in one of these dictionaries is incorporated to feature set used by the
BANNER tool. The final results on the test dataset show that our system
still needs to be improved, but the conditional random fields and, consequently, the BANNER system can be used as a first approximation to identify and
classify
keyphrases.},
 address = {Vancouver, Canada},
 author = {Segura-Bedmar, Isabel  and  Col\'{o}n-Ruiz, Crist\'{o}bal  and  Mart\'{i}nez, Paloma},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {947--950},
 publisher = {Association for Computational Linguistics},
 title = {LABDA at SemEval-2017 Task 10: Extracting Keyphrases from Scientific Publications by combining the BANNER tool and the UMLS Semantic Network},
 year = {2017}
}

@inproceedings{S17-2165,
 abstract = {This study describes the design of the NTNU system for the ScienceIE task at
the SemEval 2017 workshop. We use self-defined feature templates and multiple
conditional random fields with extracted features to identify keyphrases along
with categorized labels and their relations from scientific publications. A
total of 16 teams participated in evaluation scenario 1 (subtasks A, B, and C), with only 7 teams competing in all sub-tasks. Our best micro-averaging F1
across the three subtasks is 0.23, ranking in the middle among all 16
submissions.},
 address = {Vancouver, Canada},
 author = {Lee, Lung-Hao  and  Lee, Kuei-Ching  and  Tseng, Yuen-Hsien},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {951--955},
 publisher = {Association for Computational Linguistics},
 title = {The NTNU System at SemEval-2017 Task 10: Extracting Keyphrases and Relations from Scientific Publications Using Multiple Conditional Random Fields},
 year = {2017}
}

@inproceedings{S17-2166,
 abstract = {In this paper, we present MayoNLP's results from the participation in the
ScienceIE share task at SemEval 2017. We focused on the keyphrase
classification task (Subtask B). We explored
semantic similarities and patterns of keyphrases in scientific publications
using pre-trained word embedding models. Word Embedding Distance Pattern, which
uses the head noun word embedding to generate distance patterns based on
labeled keyphrases, is proposed as an incremental feature set to enhance the
conventional Named Entity Recognition feature sets.  Support vector machine is
used as the supervised classifier for keyphrase classification.
Our system achieved an overall F1 score of 0.67 for keyphrase classification
and 0.64 for keyphrase classification and relation detection.},
 address = {Vancouver, Canada},
 author = {Liu, Sijia  and  Shen, Feichen  and  Chaudhary, Vipin  and  Liu, Hongfang},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {956--960},
 publisher = {Association for Computational Linguistics},
 title = {MayoNLP at SemEval 2017 Task 10: Word Embedding Distance Pattern for Keyphrase Classification in Scientific Publications},
 year = {2017}
}

@inproceedings{S17-2167,
 abstract = {This paper describes our participation in SemEval-2017 Task 10.
We competed in Subtask 1 and 2 which consist respectively in identifying all
the key phrases in scientific publications and label them with one of the three
categories: Task, Process, and Material.
These scientific publications are selected from Computer Science, Material
Sciences, and Physics domains.
We followed a supervised approach for both subtasks by using a sequential
classifier (CRF - Conditional Random Fields).
For generating our solution we used a web-based application implemented in the
EU-funded research project, named CODE.
Our system achieved an F1 score of 0.39 for the Subtask 1 and 0.28 for the
Subtask 2.},
 address = {Vancouver, Canada},
 author = {Kern, Roman  and  Falk, Stefan  and  Rexha, Andi},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {961--964},
 publisher = {Association for Computational Linguistics},
 title = {Know-Center at SemEval-2017 Task 10: Sequence Classification with the CODE Annotator},
 year = {2017}
}

@inproceedings{S17-2168,
 abstract = {This paper presents our relation extraction system for subtask C of
SemEval-2017 Task 10: ScienceIE. Assuming that the keyphrases are already
annotated in the input data, our work explores a  wide range of linguistic
features, applies various feature selection techniques, optimizes the hyper
parameters and class weights and experiments with different problem
formulations (single classification model vs individual classifiers for each
keyphrase type, single-step classifier vs pipeline classifier for hyponym
relations). Performance of five popular classification algorithms are evaluated
for each problem formulation along with feature selection. The best setting
achieved an F1 score of 71.0% for synonym and 30.0% for hyponym relation on the
test data.},
 address = {Vancouver, Canada},
 author = {Barik, Biswanath  and  Marsi, Erwin},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {965--968},
 publisher = {Association for Computational Linguistics},
 title = {NTNU-2 at SemEval-2017 Task 10: Identifying Synonym and Hyponym Relations among Keyphrases in Scientific Documents},
 year = {2017}
}

@inproceedings{S17-2169,
 abstract = {In this paper, we describe our participation at the subtask of extraction of
relationships between two identified keyphrases. This task can be very helpful
in improving search engines for scientific articles. Our approach is based on
the use of a convolutional neural network (CNN) trained on the training
dataset. This deep learning model has already achieved successful
results for the extraction relationships between named entities. Thus, our
hypothesis is that this model can be also applied to extract relations between
keyphrases. The official results of the task show that
our architecture obtained an F1-score of 0.38% for Keyphrases Relation
Classification. This performance is lower than the expected due to the generic
preprocessing phase and the basic configuration of the
CNN model, more complex architectures are proposed as future work to increase
the classification rate.},
 address = {Vancouver, Canada},
 author = {Su\'{a}rez-Paniagua, V\'{i}ctor  and  Segura-Bedmar, Isabel  and  Mart\'{i}nez, Paloma},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {969--972},
 publisher = {Association for Computational Linguistics},
 title = {LABDA at SemEval-2017 Task 10: Relation Classification between keyphrases via Convolutional Neural Network},
 year = {2017}
}

@inproceedings{S17-2170,
 abstract = {We describe an end-to-end pipeline processing approach for SemEval
2017's Task 10 to extract keyphrases and their relations from
scientific publications.  We jointly identify and classify keyphrases
by modeling the subtasks as sequential labeling.  Our system utilizes
standard, surface-level features along with the adjacent word
features, and performs conditional decoding on whole text to extract
keyphrases.
We focus only on the identification and typing of keyphrases (Subtasks
A and B, together referred as extraction), but provide an end-to-end system
inclusive of keyphrase
relation identification (Subtask C) for completeness.  Our top
performing configuration achieves an $F\_1$ of 0.27 for the end-to-end
keyphrase extraction and relation identification scenario on the final test
data, and
compares on par to other top ranked systems for keyphrase extraction.  Our
system outperforms other techniques that do not employ global decoding
and hence do not account for dependencies between keyphrases. We
believe this is crucial for keyphrase classification in the given
context of scientific document mining.},
 address = {Vancouver, Canada},
 author = {Prasad, Animesh  and  Kan, Min-Yen},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {973--977},
 publisher = {Association for Computational Linguistics},
 title = {WING-NUS at SemEval-2017 Task 10: Keyphrase Extraction and Classification as Joint Sequence Labeling},
 year = {2017}
}

@inproceedings{S17-2171,
 abstract = {Over 50 million scholarly articles have been published: they constitute a
unique repository of knowledge. In particular, one may infer from them
relations between scientific concepts. Artificial neural networks have recently
been explored for relation extraction. In this work, we continue this line of
work and present a system based on a convolutional neural network to extract
relations. Our model ranked first in the SemEval-2017 task 10 (ScienceIE) for
relation extraction in scientific articles (subtask C).},
 address = {Vancouver, Canada},
 author = {Lee, Ji Young  and  Dernoncourt, Franck  and  Szolovits, Peter},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {978--984},
 publisher = {Association for Computational Linguistics},
 title = {MIT at SemEval-2017 Task 10: Relation Extraction with Convolutional Neural Networks},
 year = {2017}
}

@inproceedings{S17-2172,
 abstract = {This paper describes our TTI-COIN system that participated in SemEval-2017 Task
10. We investigated appropriate embeddings to adapt a neural end-to-end entity
and relation extraction system LSTM-ER to this task. We participated in the
full task setting of the entity segmentation, entity classification and
relation classification (scenario 1) and the setting of relation classification
only (scenario 3). The system was directly applied to the scenario 1 without
modifying the codes thanks to its generality and flexibility. Our evaluation
results show that the choice of appropriate pre-trained embeddings affected the
performance significantly. With the best embeddings, our system was ranked
third in the scenario 1 with the micro F1 score of 0.38. We also confirm that
our system can produce the micro F1 score of 0.48 for the scenario 3 on the
test data, and this score is close to the score of the 3rd ranked system in the
task.},
 address = {Vancouver, Canada},
 author = {Tsujimura, Tomoki  and  Miwa, Makoto  and  Sasaki, Yutaka},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {985--989},
 publisher = {Association for Computational Linguistics},
 title = {TTI-COIN at SemEval-2017 Task 10: Investigating Embeddings for End-to-End Relation Extraction from Scientific Papers},
 year = {2017}
}

@inproceedings{S17-2173,
 abstract = {In this paper we introduce our system participating at the 2017 SemEval shared
task on keyphrase extraction from scientific documents.
We aimed at the creation of a keyphrase extraction approach which relies on as
little external resources as possible. Without applying any hand-crafted
external resources, and only utilizing a transformed version of word embeddings
trained at Wikipedia, our proposed system manages to perform among the best
participating systems in terms of precision.},
 address = {Vancouver, Canada},
 author = {Berend, G\'{a}bor},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {990--994},
 publisher = {Association for Computational Linguistics},
 title = {SZTE-NLP at SemEval-2017 Task 10: A High Precision Sequence Model for Keyphrase Extraction Utilizing Sparse Coding for Feature Generation},
 year = {2017}
}

@inproceedings{S17-2174,
 abstract = {This paper describes the system used by the team LIPN in SemEval 2017 Task 10:
Extracting Keyphrases and Relations from Scientific Publications. The team
participated in Scenario 1, that includes three subtasks, Identification of
keyphrases (Subtask A), Classification of identified keyphrases (Subtask B) and
Extraction of relationships between two identified keyphrases (Subtask C). The
presented system was mainly focused on the use of part-of-speech tag sequences
to filter candidate keyphrases for Subtask A. Subtasks A and B were addressed
as a sequence labeling problem using Conditional Random Fields (CRFs) and even
though Subtask C was out of the scope of this approach, one rule was included
to identify synonyms.},
 address = {Vancouver, Canada},
 author = {Hernandez, Simon David  and  Buscaldi, Davide  and  Charnois, Thierry},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {995--999},
 publisher = {Association for Computational Linguistics},
 title = {LIPN at SemEval-2017 Task 10: Filtering Candidate Keyphrases from Scientific Publications with Part-of-Speech Tag Sequences to Train a Sequence Labeling Model},
 year = {2017}
}

@inproceedings{S17-2175,
 abstract = {The paper describes a system for end-user development using natural language.
Our approach uses a ranking model to identify the actions to be executed
followed by reference and parameter matching models to select parameter values
that should be set for the given commands. We discuss the results of evaluation
and possible improvements for future work.},
 address = {Vancouver, Canada},
 author = {Kubis, Marek  and  Sk\'{o}rzewski, Pawe{\l}  and  Zi\k{e}tkiewicz, Tomasz},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {1000--1004},
 publisher = {Association for Computational Linguistics},
 title = {EUDAMU at SemEval-2017 Task 11: Action Ranking and Type Matching for End-User Development},
 year = {2017}
}

@inproceedings{S17-2176,
 abstract = {This paper describes the system developed for the task of temporal information
extraction from clinical narratives in the context of the 2017 Clinical
TempEval challenge. Clinical TempEval 2017 addressed the problem of temporal
reasoning in the clinical domain by providing annotated clinical notes, pathology and radiology reports in line with Clinical TempEval challenges
2015/16, across two different evaluation phases focusing on cross domain
adaptation. Our team focused on subtasks involving extractions of temporal
spans and relations for which the developed systems showed average F-score of
0.45 and 0.47 across the two phases of evaluations.},
 address = {Vancouver, Canada},
 author = {P R, Sarath  and  R, Manikandan  and  Niwa, Yoshiki},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {1005--1009},
 publisher = {Association for Computational Linguistics},
 title = {Hitachi at SemEval-2017 Task 12: System for temporal information extraction from clinical notes},
 year = {2017}
}

@inproceedings{S17-2177,
 abstract = {This study proposes a system to participate in the Clinical TempEval 2017
shared task, a part of the SemEval 2017 Tasks. Domain adaptation was the main
challenge this year. We took part in the supervised domain adaption where data
of 591 records of colon cancer patients and 30 records of brain cancer patients
from Mayo clinic were given and we are asked to analyze the records from brain
cancer patients. Based on the THYME corpus released by the organizer of
Clinical TempEval, we propose a framework that automatically analyzes clinical
temporal events in a fine-grained level. Support vector machine (SVM) and
conditional random field (CRF) were implemented in our system for different
subtasks, including detecting clinical relevant events and time expression, determining their attributes, and identifying their relations with each other
within the document. The results showed the capability of domain
adaptation of our system.},
 address = {Vancouver, Canada},
 author = {Huang, Po-Yu  and  Huang, Hen-Hsen  and  Wang, Yu-Wun  and  Huang, Ching  and  Chen, Hsin-Hsi},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {1010--1013},
 publisher = {Association for Computational Linguistics},
 title = {NTU-1 at SemEval-2017 Task 12: Detection and classification of temporal events in clinical data with domain adaptation},
 year = {2017}
}

@inproceedings{S17-2178,
 abstract = {Temporality is crucial in understanding the course of clinical events from a
patientâs electronic health recordsand temporal processing is becoming more
and more important for improving access to content.SemEval 2017 Task 12
(Clinical TempEval) addressed this challenge using the THYME corpus, a corpus
of clinical narratives annotated with a schema based on TimeML2 guidelines. We
developed and evaluated approaches for: extraction of temporal expressions
(TIMEX3) and EVENTs; EVENT attributes; document-time relations. Our approach is
a hybrid model which is based on rule based methods, semi-supervised learning, and semantic features with addition of manually crafted rules.},
 address = {Vancouver, Canada},
 author = {Long, Yu  and  Li, Zhijing  and  Wang, Xuan  and  Li, Chen},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {1014--1018},
 publisher = {Association for Computational Linguistics},
 title = {XJNLP at SemEval-2017 Task 12: Clinical temporal information ex-traction with a Hybrid Model},
 year = {2017}
}

@inproceedings{S17-2179,
 abstract = {This paper presents our approach to participate in the SemEval 2017 Task 12:
Clinical TempEval challenge, specifically in the event and time expressions
span and attribute identification subtasks (ES, EA, TS, TA).
Our approach consisted in training Conditional Random Fields (CRF)
classifiers using the provided annotations, and in creating manually curated
rules to classify the attributes of each event and time expression.
We used a set of common features for the event and time CRF classifiers, and
a set of features specific to each type of entity, based on domain knowledge.
Training only on the source domain data, our best F-scores were 0.683 and
0.485 for event and time span identification subtasks.
When adding target domain annotations to the training data, the best F-scores
obtained were 0.729 and 0.554, for the same subtasks.
We obtained the second highest F-score of the challenge on the event polarity
subtask (0.708).
The source code of our system, Clinical Timeline Annotation (CiTA), is
available at https://github.com/lasigeBioTM/CiTA.},
 address = {Vancouver, Canada},
 author = {Lamurias, Andre  and  Sousa, Diana  and  Pereira, Sofia  and  Clarke, Luka  and  Couto, Francisco M},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {1019--1023},
 publisher = {Association for Computational Linguistics},
 title = {ULISBOA at SemEval-2017 Task 12: Extraction and classification of temporal expressions and events},
 year = {2017}
}

@inproceedings{S17-2180,
 abstract = {Clinical TempEval 2017 (SemEval 2017 Task 12) addresses the task of
cross-domain temporal extraction from clinical text. We present a system for
this task that uses supervised learning for the extraction of temporal
expression and event spans with corresponding attributes and narrative
container relations. Approaches include conditional random fields and decision
tree ensembles, using lexical, syntactic, semantic, distributional, and
rule-based features. Our system received best or second best scores in TIMEX3
span, EVENT span, and CONTAINS relation extraction.},
 address = {Vancouver, Canada},
 author = {MacAvaney, Sean  and  Cohan, Arman  and  Goharian, Nazli},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {1024--1029},
 publisher = {Association for Computational Linguistics},
 title = {GUIR at SemEval-2017 Task 12: A Framework for Cross-Domain Clinical Temporal Information Extraction},
 year = {2017}
}

@inproceedings{S17-2181,
 abstract = {In this paper, we describe the system of the KULeuven-LIIR submission for
Clinical TempEval 2017. We participated in all six subtasks, using a
combination of Support Vector Machines (SVM) for event and temporal expression
detection, and a structured perceptron for extracting temporal relations.
Moreover, we present and analyze the results from our submissions, and verify
the effectiveness of several system components. Our system performed above
average for all subtasks in both phases.},
 address = {Vancouver, Canada},
 author = {Leeuwenberg, Artuur  and  Moens, Marie-Francine},
 booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
 month = {August},
 pages = {1030--1034},
 publisher = {Association for Computational Linguistics},
 title = {KULeuven-LIIR at SemEval-2017 Task 12: Cross-Domain Temporal Information Extraction from Clinical Records},
 year = {2017}
}

