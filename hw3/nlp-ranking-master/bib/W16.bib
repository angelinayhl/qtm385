@inproceedings{W16-0101,
 address = {San Diego, California},
 author = {Beller, Charley and Katz, Graham and Ginsberg, Allen and Phipps, Chris and Bethard, Sean and Chase, Paul and Shek, Elinna and Summers, Kristen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0101},
 booktitle = {Proceedings of the Workshop on Human-Computer Question Answering},
 month = {June},
 pages = {1--7},
 publisher = {Association for Computational Linguistics},
 title = {Watson Discovery Advisor: Question-answering in an industrial setting},
 year = {2016}
}

@inproceedings{W16-0102,
 address = {San Diego, California},
 author = {Savenkov, Denis and Weitzner, Scott and Agichtein, Eugene},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0102},
 booktitle = {Proceedings of the Workshop on Human-Computer Question Answering},
 month = {June},
 pages = {8--14},
 publisher = {Association for Computational Linguistics},
 title = {Crowdsourcing for (almost) Real-time Question Answering},
 year = {2016}
}

@inproceedings{W16-0103,
 address = {San Diego, California},
 author = {Yin, Wenpeng and Ebert, Sebastian and Sch\"{u}tze, Hinrich},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0103},
 booktitle = {Proceedings of the Workshop on Human-Computer Question Answering},
 month = {June},
 pages = {15--21},
 publisher = {Association for Computational Linguistics},
 title = {Attention-Based Convolutional Neural Network for Machine Comprehension},
 year = {2016}
}

@inproceedings{W16-0104,
 address = {San Diego, California},
 author = {Aghaebrahimian, Ahmad and Jur\v{c}\'{i}\v{c}ek, Filip},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0104},
 booktitle = {Proceedings of the Workshop on Human-Computer Question Answering},
 month = {June},
 pages = {22--28},
 publisher = {Association for Computational Linguistics},
 title = {Open-domain Factoid Question Answering via Knowledge Graph Search},
 year = {2016}
}

@inproceedings{W16-0105,
 address = {San Diego, California},
 author = {Yin, Pengcheng and Lu, Zhengdong and Li, Hang and Ben, kao},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0105},
 booktitle = {Proceedings of the Workshop on Human-Computer Question Answering},
 month = {June},
 pages = {29--35},
 publisher = {Association for Computational Linguistics},
 title = {Neural Enquirer: Learning to Query Tables in Natural Language},
 year = {2016}
}

@inproceedings{W16-0106,
 address = {San Diego, California},
 author = {Yin, Jun and Jiang, Xin and Lu, Zhengdong and Shang, Lifeng and Li, Hang and Li, Xiaoming},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0106},
 booktitle = {Proceedings of the Workshop on Human-Computer Question Answering},
 month = {June},
 pages = {36--42},
 publisher = {Association for Computational Linguistics},
 title = {Neural Generative Question Answering},
 year = {2016}
}

@inproceedings{W16-0107,
 address = {San Diego, California},
 author = {Guha, Anupam and Iyyer, Mohit and Boyd-Graber, Jordan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0107},
 booktitle = {Proceedings of the Workshop on Human-Computer Question Answering},
 month = {June},
 pages = {43--47},
 publisher = {Association for Computational Linguistics},
 title = {"A Distorted Skull Lies in the Bottom Center..." Identifying Paintings from Text Descriptions},
 year = {2016}
}

@inproceedings{W16-0108,
 address = {San Diego, California},
 author = {Yoshida, Davis and Boyd-Graber, Jordan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0108},
 booktitle = {Proceedings of the Workshop on Human-Computer Question Answering},
 month = {June},
 pages = {48--52},
 publisher = {Association for Computational Linguistics},
 title = {Using Confusion Graphs to Understand Classifier Error},
 year = {2016}
}

@inproceedings{W16-0109,
 address = {San Diego, California},
 author = {Xu, Ying and Mart\'{i}nez-G\'{o}mez, Pascual and Miyao, Yusuke and Goebel, Randy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0109},
 booktitle = {Proceedings of the Workshop on Human-Computer Question Answering},
 month = {June},
 pages = {53--61},
 publisher = {Association for Computational Linguistics},
 title = {Paraphrase for Open Question Answering: New Dataset and Methods},
 year = {2016}
}

@inproceedings{W16-0201,
 address = {San Diego, California, USA},
 author = {Estes, Alex and Hench, Christopher},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0201},
 booktitle = {Proceedings of the Fifth Workshop on Computational Linguistics for Literature},
 month = {June},
 pages = {1--8},
 publisher = {Association for Computational Linguistics},
 title = {Supervised Machine Learning for Hybrid Meter},
 year = {2016}
}

@inproceedings{W16-0202,
 address = {San Diego, California, USA},
 author = {Daza, Angel and Calvo, Hiram and Figueroa-Nazuno, Jes\'{u}s},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0202},
 booktitle = {Proceedings of the Fifth Workshop on Computational Linguistics for Literature},
 month = {June},
 pages = {9--19},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Text Generation by Learning from Literary Structures},
 year = {2016}
}

@inproceedings{W16-0203,
 address = {San Diego, California, USA},
 author = {Gagliano, Andrea and Paul, Emily and Booten, Kyle and Hearst, Marti A.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0203},
 booktitle = {Proceedings of the Fifth Workshop on Computational Linguistics for Literature},
 month = {June},
 pages = {20--31},
 publisher = {Association for Computational Linguistics},
 title = {Intersecting Word Vectors to Take Figurative Language to New Heights},
 year = {2016}
}

@inproceedings{W16-0204,
 address = {San Diego, California, USA},
 author = {Schofield, Alexandra and Mehr, Leo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0204},
 booktitle = {Proceedings of the Fifth Workshop on Computational Linguistics for Literature},
 month = {June},
 pages = {32--39},
 publisher = {Association for Computational Linguistics},
 title = {Gender-Distinguishing Features in Film Dialogue},
 year = {2016}
}

@inproceedings{W16-0205,
 address = {San Diego, California, USA},
 author = {Koppel, Moshe and Michaely, Moty and Tal, Alex},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0205},
 booktitle = {Proceedings of the Fifth Workshop on Computational Linguistics for Literature},
 month = {June},
 pages = {40--46},
 publisher = {Association for Computational Linguistics},
 title = {Reconstructing Ancient Literary Texts from Noisy Manuscripts},
 year = {2016}
}

@inproceedings{W16-0206,
 address = {San Diego, California, USA},
 author = {Dubremetz, Marie and Nivre, Joakim},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0206},
 booktitle = {Proceedings of the Fifth Workshop on Computational Linguistics for Literature},
 month = {June},
 pages = {47--53},
 publisher = {Association for Computational Linguistics},
 title = {Syntax Matters for Rhetorical Structure: The Case of Chiasmus},
 year = {2016}
}

@inproceedings{W16-0207,
 address = {San Diego, California, USA},
 author = {Rahgozar, Arya and Inkpen, Diana},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0207},
 booktitle = {Proceedings of the Fifth Workshop on Computational Linguistics for Literature},
 month = {June},
 pages = {54--62},
 publisher = {Association for Computational Linguistics},
 title = {Bilingual Chronological Classification of Hafez's Poems},
 year = {2016}
}

@inproceedings{W16-0301,
 address = {San Diego, CA, USA},
 author = {Fraser, Kathleen C. and Rudzicz, Frank and Hirst, Graeme},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0301},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {1--11},
 publisher = {Association for Computational Linguistics},
 title = {Detecting late-life depression in Alzheimer's disease through analysis of speech and language},
 year = {2016}
}

@inproceedings{W16-0302,
 address = {San Diego, CA, USA},
 author = {Bullard, Joseph and Ovesdotter Alm, Cecilia and Liu, Xumin and Yu, Qi and Proa\~{n}o, Rub\'{e}n},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0302},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {12--22},
 publisher = {Association for Computational Linguistics},
 title = {Towards Early Dementia Detection: Fusing Linguistic and Non-Linguistic Clinical Data},
 year = {2016}
}

@inproceedings{W16-0303,
 address = {San Diego, CA, USA},
 author = {Shickel, Benjamin and Heesacker, Martin and Benton, Sherry and Ebadi, Ashkan and Nickerson, Paul and Rashidi, Parisa},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0303},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {23--32},
 publisher = {Association for Computational Linguistics},
 title = {Self-Reflective Sentiment Analysis},
 year = {2016}
}

@inproceedings{W16-0304,
 address = {San Diego, CA, USA},
 author = {Tanana, Michael and Dembe, Aaron and Soma, Christina S. and Imel, Zac and Atkins, David and Srikumar, Vivek},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0304},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {33--41},
 publisher = {Association for Computational Linguistics},
 title = {Is Sentiment in Movies the Same as Sentiment in Psychotherapy? Comparisons Using a New Psychotherapy Sentiment Database},
 year = {2016}
}

@inproceedings{W16-0305,
 address = {San Diego, CA, USA},
 author = {P\'{e}rez-Rosas, Ver\'{o}nica and Mihalcea, Rada and Resnicow, Kenneth and Singh, Satinder and An, Lawrence},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0305},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {42--51},
 publisher = {Association for Computational Linguistics},
 title = {Building a Motivational Interviewing Dataset},
 year = {2016}
}

@inproceedings{W16-0306,
 address = {San Diego, CA, USA},
 author = {Hwang, Jena D. and Hollingshead, Kristy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0306},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {52--62},
 publisher = {Association for Computational Linguistics},
 title = {Crazy Mad Nutters: The Language of Mental Health},
 year = {2016}
}

@inproceedings{W16-0307,
 address = {San Diego, CA, USA},
 author = {Gkotsis, George and Oellrich, Anika and Hubbard, Tim and Dobson, Richard and Liakata, Maria and Velupillai, Sumithra and Dutta, Rina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0307},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {63--73},
 publisher = {Association for Computational Linguistics},
 title = {The language of mental health problems in social media},
 year = {2016}
}

@inproceedings{W16-0308,
 address = {San Diego, CA, USA},
 author = {Parish-Morris, Julia and Liberman, Mark and Ryant, Neville and Cieri, Christopher and Bateman, Leila and Ferguson, Emily and Schultz, Robert},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0308},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {74--84},
 publisher = {Association for Computational Linguistics},
 title = {Exploring Autism Spectrum Disorders Using HLT},
 year = {2016}
}

@inproceedings{W16-0309,
 address = {San Diego, CA, USA},
 author = {Oak, Mayuresh and Behera, Anil and Thomas, Titus and Ovesdotter Alm, Cecilia and Prud'hommeaux, Emily and Homan, Christopher and Ptucha, Raymond},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0309},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {85--94},
 publisher = {Association for Computational Linguistics},
 title = {Generating Clinically Relevant Texts: A Case Study on Life-Changing Events},
 year = {2016}
}

@inproceedings{W16-0310,
 address = {San Diego, CA, USA},
 author = {Gkotsis, George and Velupillai, Sumithra and Oellrich, Anika and Dean, Harry and Liakata, Maria and Dutta, Rina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0310},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {95--105},
 publisher = {Association for Computational Linguistics},
 title = {Don't Let Notes Be Misunderstood: A Negation Detection Method for Assessing Risk of Suicide in Mental Health Records},
 year = {2016}
}

@inproceedings{W16-0311,
 address = {San Diego, CA, USA},
 author = {Coppersmith, Glen and Ngo, Kim and Leary, Ryan and Wood, Anthony},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0311},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {106--117},
 publisher = {Association for Computational Linguistics},
 title = {Exploratory Analysis of Social Media Prior to a Suicide Attempt},
 year = {2016}
}

@inproceedings{W16-0312,
 address = {San Diego, CA, USA},
 author = {Milne, David N. and Pink, Glen and Hachey, Ben and Calvo, Rafael A.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0312},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {118--127},
 publisher = {Association for Computational Linguistics},
 title = {CLPsych 2016 Shared Task: Triaging content in online peer-support forums},
 year = {2016}
}

@inproceedings{W16-0313,
 address = {San Diego, CA, USA},
 author = {Kim, Sunghwan Mac and Wang, Yufei and Wan, Stephen and Paris, Cecile},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0313},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {128--132},
 publisher = {Association for Computational Linguistics},
 title = {Data61-CSIRO systems at the CLPsych 2016 Shared Task},
 year = {2016}
}

@inproceedings{W16-0314,
 address = {San Diego, CA, USA},
 author = {Malmasi, Shervin and Zampieri, Marcos and Dras, Mark},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0314},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {133--137},
 publisher = {Association for Computational Linguistics},
 title = {Predicting Post Severity in Mental Health Forums},
 year = {2016}
}

@inproceedings{W16-0315,
 address = {San Diego, CA, USA},
 author = {Brew, Chris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0315},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {138--142},
 publisher = {Association for Computational Linguistics},
 title = {Classifying ReachOut posts with a radial basis function SVM},
 year = {2016}
}

@inproceedings{W16-0316,
 address = {San Diego, CA, USA},
 author = {Cohan, Arman and Young, Sydney and Goharian, Nazli},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0316},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {143--147},
 publisher = {Association for Computational Linguistics},
 title = {Triaging Mental Health Forum Posts},
 year = {2016}
}

@inproceedings{W16-0317,
 address = {San Diego, CA, USA},
 author = {Desmet, Bart and Jacobs, Gilles and Hoste, V\'{e}ronique},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0317},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {148--152},
 publisher = {Association for Computational Linguistics},
 title = {Mental Distress Detection and Triage in Forum Posts: The LT3 CLPsych 2016 Shared Task System},
 year = {2016}
}

@inproceedings{W16-0318,
 address = {San Diego, CA, USA},
 author = {Asgari, Ehsaneddin and Nasiriany, Soroush and Mofrad, Mohammad R.K.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0318},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {153--157},
 publisher = {Association for Computational Linguistics},
 title = {Text Analysis and Automatic Triage of Posts in a Mental Health Forum},
 year = {2016}
}

@inproceedings{W16-0319,
 address = {San Diego, CA, USA},
 author = {Friedenberg, Meir and Amiri, Hadi and Daum\'{e} III, Hal and Resnik, Philip},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0319},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {158--161},
 publisher = {Association for Computational Linguistics},
 title = {The UMD CLPsych 2016 Shared Task System: Text Representation for Predicting Triage of Forum Posts about Mental Health},
 year = {2016}
}

@inproceedings{W16-0320,
 address = {San Diego, CA, USA},
 author = {Opitz, Juri},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0320},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {162--165},
 publisher = {Association for Computational Linguistics},
 title = {Using Linear Classifiers for the Automatic Triage of Posts in the 2016 CLPsych Shared Task},
 year = {2016}
}

@inproceedings{W16-0321,
 address = {San Diego, CA, USA},
 author = {Zirikly, Ayah and Kumar, Varun and Resnik, Philip},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0321},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {166--170},
 publisher = {Association for Computational Linguistics},
 title = {The GW/UMD CLPsych 2016 Shared Task System},
 year = {2016}
}

@inproceedings{W16-0322,
 address = {San Diego, CA, USA},
 author = {Rey-Villamizar, Nicolas and Shrestha, Prasha and Solorio, Thamar and Sadeque, Farig and Bethard, Steven and Pedersen, Ted},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0322},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {171--175},
 publisher = {Association for Computational Linguistics},
 title = {Semi-supervised CLPsych 2016 Shared Task System Submission},
 year = {2016}
}

@inproceedings{W16-0323,
 address = {San Diego, CA, USA},
 author = {Wang, Chen-Kai and Dai, Hong-Jie and Chen, Chih-Wei and Jonnagaddala, Jitendra and Chang, Nai-Wen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0323},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {176--179},
 publisher = {Association for Computational Linguistics},
 title = {Combining Multiple Classifiers Using Global Ranking for ReachOut.com Post Triage},
 year = {2016}
}

@inproceedings{W16-0324,
 address = {San Diego, CA, USA},
 author = {Pink, Glen and Radford, Will and Hachey, Ben},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0324},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {180--182},
 publisher = {Association for Computational Linguistics},
 title = {Classification of mental health forum posts},
 year = {2016}
}

@inproceedings{W16-0325,
 address = {San Diego, CA, USA},
 author = {Almeida, Hayda and Queudot, Marc and Meurs, Marie-Jean},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0325},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {183--187},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Triage of Mental Health Online Forum Posts: CLPsych 2016 System Description},
 year = {2016}
}

@inproceedings{W16-0326,
 address = {San Diego, CA, USA},
 author = {Shickel, Benjamin and Rashidi, Parisa},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0326},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {188--192},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Triage of Mental Health Forum Posts},
 year = {2016}
}

@inproceedings{W16-0327,
 address = {San Diego, CA, USA},
 author = {Franco-Penya, Hector-Hugo and Mamani Sanchez, Liliana},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0327},
 booktitle = {Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology},
 month = {June},
 pages = {193--197},
 publisher = {Association for Computational Linguistics},
 title = {Text-based experiments for Predicting mental health emergencies in online web forum posts},
 year = {2016}
}

@inproceedings{W16-0401,
 address = {San Diego, California},
 author = {Balahur, Alexandra},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0401},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {1},
 publisher = {Association for Computational Linguistics},
 title = {Sentiment Analysis - What are we talking about?},
 year = {2016}
}

@inproceedings{W16-0402,
 address = {San Diego, California},
 author = {Grimes, Seth},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0402},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {2},
 publisher = {Association for Computational Linguistics},
 title = {Sentiment, Subjectivity, and Social Analysis Go ToWork: An Industry View - Invited Talk},
 year = {2016}
}

@inproceedings{W16-0403,
 address = {San Diego, California},
 author = {Hamidian, Sardar and Diab, Mona},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0403},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {3--8},
 publisher = {Association for Computational Linguistics},
 title = {Rumor Identification and Belief Investigation on Twitter},
 year = {2016}
}

@inproceedings{W16-0404,
 address = {San Diego, California},
 author = {Preo\c{t}iuc-Pietro, Daniel and Schwartz, H. Andrew and Park, Gregory and Eichstaedt, Johannes and Kern, Margaret and Ungar, Lyle and Shulman, Elisabeth},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0404},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {9--15},
 publisher = {Association for Computational Linguistics},
 title = {Modelling Valence and Arousal in Facebook posts},
 year = {2016}
}

@inproceedings{W16-0405,
 address = {San Diego, California},
 author = {Dehghani, Morteza},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0405},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {16},
 publisher = {Association for Computational Linguistics},
 title = {Purity Homophily in Social Networks - Invited Talk},
 year = {2016}
}

@inproceedings{W16-0406,
 address = {San Diego, California},
 author = {Harsley, Rachel and Gupta, Bhavesh and Di Eugenio, Barbara and Li, Huayi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0406},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {17--25},
 publisher = {Association for Computational Linguistics},
 title = {Hit Songs{\^a} Sentiments Harness Public Mood \& Predict Stock Market},
 year = {2016}
}

@inproceedings{W16-0407,
 address = {San Diego, California},
 author = {Chakraborty, Rupak and Kundu, Senjuti and Agarwal, Prakul},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0407},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {26--35},
 publisher = {Association for Computational Linguistics},
 title = {Fashioning Data - A Social Media Perspective on Fast Fashion Brands},
 year = {2016}
}

@inproceedings{W16-0408,
 address = {San Diego, California},
 author = {Socher, Richard},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0408},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {36},
 publisher = {Association for Computational Linguistics},
 title = {Deep Learning for Sentiment Analysis - Invited Talk},
 year = {2016}
}

@inproceedings{W16-0409,
 address = {San Diego, California},
 author = {Dias Cardoso, Pedro and Roy, Anindya},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0409},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {37--42},
 publisher = {Association for Computational Linguistics},
 title = {Sentiment Lexicon Creation using Continuous Latent Space and Neural Networks},
 year = {2016}
}

@inproceedings{W16-0410,
 address = {San Diego, California},
 author = {Kiritchenko, Svetlana and Mohammad, Saif},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0410},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {43--52},
 publisher = {Association for Computational Linguistics},
 title = {The Effect of Negators, Modals, and Degree Adverbs on Sentiment Composition},
 year = {2016}
}

@inproceedings{W16-0411,
 address = {San Diego, California},
 author = {Deng, Lingjia and Wiebe, Janyce},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0411},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {53--59},
 publisher = {Association for Computational Linguistics},
 title = {How can NLP Tasks Mutually Benefit Sentiment Analysis? A Holistic Approach to Sentiment Analysis},
 year = {2016}
}

@inproceedings{W16-0412,
 address = {San Diego, California},
 author = {Higgins, Derrick and Heilman, Michael and Jelesnianska, Adrianna and Ingersoll, Keith},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0412},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {60--65},
 publisher = {Association for Computational Linguistics},
 title = {An Unsupervised System for Visual Exploration of Twitter Conversations},
 year = {2016}
}

@inproceedings{W16-0413,
 address = {San Diego, California},
 author = {Wester, Aksel and {\O}vrelid, Lilja and Velldal, Erik and Hammer, Hugo Lewi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0413},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {66--71},
 publisher = {Association for Computational Linguistics},
 title = {Threat detection in online discussions},
 year = {2016}
}

@inproceedings{W16-0414,
 address = {San Diego, California},
 author = {M\'{e}nard, Pierre Andr\'{e} and Barri\`{e}re, Caroline},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0414},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {72--81},
 publisher = {Association for Computational Linguistics},
 title = {Classification of comment helpfulness to improve knowledge sharing among medical practitioners.},
 year = {2016}
}

@inproceedings{W16-0415,
 address = {San Diego, California},
 author = {Joshi, Aditya and Bhattacharyya, Pushpak and Carman, Mark},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0415},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {82--90},
 publisher = {Association for Computational Linguistics},
 title = {Political Issue Extraction Model: A Novel Hierarchical Topic Model That Uses Tweets By Political And Non-Political Authors},
 year = {2016}
}

@inproceedings{W16-0416,
 address = {San Diego, California},
 author = {Escalante, Hugo Jair and Montes y Gomez, Manuel and Villasenor, Luis and Errecalde, Marcelo Luis},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0416},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {91--99},
 publisher = {Association for Computational Linguistics},
 title = {Early text classification: a Na\"{i}ve solution},
 year = {2016}
}

@inproceedings{W16-0417,
 address = {San Diego, California},
 author = {Perumal, Krish and Hirst, Graeme},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0417},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {100--108},
 publisher = {Association for Computational Linguistics},
 title = {Semi-supervised and unsupervised categorization of posts in Web discussion forums using part-of-speech information and minimal features},
 year = {2016}
}

@inproceedings{W16-0418,
 address = {San Diego, California},
 author = {Zhou, Guangyu and Ganesan, Kavita},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0418},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {109--114},
 publisher = {Association for Computational Linguistics},
 title = {Linguistic Understanding of Complaints and Praises in User Reviews},
 year = {2016}
}

@inproceedings{W16-0419,
 address = {San Diego, California},
 author = {Jha, Vandana and R, Savitha and Shenoy, P Deepa and K R, Venugopal},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0419},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {115--121},
 publisher = {Association for Computational Linguistics},
 title = {Reputation System: Evaluating Reputation among All Good Sellers},
 year = {2016}
}

@inproceedings{W16-0420,
 address = {San Diego, California},
 author = {Ma, Zheng and Nam, Jinseok and Weihe, Karsten},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0420},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {122--127},
 publisher = {Association for Computational Linguistics},
 title = {Improve Sentiment Analysis of Citations with Author Modelling},
 year = {2016}
}

@inproceedings{W16-0421,
 address = {San Diego, California},
 author = {Panchendrarajan, Rrubaa and Ahamed, Nazick and Murugaiah, Brunthavan and Sivakumar, Prakhash and Ranathunga, Surangika and Pemasiri, Akila},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0421},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {128--136},
 publisher = {Association for Computational Linguistics},
 title = {Implicit Aspect Detection in Restaurant Reviews using Cooccurence of Words},
 year = {2016}
}

@inproceedings{W16-0422,
 address = {San Diego, California},
 author = {Jim\'{e}nez-Zafra, Salud Mar\'{i}a and Martin, Maite and Molina Gonz\'{a}lez, M. Dolores and Urena Lopez, L. Alfonso},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0422},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {137--146},
 publisher = {Association for Computational Linguistics},
 title = {Domain Adaptation of Polarity Lexicon combining Term Frequency and Bootstrapping},
 year = {2016}
}

@inproceedings{W16-0423,
 address = {San Diego, California},
 author = {Buechel, Sven and Hahn, Udo and Goldenstein, Jan and H\"{a}ndschke, Sebastian G. M. and Walgenbach, Peter},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0423},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {147--153},
 publisher = {Association for Computational Linguistics},
 title = {Do Enterprises Have Emotions?},
 year = {2016}
}

@inproceedings{W16-0424,
 address = {San Diego, California},
 author = {Palogiannidi, Elisavet and Iosif, Elias and Koutsakis, Polychronis and Potamianos, Alexandros},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0424},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {154--160},
 publisher = {Association for Computational Linguistics},
 title = {A semantic-affective compositional approach for the affective labelling of adjective-noun and noun-noun pairs},
 year = {2016}
}

@inproceedings{W16-0425,
 address = {San Diego, California},
 author = {Ghosh, Aniruddha and Veale, Dr. Tony},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0425},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {161--169},
 publisher = {Association for Computational Linguistics},
 title = {Fracking Sarcasm using Neural Network},
 year = {2016}
}

@inproceedings{W16-0426,
 address = {San Diego, California},
 author = {Klenner, Manfred},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0426},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {170},
 publisher = {Association for Computational Linguistics},
 title = {An Hymn of an even Deeper Sentiment Analysis},
 year = {2016}
}

@inproceedings{W16-0427,
 address = {San Diego, California},
 author = {Nakov, Preslav},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0427},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {171--172},
 publisher = {Association for Computational Linguistics},
 title = {Sentiment Analysis in Twitter: A SemEval Perspective},
 year = {2016}
}

@inproceedings{W16-0428,
 address = {San Diego, California},
 author = {Sebastiani, Fabrizio},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0428},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {173},
 publisher = {Association for Computational Linguistics},
 title = {The Challenge of Sentiment Quantification},
 year = {2016}
}

@inproceedings{W16-0429,
 address = {San Diego, California},
 author = {Mohammad, Saif},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0429},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {174--179},
 publisher = {Association for Computational Linguistics},
 title = {A Practical Guide to Sentiment Annotation: Challenges and Solutions},
 year = {2016}
}

@inproceedings{W16-0430,
 address = {San Diego, California},
 author = {Strapparava, Carlo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0430},
 booktitle = {Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis},
 month = {June},
 pages = {180},
 publisher = {Association for Computational Linguistics},
 title = {Emotions and NLP: Future Directions},
 year = {2016}
}

@inproceedings{W16-0501,
 address = {San Diego, CA},
 author = {Napoles, Courtney and Cahill, Aoife and Madnani, Nitin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0501},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {1--11},
 publisher = {Association for Computational Linguistics},
 title = {The Effect of Multiple Grammatical Errors on Processing Non-Native Writing},
 year = {2016}
}

@inproceedings{W16-0502,
 address = {San Diego, CA},
 author = {Xia, Menglin and Kochmar, Ekaterina and Briscoe, Ted},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0502},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {12--22},
 publisher = {Association for Computational Linguistics},
 title = {Text Readability Assessment for Second Language Learners},
 year = {2016}
}

@inproceedings{W16-0503,
 address = {San Diego, CA},
 author = {Hill, Jennifer and Simha, Rahul},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0503},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {23--30},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Generation of Context-Based Fill-in-the-Blank Exercises Using Co-occurrence Likelihoods and Google n-grams},
 year = {2016}
}

@inproceedings{W16-0504,
 address = {San Diego, CA},
 author = {Flor, Michael and Yoon, Su-Youn and Hao, Jiangang and Liu, Lei and von Davier, Alina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0504},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {31--41},
 publisher = {Association for Computational Linguistics},
 title = {Automated classification of collaborative problem solving interactions in simulated science tasks},
 year = {2016}
}

@inproceedings{W16-0505,
 address = {San Diego, CA},
 author = {Meyer, Christian M. and Koch, Johann Frerik},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0505},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {42--52},
 publisher = {Association for Computational Linguistics},
 title = {Computer-assisted stylistic revision with incomplete and noisy feedback. A pilot study},
 year = {2016}
}

@inproceedings{W16-0506,
 address = {San Diego, CA},
 author = {Daudaravicius, Vidas and Banchs, Rafael E. and Volodina, Elena and Napoles, Courtney},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0506},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {53--62},
 publisher = {Association for Computational Linguistics},
 title = {A Report on the Automatic Evaluation of Scientific Writing Shared Task},
 year = {2016}
}

@inproceedings{W16-0507,
 address = {San Diego, CA},
 author = {Beigman Klebanov, Beata and Flor, Michael and Gyawali, Binod},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0507},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {63--72},
 publisher = {Association for Computational Linguistics},
 title = {Topicality-Based Indices for Essay Scoring},
 year = {2016}
}

@inproceedings{W16-0508,
 address = {San Diego, CA},
 author = {Beinborn, Lisa and Zesch, Torsten and Gurevych, Iryna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0508},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {73--83},
 publisher = {Association for Computational Linguistics},
 title = {Predicting the Spelling Difficulty of Words for Language Learners},
 year = {2016}
}

@inproceedings{W16-0509,
 address = {San Diego, CA},
 author = {Chen, Xiaobin and Meurers, Detmar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0509},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {84--94},
 publisher = {Association for Computational Linguistics},
 title = {Characterizing Text Difficulty with Word Frequencies},
 year = {2016}
}

@inproceedings{W16-0510,
 address = {San Diego, CA},
 author = {Cummins, Ronan and Yannakoudakis, Helen and Briscoe, Ted},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0510},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {95--104},
 publisher = {Association for Computational Linguistics},
 title = {Unsupervised Modeling of Topical Relevance in L2 Learner Text},
 year = {2016}
}

@inproceedings{W16-0511,
 address = {San Diego, CA},
 author = {Flickinger, Dan and Goodman, Michael and Packard, Woodley},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0511},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {105--111},
 publisher = {Association for Computational Linguistics},
 title = {UW-Stanford System Description for AESW 2016 Shared Task on Grammatical Error Detection},
 year = {2016}
}

@inproceedings{W16-0512,
 address = {San Diego, CA},
 author = {King, Levi and Dickinson, Markus},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0512},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {112--121},
 publisher = {Association for Computational Linguistics},
 title = {Shallow Semantic Reasoning from an Incomplete Gold Standard for Learner Language},
 year = {2016}
}

@inproceedings{W16-0513,
 address = {San Diego, CA},
 author = {Lee, Lung-Hao and Lin, Bo-Lin and Yu, Liang-Chih and Tseng, Yuen-Hsien},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0513},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {122--129},
 publisher = {Association for Computational Linguistics},
 title = {The NTNU-YZU System in the AESW Shared Task: Automated Evaluation of Scientific Writing Using a Convolutional Neural Network},
 year = {2016}
}

@inproceedings{W16-0514,
 address = {San Diego, CA},
 author = {Loukina, Anastassia and Cahill, Aoife},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0514},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {130--135},
 publisher = {Association for Computational Linguistics},
 title = {Automated scoring across different modalities},
 year = {2016}
}

@inproceedings{W16-0515,
 address = {San Diego, CA},
 author = {Madnani, Nitin and Heilman, Michael and Cahill, Aoife},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0515},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {136--141},
 publisher = {Association for Computational Linguistics},
 title = {Model Combination for Correcting Preposition Selection Errors},
 year = {2016}
}

@inproceedings{W16-0516,
 address = {San Diego, CA},
 author = {Mart\'{i}nez-Santiago, Fernando and Garc\'{i}a Cumbreras, Miguel \'{A}ngel and Montejo R\'{a}ez, Arturo and D\'{i}az Galiano, Manuel Carlos},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0516},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {142--150},
 publisher = {Association for Computational Linguistics},
 title = {Pictogrammar: an AAC device based on a semantic grammar},
 year = {2016}
}

@inproceedings{W16-0517,
 address = {San Diego, CA},
 author = {Pil\'{a}n, Ildik\'{o}},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0517},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {151--161},
 publisher = {Association for Computational Linguistics},
 title = {Detecting Context Dependence in Exercise Item Candidates Selected from Corpora},
 year = {2016}
}

@inproceedings{W16-0518,
 address = {San Diego, CA},
 author = {Remse, Madeline and Mesgar, Mohsen and Strube, Michael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0518},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {162--171},
 publisher = {Association for Computational Linguistics},
 title = {Feature-Rich Error Detection in Scientific Writing Using Logistic Regression},
 year = {2016}
}

@inproceedings{W16-0519,
 address = {San Diego, CA},
 author = {Wojatzki, Michael and Melamud, Oren and Zesch, Torsten},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0519},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {172--181},
 publisher = {Association for Computational Linguistics},
 title = {Bundled Gap Filling: A New Paradigm for Unambiguous Cloze Exercises},
 year = {2016}
}

@inproceedings{W16-0520,
 address = {San Diego, CA},
 author = {Banjade, Rajendra and Maharjan, Nabin and Niraula, Nobal Bikram and Gautam, Dipesh and Samei, Borhan and Rus, Vasile},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0520},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {182--187},
 publisher = {Association for Computational Linguistics},
 title = {Evaluation Dataset (DT-Grade) and Word Weighting Approach towards Constructed Short Answers Assessment in Tutorial Dialogue Context},
 year = {2016}
}

@inproceedings{W16-0521,
 address = {San Diego, CA},
 author = {Chinkina, Maria and Meurers, Detmar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0521},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {188--198},
 publisher = {Association for Computational Linguistics},
 title = {Linguistically Aware Information Retrieval: Providing Input Enrichment for Second Language Learners},
 year = {2016}
}

@inproceedings{W16-0522,
 address = {San Diego, CA},
 author = {Beigman Klebanov, Beata and Burstein, Jill and Harackiewicz, Judith and Priniski, Stacy and Mulholland, Matthew},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0522},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {199--205},
 publisher = {Association for Computational Linguistics},
 title = {Enhancing STEM Motivation through Personal and Communal Values: NLP for Assessment of Utility Value in Student Writing},
 year = {2016}
}

@inproceedings{W16-0523,
 address = {San Diego, CA},
 author = {Ledbetter, Scott and Dickinson, Markus},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0523},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {206--216},
 publisher = {Association for Computational Linguistics},
 title = {Cost-Effectiveness in Building a Low-Resource Morphological Analyzer for Learner Language},
 year = {2016}
}

@inproceedings{W16-0524,
 address = {San Diego, CA},
 author = {Madnani, Nitin and Cahill, Aoife and Riordan, Brian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0524},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {217--222},
 publisher = {Association for Computational Linguistics},
 title = {Automatically Scoring Tests of Proficiency in Music Instruction},
 year = {2016}
}

@inproceedings{W16-0525,
 address = {San Diego, CA},
 author = {Mamani Sanchez, Liliana and Franco-Penya, Hector-Hugo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0525},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {223--228},
 publisher = {Association for Computational Linguistics},
 title = {Combined Tree Kernel-based classifiers for Assessing Quality of Scientific Text},
 year = {2016}
}

@inproceedings{W16-0526,
 address = {San Diego, CA},
 author = {Milli, Smitha and Hearst, Marti A.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0526},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {229--234},
 publisher = {Association for Computational Linguistics},
 title = {Augmenting Course Material with Open Access Textbooks},
 year = {2016}
}

@inproceedings{W16-0527,
 address = {San Diego, CA},
 author = {Rudzewitz, Bj\"{o}rn},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0527},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {235--241},
 publisher = {Association for Computational Linguistics},
 title = {Exploring the Intersection of Short Answer Assessment, Authorship Attribution, and Plagiarism Detection},
 year = {2016}
}

@inproceedings{W16-0528,
 address = {San Diego, CA},
 author = {Schmaltz, Allen and Kim, Yoon and Rush, Alexander M. and Shieber, Stuart},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0528},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {242--251},
 publisher = {Association for Computational Linguistics},
 title = {Sentence-Level Grammatical Error Identification as Sequence-to-Sequence Correction},
 year = {2016}
}

@inproceedings{W16-0529,
 address = {San Diego, CA},
 author = {Witte, Ren\'{e} and Sateli, Bahar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0529},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {252--255},
 publisher = {Association for Computational Linguistics},
 title = {Combining Off-the-shelf Grammar and Spelling Tools for the Automatic Evaluation of Scientific Writing (AESW) Shared Task 2016},
 year = {2016}
}

@inproceedings{W16-0530,
 address = {San Diego, CA},
 author = {Yuan, Zheng and Briscoe, Ted and Felice, Mariano},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0530},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {256--266},
 publisher = {Association for Computational Linguistics},
 title = {Candidate re-ranking for SMT-based grammatical error correction},
 year = {2016}
}

@inproceedings{W16-0531,
 address = {San Diego, CA},
 author = {Yoon, Su-Youn and Cho, Yeonsuk and Napolitano, Diane},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0531},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {267--276},
 publisher = {Association for Computational Linguistics},
 title = {Spoken Text Difficulty Estimation Using Linguistic Features},
 year = {2016}
}

@inproceedings{W16-0532,
 address = {San Diego, CA},
 author = {Rahimi, Zahra and Litman, Diane},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0532},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {277--282},
 publisher = {Association for Computational Linguistics},
 title = {Automatically Extracting Topical Components for a Response-to-Text Writing Assessment},
 year = {2016}
}

@inproceedings{W16-0533,
 address = {San Diego, CA},
 author = {Rei, Marek and Cummins, Ronan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0533},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {283--288},
 publisher = {Association for Computational Linguistics},
 title = {Sentence Similarity Measures for Fine-Grained Estimation of Topical Relevance in Learner Essays},
 year = {2016}
}

@inproceedings{W16-0534,
 address = {San Diego, CA},
 author = {Reynolds, Robert},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0534},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {289--300},
 publisher = {Association for Computational Linguistics},
 title = {Insights from Russian second language readability classification: complexity-dependent training requirements, and feature evaluation of multiple categories},
 year = {2016}
}

@inproceedings{W16-0535,
 address = {San Diego, CA},
 author = {Horbach, Andrea and Palmer, Alexis},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0535},
 booktitle = {Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications},
 month = {June},
 pages = {301--311},
 publisher = {Association for Computational Linguistics},
 title = {Investigating Active Learning for Short-Answer Scoring},
 year = {2016}
}

@inproceedings{W16-0601,
 address = {San Diego, California},
 author = {Butler, Alastair},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0601},
 booktitle = {Proceedings of the 2nd Workshop on Semantics-Driven Machine Translation (SedMT 2016)},
 month = {June},
 pages = {1--9},
 publisher = {Association for Computational Linguistics},
 title = {Deterministic natural language generation from meaning representations for machine translation},
 year = {2016}
}

@inproceedings{W16-0602,
 address = {San Diego, California},
 author = {Li, Liangyou and Way, Andy and Liu, Qun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0602},
 booktitle = {Proceedings of the 2nd Workshop on Semantics-Driven Machine Translation (SedMT 2016)},
 month = {June},
 pages = {10--12},
 publisher = {Association for Computational Linguistics},
 title = {Extending Phrase-Based Translation with Dependencies by Using Graphs},
 year = {2016}
}

@inproceedings{W16-0603,
 address = {San Diego, California},
 author = {Ge, Shili and Song, Rou},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0603},
 booktitle = {Proceedings of the 2nd Workshop on Semantics-Driven Machine Translation (SedMT 2016)},
 month = {June},
 pages = {13--21},
 publisher = {Association for Computational Linguistics},
 title = {The Naming Sharing Structure and its Cognitive Meaning in Chinese and English},
 year = {2016}
}

@inproceedings{W16-0604,
 address = {San Diego, California},
 author = {Simov, Kiril and Osenova, Petya and Popov, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0604},
 booktitle = {Proceedings of the 2nd Workshop on Semantics-Driven Machine Translation (SedMT 2016)},
 month = {June},
 pages = {22--26},
 publisher = {Association for Computational Linguistics},
 title = {Towards Semantic-based Hybrid Machine Translation between Bulgarian and English},
 year = {2016}
}

@inproceedings{W16-0701,
 address = {Ann Arbor, Michigan},
 author = {Recasens, Marta and Hu, Zhichao and Rhinehart, Olivia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0701},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {1--6},
 publisher = {Association for Computational Linguistics},
 title = {Sense Anaphoric Pronouns: Am I One?},
 year = {2016}
}

@inproceedings{W16-0702,
 address = {Ann Arbor, Michigan},
 author = {Grishina, Yulia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0702},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {7--15},
 publisher = {Association for Computational Linguistics},
 title = {Experiments on bridging across languages and genres},
 year = {2016}
}

@inproceedings{W16-0703,
 address = {Ann Arbor, Michigan},
 author = {Ogrodniczuk, Maciej and Zawis{\l}awska, Magdalena},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0703},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {16--22},
 publisher = {Association for Computational Linguistics},
 title = {Bridging Relations in Polish: Adaptation of Existing Typologies},
 year = {2016}
}

@inproceedings{W16-0704,
 address = {Ann Arbor, Michigan},
 author = {Kunz, Kerstin and Lapshinova-Koltunski, Ekaterina and Mart\'{i}nez, Jos\'{e} Manuel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0704},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {23--31},
 publisher = {Association for Computational Linguistics},
 title = {Beyond Identity Coreference: Contrasting Indicators of Textual Coherence in English and German},
 year = {2016}
}

@inproceedings{W16-0705,
 address = {Ann Arbor, Michigan},
 author = {Liu, Zhengzhong and Gonz\`{a}lez Pellicer, Edgar and Gillick, Daniel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0705},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {32--40},
 publisher = {Association for Computational Linguistics},
 title = {Exploring the steps of Verb Phrase Ellipsis},
 year = {2016}
}

@inproceedings{W16-0706,
 address = {Ann Arbor, Michigan},
 author = {Stede, Manfred and Grishina, Yulia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0706},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {41--46},
 publisher = {Association for Computational Linguistics},
 title = {Anaphoricity in Connectives: A Case Study on German},
 year = {2016}
}

@inproceedings{W16-0707,
 address = {Ann Arbor, Michigan},
 author = {Nedoluzhko, Anna and Lapshinova-Koltunski, Ekaterina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0707},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {47--52},
 publisher = {Association for Computational Linguistics},
 title = {Abstract Coreference in a Multilingual Perspective: a View on Czech and German},
 year = {2016}
}

@inproceedings{W16-0708,
 address = {Ann Arbor, Michigan},
 author = {Wiseman, Sam and Rush, Alexander M. and Shieber, Stuart},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0708},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {53--58},
 publisher = {Association for Computational Linguistics},
 title = {Antecedent Prediction Without a Pipeline},
 year = {2016}
}

@inproceedings{W16-0709,
 address = {Ann Arbor, Michigan},
 author = {Roitberg, Anna and Nedoluzhko, Anna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0709},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {59--66},
 publisher = {Association for Computational Linguistics},
 title = {Bridging Corpus for Russian in comparison with Czech},
 year = {2016}
}

@inproceedings{W16-0710,
 address = {Ann Arbor, Michigan},
 author = {Soraluze, Ander and Arregi, Olatz and Arregi, Xabier and Diaz de Ilarraza, Arantza and Kabadjov, Mijail and Poesio, Massimo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0710},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {67--73},
 publisher = {Association for Computational Linguistics},
 title = {Coreference Resolution for the Basque Language with BART},
 year = {2016}
}

@inproceedings{W16-0711,
 address = {Ann Arbor, Michigan},
 author = {Toldova, Svetlana and Azerkovich, Ilya and Ladygina, Alina and Roitberg, Anna and Vasilyeva, Maria},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0711},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {74--83},
 publisher = {Association for Computational Linguistics},
 title = {Error analysis for anaphora resolution in Russian: new challenging issues for anaphora resolution task in a morphologically rich language},
 year = {2016}
}

@inproceedings{W16-0712,
 address = {Ann Arbor, Michigan},
 author = {Sundar Ram, Vijay and Lalitha Devi, Sobha},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0712},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {84--91},
 publisher = {Association for Computational Linguistics},
 title = {How to Handle Split Antecedents in Tamil?},
 year = {2016}
}

@inproceedings{W16-0713,
 address = {Ann Arbor, Michigan},
 author = {Zeldes, Amir and Zhang, Shuo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0713},
 booktitle = {Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON 2016)},
 month = {June},
 pages = {92--101},
 publisher = {Association for Computational Linguistics},
 title = {When Annotation Schemes Change Rules Help: A Configurable Approach to Coreference Resolution beyond OntoNotes},
 year = {2016}
}

@inproceedings{W16-0801,
 address = {San Diego, California},
 author = {Volkova, Svitlana and Bell, Eric},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0801},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Deception Detection},
 month = {June},
 pages = {1--6},
 publisher = {Association for Computational Linguistics},
 title = {Account Deletion Prediction on RuNet: A Case Study of Suspicious Twitter Accounts Active During the Russian-Ukrainian Crisis},
 year = {2016}
}

@inproceedings{W16-0802,
 address = {San Diego, California},
 author = {Rubin, Victoria and Conroy, Niall and Chen, Yimin and Cornwell, Sarah},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0802},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Deception Detection},
 month = {June},
 pages = {7--17},
 publisher = {Association for Computational Linguistics},
 title = {Fake News or Truth? Using Satirical Cues to Detect Potentially Misleading News},
 year = {2016}
}

@inproceedings{W16-0803,
 address = {San Diego, California},
 author = {Kleinberg, Bennett and Nahari, Galit and Verschuere, Bruno},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0803},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Deception Detection},
 month = {June},
 pages = {18--25},
 publisher = {Association for Computational Linguistics},
 title = {Using the verifiability of details as a test of deception: A conceptual framework for the automation of the verifiability approach},
 year = {2016}
}

@inproceedings{W16-0804,
 address = {San Diego, California},
 author = {Fitzpatrick, Eileen and Bachenko, Joan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0804},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Deception Detection},
 month = {June},
 pages = {26--31},
 publisher = {Association for Computational Linguistics},
 title = {Estimating the amenibility of new domains for deception detection},
 year = {2016}
}

@inproceedings{W16-0805,
 address = {San Diego, California},
 author = {Kunath, Stephen and McCabe, Kevin},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0805},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Deception Detection},
 month = {June},
 pages = {32--39},
 publisher = {Association for Computational Linguistics},
 title = {The Use of Second Life for Deception Detection Research},
 year = {2016}
}

@inproceedings{W16-0806,
 address = {San Diego, California},
 author = {Levitan, Sarah Ita and Levitan, Yocheved and An, Guozhen and Levine, Michelle and Levitan, Rivka and Rosenberg, Andrew and Hirschberg, Julia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0806},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Deception Detection},
 month = {June},
 pages = {40--44},
 publisher = {Association for Computational Linguistics},
 title = {Identifying Individual Differences in Gender, Ethnicity, and Personality from Dialogue for Deception Detection},
 year = {2016}
}

@inproceedings{W16-0807,
 address = {San Diego, California},
 author = {Appling, Scott and Briscoe, Erica},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0807},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Deception Detection},
 month = {June},
 pages = {45--52},
 publisher = {Association for Computational Linguistics},
 title = {Individual Differences in Strategic Deception},
 year = {2016}
}

@inproceedings{W16-0901,
 address = {San Diego, California},
 author = {Snijders, Liselotte},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0901},
 booktitle = {Proceedings of the Workshop on Discontinuous Structures in Natural Language Processing},
 month = {June},
 pages = {1--11},
 publisher = {Association for Computational Linguistics},
 title = {An LFG Account of Discontinuous Nominal Expressions},
 year = {2016}
}

@inproceedings{W16-0902,
 address = {San Diego, California},
 author = {Uresova, Zdenka and Fucikova, Eva and Hajic, Jan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0902},
 booktitle = {Proceedings of the Workshop on Discontinuous Structures in Natural Language Processing},
 month = {June},
 pages = {12--21},
 publisher = {Association for Computational Linguistics},
 title = {Non-projectivity and valency},
 year = {2016}
}

@inproceedings{W16-0903,
 address = {San Diego, California},
 author = {Barreiro, Anabela and Batista, Fernando},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0903},
 booktitle = {Proceedings of the Workshop on Discontinuous Structures in Natural Language Processing},
 month = {June},
 pages = {22--30},
 publisher = {Association for Computational Linguistics},
 title = {Machine Translation of Non-Contiguous Multiword Units},
 year = {2016}
}

@inproceedings{W16-0904,
 address = {San Diego, California},
 author = {Balabanova, Elisaveta},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0904},
 booktitle = {Proceedings of the Workshop on Discontinuous Structures in Natural Language Processing},
 month = {June},
 pages = {31--36},
 publisher = {Association for Computational Linguistics},
 title = {Discontinuous VP in Bulgarian},
 year = {2016}
}

@inproceedings{W16-0905,
 address = {San Diego, California},
 author = {Sulger, Sebastian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0905},
 booktitle = {Proceedings of the Workshop on Discontinuous Structures in Natural Language Processing},
 month = {June},
 pages = {37--46},
 publisher = {Association for Computational Linguistics},
 title = {Discontinuous Genitives in Hindi/Urdu},
 year = {2016}
}

@inproceedings{W16-0906,
 address = {San Diego, California},
 author = {Maier, Wolfgang and Lichte, Timm},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0906},
 booktitle = {Proceedings of the Workshop on Discontinuous Structures in Natural Language Processing},
 month = {June},
 pages = {47--57},
 publisher = {Association for Computational Linguistics},
 title = {Discontinuous parsing with continuous trees},
 year = {2016}
}

@inproceedings{W16-0907,
 address = {San Diego, California},
 author = {Versley, Yannick},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-0907},
 booktitle = {Proceedings of the Workshop on Discontinuous Structures in Natural Language Processing},
 month = {June},
 pages = {58--69},
 publisher = {Association for Computational Linguistics},
 title = {Discontinuity Re\^{}2-visited: A Minimalist Approach to Pseudoprojective Constituent Parsing},
 year = {2016}
}

@inproceedings{W16-1001,
 address = {San Diego, California},
 author = {Upadhyay, Shyam and Christodoulopoulos, Christos and Roth, Dan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1001},
 booktitle = {Proceedings of the Fourth Workshop on Events},
 month = {June},
 pages = {1--7},
 publisher = {Association for Computational Linguistics},
 title = {"Making the News": Identifying Noteworthy Events in News Articles},
 year = {2016}
}

@inproceedings{W16-1002,
 address = {San Diego, California},
 author = {Croft, William and Peskova, Pavlina and Regan, Michael},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1002},
 booktitle = {Proceedings of the Fourth Workshop on Events},
 month = {June},
 pages = {8--17},
 publisher = {Association for Computational Linguistics},
 title = {Annotation of causal and aspectual structure of events in RED: a preliminary report},
 year = {2016}
}

@inproceedings{W16-1003,
 address = {San Diego, California},
 author = {Bonial, Claire and Tahmoush, David and Windisch Brown, Susan and Palmer, Martha},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1003},
 booktitle = {Proceedings of the Fourth Workshop on Events},
 month = {June},
 pages = {18--26},
 publisher = {Association for Computational Linguistics},
 title = {Multimodal Use of an Upper-Level Event Ontology},
 year = {2016}
}

@inproceedings{W16-1004,
 address = {San Diego, California},
 author = {Bies, Ann and Song, Zhiyi and Getman, Jeremy and Ellis, Joe and Mott, Justin and Strassel, Stephanie and Palmer, Martha and Mitamura, Teruko and Freedman, Marjorie and Ji, Heng and O'Gorman, Tim},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1004},
 booktitle = {Proceedings of the Fourth Workshop on Events},
 month = {June},
 pages = {27--36},
 publisher = {Association for Computational Linguistics},
 title = {A Comparison of Event Representations in DEFT},
 year = {2016}
}

@inproceedings{W16-1005,
 address = {San Diego, California},
 author = {Song, Zhiyi and Bies, Ann and Strassel, Stephanie and Ellis, Joe and Mitamura, Teruko and Dang, Hoa Trang and Yamakawa, Yukari and Holm, Sue},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1005},
 booktitle = {Proceedings of the Fourth Workshop on Events},
 month = {June},
 pages = {37--45},
 publisher = {Association for Computational Linguistics},
 title = {Event Nugget and Event Coreference Annotation},
 year = {2016}
}

@inproceedings{W16-1006,
 address = {San Diego, California},
 author = {Nakamura, Tetsuaki and Kawahara, Daisuke},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1006},
 booktitle = {Proceedings of the Fourth Workshop on Events},
 month = {June},
 pages = {46--50},
 publisher = {Association for Computational Linguistics},
 title = {Constructing a Dictionary Describing Feature Changes of Arguments in Event Sentences},
 year = {2016}
}

@inproceedings{W16-1007,
 address = {San Diego, California},
 author = {Mostafazadeh, Nasrin and Grealish, Alyson and Chambers, Nathanael and Allen, James and Vanderwende, Lucy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1007},
 booktitle = {Proceedings of the Fourth Workshop on Events},
 month = {June},
 pages = {51--61},
 publisher = {Association for Computational Linguistics},
 title = {CaTeRS: Causal and Temporal Relation Scheme for Semantic Annotation of Event Structures},
 year = {2016}
}

@inproceedings{W16-1101,
 address = {San Diego, California},
 author = {Lederer, Jenny},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1101},
 booktitle = {Proceedings of the Fourth Workshop on Metaphor in NLP},
 month = {June},
 pages = {1--9},
 publisher = {Association for Computational Linguistics},
 title = {Finding metaphorical triggers through source (not target) domain lexicalization patterns},
 year = {2016}
}

@inproceedings{W16-1102,
 address = {San Diego, California},
 author = {Haagsma, Hessel and Bjerva, Johannes},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1102},
 booktitle = {Proceedings of the Fourth Workshop on Metaphor in NLP},
 month = {June},
 pages = {10--17},
 publisher = {Association for Computational Linguistics},
 title = {Detecting novel metaphor using selectional preference information},
 year = {2016}
}

@inproceedings{W16-1103,
 address = {San Diego, California},
 author = {Rai, Sunny and Chakraverty, Shampa and Tayal, Devendra K.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1103},
 booktitle = {Proceedings of the Fourth Workshop on Metaphor in NLP},
 month = {June},
 pages = {18--27},
 publisher = {Association for Computational Linguistics},
 title = {Supervised Metaphor Detection using Conditional Random Fields},
 year = {2016}
}

@inproceedings{W16-1104,
 address = {San Diego, California},
 author = {Do Dinh, Erik-L\^{a}n and Gurevych, Iryna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1104},
 booktitle = {Proceedings of the Fourth Workshop on Metaphor in NLP},
 month = {June},
 pages = {28--33},
 publisher = {Association for Computational Linguistics},
 title = {Token-Level Metaphor Detection using Neural Networks},
 year = {2016}
}

@inproceedings{W16-1105,
 address = {San Diego, California},
 author = {Veale, Tony},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1105},
 booktitle = {Proceedings of the Fourth Workshop on Metaphor in NLP},
 month = {June},
 pages = {34--41},
 publisher = {Association for Computational Linguistics},
 title = {Round Up The Usual Suspects: Knowledge-Based Metaphor Generation},
 year = {2016}
}

@inproceedings{W16-1201,
 address = {San Diego, California},
 author = {Aldarmaki, Hanan and Diab, Mona},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1201},
 booktitle = {Proceedings of the Workshop on Multilingual and Cross{\^A}--lingual Methods in NLP},
 month = {June},
 pages = {1--9},
 publisher = {Association for Computational Linguistics},
 title = {Learning Cross-lingual Representations with Matrix Factorization},
 year = {2016}
}

@inproceedings{W16-1202,
 address = {San Diego, California},
 author = {de Lhoneux, Miryam and Nivre, Joakim},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1202},
 booktitle = {Proceedings of the Workshop on Multilingual and Cross{\^A}--lingual Methods in NLP},
 month = {June},
 pages = {10--19},
 publisher = {Association for Computational Linguistics},
 title = {Should Have, Would Have, Could Have. Investigating Verb Group Representations for Parsing with Universal Dependencies.},
 year = {2016}
}

@inproceedings{W16-1203,
 address = {San Diego, California},
 author = {Lacroix, Oph\'{e}lie and Wisniewski, Guillaume and Yvon, Fran\c{c}ois},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1203},
 booktitle = {Proceedings of the Workshop on Multilingual and Cross{\^A}--lingual Methods in NLP},
 month = {June},
 pages = {20--29},
 publisher = {Association for Computational Linguistics},
 title = {Cross-lingual Dependency Transfer : What Matters? Assessing the Impact of Pre- and Post-processing},
 year = {2016}
}

@inproceedings{W16-1204,
 address = {San Diego, California},
 author = {Al tarouti, Feras and Kalita, Jugal},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1204},
 booktitle = {Proceedings of the Workshop on Multilingual and Cross{\^A}--lingual Methods in NLP},
 month = {June},
 pages = {30--34},
 publisher = {Association for Computational Linguistics},
 title = {Enhancing Automatic Wordnet Construction Using Word Embeddings},
 year = {2016}
}

@inproceedings{W16-1205,
 address = {San Diego, California},
 author = {Aufrant, Lauriane and Wisniewski, Guillaume and Yvon, Fran\c{c}ois},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1205},
 booktitle = {Proceedings of the Workshop on Multilingual and Cross{\^A}--lingual Methods in NLP},
 month = {June},
 pages = {35--44},
 publisher = {Association for Computational Linguistics},
 title = {Cross-lingual alignment transfer: a chicken-and-egg story?},
 year = {2016}
}

@inproceedings{W16-1206,
 address = {San Diego, California},
 author = {Wan, Ada},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1206},
 booktitle = {Proceedings of the Workshop on Multilingual and Cross{\^A}--lingual Methods in NLP},
 month = {June},
 pages = {45--54},
 publisher = {Association for Computational Linguistics},
 title = {Leveraging Data-Driven Methods in Word-Level Language Identification for a Multilingual Alpine Heritage Corpus},
 year = {2016}
}

@inproceedings{W16-1207,
 address = {San Diego, California},
 author = {Saers, Markus and Wu, Dekai},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1207},
 booktitle = {Proceedings of the Workshop on Multilingual and Cross{\^A}--lingual Methods in NLP},
 month = {June},
 pages = {55--64},
 publisher = {Association for Computational Linguistics},
 title = {Learning Translations for Tagged Words: Extending the Translation Lexicon of an ITG for Low Resource Languages},
 year = {2016}
}

@inproceedings{W16-1208,
 address = {San Diego, California},
 author = {Asgari, Ehsaneddin and Mofrad, Mohammad R.K.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1208},
 booktitle = {Proceedings of the Workshop on Multilingual and Cross{\^A}--lingual Methods in NLP},
 month = {June},
 pages = {65--74},
 publisher = {Association for Computational Linguistics},
 title = {Comparing Fifty Natural Languages and Twelve Genetic Languages Using Word Embedding Language Divergence (WELD) as a Quantitative Measure of Language Distance},
 year = {2016}
}

@inproceedings{W16-1301,
 address = {San Diego, CA},
 author = {Bing, Lidong and Cohen, William and Dhingra, Bhuwan and Wang, Richard},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1301},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {1--6},
 publisher = {Association for Computational Linguistics},
 title = {Using Graphs of Classifiers to Impose Constraints on Semi-supervised Relation Extraction},
 year = {2016}
}

@inproceedings{W16-1302,
 address = {San Diego, CA},
 author = {Chisholm, Andrew and Radford, Will and Hachey, Ben},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1302},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {7--11},
 publisher = {Association for Computational Linguistics},
 title = {Discovering Entity Knowledge Bases on the Web},
 year = {2016}
}

@inproceedings{W16-1303,
 address = {San Diego, CA},
 author = {Dalvi, Bhavana and Bhakthavatsalam, Sumithra and Clark, Chris and Clark, Peter and Etzioni, Oren and Fader, Anthony and Groeneveld, Dirk},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1303},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {12--17},
 publisher = {Association for Computational Linguistics},
 title = {IKE - An Interactive Tool for Knowledge Extraction},
 year = {2016}
}

@inproceedings{W16-1304,
 address = {San Diego, CA},
 author = {Das, Rajarshi and Neelakantan, Arvind and Belanger, David and McCallum, Andrew},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1304},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {18--23},
 publisher = {Association for Computational Linguistics},
 title = {Incorporating Selectional Preferences in Multi-hop Relation Extraction},
 year = {2016}
}

@inproceedings{W16-1305,
 address = {San Diego, CA},
 author = {Gao, Ning and Dredze, Mark and Oard, Douglas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1305},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {24--28},
 publisher = {Association for Computational Linguistics},
 title = {Knowledge Base Population for Organization Mentions in Email},
 year = {2016}
}

@inproceedings{W16-1306,
 address = {San Diego, CA},
 author = {Mousselly Sergieh, Hatem and Gurevych, Iryna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1306},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {29--34},
 publisher = {Association for Computational Linguistics},
 title = {Enriching Wikidata with Frame Semantics},
 year = {2016}
}

@inproceedings{W16-1307,
 address = {San Diego, CA},
 author = {Pal, Harinder and -, Mausam},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1307},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {35--39},
 publisher = {Association for Computational Linguistics},
 title = {Demonyms and Compound Relational Nouns in Nominal Open IE},
 year = {2016}
}

@inproceedings{W16-1308,
 address = {San Diego, CA},
 author = {Razniewski, Simon and Suchanek, Fabian and Nutt, Werner},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1308},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {40--44},
 publisher = {Association for Computational Linguistics},
 title = {But What Do We Actually Know?},
 year = {2016}
}

@inproceedings{W16-1309,
 address = {San Diego, CA},
 author = {Rockt\"{a}schel, Tim and Riedel, Sebastian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1309},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {45--50},
 publisher = {Association for Computational Linguistics},
 title = {Learning Knowledge Base Inference with Neural Theorem Provers},
 year = {2016}
}

@inproceedings{W16-1310,
 address = {San Diego, CA},
 author = {Russell, Stuart and Lassen, Ole Torp and Uang, Justin and Wang, Wei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1310},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {51--56},
 publisher = {Association for Computational Linguistics},
 title = {The Physics of Text: Ontological Realism in Information Extraction},
 year = {2016}
}

@inproceedings{W16-1311,
 address = {San Diego, CA},
 author = {Nag Chowdhury, Sreyasi and Tandon, Niket and Weikum, Gerhard},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1311},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {57--62},
 publisher = {Association for Computational Linguistics},
 title = {Know2Look: Commonsense Knowledge for Visual Search},
 year = {2016}
}

@inproceedings{W16-1312,
 address = {San Diego, CA},
 author = {Verga, Patrick and McCallum, Andrew},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1312},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {63--68},
 publisher = {Association for Computational Linguistics},
 title = {Row-less Universal Schema},
 year = {2016}
}

@inproceedings{W16-1313,
 address = {San Diego, CA},
 author = {Shimaoka, Sonse and Stenetorp, Pontus and Inui, Kentaro and Riedel, Sebastian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1313},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {69--74},
 publisher = {Association for Computational Linguistics},
 title = {An Attentive Neural Architecture for Fine-grained Entity Type Classification},
 year = {2016}
}

@inproceedings{W16-1314,
 address = {San Diego, CA},
 author = {Demeester, Thomas and Rockt\"{a}schel, Tim and Riedel, Sebastian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1314},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {75--80},
 publisher = {Association for Computational Linguistics},
 title = {Regularizing Relation Representations by First-order Implications},
 year = {2016}
}

@inproceedings{W16-1315,
 address = {San Diego, CA},
 author = {Groth, Paul and Pal, Sujit and McBeath, Darin and Allen, Brad and Daniel, Ron},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1315},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {81--85},
 publisher = {Association for Computational Linguistics},
 title = {Applying Universal Schemas for Domain Specific Ontology Expansion},
 year = {2016}
}

@inproceedings{W16-1316,
 address = {San Diego, CA},
 author = {Machida, Yuichiro and Kawahara, Daisuke and Kurohashi, Sadao and Sassano, Manabu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1316},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {86--91},
 publisher = {Association for Computational Linguistics},
 title = {Design of Word Association Games using Dialog Systems for Acquisition of Word Association Knowledge},
 year = {2016}
}

@inproceedings{W16-1317,
 address = {San Diego, CA},
 author = {Martin, Teresa and Botschen, Fiete and Nagesh, Ajay and McCallum, Andrew},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1317},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {92--96},
 publisher = {Association for Computational Linguistics},
 title = {Call for Discussion: Building a New Standard Dataset for Relation Extraction Tasks},
 year = {2016}
}

@inproceedings{W16-1318,
 address = {San Diego, CA},
 author = {Soni, Ameet and Viswanathan, Dileep and Pachaiyappan, Niranjan and Natarajan, Sriraam},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1318},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {97--102},
 publisher = {Association for Computational Linguistics},
 title = {A Comparison of Weak Supervision methods for Knowledge Base Construction},
 year = {2016}
}

@inproceedings{W16-1319,
 address = {San Diego, CA},
 author = {Welbl, Johannes and Bouchard, Guillaume and Riedel, Sebastian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1319},
 booktitle = {Proceedings of the 5th Workshop on Automated Knowledge Base Construction},
 month = {June},
 pages = {103--107},
 publisher = {Association for Computational Linguistics},
 title = {A Factorization Machine Framework for Testing Bigram Embeddings in Knowledgebase Completion},
 year = {2016}
}

@inproceedings{W16-1401,
 address = {San Diego, CA, USA},
 author = {Nieto Pi\~{n}a, Luis and Johansson, Richard},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1401},
 booktitle = {Proceedings of TextGraphs-10: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {June},
 pages = {1--5},
 publisher = {Association for Computational Linguistics},
 title = {Embedding Senses for Efficient Graph-based Word Sense Disambiguation},
 year = {2016}
}

@inproceedings{W16-1402,
 address = {San Diego, CA, USA},
 author = {Demir, Seniz},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1402},
 booktitle = {Proceedings of TextGraphs-10: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {June},
 pages = {6--14},
 publisher = {Association for Computational Linguistics},
 title = {Context Tailoring for Text Normalization},
 year = {2016}
}

@inproceedings{W16-1403,
 address = {San Diego, CA, USA},
 author = {Pouran Ben Veyseh, Amir},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1403},
 booktitle = {Proceedings of TextGraphs-10: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {June},
 pages = {15--19},
 publisher = {Association for Computational Linguistics},
 title = {Cross-Lingual Question Answering Using Common Semantic Space},
 year = {2016}
}

@inproceedings{W16-1404,
 address = {San Diego, CA, USA},
 author = {Arnold, Thomas and Weihe, Karsten},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1404},
 booktitle = {Proceedings of TextGraphs-10: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {June},
 pages = {20--28},
 publisher = {Association for Computational Linguistics},
 title = {Network Motifs May Improve Quality Assessment of Text Documents},
 year = {2016}
}

@inproceedings{W16-1405,
 address = {San Diego, CA, USA},
 author = {Lai, Yi-Yu and Li, Chang and Goldwasser, Dan and Neville, Jennifer},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1405},
 booktitle = {Proceedings of TextGraphs-10: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {June},
 pages = {29--33},
 publisher = {Association for Computational Linguistics},
 title = {Better Together: Combining Language and Social Interactions into a Shared Representation},
 year = {2016}
}

@inproceedings{W16-1406,
 address = {San Diego, CA, USA},
 author = {Rodin, Ivan and Chernyak, Ekaterina and Dubov, Mikhail and Mirkin, Boris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-1406},
 booktitle = {Proceedings of TextGraphs-10: the Workshop on Graph-based Methods for Natural Language Processing},
 month = {June},
 pages = {34--38},
 publisher = {Association for Computational Linguistics},
 title = {Visualization of Dynamic Reference Graphs},
 year = {2016}
}

@inproceedings{W16-2201,
 address = {Berlin, Germany},
 author = {Shen, Yu and Chu, Chenhui and Cromieres, Fabien and Kurohashi, Sadao},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2201},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {1--11},
 publisher = {Association for Computational Linguistics},
 title = {Cross-language Projection of Dependency Trees with Constrained Partial Parsing for Tree-to-Tree Machine Translation},
 year = {2016}
}

@inproceedings{W16-2202,
 address = {Berlin, Germany},
 author = {Luong, Ngoc Quang and Popescu-Belis, Andrei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2202},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {12--20},
 publisher = {Association for Computational Linguistics},
 title = {Improving Pronoun Translation by Modeling Coreference Uncertainty},
 year = {2016}
}

@inproceedings{W16-2203,
 address = {Berlin, Germany},
 author = {Ramm, Anita and Fraser, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2203},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {21--31},
 publisher = {Association for Computational Linguistics},
 title = {Modeling verbal inflection for English to German SMT},
 year = {2016}
}

@inproceedings{W16-2204,
 address = {Berlin, Germany},
 author = {Nadejde, Maria and Birch, Alexandra and Koehn, Philipp},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2204},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {32--42},
 publisher = {Association for Computational Linguistics},
 title = {Modeling Selectional Preferences of Verbs and Nouns in String-to-Tree Machine Translation},
 year = {2016}
}

@inproceedings{W16-2205,
 address = {Berlin, Germany},
 author = {Weller-Di Marco, Marion and Fraser, Alexander and Schulte im Walde, Sabine},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2205},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {43--53},
 publisher = {Association for Computational Linguistics},
 title = {Modeling Complement Types in Phrase-Based SMT},
 year = {2016}
}

@inproceedings{W16-2206,
 address = {Berlin, Germany},
 author = {Alkhouli, Tamer and Bretschner, Gabriel and Peter, Jan-Thorsten and Hethnawi, Mohammed and Guta, Andreas and Ney, Hermann},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2206},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {54--65},
 publisher = {Association for Computational Linguistics},
 title = {Alignment-Based Neural Machine Translation},
 year = {2016}
}

@inproceedings{W16-2207,
 address = {Berlin, Germany},
 author = {Legrand, Jo\"{e}l and Auli, Michael and Collobert, Ronan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2207},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {66--73},
 publisher = {Association for Computational Linguistics},
 title = {Neural Network-based Word Alignment through Score Aggregation},
 year = {2016}
}

@inproceedings{W16-2208,
 address = {Berlin, Germany},
 author = {Niehues, Jan and Ha, Thanh-Le and Cho, Eunah and Waibel, Alex},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2208},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {74--82},
 publisher = {Association for Computational Linguistics},
 title = {Using Factored Word Representation in Neural Network Language Models},
 year = {2016}
}

@inproceedings{W16-2209,
 address = {Berlin, Germany},
 author = {Sennrich, Rico and Haddow, Barry},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2209},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {83--91},
 publisher = {Association for Computational Linguistics},
 title = {Linguistic Input Features Improve Neural Machine Translation},
 year = {2016}
}

@inproceedings{W16-2210,
 address = {Berlin, Germany},
 author = {Braune, Fabienne and Fraser, Alexander and Daum\'{e} III, Hal and Tamchyna, Ale\v{s}},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2210},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {92--101},
 publisher = {Association for Computational Linguistics},
 title = {A Framework for Discriminative Rule Selection in Hierarchical Moses},
 year = {2016}
}

@inproceedings{W16-2211,
 address = {Berlin, Germany},
 author = {Bogoychev, Nikolay and Hoang, Hieu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2211},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {102--109},
 publisher = {Association for Computational Linguistics},
 title = {Fast and highly parallelizable phrase table for statistical machine translation},
 year = {2016}
}

@inproceedings{W16-2212,
 address = {Berlin, Germany},
 author = {Kim, Yunsu and Guta, Andreas and Wuebker, Joern and Ney, Hermann},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2212},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {110--117},
 publisher = {Association for Computational Linguistics},
 title = {A Comparative Study on Vocabulary Reduction for Phrase Table Smoothing},
 year = {2016}
}

@inproceedings{W16-2213,
 address = {Berlin, Germany},
 author = {Daiber, Joachim and Stanojevi\'{c}, Milo\v{s} and Aziz, Wilker and Sima'an, Khalil},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2213},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {118--130},
 publisher = {Association for Computational Linguistics},
 title = {Examining the Relationship between Preordering and Word Order Freedom in Machine Translation},
 year = {2016}
}

@inproceedings{W16-2301,
 address = {Berlin, Germany},
 author = {Bojar, Ond\v{r}ej and Chatterjee, Rajen and Federmann, Christian and Graham, Yvette and Haddow, Barry and Huck, Matthias and Jimeno Yepes, Antonio and Koehn, Philipp and Logacheva, Varvara and Monz, Christof and Negri, Matteo and Neveol, Aurelie and Neves, Mariana and Popel, Martin and Post, Matt and Rubino, Raphael and Scarton, Carolina and Specia, Lucia and Turchi, Marco and Verspoor, Karin and Zampieri, Marcos},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2301},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {131--198},
 publisher = {Association for Computational Linguistics},
 title = {Findings of the 2016 Conference on Machine Translation},
 year = {2016}
}

@inproceedings{W16-2302,
 address = {Berlin, Germany},
 author = {Bojar, Ond\v{r}ej and Graham, Yvette and Kamran, Amir and Stanojevi\'{c}, Milo\v{s}},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2302},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {199--231},
 publisher = {Association for Computational Linguistics},
 title = {Results of the WMT16 Metrics Shared Task},
 year = {2016}
}

@inproceedings{W16-2303,
 address = {Berlin, Germany},
 author = {Jawaid, Bushra and Kamran, Amir and Stanojevi\'{c}, Milo\v{s} and Bojar, Ond\v{r}ej},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2303},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {232--238},
 publisher = {Association for Computational Linguistics},
 title = {Results of the WMT16 Tuning Shared Task},
 year = {2016}
}

@inproceedings{W16-2304,
 address = {Berlin, Germany},
 author = {Allauzen, Alexandre and Aufrant, Lauriane and Burlot, Franck and Lacroix, Oph\'{e}lie and Knyazeva, Elena and Lavergne, Thomas and Wisniewski, Guillaume and Yvon, Fran\c{c}ois},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2304},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {239--245},
 publisher = {Association for Computational Linguistics},
 title = {LIMSI$@$WMT{\^a}16: Machine Translation of News},
 year = {2016}
}

@inproceedings{W16-2305,
 address = {Berlin, Germany},
 author = {Bekta\c{s}, Emre and Yilmaz, Ertugrul and Mermer, Coskun and Durgar El-Kahlout, {\"A}$\,^{\circ}$lknur},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2305},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {246--251},
 publisher = {Association for Computational Linguistics},
 title = {T\"{U}B{\"A}$\,^{\circ}$TAK SMT System Submission for WMT2016},
 year = {2016}
}

@inproceedings{W16-2306,
 address = {Berlin, Germany},
 author = {Bicici, Ergun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2306},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {252--258},
 publisher = {Association for Computational Linguistics},
 title = {ParFDA for Instance Selection for Statistical Machine Translation},
 year = {2016}
}

@inproceedings{W16-2307,
 address = {Berlin, Germany},
 author = {Blain, Fr\'{e}d\'{e}ric and Song, Xingyi and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2307},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {259--263},
 publisher = {Association for Computational Linguistics},
 title = {Sheffield Systems for the English-Romanian WMT Translation Task},
 year = {2016}
}

@inproceedings{W16-2308,
 address = {Berlin, Germany},
 author = {Bradbury, James and Socher, Richard},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2308},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {264--267},
 publisher = {Association for Computational Linguistics},
 title = {MetaMind Neural Machine Translation System for WMT 2016},
 year = {2016}
}

@inproceedings{W16-2309,
 address = {Berlin, Germany},
 author = {Chung, Junyoung and Cho, Kyunghyun and Bengio, Yoshua},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2309},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {268--271},
 publisher = {Association for Computational Linguistics},
 title = {NYU-MILA Neural Machine Translation Systems for WMT{\^a}16},
 year = {2016}
}

@inproceedings{W16-2310,
 address = {Berlin, Germany},
 author = {Ding, Shuoyang and Duh, Kevin and Khayrallah, Huda and Koehn, Philipp and Post, Matt},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2310},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {272--280},
 publisher = {Association for Computational Linguistics},
 title = {The JHU Machine Translation Systems for WMT 2016},
 year = {2016}
}

@inproceedings{W16-2311,
 address = {Berlin, Germany},
 author = {Dvorkovich, Anton and Gubanov, Sergey and Galinskaya, Irina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2311},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {281--288},
 publisher = {Association for Computational Linguistics},
 title = {Yandex School of Data Analysis approach to English-Turkish translation at WMT16 News Translation Task},
 year = {2016}
}

@inproceedings{W16-2312,
 address = {Berlin, Germany},
 author = {Gr\"{o}nroos, Stig-Arne and Virpioja, Sami and Kurimo, Mikko},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2312},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {289--295},
 publisher = {Association for Computational Linguistics},
 title = {Hybrid Morphological Segmentation for Phrase-Based Machine Translation},
 year = {2016}
}

@inproceedings{W16-2313,
 address = {Berlin, Germany},
 author = {Gwinnup, Jeremy and Anderson, Tim and Erdmann, Grant and Young, Katherine and Kazi, Michaeel and Salesky, Elizabeth and Thompson, Brian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2313},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {296--302},
 publisher = {Association for Computational Linguistics},
 title = {The AFRL-MITLL WMT16 News-Translation Task Systems},
 year = {2016}
}

@inproceedings{W16-2314,
 address = {Berlin, Germany},
 author = {Ha, Thanh-Le and Cho, Eunah and Niehues, Jan and Mediani, Mohammed and Sperber, Matthias and Allauzen, Alexandre and Waibel, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2314},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {303--310},
 publisher = {Association for Computational Linguistics},
 title = {The Karlsruhe Institute of Technology Systems for the News Translation Task in WMT 2016},
 year = {2016}
}

@inproceedings{W16-2315,
 address = {Berlin, Germany},
 author = {Huck, Matthias and Fraser, Alexander and Haddow, Barry},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2315},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {311--318},
 publisher = {Association for Computational Linguistics},
 title = {The Edinburgh/LMU Hierarchical Machine Translation System for WMT 2016},
 year = {2016}
}

@inproceedings{W16-2316,
 address = {Berlin, Germany},
 author = {Junczys-Dowmunt, Marcin and Dwojak, Tomasz and Sennrich, Rico},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2316},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {319--325},
 publisher = {Association for Computational Linguistics},
 title = {The AMU-UEDIN Submission to the WMT16 News Translation Task: Attention-based NMT Models as Feature Functions in Phrase-based SMT},
 year = {2016}
}

@inproceedings{W16-2317,
 address = {Berlin, Germany},
 author = {Lo, Chi-kiu and Cherry, Colin and Foster, George and Stewart, Darlene and Islam, Rabib and Kazantseva, Anna and Kuhn, Roland},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2317},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {326--332},
 publisher = {Association for Computational Linguistics},
 title = {NRC Russian-English Machine Translation System for WMT 2016},
 year = {2016}
}

@inproceedings{W16-2318,
 address = {Berlin, Germany},
 author = {Mare\v{c}ek, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2318},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {333--338},
 publisher = {Association for Computational Linguistics},
 title = {Merged bilingual trees based on Universal Dependencies in Machine Translation},
 year = {2016}
}

@inproceedings{W16-2319,
 address = {Berlin, Germany},
 author = {Molchanov, Alexander and Bykov, Fedor},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2319},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {339--343},
 publisher = {Association for Computational Linguistics},
 title = {PROMT Translation Systems for WMT 2016 Translation Tasks},
 year = {2016}
}

@inproceedings{W16-2320,
 address = {Berlin, Germany},
 author = {Peter, Jan-Thorsten and Alkhouli, Tamer and Ney, Hermann and Huck, Matthias and Braune, Fabienne and Fraser, Alexander and Tamchyna, Ale\v{s} and Bojar, Ond\v{r}ej and Haddow, Barry and Sennrich, Rico and Blain, Fr\'{e}d\'{e}ric and Specia, Lucia and Niehues, Jan and Waibel, Alex and Allauzen, Alexandre and Aufrant, Lauriane and Burlot, Franck and knyazeva, elena and Lavergne, Thomas and Yvon, Fran\c{c}ois and Pinnis, M\={a}rcis and Frank, Stella},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2320},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {344--355},
 publisher = {Association for Computational Linguistics},
 title = {The QT21/HimL Combined Machine Translation System},
 year = {2016}
}

@inproceedings{W16-2321,
 address = {Berlin, Germany},
 author = {Peter, Jan-Thorsten and Alkhouli, Tamer and Guta, Andreas and Ney, Hermann},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2321},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {356--361},
 publisher = {Association for Computational Linguistics},
 title = {The RWTH Aachen University English-Romanian Machine Translation System for WMT 2016},
 year = {2016}
}

@inproceedings{W16-2322,
 address = {Berlin, Germany},
 author = {S\'{a}nchez-Cartagena, V\'{i}ctor M. and Toral, Antonio},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2322},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {362--370},
 publisher = {Association for Computational Linguistics},
 title = {Abu-MaTran at WMT 2016 Translation Task: Deep Learning, Morphological Segmentation and Tuning on Character Sequences},
 year = {2016}
}

@inproceedings{W16-2323,
 address = {Berlin, Germany},
 author = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2323},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {371--376},
 publisher = {Association for Computational Linguistics},
 title = {Edinburgh Neural Machine Translation Systems for WMT 16},
 year = {2016}
}

@inproceedings{W16-2324,
 address = {Berlin, Germany},
 author = {Stahlberg, Felix and Hasler, Eva and Byrne, Bill},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2324},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {377--384},
 publisher = {Association for Computational Linguistics},
 title = {The Edit Distance Transducer in Action: The University of Cambridge English-German System at WMT16},
 year = {2016}
}

@inproceedings{W16-2325,
 address = {Berlin, Germany},
 author = {Tamchyna, Ale\v{s} and Sudarikov, Roman and Bojar, Ond\v{r}ej and Fraser, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2325},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {385--390},
 publisher = {Association for Computational Linguistics},
 title = {CUNI-LMU Submissions in WMT2016: Chimera Constrained and Beaten},
 year = {2016}
}

@inproceedings{W16-2326,
 address = {Berlin, Germany},
 author = {Tiedemann, J\"{o}rg and Cap, Fabienne and Kanerva, Jenna and Ginter, Filip and Stymne, Sara and \"{O}stling, Robert and Weller-Di Marco, Marion},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2326},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {391--398},
 publisher = {Association for Computational Linguistics},
 title = {Phrase-Based SMT for Finnish with More Data, Better Models and Alternative Alignment and Translation Tools},
 year = {2016}
}

@inproceedings{W16-2327,
 address = {Berlin, Germany},
 author = {Williams, Philip and Sennrich, Rico and Nadejde, Maria and Huck, Matthias and Haddow, Barry and Bojar, Ond\v{r}ej},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2327},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {399--410},
 publisher = {Association for Computational Linguistics},
 title = {Edinburgh's Statistical Machine Translation Systems for WMT16},
 year = {2016}
}

@inproceedings{W16-2328,
 address = {Berlin, Germany},
 author = {Wolk, Krzysztof and Marasek, Krzysztof},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2328},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {411--414},
 publisher = {Association for Computational Linguistics},
 title = {PJAIT Systems for the WMT 2016},
 year = {2016}
}

@inproceedings{W16-2329,
 address = {Berlin, Germany},
 author = {Avramidis, Eleftherios and Aljoscha Burchardt and Vivien Macketanz and Ankit Srivastava},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2329},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {415--422},
 publisher = {Association for Computational Linguistics},
 title = {DFKI's system for WMT16 IT-domain task, including analysis of systematic errors},
 year = {2016}
}

@inproceedings{W16-2330,
 address = {Berlin, Germany},
 author = {Cuong, Hoang and Frank, Stella and Sima'an, Khalil},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2330},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {423--427},
 publisher = {Association for Computational Linguistics},
 title = {ILLC-UvA Adaptation System (Scorpio) at WMT'16 IT-DOMAIN Task},
 year = {2016}
}

@inproceedings{W16-2331,
 address = {Berlin, Germany},
 author = {Duma, Mirela-Stefania and Menzel, Wolfgang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2331},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {428--434},
 publisher = {Association for Computational Linguistics},
 title = {Data Selection for IT Texts using Paragraph Vector},
 year = {2016}
}

@inproceedings{W16-2332,
 address = {Berlin, Germany},
 author = {Gaudio, Rosa and Labaka, Gorka and Agirre, Eneko and Osenova, Petya and Simov, Kiril and Popel, Martin and Oele, Dieke and van Noord, Gertjan and Gomes, Lu\'{i}s and Ant\'{o}nio Rodrigues, Jo\~{a}o and Neale, Steven and Silva, Jo\~{a}o and Querido, Andreia and Rendeiro, Nuno and Branco, Ant\'{o}nio},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2332},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {435--441},
 publisher = {Association for Computational Linguistics},
 title = {SMT and Hybrid systems of the QTLeap project in the WMT16 IT-task},
 year = {2016}
}

@inproceedings{W16-2333,
 address = {Berlin, Germany},
 author = {Pahari, Koushik and Kuila, Alapan and Pal, Santanu and Naskar, Sudip Kumar and Bandyopadhyay, Sivaji and van Genabith, Josef},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2333},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {442--448},
 publisher = {Association for Computational Linguistics},
 title = {JU-USAAR: A Domain Adaptive MT System},
 year = {2016}
}

@inproceedings{W16-2334,
 address = {Berlin, Germany},
 author = {Rosa, Rudolf and Sudarikov, Roman and Nov\'{a}k, Michal and Popel, Martin and Bojar, Ond\v{r}ej},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2334},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {449--455},
 publisher = {Association for Computational Linguistics},
 title = {Dictionary-based Domain Adaptation of MT Systems without Retraining},
 year = {2016}
}

@inproceedings{W16-2335,
 address = {Berlin, Germany},
 author = {Aires, Jos\'{e} and Lopes, Gabriel and Gomes, Lu\'{i}s},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2335},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {456--462},
 publisher = {Association for Computational Linguistics},
 title = {English-Portuguese Biomedical Translation Task Using a Genuine Phrase-Based Statistical Machine Translation Approach},
 year = {2016}
}

@inproceedings{W16-2336,
 address = {Berlin, Germany},
 author = {Costa-juss\`{a}, Marta R. and Espa\~{n}a-Bonet, Cristina and Madhyastha, Pranava and Escolano, Carlos and Fonollosa, Jos\'{e} A. R.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2336},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {463--468},
 publisher = {Association for Computational Linguistics},
 title = {The TALP--UPC Spanish--English WMT Biomedical Task: Bilingual Embeddings and Char-based Neural Language Model Rescoring in a Phrase-based System},
 year = {2016}
}

@inproceedings{W16-2337,
 address = {Berlin, Germany},
 author = {Ive, Julia and Max, Aur\'{e}lien and Yvon, Fran\c{c}ois},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2337},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {469--476},
 publisher = {Association for Computational Linguistics},
 title = {LIMSI's Contribution to the WMT'16 Biomedical Translation Task},
 year = {2016}
}

@inproceedings{W16-2338,
 address = {Berlin, Germany},
 author = {Perez-de-Vi\~{n}aspre, Olatz and Labaka, Gorka},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2338},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {477--482},
 publisher = {Association for Computational Linguistics},
 title = {IXA Biomedical Translation System at WMT16 Biomedical Translation Task},
 year = {2016}
}

@inproceedings{W16-2339,
 address = {Berlin, Germany},
 author = {Fomicheva, Marina and Bel, N\'{u}ria and Specia, Lucia and da Cunha, Iria and Malinovskiy, Anton},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2339},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {483--490},
 publisher = {Association for Computational Linguistics},
 title = {CobaltF: A Fluent Metric for MT Evaluation},
 year = {2016}
}

@inproceedings{W16-2340,
 address = {Berlin, Germany},
 author = {McCaffery, Martin and Nederhof, Mark-Jan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2340},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {491--498},
 publisher = {Association for Computational Linguistics},
 title = {DTED: Evaluation of Machine Translation Structure Using Dependency Parsing and Tree Edit Distance},
 year = {2016}
}

@inproceedings{W16-2341,
 address = {Berlin, Germany},
 author = {Popovi\'{c}, Maja},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2341},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {499--504},
 publisher = {Association for Computational Linguistics},
 title = {chrF deconstructed: beta parameters and n-gram weights},
 year = {2016}
}

@inproceedings{W16-2342,
 address = {Berlin, Germany},
 author = {Wang, Weiyue and Peter, Jan-Thorsten and Rosendahl, Hendrik and Ney, Hermann},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2342},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {505--510},
 publisher = {Association for Computational Linguistics},
 title = {CharacTer: Translation Edit Rate on Character Level},
 year = {2016}
}

@inproceedings{W16-2343,
 address = {Berlin, Germany},
 author = {Zhang, Lilin and Weng, Zhen and Xiao, Wenyan and Wan, Jianyi and Chen, Zhiming and Tan, Yiming and Li, Maoxi and Wang, Mingwen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2343},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {511--517},
 publisher = {Association for Computational Linguistics},
 title = {Extract Domain-specific Paraphrase from Monolingual Corpus for Automatic Evaluation of Machine Translation},
 year = {2016}
}

@inproceedings{W16-2344,
 address = {Berlin, Germany},
 author = {Kocur, Viktor and Bojar, Ond\v{r}ej},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2344},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {518--524},
 publisher = {Association for Computational Linguistics},
 title = {Particle Swarm Optimization Submission for WMT16 Tuning Task},
 year = {2016}
}

@inproceedings{W16-2345,
 address = {Berlin, Germany},
 author = {Guillou, Liane and Hardmeier, Christian and Nakov, Preslav and Stymne, Sara and Tiedemann, J\"{o}rg and Versley, Yannick and Cettolo, Mauro and Webber, Bonnie and Popescu-Belis, Andrei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2345},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {525--542},
 publisher = {Association for Computational Linguistics},
 title = {Findings of the 2016 WMT Shared Task on Cross-lingual Pronoun Prediction},
 year = {2016}
}

@inproceedings{W16-2346,
 address = {Berlin, Germany},
 author = {Specia, Lucia and Frank, Stella and Sima'an, Khalil and Elliott, Desmond},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2346},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {543--553},
 publisher = {Association for Computational Linguistics},
 title = {A Shared Task on Multimodal Machine Translation and Crosslingual Image Description},
 year = {2016}
}

@inproceedings{W16-2347,
 address = {Berlin, Germany},
 author = {Buck, Christian and Koehn, Philipp},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2347},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {554--563},
 publisher = {Association for Computational Linguistics},
 title = {Findings of the WMT 2016 Bilingual Document Alignment Shared Task},
 year = {2016}
}

@inproceedings{W16-2348,
 address = {Berlin, Germany},
 author = {Bawden, Rachel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2348},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {564--570},
 publisher = {Association for Computational Linguistics},
 title = {Cross-lingual Pronoun Prediction with Linguistically Informed Features},
 year = {2016}
}

@inproceedings{W16-2349,
 address = {Berlin, Germany},
 author = {Dabre, Raj and Puzikov, Yevgeniy and Cromieres, Fabien and Kurohashi, Sadao},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2349},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {571--575},
 publisher = {Association for Computational Linguistics},
 title = {The Kyoto University Cross-Lingual Pronoun Translation System},
 year = {2016}
}

@inproceedings{W16-2350,
 address = {Berlin, Germany},
 author = {Hardmeier, Christian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2350},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {576--580},
 publisher = {Association for Computational Linguistics},
 title = {Pronoun Prediction with Latent Anaphora Resolution},
 year = {2016}
}

@inproceedings{W16-2351,
 address = {Berlin, Germany},
 author = {Lo\'{a}iciga, Sharid and Guillou, Liane and Hardmeier, Christian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2351},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {581--588},
 publisher = {Association for Computational Linguistics},
 title = {It-disambiguation and source-aware language models for cross-lingual pronoun prediction},
 year = {2016}
}

@inproceedings{W16-2352,
 address = {Berlin, Germany},
 author = {Luong, Ngoc Quang and Popescu-Belis, Andrei},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2352},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {589--595},
 publisher = {Association for Computational Linguistics},
 title = {Pronoun Language Model and Grammatical Heuristics for Aiding Pronoun Prediction},
 year = {2016}
}

@inproceedings{W16-2353,
 address = {Berlin, Germany},
 author = {Luotolahti, Juhani and Kanerva, Jenna and Ginter, Filip},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2353},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {596--601},
 publisher = {Association for Computational Linguistics},
 title = {Cross-Lingual Pronoun Prediction with Deep Recurrent Neural Networks},
 year = {2016}
}

@inproceedings{W16-2354,
 address = {Berlin, Germany},
 author = {Nov\'{a}k, Michal},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2354},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {602--608},
 publisher = {Association for Computational Linguistics},
 title = {Pronoun Prediction with Linguistic Features and Example Weighing},
 year = {2016}
}

@inproceedings{W16-2355,
 address = {Berlin, Germany},
 author = {Stymne, Sara},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2355},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {609--615},
 publisher = {Association for Computational Linguistics},
 title = {Feature Exploration for Cross-Lingual Pronoun Prediction},
 year = {2016}
}

@inproceedings{W16-2356,
 address = {Berlin, Germany},
 author = {Tiedemann, J\"{o}rg},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2356},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {616--619},
 publisher = {Association for Computational Linguistics},
 title = {A Linear Baseline Classifier for Cross-Lingual Pronoun Prediction},
 year = {2016}
}

@inproceedings{W16-2357,
 address = {Berlin, Germany},
 author = {Wetzel, Dominikus},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2357},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {620--626},
 publisher = {Association for Computational Linguistics},
 title = {Cross-lingual Pronoun Prediction for English, French and German with Maximum Entropy Classification},
 year = {2016}
}

@inproceedings{W16-2358,
 address = {Berlin, Germany},
 author = {Caglayan, Ozan and Aransa, Walid and Wang, Yaxing and Masana, Marc and Garc\'{i}a-Mart\'{i}nez, Mercedes and Bougares, Fethi and Barrault, Lo\"{i}c and van de Weijer, Joost},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2358},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {627--633},
 publisher = {Association for Computational Linguistics},
 title = {Does Multimodality Help Human and Machine for Translation and Image Captioning?},
 year = {2016}
}

@inproceedings{W16-2359,
 address = {Berlin, Germany},
 author = {Calixto, Iacer and Elliott, Desmond and Frank, Stella},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2359},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {634--638},
 publisher = {Association for Computational Linguistics},
 title = {DCU-UvA Multimodal MT System Report},
 year = {2016}
}

@inproceedings{W16-2360,
 address = {Berlin, Germany},
 author = {Huang, Po-Yao and Liu, Frederick and Shiang, Sz-Rung and Oh, Jean and Dyer, Chris},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2360},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {639--645},
 publisher = {Association for Computational Linguistics},
 title = {Attention-based Multimodal Neural Machine Translation},
 year = {2016}
}

@inproceedings{W16-2361,
 address = {Berlin, Germany},
 author = {Libovick\'{y}, Jind\v{r}ich and Helcl, Jind\v{r}ich and Tlust\'{y}, Marek and Bojar, Ond\v{r}ej and Pecina, Pavel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2361},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {646--654},
 publisher = {Association for Computational Linguistics},
 title = {CUNI System for WMT16 Automatic Post-Editing and Multimodal Translation Tasks},
 year = {2016}
}

@inproceedings{W16-2362,
 address = {Berlin, Germany},
 author = {Rodr\'{i}guez Guasch, Sergio and Costa-juss\`{a}, Marta R.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2362},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {655--659},
 publisher = {Association for Computational Linguistics},
 title = {WMT 2016 Multimodal Translation System Description based on Bidirectional Recurrent Neural Networks with Double-Embeddings},
 year = {2016}
}

@inproceedings{W16-2363,
 address = {Berlin, Germany},
 author = {Shah, Kashif and Wang, Josiah and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2363},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {660--665},
 publisher = {Association for Computational Linguistics},
 title = {SHEF-Multimodal: Grounding Machine Translation on Images},
 year = {2016}
}

@inproceedings{W16-2364,
 address = {Berlin, Germany},
 author = {Azpeitia, Andoni and Etchegoyhen, Thierry},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2364},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {666--671},
 publisher = {Association for Computational Linguistics},
 title = {DOCAL - Vicomtech's Participation in the WMT16 Shared Task on Bilingual Document Alignment},
 year = {2016}
}

@inproceedings{W16-2365,
 address = {Berlin, Germany},
 author = {Buck, Christian and Koehn, Philipp},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2365},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {672--678},
 publisher = {Association for Computational Linguistics},
 title = {Quick and Reliable Document Alignment via TF/IDF-weighted Cosine Distance},
 year = {2016}
}

@inproceedings{W16-2366,
 address = {Berlin, Germany},
 author = {Dara, Aswarth Abhilash and Lin, Yiu-Chang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2366},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {679--684},
 publisher = {Association for Computational Linguistics},
 title = {YODA System for WMT16 Shared Task: Bilingual Document Alignment},
 year = {2016}
}

@inproceedings{W16-2367,
 address = {Berlin, Germany},
 author = {Espl\`{a}-Gomis, Miquel and Forcada, Mikel and Ortiz Rojas, Sergio and Ferr\'{a}ndez-Tordera, Jorge},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2367},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {685--691},
 publisher = {Association for Computational Linguistics},
 title = {Bitextor's participation in WMT'16: shared task on document alignment},
 year = {2016}
}

@inproceedings{W16-2368,
 address = {Berlin, Germany},
 author = {Germann, Ulrich},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2368},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {692--696},
 publisher = {Association for Computational Linguistics},
 title = {Bilingual Document Alignment with Latent Semantic Indexing},
 year = {2016}
}

@inproceedings{W16-2369,
 address = {Berlin, Germany},
 author = {Gomes, Lu\'{i}s and Pereira Lopes, Gabriel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2369},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {697--702},
 publisher = {Association for Computational Linguistics},
 title = {First Steps Towards Coverage-Based Document Alignment},
 year = {2016}
}

@inproceedings{W16-2370,
 address = {Berlin, Germany},
 author = {Jakubina, Laurent and Langlais, Phillippe},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2370},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {703--709},
 publisher = {Association for Computational Linguistics},
 title = {BAD LUC$@$WMT 2016: a Bilingual Document Alignment Platform Based on Lucene},
 year = {2016}
}

@inproceedings{W16-2371,
 address = {Berlin, Germany},
 author = {Le, Thanh and Vu, Hoa Trong and Oberl\"{a}nder, Jonathan and Bojar, Ond\v{r}ej},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2371},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {710--716},
 publisher = {Association for Computational Linguistics},
 title = {Using Term Position Similarity and Language Modeling for Bilingual Document Alignment},
 year = {2016}
}

@inproceedings{W16-2372,
 address = {Berlin, Germany},
 author = {Lohar, Pintu and Afli, Haithem and Liu, Chao-Hong and Way, Andy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2372},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {717--723},
 publisher = {Association for Computational Linguistics},
 title = {The ADAPT Bilingual Document Alignment system at WMT16},
 year = {2016}
}

@inproceedings{W16-2373,
 address = {Berlin, Germany},
 author = {Mahata, Sainik and Das, Dipankar and Pal, Santanu},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2373},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {724--727},
 publisher = {Association for Computational Linguistics},
 title = {WMT2016: A Hybrid Approach to Bilingual Document Alignment},
 year = {2016}
}

@inproceedings{W16-2374,
 address = {Berlin, Germany},
 author = {Medve{\"A}, Marek and Jakub\'{i}cek, Milo\v{s} and Kov\'{a}r, Vojtech},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2374},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {728--732},
 publisher = {Association for Computational Linguistics},
 title = {English-French Document Alignment Based on Keywords and Statistical Translation},
 year = {2016}
}

@inproceedings{W16-2375,
 address = {Berlin, Germany},
 author = {Papavassiliou, Vassilis and Prokopidis, Prokopis and Piperidis, Stelios},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2375},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {733--739},
 publisher = {Association for Computational Linguistics},
 title = {The ILSP/ARC submission to the WMT 2016 Bilingual Document Alignment Shared Task},
 year = {2016}
}

@inproceedings{W16-2376,
 address = {Berlin, Germany},
 author = {Shchukin, Vadim and Khristich, Dmitry and Galinskaya, Irina},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2376},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {740--744},
 publisher = {Association for Computational Linguistics},
 title = {Word Clustering Approach to Bilingual Document Alignment (WMT 2016 Shared Task)},
 year = {2016}
}

@inproceedings{W16-2377,
 address = {Berlin, Germany},
 author = {Chatterjee, Rajen and C. de Souza, Jos\'{e} G. and Negri, Matteo and Turchi, Marco},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2377},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {745--750},
 publisher = {Association for Computational Linguistics},
 title = {The FBK Participation in the WMT 2016 Automatic Post-editing Shared Task},
 year = {2016}
}

@inproceedings{W16-2378,
 address = {Berlin, Germany},
 author = {Junczys-Dowmunt, Marcin and Grundkiewicz, Roman},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2378},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {751--758},
 publisher = {Association for Computational Linguistics},
 title = {Log-linear Combinations of Monolingual and Bilingual Neural Machine Translation Models for Automatic Post-Editing},
 year = {2016}
}

@inproceedings{W16-2379,
 address = {Berlin, Germany},
 author = {Pal, Santanu and Zampieri, Marcos and van Genabith, Josef},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2379},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {759--763},
 publisher = {Association for Computational Linguistics},
 title = {USAAR: An Operation Sequential Model for Automatic Statistical Post-Editing},
 year = {2016}
}

@inproceedings{W16-2380,
 address = {Berlin, Germany},
 author = {Abdelsalam, Amal and Bojar, Ond\v{r}ej and El-Beltagy, Samhaa},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2380},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {764--771},
 publisher = {Association for Computational Linguistics},
 title = {Bilingual Embeddings and Word Alignments for Translation Quality Estimation},
 year = {2016}
}

@inproceedings{W16-2381,
 address = {Berlin, Germany},
 author = {Beck, Daniel and Vlachos, Andreas and Paetzold, Gustavo and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2381},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {772--776},
 publisher = {Association for Computational Linguistics},
 title = {SHEF-MIME: Word-level Quality Estimation Using Imitation Learning},
 year = {2016}
}

@inproceedings{W16-2382,
 address = {Berlin, Germany},
 author = {Bicici, Ergun},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2382},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {777--781},
 publisher = {Association for Computational Linguistics},
 title = {Referential Translation Machines for Predicting Translation Performance},
 year = {2016}
}

@inproceedings{W16-2383,
 address = {Berlin, Germany},
 author = {Espl\`{a}-Gomis, Miquel and S\'{a}nchez-Mart\'{i}nez, Felipe and Forcada, Mikel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2383},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {782--786},
 publisher = {Association for Computational Linguistics},
 title = {UAlacant word-level and phrase-level machine translation quality estimation systems at WMT 2016},
 year = {2016}
}

@inproceedings{W16-2384,
 address = {Berlin, Germany},
 author = {Kim, Hyun and Lee, Jong-Hyeok},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2384},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {787--792},
 publisher = {Association for Computational Linguistics},
 title = {Recurrent Neural Network based Translation Quality Estimation},
 year = {2016}
}

@inproceedings{W16-2385,
 address = {Berlin, Germany},
 author = {Kozlova, Anna and Shmatova, Mariya and Frolov, Anton},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2385},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {793--799},
 publisher = {Association for Computational Linguistics},
 title = {YSDA Participation in the WMT'16 Quality Estimation Shared Task},
 year = {2016}
}

@inproceedings{W16-2386,
 address = {Berlin, Germany},
 author = {Logacheva, Varvara and Blain, Fr\'{e}d\'{e}ric and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2386},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {800--805},
 publisher = {Association for Computational Linguistics},
 title = {USFD{\^a}s Phrase-level Quality Estimation Systems},
 year = {2016}
}

@inproceedings{W16-2387,
 address = {Berlin, Germany},
 author = {Martins, Andr\'{e} F. T. and Astudillo, Ram\'{o}n and Hokamp, Chris and Kepler, Fabio},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2387},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {806--811},
 publisher = {Association for Computational Linguistics},
 title = {Unbabel's Participation in the WMT16 Word-Level Translation Quality Estimation Shared Task},
 year = {2016}
}

@inproceedings{W16-2388,
 address = {Berlin, Germany},
 author = {Paetzold, Gustavo and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2388},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {812--818},
 publisher = {Association for Computational Linguistics},
 title = {SimpleNets: Quality Estimation with Resource-Light Neural Networks},
 year = {2016}
}

@inproceedings{W16-2389,
 address = {Berlin, Germany},
 author = {Patel, Raj Nath and M, Sasikumar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2389},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {819--824},
 publisher = {Association for Computational Linguistics},
 title = {Translation Quality Estimation using Recurrent Neural Network},
 year = {2016}
}

@inproceedings{W16-2390,
 address = {Berlin, Germany},
 author = {Sagemo, Oscar and Stymne, Sara},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2390},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {825--830},
 publisher = {Association for Computational Linguistics},
 title = {The UU Submission to the Machine Translation Quality Estimation Task},
 year = {2016}
}

@inproceedings{W16-2391,
 address = {Berlin, Germany},
 author = {Scarton, Carolina and Beck, Daniel and Shah, Kashif and Sim Smith, Karin and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2391},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {831--837},
 publisher = {Association for Computational Linguistics},
 title = {Word embeddings and discourse information for Quality Estimation},
 year = {2016}
}

@inproceedings{W16-2392,
 address = {Berlin, Germany},
 author = {Shah, Kashif and Bougares, Fethi and Barrault, Lo\"{i}c and Specia, Lucia},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2392},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {838--842},
 publisher = {Association for Computational Linguistics},
 title = {SHEF-LIUM-NN: Sentence level Quality Estimation with Neural Network Features},
 year = {2016}
}

@inproceedings{W16-2393,
 address = {Berlin, Germany},
 author = {Tezcan, Arda and Hoste, V\'{e}ronique and Macken, Lieve},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-2393},
 booktitle = {Proceedings of the First Conference on Machine Translation},
 month = {August},
 pages = {843--850},
 publisher = {Association for Computational Linguistics},
 title = {UGENT-LT3 SCATE Submission for WMT16 Shared Task on Quality Estimation},
 year = {2016}
}

@inproceedings{W16-3301,
 address = {D{\~A}¼sseldorf, Germany},
 author = {Torr, John and Stabler, Edward P.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3301},
 booktitle = {Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+12)},
 month = {June},
 pages = {1--17},
 title = {Coordination in Minimalist Grammars: Excorporation and Across the Board (Head) Movement},
 year = {2016}
}

@inproceedings{W16-3302,
 address = {D{\~A}¼sseldorf, Germany},
 author = {Ben Khelil, Ch\'{e}rifa and Duchier, Denys and Parmentier, Yannick and Zribi, Chiraz and Ben Fraj, F\'{e}riel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3302},
 booktitle = {Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+12)},
 month = {June},
 pages = {18--26},
 title = {ArabTAG: from a Handcrafted to a Semi-automatically Generated TAG},
 year = {2016}
}

@inproceedings{W16-3303,
 address = {D{\~A}¼sseldorf, Germany},
 author = {Danlos, Laurence and Maskharashvili, Aleksandre and Pogodalla, Sylvain},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3303},
 booktitle = {Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+12)},
 month = {June},
 pages = {27--37},
 title = {Interfacing Sentential and Discourse TAG-based Grammars},
 year = {2016}
}

@inproceedings{W16-3304,
 address = {D{\~A}¼sseldorf, Germany},
 author = {Bernard, Timoth\'{e}e and Danlos, Laurence},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3304},
 booktitle = {Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+12)},
 month = {June},
 pages = {38--47},
 title = {Modelling Discourse in STAG: Subordinate Conjunctions and Attributing Phrases},
 year = {2016}
}

@inproceedings{W16-3305,
 address = {D{\~A}¼sseldorf, Germany},
 author = {Kallmeyer, Laura and Lichte, Timm and Oswald, Rainer and Petitjean, Simon},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3305},
 booktitle = {Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+12)},
 month = {June},
 pages = {48--57},
 title = {Argument linking in LTAG: A constraint-based implementation with XMG},
 year = {2016}
}

@inproceedings{W16-3306,
 address = {D{\~A}¼sseldorf, Germany},
 author = {Balogh, Kata},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3306},
 booktitle = {Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+12)},
 month = {June},
 pages = {58--66},
 title = {Verbal fields in Hungarian simple sentences and infinitival clausal complements},
 year = {2016}
}

@inproceedings{W16-3307,
 address = {D{\~A}¼sseldorf, Germany},
 author = {Storoshenko, Dennis Ryan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3307},
 booktitle = {Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+12)},
 month = {June},
 pages = {67--76},
 title = {Modelling the ziji Blocking Effect and Constraining Bound Variable Derivations in MC-TAG with Delayed Locality},
 year = {2016}
}

@inproceedings{W16-3308,
 address = {D{\~A}¼sseldorf, Germany},
 author = {Sloan, Rose},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3308},
 booktitle = {Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+12)},
 month = {June},
 pages = {77--84},
 title = {Node-based Induction of Tree-Substitution Grammars},
 year = {2016}
}

@inproceedings{W16-3309,
 address = {D{\~A}¼sseldorf, Germany},
 author = {Chung, Wonchang and Mhatre, Suhas Siddhesh and Nasr, Alexis and Rambow, Owen and Bangalore, Srinivas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3309},
 booktitle = {Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+12)},
 month = {June},
 pages = {85--92},
 title = {Revisiting Supertagging and Parsing: How to Use Supertags in Transition-Based Parsing},
 year = {2016}
}

@inproceedings{W16-3310,
 address = {D{\~A}¼sseldorf, Germany},
 author = {De Santo, Aniello and Aks\"{e}nova, Al\"{e}na and Graf, Thomas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3310},
 booktitle = {Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+12)},
 month = {June},
 pages = {93--102},
 title = {An Alternate View on Strong Lexicalization in TAG},
 year = {2016}
}

@inproceedings{W16-3311,
 address = {D{\~A}¼sseldorf, Germany},
 author = {Bauer, Daniel and Rambow, Owen},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3311},
 booktitle = {Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+12)},
 month = {June},
 pages = {103--111},
 title = {Hyperedge Replacement and Nonprojective Dependency Structures},
 year = {2016}
}

@inproceedings{W16-3312,
 address = {D{\~A}¼sseldorf, Germany},
 author = {Storoshenko, Dennis Ryan and Frank, Robert},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3312},
 booktitle = {Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+12)},
 month = {June},
 pages = {112--120},
 title = {Parasitic Gaps and the Heterogeneity of Dependency Formation in STAG},
 year = {2016}
}

@article{W16-3401,
 author = {Oliver \v{C}ulo and Jean Nitzke},
 date-modified = {2018-02-13 04:01:43 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {106--114},
 title = {Patterns of Terminological Variation in Post-editing and of Cognate Use in Machine Translation in Contrast to Human Translation},
 volume = {4},
 year = {2016}
}

@article{W16-3402,
 author = {Bogdan Babych},
 date-modified = {2018-02-13 04:02:00 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {115--128},
 title = {Graphonological Levenshtein Edit Distance: Application for Automated Cognate Identification},
 volume = {4},
 year = {2016}
}

@article{W16-3403,
 author = {Peyman Passban and Chris Hokamp and Andy Way and Qun Liu},
 date-modified = {2018-02-13 04:02:07 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {129--140},
 title = {Improving Phrase-Based SMT Using Cross-Granularity Embedding Similarity},
 volume = {4},
 year = {2016}
}

@article{W16-3404,
 author = {Joss Moorkens and Andy Way},
 date-modified = {2018-02-13 04:02:13 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {141--151},
 title = {Comparing Translator Acceptability of TM and SMT Outputs},
 volume = {4},
 year = {2016}
}

@article{W16-3405,
 author = {Mikel Forcada and Miquel Espl\`a-Gomis and Juan Antonio P\'erez-Ortiz},
 date-modified = {2018-02-13 04:02:19 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {152--164},
 title = {Stand-off Annotation of Web Content as a Legally Safer Alternative to Crawling for Distribution},
 volume = {4},
 year = {2016}
}

@article{W16-3406,
 author = {Liangyou Li and Carla Parra Escartin and Qun Liu},
 date-modified = {2018-02-13 04:02:24 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {165--177},
 title = {Combining Translation Memories and Syntax-Based SMT: Experiments with Real Industrial Data},
 volume = {4},
 year = {2016}
}

@article{W16-3407,
 author = {Karin Sim Smith and Wilker Aziz and Lucia Specia},
 date-modified = {2018-02-13 04:02:29 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {178--189},
 title = {The Trouble with Machine Translation Coherence},
 volume = {4},
 year = {2016}
}

@article{W16-3408,
 author = {Duc Tam Hoang and Ondrej Bojar},
 date-modified = {2018-02-13 04:02:34 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {190--202},
 title = {Pivoting Methods and Data for Czech-Vietnamese Translation via English},
 volume = {4},
 year = {2016}
}

@article{W16-3409,
 author = {Arda Tezcan and Veronique Hoste and Lieve Macken},
 date-modified = {2018-02-13 04:02:39 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {203--217},
 title = {Detecting Grammatical Errors in Machine Translation Output Using Dependency Parsing and Treebank Querying},
 volume = {4},
 year = {2016}
}

@article{W16-3410,
 author = {Maja Popovic and Mihael Ar\v{c}an and Arle Lommel},
 date-modified = {2018-02-13 04:02:47 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {218--229},
 title = {Potential and Limits of Using Post-edits as Reference Translations for MT Evaluation},
 volume = {4},
 year = {2016}
}

@article{W16-3411,
 author = {Sanja \v{S}tajner and Maja Popovic},
 date-modified = {2018-02-13 04:02:59 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {230--242},
 title = {Can Text Simplification Help Machine Translation?},
 volume = {4},
 year = {2016}
}

@article{W16-3412,
 author = {Thierry Etchegoyhen and Andoni Azpeitia},
 date-modified = {2018-02-13 04:03:03 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {243--255},
 title = {A Portable Method for Parallel and Comparable Document Alignment},
 volume = {4},
 year = {2016}
}

@article{W16-3413,
 author = {Hanna Bechara and Carla Parra Escartin and Constantin Orasan and Lucia Specia},
 date-modified = {2018-02-13 04:03:09 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {256--268},
 title = {Semantic Textual Similarity in Quality Estimation},
 volume = {4},
 year = {2016}
}

@article{W16-3414,
 author = {Aaron Smith and Christian Hardmeier and Joerg Tiedemann},
 date-modified = {2018-02-13 04:03:14 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {269--281},
 title = {Climbing Mont BLEU: The Strange World of Reachable High-BLEU Translations},
 volume = {4},
 year = {2016}
}

@article{W16-3415,
 author = {Miguel Domingo and Alvaro Peris and Francisco Casacuberta},
 date-modified = {2018-02-13 04:03:20 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {282--291},
 title = {Interactive-Predictive Translation Based on Multiple Word-Segments},
 volume = {4},
 year = {2016}
}

@article{W16-3416,
 author = {Ngoc Quang Luong and Andrei Popescu-Belis},
 date-modified = {2018-02-13 04:03:26 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {292--304},
 title = {A Contextual Language Model to Improve Machine Translation of Pronouns by Re-ranking Translation Hypotheses},
 volume = {4},
 year = {2016}
}

@article{W16-3417,
 author = {David Steele and Lucia Specia},
 date-modified = {2018-02-13 04:03:32 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {305--317},
 title = {Predicting and Using Implicit Discourse Elements in Chinese-English Translation},
 volume = {4},
 year = {2016}
}

@article{W16-3418,
 author = {Christian Hardmeier and Liane Guillou},
 date-modified = {2018-02-13 04:03:44 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {318--330},
 title = {A Graphical Pronoun Analysis Tool for the PROTEST Pronoun Evaluation Test Suite},
 volume = {4},
 year = {2016}
}

@article{W16-3419,
 author = {Moritz Jonas Schaeffer and Michael Carl and Isabel Lacruz and Akiko Aizawa},
 date-modified = {2018-02-13 04:03:48 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {331--345},
 title = {Measuring Cognitive Translation Effort with Activity Units},
 volume = {4},
 year = {2016}
}

@article{W16-3420,
 author = {Ke Hu and Patrick Cadwell},
 date-modified = {2018-02-13 04:03:55 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {346--353},
 title = {A Comparative Study of Post-editing Guidelines},
 volume = {4},
 year = {2016}
}

@article{W16-3421,
 author = {Victor M. S\'anchez-Cartagena and Nikola Ljube\v{s}i\'c and Filip Klubi\v{c}ka},
 date-modified = {2018-02-13 04:03:59 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {354--360},
 title = {Dealing with Data Sparseness in SMT with Factured Models and Morphological Expansion: a Case Study on Croatian},
 volume = {4},
 year = {2016}
}

@article{W16-3422,
 author = {Filip Klubi\v{c}ka and Gema Ram\'irez-S\'anchez and Nikola Ljube\v{s}i\'c},
 date-modified = {2018-02-13 04:04:04 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {361--367},
 title = {Collaborative Development of a Rule-Based Machine Translator between Croatian and Serbian},
 volume = {4},
 year = {2016}
}

@article{W16-3423,
 author = {Antonio Toral and Raphael Rubino and Gema Ram\'irez-S\'anchez},
 date-modified = {2018-02-13 04:04:09 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {368--375},
 title = {Re-assessing the Impact of SMT Techniques with Human Evaluation: a Case Study on English{\^a}Croatian},
 volume = {4},
 year = {2016}
}

@article{W16-3424,
 author = {European Association for Machine Translation},
 date-modified = {2018-02-13 04:04:14 +0000},
 journal = {Baltic Journal of Modern Computing},
 number = {2},
 pages = {376--400},
 title = {Proceedings of the 19th Annual Conference of the EAMT: Projects/Products},
 volume = {4},
 year = {2016}
}

@inproceedings{W16-3601,
 address = {Los Angeles},
 author = {Zhao, Tiancheng and Eskenazi, Maxine},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3601},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Towards End-to-End Learning for Dialog State Tracking and Management using Deep Reinforcement Learning},
 year = {2016}
}

@inproceedings{W16-3602,
 address = {Los Angeles},
 author = {Lee, Sungjin and Stent, Amanda},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3602},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {11--21},
 publisher = {Association for Computational Linguistics},
 title = {Task Lineages: Dialog State Tracking for Flexible Interaction},
 year = {2016}
}

@inproceedings{W16-3603,
 address = {Los Angeles},
 author = {Liu, Bing and Lane, Ian},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3603},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {22--30},
 publisher = {Association for Computational Linguistics},
 title = {Joint Online Spoken Language Understanding and Language Modeling With Recurrent Neural Networks},
 year = {2016}
}

@inproceedings{W16-3604,
 address = {Los Angeles},
 author = {Oraby, Shereen and Harrison, Vrindavan and Reed, Lena and Hernandez, Ernesto and Riloff, Ellen and Walker, Marilyn},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3604},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {31--41},
 publisher = {Association for Computational Linguistics},
 title = {Creating and Characterizing a Diverse Corpus of Sarcasm in Dialogue},
 year = {2016}
}

@inproceedings{W16-3605,
 address = {Los Angeles},
 author = {Barker, Emma and Paramita, Monica Lestari and Aker, Ahmet and Kurtic, Emina and Hepple, Mark and Gaizauskas, Robert},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3605},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {42--52},
 publisher = {Association for Computational Linguistics},
 title = {The SENSEI Annotated Corpus: Human Summaries of Reader Comment Conversations in On-line News},
 year = {2016}
}

@inproceedings{W16-3606,
 address = {Los Angeles},
 author = {Matsuyama, Yoichi and Papangelis, Alexandros},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3606},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {53},
 publisher = {Association for Computational Linguistics},
 title = {Special Session - The Future Directions of Dialogue-Based Intelligent Personal Assistants},
 year = {2016}
}

@inproceedings{W16-3607,
 address = {Los Angeles},
 author = {Brennan, Susan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3607},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {54},
 publisher = {Association for Computational Linguistics},
 title = {Keynote - More than meets the ear: Processes that shape dialogue},
 year = {2016}
}

@inproceedings{W16-3608,
 address = {Los Angeles},
 author = {Yu, Zhou and Nicolich-Henkin, Leah and Black, Alan W and Rudnicky, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3608},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {55--63},
 publisher = {Association for Computational Linguistics},
 title = {A Wizard-of-Oz Study on A Non-Task-Oriented Dialog Systems That Reacts to User Engagement},
 year = {2016}
}

@inproceedings{W16-3609,
 address = {Los Angeles},
 author = {Herzig, Jonathan and Feigenblat, Guy and Shmueli-Scheuer, Michal and Konopnicki, David and Rafaeli, Anat and Altman, Daniel and Spivak, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3609},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {64--73},
 publisher = {Association for Computational Linguistics},
 title = {Classifying Emotions in Customer Support Dialogues in Social Media},
 year = {2016}
}

@inproceedings{W16-3610,
 address = {Los Angeles},
 author = {Miehle, Juliana and Yoshino, Koichiro and Pragst, Louisa and Ultes, Stefan and Nakamura, Satoshi and Minker, Wolfgang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3610},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {74--79},
 publisher = {Association for Computational Linguistics},
 title = {Cultural Communication Idiosyncrasies in Human-Computer Interaction},
 year = {2016}
}

@inproceedings{W16-3611,
 address = {Los Angeles},
 author = {Casanueva, I\~{n}igo and Hain, Thomas and Nicolao, Mauro and Green, Phil},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3611},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {80--89},
 publisher = {Association for Computational Linguistics},
 title = {Using phone features to improve dialogue state tracking generalisation to unseen states},
 year = {2016}
}

@inproceedings{W16-3612,
 address = {Los Angeles},
 author = {Chen, Yu-Hsin and Choi, Jinho D.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3612},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {90--100},
 publisher = {Association for Computational Linguistics},
 title = {Character Identification on Multiparty Conversation: Identifying Mentions of Characters in TV Shows},
 year = {2016}
}

@inproceedings{W16-3613,
 address = {Los Angeles},
 author = {Fatemi, Mehdi and El Asri, Layla and Schulz, Hannes and He, Jing and Suleman, Kaheer},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3613},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {101--110},
 publisher = {Association for Computational Linguistics},
 title = {Policy Networks with Two-Stage Training for Dialogue Systems},
 year = {2016}
}

@inproceedings{W16-3614,
 address = {Los Angeles},
 author = {Ravi, Satheesh and Artstein, Ron},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3614},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {111--116},
 publisher = {Association for Computational Linguistics},
 title = {Language Portability for Dialogue Systems: Translating a Question-Answering System from English into Tamil},
 year = {2016}
}

@inproceedings{W16-3615,
 address = {Los Angeles},
 author = {Forbes-Riley, Kate and Zhang, Fan and Litman, Diane},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3615},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {117--127},
 publisher = {Association for Computational Linguistics},
 title = {Extracting PDTB Discourse Relations from Student Essays},
 year = {2016}
}

@inproceedings{W16-3616,
 address = {Los Angeles},
 author = {Hayashi, Katsuhiko and Hirao, Tsutomu and Nagata, Masaaki},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3616},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {128--136},
 publisher = {Association for Computational Linguistics},
 title = {Empirical comparison of dependency conversions for RST discourse trees},
 year = {2016}
}

@inproceedings{W16-3617,
 address = {Los Angeles},
 author = {Li, Junyi Jessy and Thadani, Kapil and Stent, Amanda},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3617},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {137--147},
 publisher = {Association for Computational Linguistics},
 title = {The Role of Discourse Units in Near-Extractive Summarization},
 year = {2016}
}

@inproceedings{W16-3618,
 address = {Los Angeles},
 author = {Nicolich-Henkin, Leah and Rose, Carolyn and Black, Alan W},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3618},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {148--156},
 publisher = {Association for Computational Linguistics},
 title = {Initiations and Interruptions in a Spoken Dialog System},
 year = {2016}
}

@inproceedings{W16-3619,
 address = {Los Angeles},
 author = {Hirano, Toru and Higashinaka, Ryuichiro and Matsuo, Yoshihiro},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3619},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {157--165},
 publisher = {Association for Computational Linguistics},
 title = {Analyzing Post-dialogue Comments by Speakers -- How Do Humans Personalize Their Utterances in Dialogue? --},
 year = {2016}
}

@inproceedings{W16-3620,
 address = {Los Angeles},
 author = {Davoodi, Elnaz and Kosseim, Leila},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3620},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {166--174},
 publisher = {Association for Computational Linguistics},
 title = {On the Contribution of Discourse Structure on Text Complexity Assessment},
 year = {2016}
}

@inproceedings{W16-3621,
 address = {Los Angeles},
 author = {Nasr, Alexis and Damnati, Geraldine and Guerraz, Aleksandra and Bechet, Frederic},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3621},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {175--184},
 publisher = {Association for Computational Linguistics},
 title = {Syntactic parsing of chat language in contact center conversation corpus},
 year = {2016}
}

@inproceedings{W16-3622,
 address = {Los Angeles},
 author = {Du\v{s}ek, Ond\v{r}ej and Jurcicek, Filip},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3622},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {185--190},
 publisher = {Association for Computational Linguistics},
 title = {A Context-aware Natural Language Generator for Dialogue Systems},
 year = {2016}
}

@inproceedings{W16-3623,
 address = {Los Angeles},
 author = {Blanchard, Nathaniel and Donnelly, Patrick and Olney, Andrew M. and Borhan, Samei and Ward, Brooke and Sun, Xiaoyi and Kelly, Sean and Nystrand, Martin and D'Mello, Sidney K.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3623},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {191--201},
 publisher = {Association for Computational Linguistics},
 title = {Identifying Teacher Questions Using Automatic Speech Recognition in Classrooms},
 year = {2016}
}

@inproceedings{W16-3624,
 address = {Los Angeles},
 author = {Laskowski, Kornel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3624},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {202--211},
 publisher = {Association for Computational Linguistics},
 title = {A framework for the automatic inference of stochastic turn-taking styles},
 year = {2016}
}

@inproceedings{W16-3625,
 address = {Los Angeles},
 author = {Inoue, Koji and Milhorat, Pierrick and Lala, Divesh and Zhao, Tianyu and Kawahara, Tatsuya},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3625},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {212--215},
 publisher = {Association for Computational Linguistics},
 title = {Talking with ERICA, an autonomous android},
 year = {2016}
}

@inproceedings{W16-3626,
 address = {Los Angeles},
 author = {Stoyanchev, Svetlana and Lison, Pierre and Bangalore, Srinivas},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3626},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {216--219},
 publisher = {Association for Computational Linguistics},
 title = {Rapid Prototyping of Form-driven Dialogue Systems Using an Open-source Framework},
 year = {2016}
}

@inproceedings{W16-3627,
 address = {Los Angeles},
 author = {Ivanov, Alexei V. and Lange, Patrick L. and Suendermann-Oeft, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3627},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {220--223},
 publisher = {Association for Computational Linguistics},
 title = {LVCSR System on a Hybrid GPU-CPU Embedded Platform for Real-Time Dialog Applications},
 year = {2016}
}

@inproceedings{W16-3628,
 address = {Los Angeles},
 author = {Matsuyama, Yoichi and Bhardwaj, Arjun and Zhao, Ran and Romeo, Oscar and Akoju, Sushma and Cassell, Justine},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3628},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {224--227},
 publisher = {Association for Computational Linguistics},
 title = {Socially-Aware Animated Intelligent Personal Assistant Agent},
 year = {2016}
}

@inproceedings{W16-3629,
 address = {Los Angeles},
 author = {Mori, Hideaki and Araki, Masahiro},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3629},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {228--231},
 publisher = {Association for Computational Linguistics},
 title = {Selection method of an appropriate response in chat-oriented dialogue systems},
 year = {2016}
}

@inproceedings{W16-3630,
 address = {Los Angeles},
 author = {Manuvinakurike, Ramesh and Kennington, Casey and DeVault, David and Schlangen, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3630},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {232--241},
 publisher = {Association for Computational Linguistics},
 title = {Real-Time Understanding of Complex Discriminative Scene Descriptions},
 year = {2016}
}

@inproceedings{W16-3631,
 address = {Los Angeles},
 author = {Kennington, Casey and Schlangen, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3631},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {242--251},
 publisher = {Association for Computational Linguistics},
 title = {Supporting Spoken Assistant Systems with a Graphical User Interface that Signals Incremental Understanding and Prediction State},
 year = {2016}
}

@inproceedings{W16-3632,
 address = {Los Angeles},
 author = {Manuvinakurike, Ramesh and Paetzel, Maike and Qu, Cheng and Schlangen, David and DeVault, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3632},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {252--262},
 publisher = {Association for Computational Linguistics},
 title = {Toward incremental dialogue act segmentation in fast-paced interactive dialogue systems},
 year = {2016}
}

@inproceedings{W16-3633,
 address = {Los Angeles},
 author = {Morency, Louis-Philippe},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3633},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {263},
 publisher = {Association for Computational Linguistics},
 title = {Keynote - Modeling Human Communication Dynamics},
 year = {2016}
}

@inproceedings{W16-3634,
 address = {Los Angeles},
 author = {Lowe, Ryan and Serban, Iulian Vlad and Noseworthy, Michael and Charlin, Laurent and Pineau, Joelle},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3634},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {264--269},
 publisher = {Association for Computational Linguistics},
 title = {On the Evaluation of Dialogue Systems with Next Utterance Classification},
 year = {2016}
}

@inproceedings{W16-3635,
 address = {Los Angeles},
 author = {Litman, Diane and Young, Steve and Gales, Mark and Knill, Kate and Ottewell, Karen and van Dalen, Rogier and Vandyke, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3635},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {270--275},
 publisher = {Association for Computational Linguistics},
 title = {Towards Using Conversations with Spoken Dialogue Systems in the Automated Assessment of Non-Native Speakers of English},
 year = {2016}
}

@inproceedings{W16-3636,
 address = {Los Angeles},
 author = {Misra, Amita and Ecker, Brian and Walker, Marilyn},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3636},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {276--287},
 publisher = {Association for Computational Linguistics},
 title = {Measuring the Similarity of Sentential Arguments in Dialogue},
 year = {2016}
}

@inproceedings{W16-3637,
 address = {Los Angeles},
 author = {Hough, Julian and Schlangen, David},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3637},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {288--298},
 publisher = {Association for Computational Linguistics},
 title = {Investigating Fluidity for Human-Robot Interaction with Real-time, Real-world Grounding Strategies},
 year = {2016}
}

@inproceedings{W16-3638,
 address = {Los Angeles},
 author = {Mehdad, Yashar and Tetreault, Joel},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3638},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {299--303},
 publisher = {Association for Computational Linguistics},
 title = {Do Characters Abuse More Than Words?},
 year = {2016}
}

@inproceedings{W16-3639,
 address = {Los Angeles},
 author = {Kumar, Abhinav and Aurisano, Jillian and Di Eugenio, Barbara and Johnson, Andrew and Gonzalez, Alberto and Leigh, Jason},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3639},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {304--309},
 publisher = {Association for Computational Linguistics},
 title = {Towards a dialogue system that supports rich visualizations of data},
 year = {2016}
}

@inproceedings{W16-3640,
 address = {Los Angeles},
 author = {Mizukami, Masahiro and Yoshino, Koichiro and Neubig, Graham and Traum, David and Nakamura, Satoshi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3640},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {310--318},
 publisher = {Association for Computational Linguistics},
 title = {Analyzing the Effect of Entrainment on Dialogue Acts},
 year = {2016}
}

@inproceedings{W16-3641,
 address = {Los Angeles},
 author = {Miyazaki, Chiaki and Hirano, Toru and Higashinaka, Ryuichiro and Matsuo, Yoshihiro},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3641},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {319--328},
 publisher = {Association for Computational Linguistics},
 title = {Towards an Entertaining Natural Language Generation System: Linguistic Peculiarities of Japanese Fictional Characters},
 year = {2016}
}

@inproceedings{W16-3642,
 address = {Los Angeles},
 author = {Li, Xiaolong and Boyer, Kristy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3642},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {329--338},
 publisher = {Association for Computational Linguistics},
 title = {Reference Resolution in Situated Dialogue with Learned Semantics},
 year = {2016}
}

@inproceedings{W16-3643,
 address = {Los Angeles},
 author = {Yu, Yanchao and Eshghi, Arash and Lemon, Oliver},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3643},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {339--349},
 publisher = {Association for Computational Linguistics},
 title = {Training an adaptive dialogue policy for interactive learning of visually grounded word meanings},
 year = {2016}
}

@inproceedings{W16-3644,
 address = {Los Angeles},
 author = {Rahimtoroghi, Elahe and Hernandez, Ernesto and Walker, Marilyn},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3644},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {350--359},
 publisher = {Association for Computational Linguistics},
 title = {Learning Fine-Grained Knowledge about Contingent Relations between Everyday Events},
 year = {2016}
}

@inproceedings{W16-3645,
 address = {Los Angeles},
 author = {Tian, Ye and Mazzocconi, Chiara and Ginzburg, Jonathan},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3645},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {360--369},
 publisher = {Association for Computational Linguistics},
 title = {When do we laugh?},
 year = {2016}
}

@inproceedings{W16-3646,
 address = {Los Angeles},
 author = {Kobori, Takahiro and Nakano, Mikio and Nakamura, Tomoaki},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3646},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {370--380},
 publisher = {Association for Computational Linguistics},
 title = {Small Talk Improves User Impressions of Interview Dialogue Systems},
 year = {2016}
}

@inproceedings{W16-3647,
 address = {Los Angeles},
 author = {Zhao, Ran and Sinha, Tanmay and Black, Alan and Cassell, Justine},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3647},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {381--392},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Recognition of Conversational Strategies in the Service of a Socially-Aware Dialog System},
 year = {2016}
}

@inproceedings{W16-3648,
 address = {Los Angeles},
 author = {Inaba, Michimasa and Takahashi, Kenichi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3648},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {393--403},
 publisher = {Association for Computational Linguistics},
 title = {Neural Utterance Ranking Model for Conversational Dialogue Systems},
 year = {2016}
}

@inproceedings{W16-3649,
 address = {Los Angeles},
 author = {Yu, Zhou and Xu, Ziyu and Black, Alan W and Rudnicky, Alexander},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-3649},
 booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 month = {September},
 pages = {404--412},
 publisher = {Association for Computational Linguistics},
 title = {Strategy and Policy Learning for Non-Task-Oriented Conversational Systems},
 year = {2016}
}

@inproceedings{W16-3701,
 abstract = {classes namely, {\sl Avyay{\=\i}bh{\=a}va}, {\sl Tatpuru\d{s}a}, {\sl
Bahuvr{\=\i}hi} and {\sl Dvandva}. Our classification is based on the
traditional classification system followed by the ancient grammar treatise {\sl
A\d{s}\d{t}{\=a}dhy{\=a}y{\=\i}}, proposed by P{\=a}\d{n}ini 25 centuries back.
We construct an elaborate features space for our system by combining
conditional rules from the grammar \Ast, semantic relations between the
compound components from a lexical database Amarako\d{s}a and linguistic
structures from the data using Adaptor Grammars. Our in-depth analysis of the
feature space highlight inadequacy of \Ast, a generative grammar, in
classifying the data samples. Our experimental results validate the
effectiveness of using lexical databases as suggested by Amba Kulkarni and Anil
Kumar, and put forward a new research direction by introducing linguistic
patterns obtained from Adaptor grammars for effective identification of
compound type. We utilise an ensemble based approach, specifically designed for
handling skewed datasets and we  %and Experimenting with various classification
methods, we
achieve an overall accuracy of 0.77 using random forest classifiers.},
 address = {Osaka, Japan},
 author = {Krishna, Amrith and Satuluri, Pavankumar and Sharma, Shubham and Kumar, Apurv and Goyal, Pawan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3701},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {1--10},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Compound Type Identification in Sanskrit: What Roles do the Corpus and Grammar Play?},
 year = {2016}
}

@inproceedings{W16-3702,
 abstract = {Grapheme-to-Phoneme (G2P) conversion is the task of predicting the
pronunciation of a word given its graphemic or written form. It is a highly
important part of both automatic speech recognition (ASR) and text-to-speech
(TTS) systems. In this paper, we evaluate seven G2P conversion approaches:
Adaptive Regularization of Weight Vectors (AROW) based structured learning
(S-AROW), Conditional Random Field (CRF), Joint-sequence models (JSM), phrase-based statistical machine translation (PBSMT), Recurrent Neural Network
(RNN),                                                        Support Vector Machine
(SVM)
based
point-wise
classification, Weighted Finite-state Transducers (WFST) on a manually tagged Myanmar phoneme
dictionary. The G2P bootstrapping experimental results were measured with both
automatic phoneme error rate (PER) calculation and also manual checking in
terms of voiced/unvoiced, tones, consonant and vowel errors. The result shows
that CRF, PBSMT and WFST approaches are the best performing methods for G2P
conversion on Myanmar language.},
 address = {Osaka, Japan},
 author = {Kyaw Thu, Ye and Pa Pa, Win and Sagisaka, Yoshinori and Iwahashi, Naoto},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3702},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {11--22},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Comparison of Grapheme-to-Phoneme Conversion Methods on a Myanmar Pronunciation Dictionary},
 year = {2016}
}

@inproceedings{W16-3703,
 abstract = {Named Entity Recognition (NER) is the task of classifying or labelling atomic
elements in the text into categories such as Person, Location or Organisation.
For Arabic language, recognizing named entities is a challenging task because
of the complexity and the unique characteristics of this language. In addition, most of the previous work focuses on Modern Standard Arabic (MSA), however, recognizing named entities in social media is becoming more interesting these
days. Dialectal Arabic (DA) and MSA are both used in social media, which is
deemed as another challenging task. Most state-of-the-art Arabic NER systems
count heavily on handcrafted engineering features and lexicons which is time
consuming. In this paper, we introduce a novel neural network architecture
which benefits both from character- and word-level representations
automatically, by using combination of bidirectional LSTM and Conditional
Random Field (CRF), eliminating the need for most feature engineering.
Moreover, our model relies on unsupervised word representations learned from
unannotated corpora. Experimental results demonstrate that our model achieves
state-of-the-art performance on publicly available benchmark for Arabic NER for
social media and surpassing the previous system by a large margin.},
 address = {Osaka, Japan},
 author = {Gridach, Mourad},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3703},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {23--32},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Character-Aware Neural Networks for Arabic Named Entity Recognition for Social Media},
 year = {2016}
}

@inproceedings{W16-3704,
 abstract = {In recent years there has been a lot of interest in cross-lingual parsing for
developing treebanks for languages with small or no annotated treebanks. In
this paper, we explore the development of a cross-lingual transfer parser from
Hindi to Bengali using a Hindi parser and a Hindi-Bengali parallel corpus. A
parser is trained and applied to the Hindi sentences of the parallel corpus
and the parse trees are projected to construct probable parse trees of the
corresponding Bengali sentences. Only about 14% of these trees are complete
(transferred trees contain all the target sentence words) and they are used to
construct a Bengali parser. We relax the criteria of completeness to consider
well-formed trees (43% of the trees) leading to an improvement. We note
that the words often do not have a one-to-one mapping in the two languages but
considering sentences at the chunk-level results in better correspondence
between the two languages. Based on this we present a method to use chunking as
a preprocessing step and do the transfer on the chunk trees. We find that about
72% of the projected parse trees of Bengali are now well-formed. The resultant
parser achieves significant improvement in both Unlabeled Attachment Score
(UAS) as
well as Labeled Attachment Score (LAS) over the baseline word-level transferred
parser.
Author{3}{Affiliation}},
 address = {Osaka, Japan},
 author = {Das, Ayan and Saha, Agnivo and Sarkar, Sudeshna},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3704},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {33--43},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Development of a Bengali parser by cross-lingual transfer from Hindi},
 year = {2016}
}

@inproceedings{W16-3705,
 abstract = {Currently, corpus based-similarity, string-based similarity, and
knowledge-based similarity techniques are used to compare short phrases.
However, no work has been conducted on the similarity of phrases in Sinhala
language. In this paper, we present a hybrid methodology to compute the
similarity between two Sinhala sentences using a Semantic Similarity
Measurement technique (corpus-based similarity measurement plus knowledge-based
similarity measurement) that makes use of word order information. Since Sinhala
WordNet is still under construction, we used lexical resources in performing
this semantic similarity calculation. Evaluation using 4000 sentence pairs
yielded an average MSE of 0.145 and a Pearson correla-tion factor of 0.832.},
 address = {Osaka, Japan},
 author = {Kadupitiya, Jcs and Ranathunga, Surangika and Dias, Gihan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3705},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {44--53},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Sinhala Short Sentence Similarity Calculation using Corpus-Based and Knowledge-Based Similarity Measures},
 year = {2016}
}

@inproceedings{W16-3706,
 abstract = {This paper focuses on the generation of case markers for free word order
languages
that use case markers as phrasal clitics for marking the
relationship between the dependent-noun and its head. The generation of such
clitics becomes essential task especially when translating from fixed word
order
languages where syntactic relations are identified by the positions of the
dependent-nouns. To address the problem of missing markers on source-side, artificial markers are added in source to improve alignments with its target
counterparts.
Up to 1 BLEU point increase is observed over the baseline on different test
sets for English-to-Urdu.},
 address = {Osaka, Japan},
 author = {Jawaid, Bushra and Kamran, Amir and Bojar, Ond\v{r}ej},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3706},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {54--63},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Enriching Source for English-to-Urdu Machine Translation},
 year = {2016}
}

@inproceedings{W16-3707,
 abstract = {Action verbs are one of the frequently occurring linguistic elements in any
given natural language as the speakers use them during every linguistic
intercourse. However, each language expresses action verbs in its own
inherently unique manner by categorization. One verb can refer to several
interpretations of actions and one action can be expressed by more than one
verb. The inter-language and intra-language variations create ambiguity for the
translation of languages from the source language to target language with
respect to action verbs. IMAGACT is a corpus-based ontological platform of
action verbs translated from prototypic animated images explained in English
and Italian as meta-languages. In this paper, we are presenting the issues and
challenges in translating action verbs of Indian languages as target and
English as source language by observing the animated images. Among the ten
Indian languages which have been annotated so far on the platform are Sanskrit, Hindi, Urdu, Odia (Oriya), Bengali, Manipuri, Tamil, Assamese, Magahi and
Marathi. Out of them, Manipuri belongs to the Sino-Tibetan, Tamil comes off the
Dravidian and the rest owe their genesis to the Indo-Aryan language family. One
of the issues is that the one-word morphological English verbs are translated
into most of the Indian languages as verbs having more than one-word form; for
instance as in the case of conjunct, compound, serial verbs and so on. We are
further presenting a cross-lingual comparison of action verbs among Indian
languages. In addition, we are also dealing with the issues in disambiguating
animated images by the L1 native speakers using competence-based judgements and
the theoretical and machine translation implications they bear.},
 address = {Osaka, Japan},
 author = {Behera, Pitambar and Muzaffar, Sharmin and Ojha, Atul kr. and Jha, Girish},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3707},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {64--73},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The IMAGACT4ALL Ontology of Animated Images: Implications for Theoretical and Machine Translation of Action Verbs from English-Indian Languages},
 year = {2016}
}

@inproceedings{W16-3708,
 abstract = {The automatic analysis of emotions conveyed in social media content, e.g., tweets, has many beneficial applications. In the Philippines, one of the most
disaster-prone countries in the world, such methods could potentially enable
first responders to make timely decisions despite the risk of data deluge.
However, recognising emotions expressed in Philippine-generated tweets, which
are mostly written in Filipino, English or a mix of both, is a non-trivial
task. In order to facilitate the development of natural language processing
(NLP) methods that will automate such type of analysis, we have built a corpus
of tweets whose predominant emotions have been manually annotated by means of
crowdsourcing. Defining measures ensuring that only high-quality annotations
were retained, we have produced a gold standard corpus of 1,146
emotion-labelled Filipino and English tweets. We validate the value of this
manually produced resource by demonstrating that an automatic
emotion-prediction method based on the use of a publicly available word-emotion
association lexicon was unable to reproduce the labels assigned via
crowdsourcing.
While we are planning to make a few extensions to the corpus in the near
future, its current version has been made publicly available in order to foster
the development of emotion analysis methods based on advanced Filipino and
English NLP.},
 address = {Osaka, Japan},
 author = {Lapitan, Fermin Roberto and Batista-Navarro, Riza Theresa and Albacea, Eliezer},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3708},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {74--82},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Crowdsourcing-based Annotation of Emotions in Filipino and English Tweets},
 year = {2016}
}

@inproceedings{W16-3710,
 abstract = {In this paper, we describe the results of sentiment analysis on tweets in three
Indian languages -- Bengali, Hindi, and Tamil. We used the recently released
SAIL dataset (Patra et al., 2015), and obtained state-of-the-art results in all
three languages. Our features are simple, robust, scalable, and
language-independent. Further, we show that these simple features provide
better results than more complex and language-specific features, in two
separate classification tasks. Detailed feature analysis and error analysis
have been reported, along with learning curves for Hindi and Bengali.},
 address = {Osaka, Japan},
 author = {Phani, Shanta and Lahiri, Shibamouli and Biswas, Arindam},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3710},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {93--102},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Sentiment Analysis of Tweets in Three Indian Languages},
 year = {2016}
}

@inproceedings{W16-3711,
 abstract = {In Machine Translation, divergence is one of the major barriers which plays a
deciding role in determining the efficiency of the system at hand. Translation
divergences originate when there is structural discrepancies between the input
and the output languages. It can be of various types based on the issues we are
addressing to such as linguistic, cultural, communicative and so on. Owing to
the fact that two languages owe their origin to different language families, linguistic divergences emerge. The present study attempts at categorizing
different types of linguistic divergences: the lexical-semantic and syntactic.
In addition, it also helps identify and resolve the divergent linguistic
features between English as source language and Bhojpuri as target language
pair. Dorr{\^a}s theoretical framework (1994, 1994a) has been followed in the
classification and resolution procedure. Furthermore, so far as the methodology
is concerned, we have adhered to the Dorr{\^a}s Lexical Conceptual Structure for
the resolution of divergences. This research will prove to be beneficial for
developing efficient MT systems if the mentioned factors are incorporated
considering the inherent structural constraints between source and target
languages.ated considering the inherent structural constraints between SL and
TL pairs.},
 address = {Osaka, Japan},
 author = {Behera, Pitambar and Mourya, Neha and Pandey, Vandana},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3711},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {103--113},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Dealing with Linguistic Divergences in English-Bhojpuri Machine Translation},
 year = {2016}
}

@inproceedings{W16-3712,
 abstract = {In this paper, we discuss our creation of a web corpus of spoken Hindi (COSH), one of the Indo-Aryan languages spoken mainly in the Indian subcontinent. We
also point out notable problems we{\^a}ve encountered in the web corpus and the
special concordancer. After observing the kind of technical problems we
encountered, especially regarding annotation tagged by Shiva Reddy{\^a}s tagger, we argue how they can be solved when using COSH for linguistic studies.
Finally, we mention the kinds of linguistic research that we non-native
speakers of Hindi can do using the corpus, especially in pragmatics and
semantics, and from a comparative viewpoint to Japanese.},
 address = {Osaka, Japan},
 author = {Nishioka, Miki and Akasegawa, Shiro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3712},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {114--123},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The development of a web corpus of Hindi language and corpus-based comparative studies to Japanese},
 year = {2016}
}

@inproceedings{W16-3713,
 abstract = {A sentence aligned parallel corpus is an important prerequisite in statistical
machine translation. However, manual creation of such a parallel corpus is time
consuming, and requires experts fluent in both languages. Automatic creation of
a sentence aligned parallel corpus using parallel text is the solution to this
problem. In this paper, we present the first ever empirical evaluation carried
out to identify the best method to automatically create a sentence aligned
Sinhala-Tamil parallel corpus. Annual reports from Sri Lankan government
institutions were used as the parallel text for aligning. Despite both Sinhala
and Tamil being under-resourced languages, we were able to achieve an F-score
value  of 0.791 using a hybrid approach that makes use of a bilingual
dictionary.},
 address = {Osaka, Japan},
 author = {Abdul Hameed, Riyafa and Pathirennehelage, Nadeeshani and Ihalapathirana, Anusha and Ziyad Mohamed, Maryam and Ranathunga, Surangika and Jayasena, Sanath and Dias, Gihan and Fernando, Sandareka},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3713},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {124--132},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Automatic Creation of a Sentence Aligned Sinhala-Tamil Parallel Corpus},
 year = {2016}
}

@inproceedings{W16-3714,
 abstract = {Acquiring labeled speech for low-resource languages is a difficult task in the
absence of native speakers of the language. One solution to this problem
involves collecting speech transcriptions from crowd workers who are foreign or
non-native speakers of a given target language. From these mismatched
transcriptions, one can derive probabilistic phone transcriptions that are
defined over the set of all target language phones using a noisy channel model.
This paper extends prior work on deriving probabilistic transcriptions (PTs)
from mismatched transcriptions by 1) modelling multilingual channels and 2)
introducing a clustering-based phonetic mapping technique to improve the
quality of PTs. Mismatched crowdsourcing for multilingual channels has certain
properties of projection mapping, e.g., it can be interpreted as a clustering
based on singular value decomposition of the segment alignments. To this end, we explore the use of distinctive feature weights, lexical tone confusions, and
a two-step clustering algorithm to learn projections of phoneme segments from
mismatched multilingual transcriber languages to the target language. We
evaluate our techniques using mismatched transcriptions for Cantonese speech
acquired from native English and Mandarin speakers. We observe a 5-9% relative
reduction in phone error rate for the predicted Cantonese phone transcriptions
using our proposed techniques compared with the previous PT method.},
 address = {Osaka, Japan},
 author = {Chen, Wenda and Hasegawa-Johnson, Mark and Chen, Nancy and Jyothi, Preethi and Varshney, Lav},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3714},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {133--141},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Clustering-based Phonetic Projection in Mismatched Crowdsourcing Channels for Low-resourced ASR},
 year = {2016}
}

@inproceedings{W16-3715,
 abstract = {The paper describes a new tagset for the morphological disambiguation of
Sanskrit, and compares the accuracy of two machine learning methods
(Conditional Random Fields, deep recurrent neural networks) for this task, with
a special focus on how to model the lexicographic information. It reports a
significant improvement over previously published results.},
 address = {Osaka, Japan},
 author = {Hellwig, Oliver},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3715},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {142--151},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Improving the Morphological Analysis of Classical Sanskrit},
 year = {2016}
}

@inproceedings{W16-3716,
 abstract = {In Cross-Language Information Retrieval, finding the appropriate translation of
the source language query has always been a difficult problem to solve. We
propose a technique towards solving this problem with the help of multilingual
word clusters obtained from multilingual word embeddings. We use word
embeddings of the languages projected to a common vector space on which a
community-detection algorithm is applied to find clusters such that words that
represent
the same concept from different languages fall in the same group. We utilize
these multilingual word clusters to perform query translation for
Cross-Language Information Retrieval for three languages - English, Hindi and
Bengali. We have experimented with the FIRE 2012 and Wikipedia datasets and
have shown improvements over several standard methods like dictionary-based
method, a transliteration-based model and Google Translate.},
 address = {Osaka, Japan},
 author = {Bhattacharya, Paheli and Goyal, Pawan and Sarkar, Sudeshna},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3716},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {152--162},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Query Translation for Cross-Language Information Retrieval using Multilingual Word Clusters},
 year = {2016}
}

@inproceedings{W16-3717,
 abstract = {Neural machine translation (NMT) models have recently been shown to be very
successful in machine translation (MT). The use of LSTMs in machine translation
has significantly improved the translation performance for longer sentences by
being able to capture the context and long range correlations of the sentences
in their hidden layers. The attention model based NMT system (Bahdanau et al., 2014) has become the state-of-the-art, performing equal or better than other
statistical MT approaches. In this paper, we wish to study the performance of
the
attention-model based NMT system (Bahdanau et al., 2014) on the Indian language
pair, Hindi and Bengali, and do an analysis on the types or errors that occur
in case when the languages are morphologically rich and there is a scarcity of
large parallel training corpus. We then carry out certain post-processing
heuristic steps to improve the quality of the translated statements and suggest
further measures that can be carried out.
Author{4}{Affiliation}},
 address = {Osaka, Japan},
 author = {Das, Ayan and Yerra, Pranay and Kumar, Ken and Sarkar, Sudeshna},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3717},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {163--172},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A study of attention-based neural machine translation model on Indian languages},
 year = {2016}
}

@inproceedings{W16-3718,
 abstract = {This paper presents a new comprehensive multi-level Part-Of-Speech tag set and
a Support Vector Machine based Part-Of-Speech tagger for the Sinhala language.
The currently available tag set for Sinhala has two limitations: the
unavailability of tags to represent some word classes and the lack of tags to
capture inflection based grammatical variations of words. The new tag set, presented in this paper overcomes both of these limitations. The accuracy of
available Sinhala Part-Of-Speech taggers, which are based on Hidden Markov
Models, still falls far behind state of the art. Our Support Vector Machine
based tagger achieved an overall accuracy of 84.68% with 59.86% accuracy for
unknown words and 87.12% for known words, when the test set contains 10% of
unknown words.},
 address = {Osaka, Japan},
 author = {Fernando, Sandareka and Ranathunga, Surangika and Jayasena, Sanath and Dias, Gihan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3718},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {173--182},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Comprehensive Part-Of-Speech Tag Set and SVM based POS Tagger for Sinhala},
 year = {2016}
}

@inproceedings{W16-3719,
 abstract = {Multilingual language processing tasks like statistical machine translation and
cross language information retrieval rely mainly on availability of accurate
parallel corpora. Manual construction of such corpus can be extremely expensive
and time consuming. In this paper we present a simple yet efficient method to
generate huge amount of reasonably accurate parallel corpus with minimal user
efforts. We utilize the availability of large number of English books and their
corresponding translations in other languages to build parallel corpus. Optical
Character Recognizing systems are used to digitize such books. We propose a
robust dictionary based parallel corpus generation system for alignment of
multilingual text at different levels of granularity (sentence, paragraphs, etc). We show the performance of our proposed method on a manually aligned
dataset of 300 Hindi-English sentences and 100 English-Malayalam sentences.},
 address = {Osaka, Japan},
 author = {Bakliwal, Priyam and V V, Devadath and Jawahar, C V},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3719},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {183--187},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Align Me: A framework to generate Parallel Corpus Using OCRs and Bilingual Dictionaries},
 year = {2016}
}

@inproceedings{W16-3720,
 abstract = {We present a research on learning Indonesian-Chinese bilingual lexicon using
monolingual word embedding and bilingual seed lexicons to build shared
bilingual word embedding space. We take the first attempt to examine the impact
of different monolingual signals for the choice of seed lexicons on the model
performance.  We found that although monolingual signals alone do not seem to
outperform signals coverings all words, the significant improvement for
learning word translation of the same signal types may suggest that linguistic
features possess value for further study in distinguishing the semantic margins
of the shared word embedding space.},
 address = {Osaka, Japan},
 author = {Qiu, Xinying and Zhu, Gangqin},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3720},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {188--193},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Learning Indonesian-Chinese Lexicon with Bilingual Word Embedding Models and Monolingual Signals},
 year = {2016}
}

@inproceedings{W16-3721,
 abstract = {In this paper, we present how we generated two rich online bilingual
dictionaries {\^a} Lao-French and French-Lao {\^a} from unstructured dictionaries
in Microsoft Word files. Then we shortly discuss the possible reuse of the
lexical data for Machine Translation projects.},
 address = {Osaka, Japan},
 author = {Berment, Vincent},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3721},
 booktitle = {Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)},
 month = {December},
 pages = {194--197},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Creating rich online dictionaries for the Lao--French language pair, reusable for Machine Translation},
 year = {2016}
}

@inproceedings{W16-3801,
 abstract = {The paper is a corpus study of the factors involved in disambiguating potential
scope ambiguity in sentences with negation and universal quantifier, such as "I
don{\^a}t want talk to all these people", which can alternatively mean {\^a}I
don{\^a}t want to talk to any of these people{\^a} and {\^a}I don{\^a}t want to talk to
some of these people{\^a}. The relevant factors are demonstrated to be largely
different from those involved in disambiguating lexical polysemy. They include
the syntactic function of the constituent containing "all" quantifier (subject, direct
complement, adjunct), as well as the deepness of its embedding; the status of
the main predicate and "all" constituent with respect to the information
structure of the 6utterance (topic vs. focus, given vs. new information);
pragmatic implicatures
pertaining to the situations described in the utterances.},
 address = {Osaka, Japan},
 author = {Apresjan, Valentina},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3801},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {1--6},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Information structure, syntax, and pragmatics and other factors in resolving scope ambiguity},
 year = {2016}
}

@inproceedings{W16-3802,
 abstract = {In this talk, I will outline a range of challenges presented by multiword
expressions in terms of (lexicalist) precision grammar engineering, and
different strategies for accommodating those challenges, in an attempt to
strike the right balance in terms of generalisation and over- and
under-generation.},
 address = {Osaka, Japan},
 author = {Baldwin, Timothy},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3802},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {7},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Multiword Expressions at the Grammar-Lexicon Interface},
 year = {2016}
}

@inproceedings{W16-3803,
 abstract = {Microsyntactic linguistic units, such as syntactic idioms and non-standard
syntactic constructions, are poorly represented in linguistic resources, mostly
because the former are elements occupying an intermediate position between the
lexicon and the grammar
and the latter are too specific to be routinely tackled by general grammars.
Consequently, many such units produce substantial gaps in systems intended to
solve sophisticated computational linguistics tasks, such as parsing, deep
semantic analysis, question answering, machine translation, or text generation.
They also present obstacles for applying advanced techniques to these tasks, such as machine learning. The paper discusses an approach aimed at bridging
such gaps, focusing on the development of monolingual and multilingual corpora
where microsyntactic units are to be tagged.},
 address = {Osaka, Japan},
 author = {Iomdin, Leonid},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3803},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {8--17},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Microsyntactic Phenomena as a Computational Linguistics Issue},
 year = {2016}
}

@inproceedings{W16-3804,
 abstract = {An excellent example of a phenomenon bridging a lexicon and a grammar is
provided by grammaticalized alternations (e.g., passivization, reflexivity, and
reciprocity): these alternations represent productive grammatical processes
which are, however, lexically determined. While grammaticalized alternations
keep lexical meaning of verbs unchanged, they are usually characterized by
various changes in their morphosyntactic structure.
In this contribution, we demonstrate on the example of reciprocity and its
representation in the valency lexicon of Czech verbs, VALLEX how a linguistic
description of complex (and still systemic) changes characteristic of
grammaticalized alternations can benefit from an integration of grammatical
rules into a valency lexicon. In contrast to other types of grammaticalized
alternations, reciprocity in Czech has received relatively little
attention although it closely interacts with various linguistic phenomena
(e.g., with light verbs, diatheses, and reflexivity).},
 address = {Osaka, Japan},
 author = {Lopatkova, Marketa and Kettnerov\'{a}, V\'{a}clava},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3804},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {18--27},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Alternations: From Lexicon to Grammar And Back Again},
 year = {2016}
}

@inproceedings{W16-3805,
 abstract = {Language-endowed intelligent agents benefit from leveraging lexical knowledge
falling at different points along a spectrum of compositionality. This means
that robust computational lexicons should include not only the compositional
expectations of argument-taking words, but also non-compositional collocations
(idioms), semi-compositional collocations that might be difficult for an agent
to interpret (e.g., standard metaphors), and even collocations that could be
compositionally analyzed but are so frequently encountered that recording their
meaning increases the efficiency of interpretation. In this paper we argue that
yet another type of string-to-meaning mapping can also be useful to intelligent
agents: remembered semantic analyses of actual text inputs. These can be viewed
as super-specific multi-word expressions whose recorded interpretations mimic a
person{\^a}s memories of knowledge previously learned from language input. These
differ from typical annotated corpora in two ways. First, they provide a full, context-sensitive semantic interpretation rather than select features. Second, they are are formulated in the ontologically-grounded metalanguage used in a
particular agent environment, meaning that the interpretations contribute to
the dynamically evolving cognitive capabilites of agents configured in that
environment.},
 address = {Osaka, Japan},
 author = {McShane, Marjorie and Nirenburg, Sergei},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3805},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {28--37},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Extra-Specific Multiword Expressions for Language-Endowed Intelligent Agents},
 year = {2016}
}

@inproceedings{W16-3806,
 abstract = {Universal Dependencies is an initiative to develop cross-linguistically
consistent grammatical annotation for many languages, with the goal of
facilitating multilingual parser development, cross-lingual learning and
parsing research from a language typology perspective. It assumes a
dependency-based approach to syntax and a lexicalist approach to morphology, which together entail that the fundamental units of grammatical annotation are
words. Words have properties captured by morphological annotation and enter
into relations captured by syntactic annotation. Moreover, priority is given to
relations between lexical content words, as opposed to grammatical function
words. In this position paper, I discuss how this approach allows us to capture
similarities and differences across typologically diverse languages.},
 address = {Osaka, Japan},
 author = {Nivre, Joakim},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3806},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {38--40},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Universal Dependencies: A Cross-Linguistic Perspective on Grammar and Lexicon},
 year = {2016}
}

@inproceedings{W16-3807,
 abstract = {Human communication is a multimodal activity, involving not only
speech and written expressions, but intonation, images, gestures, visual clues, and the
interpretation of actions through perception. In this  paper, we
describe  the design  of a multimodal lexicon that is able to
accommodate the diverse modalities that present themselves in NLP applications.
We have been developing a multimodal semantic representation, VoxML, that
integrates the encoding of semantic, visual, gestural, and action-based
features
associated with linguistic expressions.},
 address = {Osaka, Japan},
 author = {Pustejovsky, James and Do, Tuan and Kehat, Gitit and Krishnaswamy, Nikhil},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3807},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {41--47},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The Development of Multimodal Lexical Resources},
 year = {2016}
}

@inproceedings{W16-3808,
 abstract = {Valency slot filling is a semantic glue, which brings together the meanings of
words. As regards the position of an argument in the dependency structure with
respect to its predicate, there exist three types of valency filling: active
(canonical), passive, and discontinuous. Of these, the first type is studied
much better than the other two. As a rule, canonical actants are unambiguously
marked in the syntactic structure, and each actant corresponds to a unique
syntactic position. Linguistic information on which syntactic function an
actant might have (subject, direct or indirect object), what its morphological
form should be and which prepositions or conjunctions it requires, can be given
in the lexicon in the form of government patterns, subcategorization frames, or
similar data structures. We concentrate on non-canonical cases of valency
filling in Russian, which are characteristic of non-verbal parts of speech, such as adverbs, adjectives, and particles, in the first place. They are more
difficult to handle than canonical ones, because the position of the actant in
the tree is governed by more complicated rules. A valency may be filled by
expressions occupying different syntactic positions, and a syntactic position
may accept expressions filling different valencies of the same word. We show
how these phenomena can be processed in a semantic analyzer.},
 address = {Osaka, Japan},
 author = {Boguslavsky, Igor},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3808},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {51--60},
 publisher = {The COLING 2016 Organizing Committee},
 title = {On the Non-canonical Valency Filling},
 year = {2016}
}

@inproceedings{W16-3809,
 abstract = {Verbenet is a French lexicon developed by {\^a}translation{\^a} of its English
counterpart {\^a} VerbNet
(Kipper-Schuler, 2005){\^a}and treatment of the specificities of French syntax
(Pradet et al., 2014;
Danlos et al., 2016). One difficulty encountered in its development springs
from the fact that the
list of (potentially numerous) frames has no internal organization. This paper
proposes a type
system for frames that shows whether two frames are variants of a given
alternation. Frame typing facilitates coherence checking of the resource in a
{\^a}virtuous circle{\^a}. We present the principles
underlying a program we developed and used to automatically type frames in
VerbeNet. We also show that our system is portable to other languages.},
 address = {Osaka, Japan},
 author = {Danlos, Laurence and Constant, Matthieu and Barque, Lucie},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3809},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {61--70},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Improvement of VerbNet-like resources by frame typing},
 year = {2016}
}

@inproceedings{W16-3810,
 abstract = {We present an attempt to automatically identify Czech deverbative nouns using
several methods that use large corpora as well as existing lexical resources.
The motivation for the task is to extend a verbal valency (i.e., predicate-argument) lexicon by adding nouns that share the valency properties
with the base verb, assuming their properties can be derived (even if not
trivially) from the underlying verb by deterministic grammatical rules. At the
same time, even in inflective languages, not all deverbatives are simply
created from their underlying base verb by regular lexical derivation
processes. We have thus developed hybrid techniques that use both large
parallel corpora and several standard lexical resources. Thanks to the use of
parallel corpora, the resulting sets contain also synonyms, which the lexical
derivation rules cannot get. For evaluation, we have manually created a small, 100-verb gold data since no such dataset was initially available for Czech.},
 address = {Osaka, Japan},
 author = {Fucikova, Eva and Hajic, Jan and Uresova, Zdenka},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3810},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {71--80},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Enriching a Valency Lexicon by Deverbative Nouns},
 year = {2016}
}

@inproceedings{W16-3811,
 abstract = {We present an interdisciplinary study on the interaction between the
interpretation of noun-noun deverbal compounds (DCs; e.g., task assignment) and
the morphosyntactic properties of their deverbal heads in English. Underlying
hypotheses from theoretical linguistics are tested with tools and resources
from computational linguistics. We start with Grimshaw{\^a}s (1990) insight that
deverbal nouns are ambiguous between argument-supporting nominal (ASN)
readings, which inherit verbal arguments (e.g., the assignment of the tasks), and the less verbal and more lexicalized Result Nominal and Simple Event
readings (e.g., a two-page assignment). Following Grimshaw, our hypothesis is
that the former will realize object arguments in DCs, while the latter will
receive a wider range of interpretations like root compounds headed by
non-derived nouns (e.g., chocolate box). Evidence from a large corpus assisted
by machine learning techniques confirms this hypothesis, by showing that, besides other features, the realization of internal arguments by deverbal heads
outside compounds (i.e., the most distinctive ASN-property in Grimshaw 1990) is
a good predictor for an object interpretation of non-heads in DCs.},
 address = {Osaka, Japan},
 author = {Iordachioaia, Gianina and van der Plas, Lonneke and Jagfeld, Glorianna},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3811},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {81--91},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The Grammar of English Deverbal Compounds and their Meaning},
 year = {2016}
}

@inproceedings{W16-3812,
 abstract = {We show how to turn a large-scale syntactic dictionary into a dependency-based
unification grammar where each piece of lexical information calls a separate
rule, yielding a super granular grammar. Subcategorization, raising and control
verbs, auxiliaries and copula, passivization, and tough-movement are discussed.
We focus on the semantics-syntax interface and offer a new perspective on
syntactic structure.},
 address = {Osaka, Japan},
 author = {Kahane, Sylvain and Lareau, Fran\c{c}ois},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3812},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {92--101},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Encoding a syntactic dictionary into a super granular unification grammar},
 year = {2016}
}

@inproceedings{W16-3813,
 abstract = {This paper presents our ongoing work on compilation of English multi-word
expression (MWE) lexicon.  We are especially interested in collecting flexible
MWEs, in which some other components can intervene the expression such as "a
number of'' vs "a large number of'' where a modifier of "number'' can be placed
in the expression and inherit the original meaning.  We fiest collect possible
candidates of flexible English MWEs from the web, and annotate all of their
occurrences in the Wall Street Journal portion of Ontonotes corpus.  We make
use of word dependency strcuture information of the sentences converted from
the phrase structure annotation.  This process enables semi-automatic
annotation of MWEs in the corpus and simultanaously produces the internal and
external dependency representation of flexible MWEs.},
 address = {Osaka, Japan},
 author = {Morimoto, Ayaka and Yoshimoto, Akifumi and Kato, Akihiko and Shindo, Hiroyuki and Matsumoto, Yuji},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3813},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {102--109},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Identification of Flexible Multiword Expressions with the Help of Dependency Structure Annotation},
 year = {2016}
}

@inproceedings{W16-3814,
 abstract = {The paper presents a contrastive description of reflexive possessive pronouns
{\^a}sv{\AA}¯j{\^a} in Czech and {\^a}svoj{\^a} in Russian. The research concerns
syntactic, semantic and pragmatic aspects. With our analysis, we shed a new
light on the already investigated issue, which comes from a detailed comparison
of the phenomenon of possessive reflexivization in two typologically and
genetically similar languages. We show that whereas in Czech, the possessive
reflexivization is mostly limited to syntactic functions and does not go beyond
the grammar, in Russian it gets additional semantic meanings and moves
substan-tially towards the lexicon. The obtained knowledge allows  us to
explain heretofore unclear marginal uses of reflexives in each language.},
 address = {Osaka, Japan},
 author = {Nedoluzhko, Anna},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3814},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {110--119},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A new look at possessive reflexivization: A comparative study between Czech and Russian},
 year = {2016}
}

@inproceedings{W16-3815,
 abstract = {A specific language as used by different speakers and in different situations
has a number of more or less distant varieties. Extending the notion of
non-standard language to varieties that do not fit an explicitly or implicitly
assumed norm or pattern, we look for methods and tools that could be applied to
this domain. The needs start from the theoretical side: categories usable for
the analysis of non-standard language are not readily available, and continue
to methods and tools required for its detection and diagnostics. A general
discussion of issues related to non-standard language is followed by two case
studies. The first study presents a taxonomy of morphosyntactic categories as
an attempt to analyse non-standard forms produced by non-native learners of
Czech. The second study focusses on the role of a rule-based grammar and
lexicon in the process of building and
using a parsebank.},
 address = {Osaka, Japan},
 author = {Rosen, Alexandr},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3815},
 booktitle = {Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (GramLex)},
 month = {December},
 pages = {120--131},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Modeling non-standard language},
 year = {2016}
}

@inproceedings{W16-3901,
 abstract = {Real world data differs radically from the benchmark corpora we use in NLP, resulting in large performance drops. The reason for this problem is obvious:
NLP models are trained on limited samples from canonical varieties considered
standard. However, there are many dimensions, e.g., sociodemographic, language, genre, sentence type, etc. on which texts can differ from the standard. The
solution is not obvious: we cannot control for all factors, and it is not clear
how to best go beyond the current practice of training on homogeneous data from
a single domain and language.
In this talk, I review the notion of canonicity, and how it shapes our
community's approach to language. I argue for the use of fortuitous data.
Fortuitous data is data out there that just waits to be harvested. It includes
data which is in plain sight, but is often neglected, and more distant sources
like behavioral data, which first need to be refined. They provide additional
contexts and a myriad of opportunities to build more adaptive language
technology, some of which I will explore in this talk.},
 address = {Osaka, Japan},
 author = {Plank, Barbara},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3901},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {1},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Processing non-canonical or noisy text: fortuitous data to the rescue},
 year = {2016}
}

@inproceedings{W16-3902,
 abstract = {Entity linking and semantic parsing have been shown to be crucial to important
applications such as question answering and document understanding. These tasks
often require structured learning models, which make predictions on multiple
interdependent variables. In this talk, I argue that carefully designed
structured learning algorithms play a central role in entity linking and
semantic parsing tasks. In particular, I will present several new structured
learning models for entity linking, which jointly detect mentions and
disambiguate entities as well as capture non-textual information. I will then
show how to use a staged search procedure to building a state-of-the-art
knowledge base question answering system. Finally, if time permits, I will
discuss different supervision protocols for training semantic parsers and the
value of labeling semantic parses.},
 address = {Osaka, Japan},
 author = {Chang, Ming-Wei},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3902},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {2},
 publisher = {The COLING 2016 Organizing Committee},
 title = {From Entity Linking to Question Answering -- Recent Progress on Semantic Grounding Tasks},
 year = {2016}
}

@inproceedings{W16-3903,
 abstract = {This talk presents two NLP systems that were developed for helping disaster
victims and rescue workers in the aftermath of large-scale disasters. DISAANA
provides answers to questions such as "What is in short supply in Tokyo?" and
displays locations related to each answer on a map. D-SUMM automatically
summarizes a large number of disaster related reports concerning a specified
area and helps rescue workers to understand disaster situations from a macro
perspective. Both systems are publicly available as Web services.  In the
aftermath of the 2016 Kumamoto Earthquake (M7.0), the Japanese government
actually used DISAANA to analyze the situation.},
 address = {Osaka, Japan},
 author = {Torisawa, Kentaro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3903},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {3},
 publisher = {The COLING 2016 Organizing Committee},
 title = {DISAANA and D-SUMM: Large-scale Real Time NLP Systems for Analyzing Disaster Related Reports in Tweets},
 year = {2016}
}

@inproceedings{W16-3904,
 abstract = {In this paper we present a series of experiments on discriminating between
private and corporate accounts on Twitter. We define features based on Twitter
metadata, morphosyntactic tags and surface forms, showing that the simple
bag-of-words model achieves single best results that can, however, be improved
by building a weighted soft ensemble of classifiers based on each feature type.
Investigating the time and language dependence of each feature type delivers
quite unexpecting results showing that features based on metadata are neither
time- nor language-insensitive as the way the two user groups use the social
network varies heavily through time and space.},
 address = {Osaka, Japan},
 author = {Ljube\v{s}i\'{c}, Nikola and Fi\v{s}er, Darja},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3904},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {4--12},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Private or Corporate? Predicting User Types on Twitter},
 year = {2016}
}

@inproceedings{W16-3905,
 abstract = {User-generated content presents many challenges for its automatic processing.
While many of them do come from out-of-vocabulary effects, others spawn from
different linguistic phenomena such as unusual syntax. In this work we present
a French three-domain data set made up of ques- tion headlines from a cooking
forum, game chat logs and associated forums from two popular online games
(MINECRAFT \& LEAGUE OF LEGENDS). We chose these domains because they encompass
different degrees of lexical and syntactic compliance with canonical language.
We conduct an automatic and manual evaluation of the difficulties of processing
these domains for part-of-speech prediction, and introduce a pilot study to
determine whether dependency analysis lends itself well to annotate these data.
We also discuss the development cost of our data set.},
 address = {Osaka, Japan},
 author = {Mart\'{i}nez Alonso, H\'{e}ctor and Seddah, Djam\'{e} and Sagot, Beno\^{i}t},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3905},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {13--23},
 publisher = {The COLING 2016 Organizing Committee},
 title = {From Noisy Questions to Minecraft Texts: Annotation Challenges in Extreme Syntax Scenario},
 year = {2016}
}

@inproceedings{W16-3906,
 abstract = {Information extraction from user-generated text has gained much attention with
the growth of the Web.Disaster analysis using information from social media
provides valuable, real-time, geolocation information for helping people caught
up these in disasters. However, it is not convenient to analyze texts posted on
social media because disaster keywords match any texts that contain words. For
collecting posts about a disaster from social media, we need to develop a
classifier to filter posts irrelevant to disasters. Moreover, because of the
nature of social media, we can take advantage of posts that come with GPS
information.
However, a post does not always refer to an event occurring at the place where
it has been posted.
Therefore, we propose a new task of classifying whether a flood disaster
occurred, in addition to predicting the geolocation of events from
user-generated text. We report the annotation of the flood disaster corpus and
develop a classifier to demonstrate the use of this corpus for disaster
analysis.
Author{2}{Affiliation}},
 address = {Osaka, Japan},
 author = {Asakura, Yasunobu and Hangyo, Masatsugu and Komachi, Mamoru},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3906},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {24--32},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Disaster Analysis using User-Generated Weather Report},
 year = {2016}
}

@inproceedings{W16-3907,
 abstract = {We present a data-driven method for determining the veracity of a set of
rumorous claims on social media data. Tweets from different sources pertaining
to a rumor are processed on three levels: first, factuality values are assigned
to each tweet based on four textual cue categories relevant for our journalism
use case; these amalgamate speaker support in terms of polarity and commitment
in terms of certainty and speculation. Next, the proportions of these lexical
cues are utilized as predictors for tweet certainty in a generalized linear
regression model. Subsequently, lexical cue proportions, predicted certainty, as well as their time course characteristics are used to compute veracity for
each rumor in terms of the identity of the rumor-resolving tweet and its binary
resolution value judgment. The system operates without access to
extralinguistic resources. Evaluated on the data portion for which hand-labeled
examples were available, it achieves .74 F1-score on identifying rumor
resolving tweets and .76 F1-score on predicting if a rumor is resolved as true
or false.},
 address = {Osaka, Japan},
 author = {Reichel, Uwe and Lendvai, Piroska},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3907},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {33--42},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Veracity Computing from Lexical Cues and Perceived Certainty Trends},
 year = {2016}
}

@inproceedings{W16-3908,
 abstract = {A major challenge for statistical machine translation (SMT) of
Arabic-to-English user-generated text is the prevalence of text written in
Arabizi, or Romanized Arabic. When facing such texts, a translation system
trained on conventional Arabic-English data will suffer from extremely low
model coverage. In addition, Arabizi is not regulated by any official
standardization and therefore highly ambiguous, which prevents rule-based
approaches from achieving good translation results. In this paper, we improve
Arabizi-to-English machine translation by presenting a simple but effective
Arabizi-to-Arabic transliteration pipeline that does not require knowledge by
experts or native Arabic speakers. We incorporate this pipeline into a
phrase-based SMT system, and show that translation quality after automatically
transliterating Arabizi to Arabic yields results that are comparable to those
achieved after human transliteration.},
 address = {Osaka, Japan},
 author = {van der Wees, Marlies and Bisazza, Arianna and Monz, Christof},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3908},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {43--50},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Simple but Effective Approach to Improve Arabizi-to-English Statistical Machine Translation},
 year = {2016}
}

@inproceedings{W16-3909,
 abstract = {Name Variation in Community Question Answering Systems
Abstract
Community question answering systems are forums where users can ask and answer
questions in various categories. Examples are Yahoo! Answers, Quora, and Stack
Overflow. A common challenge with such systems is that a significant percentage
of asked questions are left unanswered. In this paper, we propose an algorithm
to reduce the number of unanswered questions in Yahoo! Answers by reusing the
answer to the most similar past resolved question to the unanswered question, from the site. Semantically similar questions could be worded differently, thereby making it difficult to find questions that have shared needs. For
example, "Who is the best player for the Reds?" and "Who is currently the
biggest star at Manchester United?" have a shared need but
are worded differently; also, "Reds" and "Manchester United" are used to refer
to the soccer team Manchester United football club. In this research, we focus
on question categories that contain a large number of named entities and entity
name variations. We show that in these categories, entity linking can be used
to identify relevant past resolved questions with shared needs as a given
question by disambiguating named entities and matching these questions based on
the disambiguated entities, identified entities, and knowledge base information
related to these entities. We evaluated our algorithm on a new dataset
constructed from Yahoo! Answers. The dataset contains annotated question pairs, (Qgiven, [Qpast, Answer]). We carried out experiments on several question
categories and show that an entity-based approach gives good performance when
searching for similar questions in entity rich categories.},
 address = {Osaka, Japan},
 author = {Andy, Anietie and Sekine, Satoshi and Rwebangira, Mugizi and Dredze, Mark},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3909},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {51--60},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Name Variation in Community Question Answering Systems},
 year = {2016}
}

@inproceedings{W16-3910,
 abstract = {Using aliases to refer to public figures is one way to make fun of people, to
express sarcasm, or even to sidestep legal issues when expressing opinions on
social media. However, linking an alias back to the real name is difficult, as
it entails phonemic, graphemic, and semantic challenges. In this paper, we
propose a phonemic-based approach and inject semantic information to align
aliases with politicians' Chinese formal names. The proposed approach creates
an HMM model for each name to model its phonemes and takes into account
document-level pairwise mutual information to capture the semantic relations to
the alias. In this work we also introduce two new datasets consisting of 167
phonemic pairs and 279 mixed pairs of aliases and formal names. Experimental
results show that the proposed approach models both phonemic and semantic
information and outperforms previous work on both the phonemic and mixed
datasets with the best top-1 accuracies of 0.78 and 0.59 respectively.},
 address = {Osaka, Japan},
 author = {Wang, Wei-Chung and Chen, Hung-Chen and Ji, Zhi-Kai and Hsiao, Hui-I and Chiu, Yu-Shian and Ku, Lun-Wei},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3910},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {61--69},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Whose Nickname is This? Recognizing Politicians from Their Aliases},
 year = {2016}
}

@inproceedings{W16-3911,
 abstract = {Accurate event detection in social media is very challenging because user
generated contents are extremely noisy and sparse in content. Event indicators
are generally words or phrases that act as a trigger that help us understand
the semantics of the context they occur in. We present a weakly supervised
approach that relies on  using a single strong event indicator phrase as a seed
to acquire a variety of additional event cues. We propose to leverage various
types of implicit event indicators, such as props, actors and precursor events, to achieve precise event detection. We experimented with civil
unrest events and show that the automatically learnt event indicators are
effective in identifying specific types of events.},
 address = {Osaka, Japan},
 author = {Jain, Ajit and Kasiviswanathan, Girish and Huang, Ruihong},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3911},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {70--77},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Towards Accurate Event Detection in Social Media: A Weakly Supervised Approach for Learning Implicit Event Indicators},
 year = {2016}
}

@inproceedings{W16-3912,
 abstract = {Stemming is an essential processing step in a wide range of high level text
processing applications such as information extraction, machine translation and
sentiment analysis. It is used to reduce words to their stems. Many stemming
algorithms have been developed for Modern Standard Arabic (MSA). Although
Arabic tweets and MSA are closely related and share many characteristics, there
are substantial differences between them in lexicon and syntax. In this paper, we introduce a light Arabic stemmer for Arabic tweets. Our results show
improvements over the performance of a number of well-known stemmers for
Arabic.},
 address = {Osaka, Japan},
 author = {Albogamy, Fahad and Ramsay, Allan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3912},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {78--84},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Unsupervised Stemmer for Arabic Tweets},
 year = {2016}
}

@inproceedings{W16-3913,
 abstract = {Topic modelling techniques such as LDA have recently been applied to speech
transcripts and OCR output. These corpora may contain noisy or erroneous texts
which may undermine topic stability. Therefore, it is important to know how
well a topic modelling algorithm will perform when applied to noisy data. In
this paper we show that different types of textual noise can have diverse
effects on the stability of topic models.  On the other hand, topic model
stability is not consistent with the same type but different levels of noise.
We introduce a dictionary filtering approach to address this challenge, with
the result that a topic model with the correct number of topics is always
identified across different levels of noise.},
 address = {Osaka, Japan},
 author = {Su, Jing and Greene, Derek and Boydell, Oisin},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3913},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {85--93},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Topic Stability over Noisy Sources},
 year = {2016}
}

@inproceedings{W16-3914,
 abstract = {Postmarketing surveillance (PMS) has the vital aim to monitor effects of drugs
after release for use by the general population, but suffers from
under-reporting and limited coverage. Automatic methods for detecting  drug
effect reports, especially for social media, could vastly increase the scope of
PMS. Very few automatic PMS methods are currently available, in particular for
the messy text types encountered on Twitter. In this paper we describe first
results for developing PMS methods specifically for tweets. We describe the
corpus of 125,669 tweets we have created and annotated to train and test the
tools. We find that generic tools perform well for tweet-level language
identification and tweet-level sentiment analysis (both 0.94 F1-Score). For
detection of effect mentions we are able to achieve 0.87 F1-Score, while
effect-level adverse-vs.-beneficial analysis proves harder with an F1-Score of
0.64. Among other things, our results indicate that MetaMap semantic types
provide a very promising basis for identifying drug effect mentions in tweets.},
 address = {Osaka, Japan},
 author = {Pain, Julie and Levacher, Jessie and Quinquenel, Adam and Belz, Anja},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3914},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {94--101},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Analysis of Twitter Data for Postmarketing Surveillance in Pharmacovigilance},
 year = {2016}
}

@inproceedings{W16-3915,
 abstract = {In social networks services like Twitter, users are overwhelmed with huge
amount of social data, most of which are short, unstructured and highly noisy. Identifying accurate
information from
this huge amount of data is indeed a hard task. Classification of tweets into
organized form will
help the user to easily access these required information. Our first
contribution relates to filtering
parts of speech and preprocessing this kind of highly noisy and short data. Our
second contribution
concerns the named entity recognition (NER) in tweets. Thus, the adaptation of
existing
language tools for natural languages, noisy and not accurate language tweets, is necessary. Our
third contribution involves segmentation of hashtags and a semantic enrichment
using a combination
of relations from WordNet, which helps the performance of our classification
system, including disambiguation of named entities, abbreviations and acronyms. Graph
theory is used
to cluster the words extracted from WordNet and tweets, based on the idea of
connected components.
We test our automatic classification system with four categories: politics, economy, sports
and the medical field. We evaluate and compare several automatic classification
systems using
part or all of the items described in our contributions and found that
filtering by part of speech
and named entity recognition dramatically increase the classification precision
to 77.3 %. Moreover, a classification system incorporating segmentation of hashtags and semantic
enrichment by
two relations from WordNet, synonymy and hyperonymy, increase classification
precision up to
83.4 %.},
 address = {Osaka, Japan},
 author = {Belainine, Billal and Fonseca, Alexsandro and Sadat, Fatiha},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3915},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {102--111},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Named Entity Recognition and Hashtag Decomposition to Improve the Classification of Tweets},
 year = {2016}
}

@inproceedings{W16-3916,
 abstract = {Text normalization techniques based on rules, lexicons or supervised training
requiring large
corpora are not scalable nor domain interchangeable, and this makes them
unsuitable for normal-
izing user-generated content (UGC). Current tools available for Brazilian
Portuguese make use
of such techniques. In this work we propose a technique based on distributed
representation of
words (or word embeddings). It generates continuous numeric vectors of
high-dimensionality to
represent words. The vectors explicitly encode many linguistic regularities and
patterns, as well
as syntactic and semantic word relationships. Words that share semantic
similarity are repre-
sented by similar vectors. Based on these features, we present a totally
unsupervised, expandable
and language and domain independent method for learning normalization lexicons
from word
embeddings. Our approach obtains high correction rate of orthographic errors
and internet slang
in product reviews, outperforming the current available tools for Brazilian
Portuguese.},
 address = {Osaka, Japan},
 author = {Costa Bertaglia, Thales Felipe and Volpe Nunes, Maria das Gra\c{c}as},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3916},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {112--120},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Exploring Word Embeddings for Unsupervised Textual User-Generated Content Normalization},
 year = {2016}
}

@inproceedings{W16-3917,
 abstract = {The SemEval-2010 benchmark dataset has brought renewed attention to the task of
automatic keyphrase extraction. This dataset is made up of scientific articles
that were automatically converted from PDF format to plain text and thus
require careful preprocessing so that irrevelant spans of text do not
negatively affect keyphrase extraction performance. In previous work, a wide
range of document preprocessing techniques were described but their impact on
the overall performance of keyphrase extraction models is still unexplored.
Here, we re-assess the performance of several keyphrase extraction models and
measure their robustness against increasingly sophisticated levels of document
preprocessing.
Author{2}{Affiliation}},
 address = {Osaka, Japan},
 author = {Boudin, Florian and Mougard, Hugo and Cram, Damien},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3917},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {121--128},
 publisher = {The COLING 2016 Organizing Committee},
 title = {How Document Pre-processing affects Keyphrase Extraction Performance},
 year = {2016}
}

@inproceedings{W16-3918,
 abstract = {Text normalization is the task of transforming lexical variants to their
canonical forms.
We model the problem of text normalization as a character-level sequence to
sequence learning problem
and present a neural encoder-decoder model for solving it.
To train the encoder-decoder model, many sentences pairs are generally
required.
However, Japanese non-standard canonical pairs are scarce in the form of
parallel corpora.
To address this issue, we propose a method of data augmentation to increase
data size
by converting existing resources into synthesized non-standard forms using
handcrafted rules.
We conducted an experiment to demonstrate that the synthesized corpus
contributes to stably train an encoder-decoder model and improve the
performance of Japanese text normalization.},
 address = {Osaka, Japan},
 author = {Ikeda, Taishi and Shindo, Hiroyuki and Matsumoto, Yuji},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3918},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {129--137},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Japanese Text Normalization with Encoder-Decoder Model},
 year = {2016}
}

@inproceedings{W16-3919,
 abstract = {This paper presents the results of the Twitter Named Entity Recognition shared
task associated with W-NUT 2016: a named entity tagging task with 10 teams
participating. We outline the shared task, annotation process and dataset
statistics, and provide a high-level overview of the
participating systems for each shared task.},
 address = {Osaka, Japan},
 author = {Strauss, Benjamin and Toma, Bethany and Ritter, Alan and de Marneffe, Marie-Catherine and Xu, Wei},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3919},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {138--144},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Results of the WNUT16 Named Entity Recognition Shared Task},
 year = {2016}
}

@inproceedings{W16-3920,
 abstract = {In this paper, we present our approach for named entity recognition in Twitter
messages that we used in our participation in the Named Entity Recognition in
Twitter shared task at the COLING 2016 Workshop on Noisy User-generated text
(WNUT). The main challenge that we aim to tackle in our participation is the
short, noisy and colloquial nature of tweets, which makes named entity
recognition in Twitter message a challenging task. In particular, we
investigate an approach for dealing with this problem by enabling bidirectional
long short-term memory (LSTM) to automatically learn orthographic features
without requiring feature engineering. In comparison with other systems
participating in the shared task, our system achieved the most effective
performance on both the `segmentation and categorisation' and the `segmentation
only' sub-tasks.},
 address = {Osaka, Japan},
 author = {Limsopatham, Nut and Collier, Nigel},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3920},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {145--152},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Bidirectional LSTM for Named Entity Recognition in Twitter Messages},
 year = {2016}
}

@inproceedings{W16-3921,
 abstract = {Named entity recognition (NER) in social media (e.g., Twitter) is a challenging
task due to the noisy nature of text. As part of our participation in the W-NUT
2016 Named Entity Recognition Shared Task, we proposed an unsupervised learning
approach using deep neural networks and leverage a knowledge base (i.e., DBpedia) to bootstrap sparse entity types with weakly labelled data. To further
boost the performance, we employed a more sophisticated tagging scheme and
applied dropout as a regularisation technique in order to reduce overfitting.
Even without hand- crafting linguistic features nor leveraging any of the
W-NUT-provided gazetteers, we obtained robust performance with our approach, which ranked third amongst all shared task participants according to the
official evaluation on a gold standard named entity-annotated corpus of 3,856
tweets.},
 address = {Osaka, Japan},
 author = {Espinosa, Kurt Junshean and Batista-Navarro, Riza Theresa and Ananiadou, Sophia},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3921},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {153--163},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Learning to recognise named entities in tweets by exploiting weakly labelled data},
 year = {2016}
}

@inproceedings{W16-3922,
 abstract = {Twitter named entity recognition is the process of identifying proper names and
classifying them into some predefined labels/categories. The paper introduces a
Twitter named entity system using a supervised machine learning approach, namely Conditional Random Fields. A large set of different features was
developed and the system was trained using these. The Twitter named entity task
can be divided into two parts: i) Named entity extraction from tweets and ii)
Twitter name classification into ten different types. For Twitter named entity
recognition on unseen test data, our system obtained the second highest F1
score in the shared task: 63.22%. The system performance on the classification
task was worse, with an F1 measure of 40.06% on unseen test data, which was the
fourth best of the ten systems participating in the shared task.},
 address = {Osaka, Japan},
 author = {Sikdar, Utpal Kumar and Gamb\"{a}ck, Bj\"{o}rn},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3922},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {164--170},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Feature-Rich Twitter Named Entity Recognition and Classification},
 year = {2016}
}

@inproceedings{W16-3923,
 abstract = {We presented in this work our participation in the 2nd Named Entity Recognition
for Twitter shared task. The task has been cast as a sequence labeling one and
we employed a learning to search approach in order to tackle it. We also
leveraged LOD for extracting rich contextual features for the named-entities.
Our submission
achieved  F-scores of 46.16 and 60.24 for the classification and the
segmentation tasks and ranked 2nd and 3rd respectively. The post-analysis
showed that LOD features improved substantially the performance of our system
as they counter-balance the lack of context in tweets. The shared task gave us
the opportunity to test the performance of NER systems in short and noisy
textual data. The results of the participated systems shows that the task is
far to be considered as a solved one and  methods with stellar performance in
normal texts need to be revised.},
 address = {Osaka, Japan},
 author = {Partalas, Ioannis and Lopez, C\'{e}dric and Derbas, Nadia and Kalitvianski, Ruslan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3923},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {171--177},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Learning to Search for Recognizing Named Entities in Twitter},
 year = {2016}
}

@inproceedings{W16-3924,
 abstract = {In this paper, we describe the DeepNNNER entry to The 2nd Workshop on Noisy
User-generated Text (WNUT) Shared Task \#2: Named Entity Recognition in Twitter.
Our shared task submission adopts the bidirectional LSTM-CNN model of Chiu and
Nichols (2016), as it has been shown to perform well on both newswire and Web
texts. It uses word embeddings trained on large-scale Web text collections
together with text normalization to cope with the diversity in Web texts, and
lexicons for target named entity classes constructed from publicly-available
sources. Extended evaluation comparing the effectiveness of various word
embeddings, text normalization, and lexicon settings shows that our system
achieves a maximum F1-score of 47.24, performance surpassing that of the shared
task's second-ranked system.},
 address = {Osaka, Japan},
 author = {Dugas, Fabrice and Nichols, Eric},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3924},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {178--187},
 publisher = {The COLING 2016 Organizing Committee},
 title = {DeepNNNER: Applying BLSTM-CNNs and Extended Lexicons to Named Entity Recognition in Tweets},
 year = {2016}
}

@inproceedings{W16-3925,
 abstract = {This paper describes the ASU system submitted in the COLING W-NUT 2016 Twitter
Named Entity Recognition (NER) task.
We present an experimental study on applying deep learning to extracting named
entities (NEs) from tweets.
We built two Long Short-Term Memory (LSTM) models for the task.
The first model was built to extract named entities without types while the
second model was built to extract and then classify them into 10 fine-grained
entity classes.
In this effort, we show detailed experimentation results on the effectiveness
of word embeddings, brown clusters, part-of-speech (POS) tags, shape features, gazetteers, and local context for the tweet input vector representation to the
LSTM model.
Also, we present a set of experiments, to better design the network parameters
for the Twitter NER task.
Our system was ranked the fifth out of ten participants with a final f1-score
for the typed classes of 39% and 55% for the non typed ones.},
 address = {Osaka, Japan},
 author = {Gerguis, Michel Naim and Salama, Cherif and El-Kharashi, M. Watheq},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3925},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {188--196},
 publisher = {The COLING 2016 Organizing Committee},
 title = {ASU: An Experimental Study on Applying Deep Learning in Twitter Named Entity Recognition.},
 year = {2016}
}

@inproceedings{W16-3926,
 abstract = {This paper describes our system used in the 2nd Workshop on Noisy
User-generated Text (WNUT) shared task for Named Entity Recognition (NER) in
Twitter, in conjunction with Coling 2016. Our system is based on supervised
machine learning by applying Conditional Random Fields (CRF) to train two
classifiers for two evaluations. The first evaluation aims at predicting the 10
fine-grained types of named entities; while the second evaluation aims at
predicting no type of named entities. The experimental results show that our
method has significantly improved Twitter NER performance.},
 address = {Osaka, Japan},
 author = {LE, Ngoc Tan and Mallek, Fatma and Sadat, Fatiha},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3926},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {197--202},
 publisher = {The COLING 2016 Organizing Committee},
 title = {UQAM-NTL: Named entity recognition in Twitter messages},
 year = {2016}
}

@inproceedings{W16-3927,
 abstract = {Many of the existing Named Entity Recognition (NER) solutions are built based
on news corpus data with proper syntax. These solutions might not lead to
highly accurate results when being applied to noisy, user generated data, e.g., tweets, which can feature sloppy spelling, concept drift, and limited
contextualization of terms and concepts due to length constraints. The models
described in this paper are based on linear chain conditional random fields
(CRFs), use the BIEOU encoding scheme, and leverage random feature dropout for
up-sampling the training data. The considered features include word clusters
and pre-trained distributed word representations, updated gazetteer features, and global context predictions. The latter feature allows for ingesting the
meaning of new or rare tokens into the system via unsupervised learning and for
alleviating the need to learn lexicon based features, which usually tend to be
high dimensional. In this paper, we report on the solution [ST] we submitted to
the WNUT 2016 NER shared task. We also present an improvement over our original
submission [SI], which we built by using semi-supervised learning on labelled
training data and pre-trained resourced constructed from unlabelled tweet data.
Our ST solution achieved an F1 score of 1.2% higher than the baseline (35.1%
F1) for the task of extracting 10 entity types. The SI resulted in an increase
of 8.2% in F1 score over the base-line (7.08% over ST). Finally, the SI
model{\^a}s evaluation on the test data achieved a F1 score of 47.3% (~1.15%
increase over the 2nd best submitted solution). Our experimental setup and
results are available as a standalone twitter NER tool at
https://github.com/napsternxg/TwitterNER.},
 address = {Osaka, Japan},
 author = {Mishra, Shubhanshu and Diesner, Jana},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3927},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {203--212},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Semi-supervised Named Entity Recognition in noisy-text},
 year = {2016}
}

@inproceedings{W16-3928,
 abstract = {This paper presents the shared task for English Twitter geolocation prediction
in WNUT 2016. We discuss details of task settings, data preparations and
participant systems. The derived dataset and performance figures from each
system provide baselines for future research in this realm.},
 address = {Osaka, Japan},
 author = {Han, Bo and Rahimi, Afshin and Derczynski, Leon and Baldwin, Timothy},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3928},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {213--217},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Twitter Geolocation Prediction Shared Task of the 2016 Workshop on Noisy User-generated Text},
 year = {2016}
}

@inproceedings{W16-3929,
 abstract = {In this paper, we describe CSIRO Data61{\^a}s participation in the Geolocation
shared task at the
Workshop for Noisy User-generated Text. Our approach was to use ensemble
methods to capitalise
on four component methods: heuristics based on metadata, a label propagation
method, timezone text classifiers, and an information retrieval approach. The ensembles
we explored
focused on examining the role of language technologies in geolocation
prediction and also in
examining the use of hard voting and cascading ensemble methods. Based on the
accuracy of
city-level predictions, our systems were the best performing submissions at
this year{\^a}s shared
task. Furthermore, when estimating the latitude and longitude of a user, our
median error distance
was accurate to within 30 kilometers.},
 address = {Osaka, Japan},
 author = {Jayasinghe, Gaya and Jin, Brian and Mchugh, James and Robinson, Bella and Wan, Stephen},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3929},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {218--226},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CSIRO Data61 at the WNUT Geo Shared Task},
 year = {2016}
}

@inproceedings{W16-3930,
 abstract = {Knowing the location of a social media user and their posts is important for
various purposes, such as the recommendation of location-based items/services, and locality detection of crisis/disasters. This paper describes our submission
to the shared task ``Geolocation Prediction in Twitter" of the 2nd Workshop on
Noisy User-generated Text. In this shared task, we propose an algorithm to
predict the location of Twitter users and tweets using a multinomial Naive
Bayes classifier trained on Location Indicative Words and various textual
features (such as city/country names, \#hashtags and $@$mentions). We compared our
approach against various baselines based on Location Indicative Words, city/country names, \#hashtags and $@$mentions as individual feature sets, and
experimental results show that our approach outperforms these baselines in
terms of classification accuracy, mean and median error distance.},
 address = {Osaka, Japan},
 author = {Chi, Lianhua and Lim, Kwan Hui and Alam, Nebula and Butler, Christopher J.},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3930},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {227--234},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Geolocation Prediction in Twitter Using Location Indicative Words and Textual Features},
 year = {2016}
}

@inproceedings{W16-3931,
 abstract = {This paper describes a model that we submitted to W-NUT 2016 Shared task \#1:
Geolocation Prediction in Twitter. Our model classifies a tweet or a user to a
city using a simple neural networks structure with fully-connected layers and
average pooling processes. From the findings of previous geolocation prediction
approaches, we integrated various user metadata along with message texts and
trained the model with them. In the test run of the task, the model achieved
the accuracy of 40.91% and the median distance error of 69.50 km in
message-level prediction and the accuracy of 47.55% and the median distance
error of 16.13 km in user-level prediction. These results are moderate
performances in terms of accuracy and best performances in terms of distance.
The results show a promising extension of neural networks based models for
geolocation prediction where recent advances in neural networks can be added to
enhance our current simple model.},
 address = {Osaka, Japan},
 author = {Miura, Yasuhide and Taniguchi, Motoki and Taniguchi, Tomoki and Ohkuma, Tomoko},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-3931},
 booktitle = {Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)},
 month = {December},
 pages = {235--239},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Simple Scalable Neural Networks based Model for Geolocation Prediction in Twitter},
 year = {2016}
}

@inproceedings{W16-4001,
 abstract = {The availability of Language Technology Resources and Tools generates a
considerable methodological potential in the Digital Humanities: aspects of
research questions from the Humanities and Social Sciences can be addressed on
text collections in ways that were unavailable to traditional approaches.  I
start this talk by sketching some sample scenarios of Digital Humanities
projects which involve various Humanities and Social Science disciplines, noting that the potential for a meaningful contribution to higher-level
questions is highest when the employed language technological models are
carefully tailored both (a) to characteristics of the given target corpus, and
(b) to relevant analytical subtasks feeding the discipline-specific research
questions.
Keeping up a multidisciplinary perspective, I then point out a recurrent
dilemma in Digital Humanities projects that follow the conventional set-up of
collaboration: to build high-quality computational models for the data, fixed
analytical targets should be specified as early as possible -- but to be able
to respond to Humanities questions as they evolve over the course of analysis, the analytical machinery should be kept maximally flexible.  To reach both, I
argue for a novel collaborative culture that rests on a more interleaved, continuous dialogue.  (Re-)Specification of analytical targets should be an
ongoing process in which the Humanities Scholars and Social Scientists play a
role that is as important as the Computational Scientists' role.  A promising
approach lies in the identification of re-occurring types of analytical
subtasks, beyond linguistic standard tasks, which can form building blocks for
text analysis across disciplines, and for which corpus-based characterizations
(viz. annotations) can be collected, compared and revised.  On such grounds, computational modeling is more directly tied to the evolving research
questions, and hence the seemingly opposing needs of reliable target
specifications vs. "malleable" frameworks of analysis can be reconciled.
Experimental work following this approach is under way in the Center for
Reflected Text Analytics (CRETA) in Stuttgart.},
 address = {Osaka, Japan},
 author = {Kuhn, Jonas},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4001},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {1},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Flexible and Reliable Text Analytics in the Digital Humanities -- Some Methodological Considerations},
 year = {2016}
}

@inproceedings{W16-4002,
 abstract = {We examine two different methods for finding rising words (among which
neologisms) and falling words (among which archaisms) in decades of magazine
texts (millions of words) and in years of tweets (billions of words): one based
on correlation coefficients of relative frequencies and time, and one based on
comparing initial and final word frequencies of time intervals. We find that
smoothing frequency scores improves the precision scores of both methods and
that the correlation coefficients perform better on magazine text but worse on
tweets. Since the two ranking methods find different words they can be used in
side-by-side to study the behavior of words over time.},
 address = {Osaka, Japan},
 author = {Tjong Kim Sang, Erik},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4002},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {2--9},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Finding Rising and Falling Words},
 year = {2016}
}

@inproceedings{W16-4003,
 abstract = {Multimodal question answering in the cultural heritage domain allows visitors
to ask questions in a more natural way and thus provides better user
experiences with cultural objects while visiting a museum, landmark or any
other historical site. In this paper, we introduce the construction of a golden
standard dataset that will aid research of multimodal question answering in the
cultural heritage domain. The dataset, which will be soon released to the
public, contains multimodal content including images of typical artworks from
the fascinating old-Egyptian Amarna period, related image-containing documents
of the artworks and over 800 multimodal queries integrating visual and textual
questions. The multimodal questions and related documents are all in English.
The multimodal questions are linked to relevant paragraphs in the related
documents that contain the answer to the multimodal query.},
 address = {Osaka, Japan},
 author = {Sheng, Shurong and Van Gool, Luc and Moens, Marie-Francine},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4003},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {10--17},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Dataset for Multimodal Question Answering in the Cultural Heritage Domain},
 year = {2016}
}

@inproceedings{W16-4004,
 abstract = {In this paper a social network is extracted from a literary text. The social
network shows, how frequent the characters interact and how similar their
social behavior is. Two types of similarity measures are used: the first
applies co-occurrence statistics, while the second exploits cosine similarity
on different types of word embedding vectors.
The results are evaluated by a paid micro-task crowdsourcing survey. The
experiments suggest that specific types of word embeddings like word2vec are
well-suited for the task at hand and the specific circumstances of literary
fiction text.},
 address = {Osaka, Japan},
 author = {Wohlgenannt, Gerhard and Chernyak, Ekaterina and Ilvovsky, Dmitry},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4004},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {18--25},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Extracting Social Networks from Literary Text with Word Embedding Tools},
 year = {2016}
}

@inproceedings{W16-4005,
 abstract = {We present an approach to detect differences in lexical semantics across
English language registers, using word embedding models from distributional
semantics paradigm. Models trained on register-specific subcorpora of the BNC
corpus are employed to compare lists of nearest associates for particular words
and draw conclusions about their semantic shifts depending on register in which
they are used. The models are evaluated on the task of register classification
with the help of the deep inverse regression approach.
Additionally, we present a demo web service featuring most of the described
models and allowing to explore word meanings in different English registers and
to detect register affiliation for arbitrary texts. The code for the service
can be easily adapted to any set of underlying models.},
 address = {Osaka, Japan},
 author = {Kutuzov, Andrey and Kuzmenko, Elizaveta and Marakasova, Anna},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4005},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {26--34},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Exploration of register-dependent lexical semantics using word embeddings},
 year = {2016}
}

@inproceedings{W16-4006,
 abstract = {We are constructing an annotated diachronic corpora of the Japanese language.
In part of thiswork, we construct a corpus of Manyosyu, which is an old
Japanese poetry anthology. In thispaper, we describe how to align the
transcribed text and its original text semiautomatically to beable to
cross-reference them in our Manyosyu corpus. Although we align the original
charactersto the transcribed words manually, we preliminarily align the
transcribed and original charactersby using an unsupervised automatic alignment
technique of statistical machine translation toalleviate the work. We found
that automatic alignment achieves an F1-measure of 0.83; thus, eachpoem has
1--2 alignment errors. However, finding these errors and modifying them are
less workintensiveand more efficient than fully manual annotation. The
alignment probabilities can beutilized in this modification. Moreover, we found
that we can locate the uncertain transcriptionsin our corpus and compare them
to other transcriptions, by using the alignment probabilities.},
 address = {Osaka, Japan},
 author = {Oka, Teruaki and Kono, Tomoaki},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4006},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {35--44},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Original-Transcribed Text Alignment for Manyosyu Written by Old Japanese Language},
 year = {2016}
}

@inproceedings{W16-4007,
 abstract = {Arabic is a widely-spoken language with a rich and long history spanning more
than fourteen centuries. Yet existing Arabic corpora largely focus on the
modern period or lack sufficient diachronic information. We develop a
large-scale, historical corpus of Arabic of about 1 billion words from diverse
periods of time. We clean this corpus, process it with a morphological
analyzer, and enhance it by detecting parallel passages and automatically
dating undated texts. We demonstrate its utility with selected case-studies in
which we show its application to the digital humanities.},
 address = {Osaka, Japan},
 author = {Belinkov, Yonatan and Magidow, Alexander and Romanov, Maxim and Shmidman, Avi and Koppel, Moshe},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4007},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {45--53},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Shamela: A Large-Scale Historical Arabic Corpus},
 year = {2016}
}

@inproceedings{W16-4008,
 abstract = {We here describe a novel methodology for measuring affective language in
historical text by expanding an affective lexicon and jointly adapting it to
prior language stages. We automatically construct a lexicon for word-emotion
association of 18th and 19th century German which is then validated against
expert ratings. Subsequently, this resource is used to identify distinct
emotional patterns and trace long-term emotional trends in different genres of
writing spanning several centuries.},
 address = {Osaka, Japan},
 author = {Buechel, Sven and Hellrich, Johannes and Hahn, Udo},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4008},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {54--61},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Feelings from the Past{\^a}Adapting Affective Lexicons for Historical Emotion Analysis},
 year = {2016}
}

@inproceedings{W16-4009,
 abstract = {Historical treebanks tend to be manually annotated, which is not surprising, since state-of-the-art parsers are not accurate enough to ensure high-quality
annotation for historical texts. We test whether automatic parsing can be an
efficient pre-annotation tool for Old East Slavic texts. We use the TOROT
treebank from the PROIEL treebank family. We convert the PROIEL format to the
CONLL format and use MaltParser to create syntactic pre-annotation. Using the
most conservative evaluation method, which takes into account PROIEL-specific
features, MaltParser by itself yields 0.845 unlabelled attachment score, 0.779
labelled attachment score and 0.741 secondary dependency accuracy (note, though, that the test set comes from a relatively simple genre and contains
rather short sentences). Experiments with human annotators show that
preparsing, if limited to sentences where no changes to word or sentence
boundaries are required, increases their annotation rate. For experienced
annotators, the speed gain varies from 5.80% to 16.57%, for inexperienced
annotators from 14.61% to 32.17% (using conservative estimates). There are no
strong reliable differences in the annotation accuracy, which means that there
is no reason to suspect that using preparsing might lower the final annotation
quality.},
 address = {Osaka, Japan},
 author = {Eckhoff, Hanne Martine and Berdicevskis, Aleksandrs},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4009},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {62--70},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Automatic parsing as an efficient pre-annotation tool for historical texts},
 year = {2016}
}

@inproceedings{W16-4010,
 abstract = {In this paper we will discuss a method for data visualization together with its
potential usefulness in
digital humanities and philosophy of language. We compiled a multilingual
parallel corpus from different
versions of \textit{Wittgenstein{\^a}s Tractatus Logico-philosophicus}, including
the original in German and
translations into English, Spanish, French, and Russian. Using this corpus, we
compute a similarity measure
between propositions and render a visual network of relations for different
languages.},
 address = {Osaka, Japan},
 author = {Bucur, Anca and Nisioi, Sergiu},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4010},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {71--75},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Visual Representation of Wittgenstein's Tractatus Logico-Philosophicus},
 year = {2016}
}

@inproceedings{W16-4011,
 abstract = {We introduce the third major release of WebAnno, a generic web-based annotation
tool for distributed teams. New features in this release focus on semantic
annotation tasks (e.g. semantic role labelling or event annotation) and allow
the tight integration of semantic annotations with syntactic annotations. In
particular, we introduce the concept of slot features, a novel constraint
mechanism that allows modelling the interaction between semantic and syntactic
annotations, as well as a new annotation user interface. The new features were
developed and used in an annotation project for semantic roles on German texts.
The paper briefly introduces this project and reports on experiences performing
annotations with the new tool. On a comparative evaluation, our tool reaches
significant speedups over WebAnno 2 for a semantic annotation task.},
 address = {Osaka, Japan},
 author = {Eckart de Castilho, Richard and M\'{u}jdricza-Maydt, \'{E}va and Yimam, Seid Muhie and Hartmann, Silvana and Gurevych, Iryna and Frank, Anette and Biemann, Chris},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4011},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {76--84},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Web-based Tool for the Integrated Annotation of Semantic and Syntactic Structures},
 year = {2016}
}

@inproceedings{W16-4012,
 abstract = {Although spanning thousands of years and genres as diverse as liturgy, historiography, lyric and other forms of prose and poetry, the body of Latin
texts is still relatively sparse compared to English. Data sparsity in Latin
presents a number of challenges for traditional Named Entity Recognition
techniques. Solving such challenges and enabling reliable Named Entity
Recognition in Latin texts can facilitate many down-stream applications, from
machine translation to digital historiography, enabling Classicists, historians, and archaeologists for instance, to track the relationships of
historical persons, places, and groups on a large scale. This paper presents
the first annotated corpus for evaluating Named Entity Recognition in Latin, as
well as a fully supervised model that achieves over 90% F-score on a held-out
test set, significantly outperforming a competitive baseline. We also present a
novel active learning strategy that predicts how many and which sentences need
to be annotated for named entities in order to attain a specified degree of
accuracy when recognizing named entities automatically in a given text. This
maximizes the productivity of annotators while simultaneously controlling
quality.},
 address = {Osaka, Japan},
 author = {Erdmann, Alexander and Brown, Christopher and Joseph, Brian and Janse, Mark and Ajaka, Petra and Elsner, Micha and de Marneffe, Marie-Catherine},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4012},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {85--93},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Challenges and Solutions for Latin Named Entity Recognition},
 year = {2016}
}

@inproceedings{W16-4013,
 abstract = {We present ANNISVis, a webapp for comparative visualization of geographical
distribution of linguistic data, as well as a sample deployment for a corpus of
Middle High German texts. Unlike existing geographical visualization solutions, which work with pre-existing data sets, or are bound to specific corpora, ANNISVis allows the user to formulate multiple ad-hoc queries and visualizes
them on a map, and it can be configured for any corpus that can be imported
into ANNIS. This enables explorative queries of the quantitative aspects of a
corpus with geographical features. The tool will be made available to download
in open source.},
 address = {Osaka, Japan},
 author = {Petran, Florian},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4013},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {94--100},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Geographical Visualization of Search Results in Historical Corpora},
 year = {2016}
}

@inproceedings{W16-4014,
 abstract = {In the Danish CLARIN-DK infrastructure, chaining language technology (LT) tools
into a workflow is easy even for a non-expert user, because she only needs to
specify the input and the desired output of the workflow. With this information
and the registered input and output profiles of the available tools, the
CLARIN-DK workflow management system (WMS) computes combinations of tools that
will give the desired result. This advanced functionality was originally not
envisaged, but came within reach by writing the WMS partly in Java and partly
in a programming language for symbolic computation, Bracmat. Handling LT tool
profiles, including the computation of workflows, is easier with Bracmat's
language constructs for tree pattern matching and tree construction than with
the language constructs offered by mainstream programming languages.},
 address = {Osaka, Japan},
 author = {Jongejan, Bart},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4014},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {101--108},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Implementation of a Workflow Management System for Non-Expert Users},
 year = {2016}
}

@inproceedings{W16-4015,
 abstract = {Machine Translation (MT) plays a critical role in expanding capacity in the
translation industry.
However, many valuable documents, including digital documents, are encoded in
non-accessible formats for machine processing (e.g., Historical or Legal
documents).
Such documents must be passed through a process of Optical Character
Recognition (OCR) to render the text suitable for MT.
No matter how good the OCR is, this process introduces recognition
errors, which often renders MT ineffective. In this paper, we propose a new OCR
to MT framework based on adding a new OCR error correction module to enhance
the overall quality of translation.
Experimentation shows that our new system correction based on the combination
of Language Modeling and Translation methods outperforms the baseline system by
nearly 30% relative improvement.},
 address = {Osaka, Japan},
 author = {Afli, Haithem and Way, Andy},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4015},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {109--116},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Integrating Optical Character Recognition and Machine Translation of Historical Documents},
 year = {2016}
}

@inproceedings{W16-4016,
 abstract = {In this paper we describe how the complexity of human communication can be
analysed with the help of language technology. We present the HuComTech corpus, a multimodal corpus containing 50 hours of videotaped interviews containing a
rich annotation of about 2 million items annotated on 33 levels. The corpus
serves as a general resource for a wide range of re-search addressing natural
conversation between humans in their full complexity. It can benefit
particularly digital humanities researchers working in the field of pragmatics, conversational analysis and discourse analysis. We will present a number of
tools and automated methods that can help such enquiries. In particular, we
will highlight the tool Theme, which is designed to uncover hidden temporal
patterns (called T-patterns) in human interaction, and will show how it can
applied to the study of multimodal communication.},
 address = {Osaka, Japan},
 author = {Hunyadi, L\'{a}szl\'{o} and V\'{a}radi, Tam\'{a}s and Szekr\'{e}nyes, Istv\'{a}n},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4016},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {117--124},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Language technology tools and resources for the analysis of multimodal communication},
 year = {2016}
}

@inproceedings{W16-4017,
 abstract = {Most modern and post-modern poems have developed a post-metrical idea of
lyrical prosody that employs rhythmical features of everyday language and prose
instead of a strict adherence to rhyme and metrical schemes. This development
is subsumed under the term free verse prosody. We present our methodology for
the large-scale analysis of modern and post-modern poetry in both their written
form and as spoken aloud by the author. We employ language processing tools to
align text and speech, to generate a null-model of how the poem would be spoken
by a na\"{i}ve reader, and to extract contrastive prosodic features used by the
poet. On these, we intend to build our model of free verse prosody, which will
help to understand, differentiate and relate the different styles of free verse
poetry. We plan to use our processing scheme on large amounts of data to
iteratively build models of styles, to validate and guide manual style
annotation, to identify further rhythmical categories, and ultimately to
broaden our understanding of free verse poetry. In this paper, we report on a
proof-of-concept of our methodology using smaller amounts of poems and a
limited set of features. We find that our methodology helps to extract
differentiating features in the authors' speech that can be explained by
philological insight. Thus, our automatic method helps to guide the literary
analysis and this in turn helps to improve our computational models.},
 address = {Osaka, Japan},
 author = {Baumann, Timo and Meyer-Sickendiek, Burkhard},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4017},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {125--130},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Large-scale Analysis of Spoken Free-verse Poetry},
 year = {2016}
}

@inproceedings{W16-4018,
 abstract = {This paper presents a tool to investigate the design of multimodal instructions
(MIs), i.e., instructions that contain both text and pictures. The benefit of
including pictures in information presentation has been established, but the
characteristics of those pictures and of their textual counterparts and the
rela-tion(s) between them have not been researched in a systematic manner. We
present the PAT Work-bench, a tool to store, annotate and retrieve MIs based on
a validated coding scheme with currently 42 categories that describe
instructions in terms of textual features, pictorial elements, and relations
be-tween text and pictures. We describe how the PAT Workbench facilitates
collaborative annotation and inter-annotator agreement calculation. Future work
on the tool includes expanding its functionality and usability by (i) making
the MI annotation scheme dynamic for adding relevant features based on
empirical evaluations of the MIs, (ii) implementing algorithms for automatic
tagging of MI features, and (iii) implementing automatic MI evaluation
algorithms based on results obtained via e.g. crowdsourced assessments of MIs.},
 address = {Osaka, Japan},
 author = {van der Sluis, Ielka and Kloppenburg, Lennart and Redeker, Gisela},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4018},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {131--139},
 publisher = {The COLING 2016 Organizing Committee},
 title = {PAT workbench: Annotation and Evaluation of Text and Pictures in Multimodal Instructions},
 year = {2016}
}

@inproceedings{W16-4019,
 abstract = {The increasing amount of multilingual text collections available in different
domains makes its automatic processing essential for the development of a given
field. However, standard processing techniques based on statistical clues and
keyword searches have clear limitations. Instead, we propose a knowledge-based
processing pipeline which overcomes most of the limitations of these
techniques. This, in turn, enables direct comparison across texts in different
languages without the need of translation. In this paper we show the potential
of this approach for semantically indexing multilingual text collections in the
history domain. In our experiments we used a version of the Bible translated in
four different languages, evaluating the precision of our semantic indexing
pipeline and showing its reliability on the cross-lingual text retrieval task.},
 address = {Osaka, Japan},
 author = {Raganato, Alessandro and Camacho-Collados, Jose and Raganato, Antonio and Joung, Yunseo},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4019},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {140--147},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Semantic Indexing of Multilingual Corpora and its Application on the History Domain},
 year = {2016}
}

@inproceedings{W16-4020,
 abstract = {This paper presents on-going work on creating NLP tools for under-resourced
languages from very sparse training data coming from linguistic field work. In
this work, we focus on Ingush, a  Nakh-Daghestanian language spoken by about
300,000 people in the Russian republics Ingushetia and Chechnya. We present
work on morphosyntactic taggers trained on transcribed and linguistically
analyzed recordings and dependency parsers using English glosses to project
annotation for creating synthetic treebanks. Our preliminary results are
promising, supporting the goal of bootstrapping efficient NLP tools with
limited
or no task-specific annotated data resources available.},
 address = {Osaka, Japan},
 author = {Tiedemann, J\"{o}rg and Nichols, Johanna and Sprouse, Ronald},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4020},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {148--155},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Tagging Ingush - Language Technology For Low-Resource Languages Using Resources From Linguistic Field Work},
 year = {2016}
}

@inproceedings{W16-4021,
 abstract = {This paper gives an overview of the MultiTal project, which aims to create a
research infrastructure that ensures long-term distribution of NLP tools
descriptions. The goal is to make NLP tools more accessible and usable to
end-users of different disciplines.
The infrastructure is built on a meta-data scheme modelling and standardising
multilingual NLP tools documentation. The model is conceptualised using an OWL
ontology. The formal representation of the ontology allows us to automatically
generate organised and structured documentation in different languages for each
represented tool.},
 address = {Osaka, Japan},
 author = {Sadoun, Driss and Mkhitaryan, Satenik and Nouvel, Damien and Valette, Mathieu},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4021},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {156--163},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The MultiTal NLP tool infrastructure},
 year = {2016}
}

@inproceedings{W16-4022,
 abstract = {This article describes work on enabling the addition of temporal information to
senses of words in linguistic linked open data lexica based on the lemonDia
model. Our contribution in this article is twofold. On the one hand, we
demonstrate how lemonDia enables the querying of diachronic lexical datasets
using OWL-oriented Semantic Web based technologies. On the other hand, we
present a preliminary version of an interactive interface intended to help
users in creating lexical datasets that model meaning change over time.},
 address = {Osaka, Japan},
 author = {Khan, Fahad and Bellandi, Andrea and Monachini, Monica},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4022},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {164--171},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Tools and Instruments for Building and Querying Diachronic Computational Lexica},
 year = {2016}
}

@inproceedings{W16-4023,
 abstract = {(This is the abstract for the submission.)
Large-scale comparisons between the poetry of Tang and Song dynasties shed
light on how words and expressions were used and shared among the poets. That
some words were used only in the Tang poetry and some only in the Song poetry
could lead to interesting research in linguistics. That the most frequent
colors are different in the Tang and Song poetry provides a trace of the
changing social circumstances in the dynasties. Results of the current work
link to research topics of lexicography, semantics, and social transitions. We
discuss our findings and present our algorithms for efficient comparisons among
the poems, which are crucial for completing billion times of comparisons within
acceptable time.},
 address = {Osaka, Japan},
 author = {Liu, Chao-Lin and Luo, Kuo-Feng},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4023},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {172--180},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Tracking Words in Chinese Poetry of Tang and Song Dynasties with the China Biographical Database},
 year = {2016}
}

@inproceedings{W16-4024,
 abstract = {The following paper describes the first steps in the development of an ontology
for the textbook research discipline. The aim of the project WorldViews is to
establish a digital edition focussing on views of the world depicted in
textbooks. For this purpose an initial TEI profile has been formalised and
tested as a use case to enable the semantical encoding of the resource
'textbook'. This profile shall provide a basic data model describing major
facets of the textbook's structure relevant to historians.},
 address = {Osaka, Japan},
 author = {Stahn, Lena-Luise and Hennicke, Steffen and De Luca, Ernesto William},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4024},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {181--186},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Using TEI for textbook research},
 year = {2016}
}

@inproceedings{W16-4025,
 abstract = {In this paper we present a new combination of existing language tools for
Polish with a popular data mining platform intended to help researchers from
digital humanities perform computational analyses without any programming. The
toolset includes RapidMiner Studio, a software solution offering graphical
setup of integrated analytical processes and Multiservice, a Web service
offering access to several state-of-the-art linguistic tools for Polish. The
setting is verified in a simple task of counting frequencies of unknown words
in a small corpus.},
 address = {Osaka, Japan},
 author = {Ogrodniczuk, Maciej},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4025},
 booktitle = {Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)},
 month = {December},
 pages = {187--195},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Web services and data mining: combining linguistic tools for Polish with an analytical platform},
 year = {2016}
}

@inproceedings{W16-4101,
 abstract = {In this paper, we propose to use a subfield of machine learning --grammatical
inference-- to measure linguistic complexity from a developmental point of
view. We focus on relative complexity by considering a child learner in the
process of first language acquisition. The relevance of grammatical inference
models for measuring linguistic complexity from a developmental point of view
is based on the fact that algorithms proposed in this area can be considered
computational models for studying first language acquisition. Even though it
will be possible to use different techniques from the field of machine learning
as computational models for dealing with linguistic complexity --since in any
model we have algorithms that can learn from data--, we claim that grammatical
inference models offer some advantages over other tools.},
 address = {Osaka, Japan},
 author = {Jimenez Lopez, Maria Dolores and Becerra-Bonache, Leonor},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4101},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {1--11},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Could Machine Learning Shed Light on Natural Language Complexity?},
 year = {2016}
}

@inproceedings{W16-4102,
 abstract = {In this paper, we introduce for the first time a Distributional Model for
computing semantic complexity, inspired by the general principles of the
Memory, Unification and Control framework(Hagoort, 2013; Hagoort, 2016). We
argue that sentence comprehension is an incremental process driven by the goal
of constructing a coherent representation of the event represented by the
sentence. The composition cost of a sentence depends on the semantic coherence
of the event being constructed and on the activation degree of the linguistic
constructions. We also report the results of a first evaluation of the model on
the Bicknell dataset (Bicknell et al., 2010).},
 address = {Osaka, Japan},
 author = {Chersoni, Emmanuele and Blache, Philippe and Lenci, Alessandro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4102},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {12--22},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Towards a Distributional Model of Semantic Complexity},
 year = {2016}
}

@inproceedings{W16-4103,
 abstract = {We present a novel approach to the automatic assessment of text complexity
based on a sliding-window technique that tracks the distribution of complexity
within a text. Such distribution is captured by what we term {\^a}complexity
contours{\^a} derived from a series of measurements for a given linguistic
complexity measure. This approach is implemented in an automatic computational
tool, CoCoGen -- Complexity Contour Generator, which in its current version
supports 32 indices of linguistic complexity. The goal of the paper is twofold:
(1) to introduce the design of our computational tool based on a sliding-window
technique and (2) to showcase this approach in the area of second language (L2)
learning, i.e. more specifically, in the area of L2 writing.},
 address = {Osaka, Japan},
 author = {Marcus, Str\"{o}bel and Kerz, Elma and Wiechmann, Daniel and Neumann, Stella},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4103},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {23--31},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CoCoGen - Complexity Contour Generator: Automatic Assessment of Linguistic Complexity Using a Sliding-Window Technique},
 year = {2016}
}

@inproceedings{W16-4104,
 abstract = {This study demonstrates a weakness in how n-gram and PCFG surprisal are used to
predict reading times in eye-tracking data. In particular, the information
conveyed by words skipped during saccades is not usually included in the
surprisal measures. This study shows that correcting the surprisal calculation
improves n-gram surprisal and that upcoming n-grams affect reading times, replicating previous findings of how lexical frequencies affect reading times.
In contrast, the predictivity of PCFG surprisal does not benefit from the
surprisal correction despite the fact that lexical sequences skipped by
saccades are processed by readers, as demonstrated by the corrected n-gram
measure. These results raise questions about the formulation of
information-theoretic measures of syntactic processing such as PCFG surprisal
and entropy reduction when applied to reading times.},
 address = {Osaka, Japan},
 author = {van Schijndel, Marten and Schuler, William},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4104},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {32--37},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Addressing surprisal deficiencies in reading time models},
 year = {2016}
}

@inproceedings{W16-4105,
 abstract = {Computational approaches to readability assessment are generally built and
evaluated using gold standard corpora labeled by publishers or teachers rather
than being grounded in observations about human performance. Considering that
both the reading process and the outcome can be observed, there is an empirical
wealth that could be used to ground computational analysis of text readability.
This will also support explicit readability models connecting text complexity
and the reader{\^a}s language proficiency to the reading process and outcomes.
This paper takes a step in this direction by reporting on an experiment to
study how the rela- tion between text complexity and reader{\^a}s language
proficiency affects the reading process and performance outcomes of readers
after reading We modeled the reading process using three eye tracking
variables: fixation count, average fixation count, and second pass reading
duration. Our models for these variables explained 78.9%, 74% and 67.4%
variance, respectively. Performance outcome was modeled through recall and
comprehension questions, and these models explained 58.9% and 27.6% of the
variance, respectively. While the online models give us a better under-
standing of the cognitive correlates of reading with text complexity and
language proficiency, modeling of the offline measures can be particularly
relevant for incorporating user aspects into readability models.},
 address = {Osaka, Japan},
 author = {Vajjala, Sowmya and Meurers, Detmar and Eitel, Alexander and Scheiter, Katharina},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4105},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {38--48},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Towards grounding computational linguistic approaches to readability: Modeling reader-text interaction for easy and difficult texts},
 year = {2016}
}

@inproceedings{W16-4106,
 abstract = {Studies on the role of memory as a predictor of reading time latencies (1)
differ in their predictions about when memory effects should occur in
processing and (2) have had mixed results, with strong positive effects
emerging from isolated constructed stimuli and weak or even negative effects
emerging from naturally-occurring stimuli. Our study addresses these concerns
by comparing several implementations of prominent sentence processing theories
on an exploratory corpus and evaluating the most successful of these on a
confirmatory corpus, using a new self-paced reading corpus of seemingly natural
narratives constructed to contain an unusually high proportion of
memory-intensive constructions. We show highly significant and complementary
broad-coverage latency effects both for predictors based on the Dependency
Locality Theory and for predictors based on a left-corner parsing model of
sentence processing. Our results indicate that memory access during sentence
processing does take time, but suggest that stimuli requiring many memory
access events may be necessary in order to observe the effect.},
 address = {Osaka, Japan},
 author = {Shain, Cory and van Schijndel, Marten and Futrell, Richard and Gibson, Edward and Schuler, William},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4106},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {49--58},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Memory access during incremental sentence processing causes reading time latency},
 year = {2016}
}

@inproceedings{W16-4107,
 abstract = {Lexical complexity plays a central role in readability, particularly for
dyslexic children and poor readers because of their slow and laborious decoding
and word recognition skills. Although some features to aid readability may be
common to most languages (e.g., the majority of 'easy' words are of low
frequency), we believe that lexical complexity is mainly language-specific. In
this paper, we define lexical complexity for French and we present a pilot
study on the effects of text simplification in dyslexic children. The
participants were asked to read out loud original and manually simplified
versions of a standardized French text corpus and to answer comprehension
questions after reading each text. The analysis of the results shows that the
simplifications performed were beneficial in terms of reading speed and they
reduced the number of reading errors (mainly lexical ones) without a loss in
comprehension. Although the number of participants in this study was rather
small (N=10), the results are
promising and contribute to the development of applications in computational
linguistics.},
 address = {Osaka, Japan},
 author = {Gala, Nuria and Ziegler, Johannes},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4107},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {59--66},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Reducing lexical complexity as a tool to increase text accessibility for children with dyslexia},
 year = {2016}
}

@inproceedings{W16-4108,
 abstract = {In this paper we will be dealing with different levels of complexity in the
processing of Italian, a Romance language inheriting many properties from Latin
which make it an almost free word order language . The paper is concerned with
syntactic complexity as measurable on the basis of the cognitive parser that
incrementally builds up a syntactic representation to be used by the semantic
component. The theory behind will be LFG and parsing preferences will be used
to justify one choice both from a principled and a processing point of view.
LFG is a transformationless theory in which there is no deep structure separate
from surface syntactic structure. This is partially in accordance with
constructional theories in which noncanonical structures containing
non-argument functions FOCUS/TOPIC are treated as multifunctional constituents.
Complexity is computed on a processing basis following suggestions made by
Blache and demonstrated by Kluender and Chesi},
 address = {Osaka, Japan},
 author = {Delmonte, Rodolfo},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4108},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {67--78},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Syntactic and Lexical Complexity in Italian Noncanonical Structures},
 year = {2016}
}

@inproceedings{W16-4109,
 abstract = {Previous researches have shown that learning multiple representations for
polysemous words can improve the performance of word embeddings on many tasks.
However, this leads to another problem. Several vectors of a word may actually
point to the same meaning, namely pseudo multi-sense. In this paper, we
introduce the concept of pseudo multi-sense, and then propose an algorithm to
detect such cases. With the consideration of the detected pseudo multi-sense
cases, we try to refine the existing word embeddings to eliminate the influence
of pseudo multi-sense. Moreover, we apply our algorithm on previous released
multi-sense word embeddings and tested it on artificial word similarity tasks
and the analogy task. The result of the experiments shows that diminishing
pseudo multi-sense can improve the quality of word representations. Thus, our
method is actually an efficient way to reduce linguistic complexity.},
 address = {Osaka, Japan},
 author = {Shi, Haoyue and Li, Caihua and Hu, Junfeng},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4109},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {79--88},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Real Multi-Sense or Pseudo Multi-Sense: An Approach to Improve Word Representation},
 year = {2016}
}

@inproceedings{W16-4110,
 abstract = {In this paper, we present a comparative analysis of statistically predictive
syntactic features of complexity and the treatment of these features by humans
when simplifying texts. To that end, we have used a list of the most five
statistically predictive features obtained automatically and the Corpus of
Basque Simplified Texts (CBST) to analyse how the syntactic phenomena in these
features have been manually simplified. Our aim is to go beyond the
descriptions of operations found in the corpus and relate the multidisciplinary
findings to understand text complexity from different points of view. We also
present some issues that can be important when analysing linguistic complexity.},
 address = {Osaka, Japan},
 author = {Gonzalez-Dios, Itziar and Aranzabe, Mar\'{i}a Jes\'{u}s and D\'{i}az de Ilarraza, Arantza},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4110},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {89--97},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Preliminary Study of Statistically Predictive Syntactic Complexity Features and Manual Simplifications in Basque},
 year = {2016}
}

@inproceedings{W16-4111,
 abstract = {Pause analysis of key-stroke logged translations is a hallmark of process based
translation studies.
However, an exact definition of what a cognitively effortful pause during the
translation process is has not been found yet (Saldanha and O{\^a}Brien, 2013).
This paper investigates the design of a key-stroke and subject dependent
identification system of cognitive effort to track complexity in translation
with keystroke logging (cf. also (Dragsted, 2005) (Couto-Vale, in
preparation)). It is an elastic measure that takes into account idiosyncratic
pause duration of translators as well as further confounds such as bi-gram
frequency, letter frequency and some motor tasks involved in writing. The
method is
compared to a common static threshold of 1000 ms in an analysis of cognitive
effort during the translation of grammatical functions from English to German.
Additionally, the results are triangulated with eye tracking data for further
validation. The findings show that at least for smaller sets of data a
dynamic pause assessment may lead to more accurate results than a generic
static pause threshold of similar duration.},
 address = {Osaka, Japan},
 author = {Heilmann, Arndt and Neumann, Stella},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4111},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {98--103},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Dynamic pause assessment of keystroke logged data for the detection of complexity in translation and monolingual text production},
 year = {2016}
}

@inproceedings{W16-4112,
 abstract = {Data driven approaches to readability analysis for languages other than English
has been plagued by a scarcity of suitable corpora. Often, relevant corpora
consist only of easy-to-read texts with no rank information or empirical
readability scores, making only binary approaches, such as classification, applicable. We propose a Bayesian, latent variable, approach to get the most
out of these kinds of corpora. In this paper we present results on using such a
model for readability ranking. The model is evaluated on a preliminary corpus
of ranked student texts with encouraging results. We also assess the model by
showing that it performs readability classification on par with a state of the
art classifier while at the same being transparent enough to allow more
sophisticated interpretations.},
 address = {Osaka, Japan},
 author = {Falkenjack, Johan and Jonsson, Arne},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4112},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {104--112},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Implicit readability ranking using the latent variable of a Bayesian Probit model},
 year = {2016}
}

@inproceedings{W16-4113,
 abstract = {Informed by research on readability and language acquisition, computational
linguists have developed sophisticated tools for the analysis of linguistic
complexity. While some tools are starting to become accessible on the web, there still is a disconnect between the features that can in principle be
identified based on state-of-the-art computational linguistic analysis, and the
analyses a second language acquisition researcher, teacher, or textbook writer
can readily obtain and visualize for their own collection of texts.
This short paper presents a web-based tool development that aims to meet this
challenge. The Common Text Analysis Platform (CTAP) is designed to support
fully configurable linguistic feature extraction for a wide range of complexity
analyses. It features a user-friendly interface, modularized and reusable
analysis component integration, and flexible corpus and feature management.
Building on the Unstructured Information Management framework (UIMA), CTAP
readily supports integration of state-of-the-art NLP and complexity feature
extraction maintaining modularization and reusability. CTAP thereby aims at
providing a common platform for complexity analysis, encouraging research
collaboration and sharing of feature extraction components---to jointly advance
the state-of-the-art in complexity analysis in a form that readily supports
real-life use by ordinary users.},
 address = {Osaka, Japan},
 author = {Chen, Xiaobin and Meurers, Detmar},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4113},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {113--119},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CTAP: A Web-Based Tool Supporting Automatic Complexity Analysis},
 year = {2016}
}

@inproceedings{W16-4114,
 abstract = {We bring together knowledge from two different types of language learning data, texts learners read and texts they write, to improve  linguistic complexity
classification in the latter. Linguistic complexity in the foreign and second
language learning context can be expressed in terms of proficiency levels. We
show that incorporating features capturing lexical complexity information from
reading passages can boost significantly the machine learning based
classification of learner-written texts into proficiency levels. With an F1
score of .8 our system rivals state-of-the-art results reported for other
languages for this task. Finally, we present a freely available web-based tool
for proficiency level classification and lexical complexity visualization for
both learner writings and reading texts.},
 address = {Osaka, Japan},
 author = {Pil\'{a}n, Ildik\'{o} and Alfter, David and Volodina, Elena},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4114},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {120--126},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Coursebook Texts as a Helping Hand for Classifying Linguistic Complexity in Language Learners' Writings},
 year = {2016}
}

@inproceedings{W16-4115,
 abstract = {Arabic writing is typically underspecified for short vowels and other markups, referred to as diacritics. In addition to the lexical ambiguity exhibited in
most languages, the lack of diacritics in written Arabic adds another layer of
ambiguity which is an artifact of the orthography. In this paper, we present
the details of three annotation experimental conditions designed to study the
impact of  automatic ambiguity detection, on  annotation speed and quality in a
large scale annotation project.},
 address = {Osaka, Japan},
 author = {Zaghouani, Wajdi and Hawwari, Abdelati and Alqahtani, Sawsan and Bouamor, Houda and Ghoneim, Mahmoud and Diab, Mona and Oflazer, Kemal},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4115},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {127--136},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Using Ambiguity Detection to Streamline Linguistic Annotation},
 year = {2016}
}

@inproceedings{W16-4116,
 abstract = {Computational linguistic approaches to sign languages could benefit from
investigating how complexity influences structure.
We investigate whether morphological complexity has an effect on the order of
Verb (V) and Object (O) in Swedish Sign Language (SSL), on the basis of
elicited data from five Deaf signers.
We find a significant difference in the distribution of the orderings OV vs.
VO, based on an analysis of morphological weight.
While morphologically heavy verbs exhibit a general preference for OV, humanness seems to affect the ordering in the opposite direction, with [+human]
Objects pushing towards a preference for VO.},
 address = {Osaka, Japan},
 author = {Bjerva, Johannes and B\"{o}rstell, Carl},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4116},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {137--141},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Morphological Complexity Influences Verb-Object Order in Swedish Sign Language},
 year = {2016}
}

@inproceedings{W16-4117,
 abstract = {Language complexity is an intriguing phenomenon argued to play an important
role in both language learning and processing. The need to compare languages
with regard to their complexity resulted in a multitude of approaches and
methods, ranging from accounts targeting specific structural features to global
quantification of variation more generally. In this paper, we investigate the
degree to which morphological complexity measures are mutually correlated in a
sample of more than 500 languages of 101 language families. We use human expert
judgements from the World Atlas of Language Structures (WALS), and compare them
to four quantitative measures automatically calculated from language corpora.
These consist of three previously defined corpus-derived measures, which are
all monolingual, and one new measure based on automatic word-alignment across
pairs of languages. We find strong correlations between all the measures, illustrating that both expert judgements and automated approaches converge to
similar complexity ratings, and can be used interchangeably.},
 address = {Osaka, Japan},
 author = {Bentz, Christian and Ruzsics, Tatyana and Koplenig, Alexander and Samardzic, Tanja},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4117},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {142--153},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Comparison Between Morphological Complexity Measures: Typological Data vs. Language Corpora},
 year = {2016}
}

@inproceedings{W16-4118,
 abstract = {Comparable or parallel corpora are beneficial for many NLP tasks. The automatic
collection of corpora enables large-scale resources, even for less-resourced
languages, which in turn can be useful for deducing rules and patterns for text
rewriting algorithms, a subtask of automatic text simplification.
We present two methods for the alignment of Swedish easy-to-read text segments
to text segments from a reference corpus. The first method (M1) was originally
developed for the task of text reuse detection, measuring sentence similarity
by a modified version of a TF-IDF vector space model. A second method (M2), also accounting for part-of-speech tags, was developed, and the methods were
compared.
For evaluation, a crowdsourcing platform was built for human judgement data
collection, and preliminary results showed that cosine similarity relates
better to human ranks than the Dice coefficient. We also saw a tendency that
including syntactic context to the TF-IDF vector space model is beneficial for
this kind of paraphrase alignment task.},
 address = {Osaka, Japan},
 author = {Albertsson, Sarah and Rennes, Evelina and Jonsson, Arne},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4118},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {154--163},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Similarity-Based Alignment of Monolingual Corpora for Text Simplification Purposes},
 year = {2016}
}

@inproceedings{W16-4119,
 abstract = {This work presents a framework for the automatic construction of large Web
corpora classified by readability level. We compare different Machine Learning
classifiers for the task of readabil- ity assessment focusing on Portuguese and
English texts, analysing the impact of variables like the feature inventory
used in the resulting corpus. In a comparison between shallow and deeper
features, the former already produce F-measures of over 0.75 for Portuguese
texts, but the use of additional features results in even better results, in
most cases. For English, shallow features also perform well as do classic
readability formulas. Comparing different classifiers for the task, logistic
regression obtained, in general, the best results, but with considerable
differences be- tween the results for two and those for three-classes, especially regarding the intermediary class. Given the large scale of the
resulting corpus, for evaluation we adopt the agreement between different
classifiers as an indication of readability assessment certainty. As a result
of this work, a large corpus for Brazilian Portuguese was built, including 1.7
million documents and about 1.6 billion tokens, already parsed and annotated
with 134 different textual attributes, along with the agreement among the
various classifiers.},
 address = {Osaka, Japan},
 author = {Wagner Filho, Jorge Alberto and Wilkens, Rodrigo and Villavicencio, Aline},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4119},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {164--173},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Automatic Construction of Large Readability Corpora},
 year = {2016}
}

@inproceedings{W16-4120,
 abstract = {This work investigates the application of a measure of surprisal to modeling a
grammatical variation phenomenon between near-synonymous constructions. We
investigate a particular variation phenomenon, word order variation in Dutch
two-verb clusters, where it has been established that word order choice is
affected by processing cost. Several multifactorial corpus studies of Dutch
verb clusters have used other measures of processing complexity to show that
this factor affects word order choice. This previous work allows us to compare
the surprisal measure, which is based on constraint satisfaction theories of
language modeling, to those previously used measures, which are more directly
linked to empirical observations of processing complexity. Our results show
that surprisal does not predict the word order choice by itself, but is a
significant predictor when used in a measure of uniform information density
(UID). This lends support to the view that human language processing is
facilitated not so much by predictable sequences of words but more by sequences
of words in which information is spread evenly.},
 address = {Osaka, Japan},
 author = {Bloem, Jelke},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4120},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {174--185},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Testing the Processing Hypothesis of word order variation using a probabilistic language model},
 year = {2016}
}

@inproceedings{W16-4121,
 abstract = {The relative contributions of meaning and form to sentence processing remains
an outstanding issue across the language sciences. We examine this issue by
formalizing four incremental complexity metrics and comparing them against
freely-available ROI timecourses. Syntax-related metrics based on top-down
parsing and structural dependency-distance turn out to significantly improve a
regression model, compared to a simpler model that formalizes only conceptual
combination using a distributional vector-space model. This confirms the view
of the anterior temporal lobes as combinatory engines that deal in both form
(see e.g. Brennan et al., 2012; Mazoyer, 1993) and meaning (see e.g., Patterson
et al., 2007). This same characterization applies to a posterior temporal
region in roughly ``Wernicke's Area.''},
 address = {Osaka, Japan},
 author = {Li, Jixing and Brennan, Jonathan and Mahar, Adam and Hale, John},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4121},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {186--191},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Temporal Lobes as Combinatory Engines for both Form and Meaning},
 year = {2016}
}

@inproceedings{W16-4122,
 abstract = {This paper investigates the use of automatic speech recognition (ASR) errors as
indicators of the second language (L2) learners' listening difficulties and in
doing so strives to overcome the shortcomings of Partial and Synchronized
Caption (PSC) system. PSC is a system that generates a partial caption
including difficult words detected based on high speech rate, low frequency, and specificity. To improve the choice of words in this system, and explore a
better method to detect speech challenges, ASR errors were investigated as a
model of the L2 listener, hypothesizing that some of these errors are similar
to those of language learners' when transcribing the videos. To investigate
this hypothesis, ASR errors in transcription of several TED talks were analyzed
and compared with PSC's selected words. Both the overlapping and mismatching
cases were analyzed to investigate possible improvement for the PSC system.
Those ASR errors that were not detected by PSC as cases of learners'
difficulties were further analyzed and classified into four categories:
homophones, minimal pairs, breached boundaries and negatives. These errors were
embedded into the baseline PSC to make the enhanced version and were evaluated
in an experiment with L2 learners. The results indicated that the enhanced
version, which encompasses the ASR errors addresses most of the L2 learners'
difficulties and better assists them in comprehending challenging video
segments as compared with the baseline.},
 address = {Osaka, Japan},
 author = {Mirzaei, Maryam Sadat and Meshgi, Kourosh and Kawahara, Tatsuya},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4122},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {192--201},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Automatic Speech Recognition Errors as a Predictor of L2 Listening Difficulties},
 year = {2016}
}

@inproceedings{W16-4123,
 abstract = {Eye-tracking reading times have been attested to reflect cognitive processes
underlying sentence comprehension. However, the use of reading times in NLP
applications is an underexplored area of research. In this initial work we
build an automatic system to assess sentence complexity using automatically
predicted eye-tracking reading time measures and demonstrate the efficacy of
these reading times for a well known NLP task, namely, readability assessment.
We use a machine learning model and a set of features known to be significant
predictors of reading times in order to learn per-word reading times from a
corpus of English text having reading times of human readers. Subsequently, we
use the model to predict reading times for novel text in the context of the
aforementioned task. A model based only on reading times gave competitive
results compared to the systems that use extensive syntactic features to
compute linguistic complexity. Our work, to the best of our knowledge, is the
first study to show that automatically predicted reading times can successfully
model the difficulty of a text and can be deployed in practical text processing
applications.},
 address = {Osaka, Japan},
 author = {Singh, Abhinav Deep and Mehta, Poojan and Husain, Samar and Rajakrishnan, Rajkumar},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4123},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {202--212},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Quantifying sentence complexity based on eye-tracking measures},
 year = {2016}
}

@inproceedings{W16-4124,
 abstract = {The article presents results of entropy rate estimation for human languages
across six languages by using large, state-of-the-art corpora of up to 7.8
gigabytes. To obtain the estimates for data length tending to infinity, we use
an extrapolation function given by an ansatz. Whereas some ansatzes of this
kind were proposed in previous research papers, here we introduce a stretched
exponential extrapolation function that has a smaller error of fit. In this
way, we uncover a possibility that the entropy rates of human languages are
positive but 20% smaller than previously reported.},
 address = {Osaka, Japan},
 author = {Takahira, Ryosuke and Tanaka-Ishii, Kumiko and D{\"A}bowski, {\AA}ukasz},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4124},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {213--221},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Upper Bound of Entropy Rate Revisited ---A New Extrapolation of Compressed Large-Scale Corpora---},
 year = {2016}
}

@inproceedings{W16-4125,
 abstract = {The morphological complexity of languages differs widely and changes over time.
Pathways of change are often driven by the interplay of multiple competing
factors, and are hard to disentangle. We here focus on a paradigmatic scenario
of language change: the reduction of morphological complexity from Latin
towards the Romance languages. To establish a causal explanation for this
phenomenon, we employ three lines of evidence: 1) analyses of parallel corpora
to measure the complexity of words in actual language production, 2)
applications of NLP tools to further tease apart the contribution of
inflectional morphology to word complexity, and 3) experimental data from
artificial language learning, which illustrate the learning pressures at play
when morphology simplifies. These three lines of evidence converge to show that
pressures associated with imperfect language learning are good candidates to
causally explain the reduction in morphological complexity in the
Latin-to-Romance scenario. More generally, we argue that combining corpus, computational and experimental evidence is the way forward in historical
linguistics and linguistic typology.},
 address = {Osaka, Japan},
 author = {Bentz, Christian and Berdicevskis, Aleksandrs},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4125},
 booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (CL4LC)},
 month = {December},
 pages = {222--232},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Learning pressures reduce morphological complexity: Linking corpus, computational and experimental evidence},
 year = {2016}
}

@inproceedings{W16-4201,
 abstract = {The goal of this paper is to examine the impact of simple feature engineering
mechanisms before applying more sophisticated techniques to the task of medical
NER. Sometimes papers using scientifically sound techniques present raw
baselines that could be improved adding simple and cheap features. This work
focuses on entity recognition for the clinical domain for three languages:
English, Swedish and Spanish. The task is tackled using simple features, starting from the window size, capitalization, prefixes, and moving to POS and
semantic tags. This work demonstrates that a simple initial step of feature
engineering can improve the baseline results significantly. Hence, the
contributions of this paper are: first, a short list of guidelines well
supported with experimental results on three languages and, second, a detailed
description of the relevance of these features for medical NER.
Author{1}{Affiliation}},
 address = {Osaka, Japan},
 author = {Weegar, Rebecka and Casillas, Arantza and Diaz de Ilarraza, Arantza and Oronoz, Maite and P\'{e}rez, Alicia and Gojenola, Koldo},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4201},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {1--6},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The impact of simple feature engineering in multilingual medical NER},
 year = {2016}
}

@inproceedings{W16-4202,
 abstract = {Automated extraction of concepts from patient clinical records is an essential
facilitator of clinical research. For this reason, the 2010 i2b2/VA Natural
Language
Processing Challenges for Clinical Records introduced a concept extraction task
aimed at identifying and classifying concepts into predefined categories (i.e., treatments, tests and problems). State-of-the-art concept extraction approaches
heavily rely on handcrafted features and domain-specific resources which are
hard to collect and define. For this reason, this paper proposes an
alternative, streamlined approach: a recurrent neural network (the
bidirectional LSTM with CRF decoding) initialized with general-purpose, off-the-shelf word embeddings. The experimental results achieved on the 2010
i2b2/VA reference corpora using the proposed framework outperform all recent
methods and ranks closely to the best submission from the original 2010 i2b2/VA
challenge.},
 address = {Osaka, Japan},
 author = {Chalapathy, Raghavendra and Zare Borzeshi, Ehsan and Piccardi, Massimo},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4202},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {7--12},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Bidirectional LSTM-CRF for Clinical Concept Extraction},
 year = {2016}
}

@inproceedings{W16-4203,
 abstract = {Due to the recent replacements of physical documents with electronic medical
records (EMR), the importance of information processing in medical fields has
been increased. We have been organizing the MedNLP task series in NTCIR-10 and
11. These workshops were the first shared tasks which attempt to evaluate
technologies that retrieve important information from medical reports written
in Japanese. In this report, we describe the NTCIR-12 MedNLPDoc task which is
designed for more advanced and practical use for the medical fields. This task
is considered as a multi-labeling task to a patient record. This report
presents results of the shared task, discusses and illustrates remained issues
in the medical natural language processing field.
Author{4}{Affiliation}},
 address = {Osaka, Japan},
 author = {Aramaki, Eiji and Kano, Yoshinobu and Ohkuma, Tomoko and Morita, Mizuki},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4203},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {13--16},
 publisher = {The COLING 2016 Organizing Committee},
 title = {MedNLPDoc: Japanese Shared Task for Clinical NLP},
 year = {2016}
}

@inproceedings{W16-4204,
 abstract = {Patient notes contain a wealth of information of potentially great interest to
medical investigators. However, to protect patients' privacy, Protected Health
Information (PHI) must be removed from the patient notes before they can be
legally released, a process known as patient note de-identification. The main
objective for a de-identification system is to have the highest possible
recall. Recently, the first neural-network-based de-identification system has
been proposed, yielding state-of-the-art results. Unlike other systems, it does
not rely on human-engineered features, which allows it to be quickly deployed, but does not leverage knowledge from human experts or from electronic health
records (EHRs). In this work, we explore a method to incorporate
human-engineered features as well as features derived from EHRs to a
neural-network-based de-identification system. Our results show that the
addition of features, especially the EHR-derived features, further improves the
state-of-the-art in patient note de-identification, including for some of the
most sensitive PHI types such as patient names. Since in a real-life setting
patient notes typically come with EHRs, we recommend developers of
de-identification systems to leverage the information EHRs contain.},
 address = {Osaka, Japan},
 author = {Lee, Ji Young and Dernoncourt, Franck and Uzuner, Ozlem and Szolovits, Peter},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4204},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {17--22},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Feature-Augmented Neural Networks for Patient Note De-identification},
 year = {2016}
}

@inproceedings{W16-4205,
 abstract = {Semi-supervised clustering is an attractive alternative for traditional
(unsupervised) clustering in targeted applications. By using the information of
a small annotated dataset, semi-supervised clustering can produce clusters that
are customized to the application domain. In this paper, we
present a semi-supervised clustering technique based on a multi-objective
evolutionary algorithm (NSGA-II-clus). We apply this technique to the task of
clustering medical publications for Evidence Based Medicine (EBM) and observe
an improvement of the results against unsupervised
and other semi-supervised clustering techniques.},
 address = {Osaka, Japan},
 author = {Sahoo, Pracheta and Ekbal, Asif and Saha, Sriparna and Molla, Diego and Nandan, Kaushik},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4205},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {23--31},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Semi-supervised Clustering of Medical Text},
 year = {2016}
}

@inproceedings{W16-4206,
 abstract = {Rapid growth in Electronic Medical Records (EMR) has emerged to an expansion of
data in the
clinical domain. The majority of the available health care information is
sealed in the form of narrative
documents which form the rich source of clinical information. Text mining of
such clinical
records has gained huge attention in various medical applications like
treatment and decision making.
However, medical records enclose patient Private Health Information (PHI) which
can
reveal the identities of the patients. In order to retain the privacy of
patients, it is mandatory to remove
all the PHI information prior to making it publicly available. The aim is to
de-identify or
encrypt the PHI from the patient medical records. In this paper, we propose an
algorithm based
on deep learning architecture to solve this problem. We perform
de-identification of seven PHI
terms from the clinical records. Experiments on benchmark datasets show that
our proposed
approach achieves encouraging performance, which is better than the baseline
model developed
with Conditional Random Field.},
 address = {Osaka, Japan},
 author = {Yadav, Shweta and Ekbal, Asif and Saha, Sriparna and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4206},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {32--41},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Deep Learning Architecture for Patient Data De-identification in Clinical Records},
 year = {2016}
}

@inproceedings{W16-4207,
 abstract = {Paraphrase generation is important in various applications such as search, summarization, and question answering due to its ability to generate textual
alternatives while keeping the overall meaning intact. Clinical paraphrase
generation is especially vital in building patient-centric clinical decision
support (CDS) applications where users are able to understand complex clinical
jargons via easily comprehensible alternative paraphrases. This paper presents
Neural Clinical Paraphrase Generation (NCPG), a novel approach that casts the
task as a monolingual neural machine translation (NMT) problem. We propose an
end-to-end neural network built on an attention-based bidirectional Recurrent
Neural Network (RNN) architecture with an encoder-decoder framework to perform
the task. Conventional bilingual NMT models mostly rely on word-level modeling
and are often limited by out-of-vocabulary (OOV) issues. In contrast, we
represent the source and target paraphrase pairs as character sequences to
address this limitation. To the best of our knowledge, this is the first work
that uses attention-based RNNs for clinical paraphrase generation and also
proposes an end-to-end character-level modeling for this task. Extensive
experiments on a large curated clinical paraphrase corpus show that the
attention-based NCPG models achieve improvements of up to 5.2 BLEU points and
0.5 METEOR points over a non-attention based strong baseline for word-level
modeling, whereas further gains of up to 6.1 BLEU points and 1.3 METEOR points
are obtained by the character-level NCPG models over their word-level
counterparts. Overall, our models demonstrate comparable performance relative
to the state-of-the-art phrase-based non-neural models.},
 address = {Osaka, Japan},
 author = {Hasan, Sadid A. and Liu, Bo and Liu, Joey and Qadir, Ashequl and Lee, Kathy and Datla, Vivek and Prakash, Aaditya and Farri, Oladimeji},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4207},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {42--53},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Neural Clinical Paraphrase Generation with Attention},
 year = {2016}
}

@inproceedings{W16-4208,
 abstract = {The proliferation of deep learning methods in natural language processing (NLP)
and the large amounts of data they often require stands in stark contrast to
the relatively data-poor clinical NLP domain. In particular, large text corpora
are necessary to build high-quality word embeddings, yet often large corpora
that are suitably representative of the target clinical data are unavailable.
This forces a choice between building embeddings from small clinical corpora
and less representative, larger corpora. This paper explores this trade-off, as
well as intermediate compromise solutions. Two standard clinical NLP tasks (the
i2b2 2010 concept and assertion tasks) are evaluated with commonly used deep
learning models (recurrent neural networks and convolutional neural networks)
using a set of six corpora ranging from the target i2b2 data to large
open-domain datasets. While combinations of corpora are generally found to work
best, the single-best corpus is generally task-dependent.},
 address = {Osaka, Japan},
 author = {Roberts, Kirk},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4208},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {54--63},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Assessing the Corpus Size vs. Similarity Trade-off for Word Embeddings in Clinical NLP},
 year = {2016}
}

@inproceedings{W16-4209,
 abstract = {Importance of utilizing medical information is getting increased as electronic
health records (EHRs) are widely used nowadays. We aim to assign international
standardized disease codes, ICD-10, to Japanese textual information in EHRs for
users to reuse the information accurately. In this paper, we propose methods to
automatically extract diagnosis and to assign ICD codes to Japanese medical
records. Due to the lack of available training data, we dare employed
rule-based methods rather than machine learning. We observed characteristics of
medical records carefully, writing rules to make effective methods by hand. We
applied our system to the NTCIR-12 MedNLPDoc shared task data where
participants are required to assign ICD-10 codes of possible diagnosis in given
EHRs. In this shared task, our system achieved the highest F-measure score
among all participants in the most severe evaluation criteria. Through
comparison with other approaches, we show that our approach could be a useful
milestone for the future development of Japanese medical record processing.},
 address = {Osaka, Japan},
 author = {Sakishita, Masahito and Kano, Yoshinobu},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4209},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {64--68},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Inference of ICD Codes from Japanese Medical Records by Searching Disease Names},
 year = {2016}
}

@inproceedings{W16-4210,
 abstract = {In this work we present a fine-grained annotation schema to detect named
entities in German clinical data of chronically ill patients with kidney
diseases. The annotation schema is driven by the needs of our clinical partners
and the linguistic aspects of German language. In order to generate annotations
within a short period, the work also presents a semi-automatic annotation which
uses additional sources of knowledge such as UMLS, to pre-annotate concepts in
advance. The presented schema will be used to apply novel techniques from
natural language processing and machine learning to support doctors treating
their patients by improved information access from unstructured German texts.},
 address = {Osaka, Japan},
 author = {Roller, Roland and Uszkoreit, Hans and Xu, Feiyu and Seiffe, Laura and Mikhailov, Michael and Staeck, Oliver and Budde, Klemens and Halleck, Fabian and Schmidt, Danilo},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4210},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {69--77},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A fine-grained corpus annotation schema of German nephrology records},
 year = {2016}
}

@inproceedings{W16-4211,
 abstract = {In recent years, detecting Alzheimer disease (AD) in early stages based on
natural language processing (NLP) has drawn much attention. To date, vocabulary
size, grammatical complexity, and fluency have been studied using NLP metrics.
However, the content analysis of AD narratives is still unreachable for NLP.
This study investigates features of the words that AD patients use in their
spoken language. After recruiting 18 examinees of 53--90 years old (mean:
76.89), they were divided into two groups based on MMSE scores. The AD group
comprised 9 examinees with scores of 21 or lower. The healthy control group
comprised 9 examinees with a score of 22 or higher. Linguistic Inquiry and Word
Count (LIWC) classified words were used to categorize the words that the
examinees used. The word frequency was found from observation. Significant
differences were confirmed for the usage of impersonal pronouns in the AD
group. This result demonstrated the basic feasibility of the proposed NLP-based
detection
approach.},
 address = {Osaka, Japan},
 author = {Shibata, Daisaku and Wakamiya, Shoko and Kinoshita, Ayae and Aramaki, Eiji},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4211},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {78--85},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Detecting Japanese Patients with Alzheimer{\^a}s Disease based on Word Category Frequencies},
 year = {2016}
}

@inproceedings{W16-4212,
 abstract = {The number of unstructured medical records kept in hospital information systems
is increasing.
The conditions of patients are formulated as outcomes in clinical pathway.
A variance of an outcome describes deviations from standards of care like a
patient's bad condition.
The present paper applied text mining to extract feature words and phrases of
the variance from admission records.
We report the cases the variances of ``pain control'' and ``no neuropathy
worsening'' in cerebral infarction.},
 address = {Osaka, Japan},
 author = {Yamashita, Takanori and Wakata, Yoshifumi and Soejima, Hidehisa and Nakashima, Naoki and Hirokawa, Sachio},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4212},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {86--90},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Prediction of Key Patient Outcome from Sentence and Word of Medical Text Records},
 year = {2016}
}

@inproceedings{W16-4213,
 abstract = {Clinical narratives in electronic health record systems are a rich resource of
patient-based information. They constitute an ongoing challenge for natural
language processing, due to their high compactness and abundance of short
forms. German medical texts exhibit numerous ad-hoc abbreviations that
terminate with a period character. The disambiguation of period characters is
therefore an important task for sentence and abbreviation detection. This task
is addressed by a combination of co-occurrence information of word types with
trailing period characters, a large domain dictionary, and a simple rule
engine, thus merging statistical and dictionary-based disambiguation
strategies. An F-measure of 0.95 could be reached by using the unsupervised
approach presented in this paper. The results are promising for a
domain-independent abbreviation detection strategy, because our approach avoids
retraining of models or use case specific feature engineering efforts required
for supervised machine learning approaches.},
 address = {Osaka, Japan},
 author = {Kreuzthaler, Markus and Oleynik, Michel and Avian, Alexander and Schulz, Stefan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4213},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {91--98},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Unsupervised Abbreviation Detection in Clinical Narratives},
 year = {2016}
}

@inproceedings{W16-4214,
 abstract = {The issue of privacy has always been a concern when clinical texts are used for
research purposes. Personal health information (PHI) (such as name and
identification number) needs to be removed so that patients cannot be
identified. Manual anonymization is not feasible due to the large number of
clinical texts to be anonymized. In this paper, we tackle the task of
anonymizing clinical texts written in sentence fragments and which frequently
contain symbols, abbreviations, and misspelled words. Our clinical texts
therefore differ from those in the i2b2 shared tasks which are in prose form
with complete sentences. Our clinical texts are also part of a structured
database which contains patient name and identification number in structured
fields. As such, we formulate our anonymization task as spelling variant
detection, exploiting patients' personal information in the structured fields
to detect their spelling variants in clinical texts. We successfully anonymized
clinical texts consisting of more than 200 million words, using minimum edit
distance and regular expression patterns.},
 address = {Osaka, Japan},
 author = {Yuwono, Steven Kester and Ng, Hwee Tou and Ngiam, Kee Yuan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4214},
 booktitle = {Proceedings of the Clinical Natural Language Processing Workshop (ClinicalNLP)},
 month = {December},
 pages = {99--103},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Automated Anonymization as Spelling Variant Detection},
 year = {2016}
}

@inproceedings{W16-4301,
 abstract = {Men are from Mars and women are from Venus - or so the genre of relationship
literature would have us believe. But there is some truth in this idea, and
researchers in fields as diverse as psychology, sociology, and linguistics have
explored ways to better understand the differences between genders. In this
paper, we take another look at the problem of gender discrimination and attempt
to move beyond the typical surface-level text classification approach, by (1)
identifying semantic and psycholinguistic word classes that reflect systematic
differences between men and women and (2) finding differences between genders
in the ways they use the same words. We describe several experiments and report
results on a large collection of blogs authored by men and women.},
 address = {Osaka, Japan},
 author = {Garimella, Aparna and Mihalcea, Rada},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4301},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {1--10},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Zooming in on Gender Differences in Social Media},
 year = {2016}
}

@inproceedings{W16-4302,
 abstract = {Recent studies have demonstrated gender and cultural differences in the
recognition of emotions in facial expressions. However, most studies were
conducted on American subjects. In this pa- per, we explore the
generalizability of several findings to a non-American culture in the form of
Danish subjects. We conduct an emotion recognition task followed by two
stereotype question- naires with different genders and age groups. While recent
findings (Krems et al., 2015) suggest that women are biased to see anger in
neutral facial expressions posed by females, in our sample both genders assign
higher ratings of anger to all emotions expressed by females. Furthermore, we
demonstrate an effect of gender on the fear-surprise-confusion observed by
Tomkins and McCarter (1964); females overpredict fear, while males overpredict
surprise.},
 address = {Osaka, Japan},
 author = {Schneevogt, Daniela and Paggio, Patrizia},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4302},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {11--19},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The Effect of Gender and Age Differences on the Recognition of Emotions from Facial Expressions},
 year = {2016}
}

@inproceedings{W16-4303,
 abstract = {Many methods have been used to recognise author personality traits from text, typically combining linguistic feature engineering with shallow learning
models, e.g. linear regression or Support Vector Machines. This work uses
deep-learning-based models and atomic features of text, the characters, to
build hierarchical, vectorial word and sentence representations for trait
inference. This method, applied to a corpus of tweets, shows state-of-the-art
performance across five traits compared with prior work. The results, supported
by preliminary visualisation work, are encouraging for the ability to detect
complex human traits.},
 address = {Osaka, Japan},
 author = {Liu, Fei and Perez, Julien and Nowson, Scott},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4303},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {20--29},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Recurrent and Compositional Model for Personality Trait Recognition from Short Texts},
 year = {2016}
}

@inproceedings{W16-4304,
 abstract = {We exploit the Facebook reaction feature in a distant supervised fashion to
train a support vector machine classifier for emotion detection, using several
feature combinations and combining different Facebook pages. We test our models
on existing benchmarks for emotion detection and show that employing only
information that is derived completely automatically, thus without relying on
any handcrafted lexicon as it's usually done, we can achieve competitive
results. The results also show that there is large room for improvement, especially by gearing the collection of Facebook pages, with a view to the
target domain.},
 address = {Osaka, Japan},
 author = {Pool, Chris and Nissim, Malvina},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4304},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {30--39},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Distant supervision for emotion detection using Facebook reactions},
 year = {2016}
}

@inproceedings{W16-4305,
 abstract = {This paper proposes a graphical framework to extract  opinionated sentences
which highlight different contexts within a given news article by introducing
the concept of diversity in a graphical model for opinion detection.We conduct
extensive evaluations and find that the proposed modification leads to
impressive improvement in performance and makes the final results of the model
much more usable. The proposed method (OP-D) not only performs much better than
the other techniques used for opinion detection as well as introducing
diversity, but is also able to select opinions from different categories {Asher
et al. 2009 Appraisal}. By developing a classification model which categorizes
the identified sentences into various opinion categories, we find that OP-D is
able to push opinions from different categories uniformly among the top
opinions.},
 address = {Osaka, Japan},
 author = {Mullick, Ankan and Goyal, Pawan and Ganguly, Niloy},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4305},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {40--49},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A graphical framework to detect and categorize diverse opinions from online news},
 year = {2016}
}

@inproceedings{W16-4306,
 abstract = {Automatic detection of five language components, which are all relevant for
expressing opinions and for stance taking, was studied: positive sentiment, negative sentiment, speculation, contrast and condition. A resource-aware
approach was taken, which included manual annotation of 500 training samples
and the use of limited lexical resources. Active learning was compared to
random selection of training data, as well as to a lexicon-based method. Active
learning was successful for the categories speculation, contrast and condition, but not for the two sentiment categories, for which results achieved when using
active learning were similar to those achieved when applying a random selection
of training data. This difference is likely due to a larger variation in how
sentiment is expressed than in how speakers express the other three categories.
This larger variation was also shown by the lower recall results achieved by
the lexicon-based approach for sentiment than for the categories speculation, contrast and condition.},
 address = {Osaka, Japan},
 author = {Skeppstedt, Maria and Sahlgren, Magnus and Paradis, Carita and Kerren, Andreas},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4306},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {50--59},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Active learning for detection of stance components},
 year = {2016}
}

@inproceedings{W16-4307,
 abstract = {We investigate the application of kernel methods to representing both
structural and lexical knowledge for predicting polarity of opinions in
consumer product review.  We introduce any-gram kernels which model lexical
information in a significantly faster way than the traditional n-gram features, while capturing all possible orders of n-grams n in a sequence without the need
to explicitly present a pre-specified set of such orders. We also present an
effective format to represent constituency and dependency structure together
with aspect terms and sentiment polarity scores. Furthermore, we modify the
traditional tree kernel function to compute the similarity based on word
embedding vectors instead of exact string match and present experiments using
the new models.},
 address = {Osaka, Japan},
 author = {Kaljahi, Rasoul and Foster, Jennifer},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4307},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {60--69},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Detecting Opinion Polarities using Kernel Methods},
 year = {2016}
}

@inproceedings{W16-4308,
 abstract = {This paper explores humour recognition for Twitter-based hashtag games. Given
their popularity, frequency, and relatively formulaic nature, these games make
a good target for computational humour research and can leverage Twitter likes
and retweets as humour judgments. In this work, we use pair-wise relative
humour judgments to examine several measures of semantic relatedness between
setups and punchlines on a hashtag game corpus we collected and annotated.
Results show that perplexity, Normalized Google Distance, and free-word
association-based features are all useful in identifying "funnier" hashtag game
responses. In fact, we provide empirical evidence that funnier punchlines tend
to be more obscure, although more obscure punchlines are not necessarily rated
funnier. Furthermore, the asymmetric nature of free-word association features
allows us to see that while punchlines should be harder to predict given a
setup, they should also be relatively easy to understand in context.},
 address = {Osaka, Japan},
 author = {Cattle, Andrew and Ma, Xiaojuan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4308},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {70--79},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Effects of Semantic Relatedness between Setups and Punchlines in Twitter Hashtag Games},
 year = {2016}
}

@inproceedings{W16-4309,
 abstract = {Despite a substantial progress made in developing new sentiment
lexicon generation (SLG) methods for English, the task of
transferring these approaches to other languages and domains in a
sound way still remains open.  In this paper, we contribute to the
solution of this problem by systematically comparing semi-automatic
translations of common English polarity lists with the results of
the original automatic SLG algorithms, which were applied directly
to German data.  We evaluate these lexicons on a corpus of 7,992
manually annotated tweets.  In addition to that, we also collate the
results of dictionary- and corpus-based SLG methods in order to find
out which of these paradigms is better suited for the inherently
noisy domain of social media.  Our experiments show that
semi-automatic translations notably outperform automatic systems
(reaching a macro-averaged F1-score of 0.589), and that
dictionary-based techniques produce much better polarity lists as
compared to corpus-based approaches (whose best F1-scores run up
to 0.479 and 0.419 respectively) even for the non-standard Twitter
genre.},
 address = {Osaka, Japan},
 author = {Sidarenka, Uladzimir and Stede, Manfred},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4309},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {80--90},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Generating Sentiment Lexicons for German Twitter},
 year = {2016}
}

@inproceedings{W16-4310,
 abstract = {Detecting depression or personality traits, tutoring and student behaviour
systems, or identifying cases of cyber-bulling are a few of the wide range of
the applications, in which the automatic detection of emotion is a crucial
element. Emotion detection has the potential of high impact by contributing the
benefit of business, society, politics or education. Given this context, the
main objective of our research is to contribute to the resolution of one of the
most important challenges in textual emotion detection task: the problems of
emotional corpora annotation. This will be tackled by proposing of a new
semi-automatic methodology. Our innovative methodology consists in two main
phases: (1) an automatic process to pre-annotate the unlabelled sentences with
a reduced number of emotional categories; and (2) a refinement manual process
where human annotators will determine which is the predominant emotion between
the emotional categories selected in the phase 1. Our proposal in this paper is
to show and evaluate the pre-annotation process to analyse the feasibility and
the benefits by the methodology proposed. The results obtained are promising
and allow obtaining a substantial improvement of annotation time and cost and
confirm the usefulness of our pre-annotation process to improve the annotation
task.},
 address = {Osaka, Japan},
 author = {Canales, Lea and Strapparava, Carlo and Boldrini, Ester and Martinez-Barco, Patricio},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4310},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {91--100},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Innovative Semi-Automatic Methodology to Annotate Emotional Corpora},
 year = {2016}
}

@inproceedings{W16-4311,
 abstract = {We created a model to estimate personality trait from authors' text written in
Japanese and measured its performance by conducting surveys and analyzing the
Twitter data of 1,630 users. We used the Big Five personality traits for
personality trait estimation. Our approach is a combination of category- and
Word2Vec-based approaches. For the category-based element, we added several
unique Japanese categories along with the ones regularly used in the English
model, and for the Word2Vec-based element, we used a model called GloVe. We
found that some of the newly added categories have a stronger correlation with
personality traits than other categories do and that the combination of the
category- and Word2Vec-based approaches improves the accuracy of the
personality trait estimation compared with the case of using just one of them.},
 address = {Osaka, Japan},
 author = {Kamijo, Koichi and Nasukawa, Tetsuya and Kitamura, Hideya},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4311},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {101--109},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Personality Estimation from Japanese Text},
 year = {2016}
}

@inproceedings{W16-4312,
 abstract = {On June 23rd 2016, UK held the referendum which ratified the exit from the EU.
While most of the traditional pollsters failed to forecast the final vote, there were online systems that hit the result with high accuracy using opinion
mining techniques and big data. Starting one month before, we collected and
monitored millions of posts about the referendum from social media
conversations, and exploited Natural Language Processing techniques to predict
the referendum outcome. In this paper we discuss the methods used by
traditional pollsters and compare it to the predictions based on different
opinion mining techniques. We find that opinion mining based on
agreement/disagreement classification works better than opinion mining based on
polarity classification in the forecast of the referendum outcome.},
 address = {Osaka, Japan},
 author = {Celli, Fabio and Stepanov, Evgeny and Poesio, Massimo and Riccardi, Giuseppe},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4312},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {110--118},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Predicting Brexit: Classifying Agreement is Better than Sentiment and Pollsters},
 year = {2016}
}

@inproceedings{W16-4313,
 abstract = {The conundrum of understanding and classifying sarcasm has been dealt with by
the traditional theorists as an analysis of a sarcastic utterance and the
ironic situation that surrounds it. The problem with such an approach is that
it is too narrow, as it is unable to sufficiently utilize the two indispensable
agents in making such an utterance, viz. the speaker and the listener. It
undermines the necessary context required to comprehend a sarcastic utterance.
In this paper, we propose a novel approach towards understanding sarcasm in
terms of the existing knowledge hierarchy between the two participants, which
forms the basis of the context that both agents share. The difference in
relationship of the speaker of the sarcastic utterance and the disparate
audience found on social media, such as Twitter, is also captured. We then
apply our model on a corpus of tweets to achieve significant results and
consequently, shed light on subjective nature of context, which is contingent
on the relation between the speaker and the listener.},
 address = {Osaka, Japan},
 author = {Bali, Taradheesh and Singh, Navjyoti},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4313},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {119--127},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Sarcasm Detection : Building a Contextual Hierarchy},
 year = {2016}
}

@inproceedings{W16-4314,
 abstract = {A growing body of research exploits social media behaviors to gauge
psychological character-istics, though trait empathy has received little
attention. Because of its intimate link to the abil-ity to relate to others, our research aims to predict participants{\^a} levels of empathy, given their
textual and friending behaviors on Facebook. Using Poisson regression, we
compared the vari-ance explained in Davis{\^a} Interpersonal Reactivity Index
(IRI) scores on four constructs (em-pathic concern, personal distress, fantasy, perspective taking), by two classes of variables: 1) post content and 2)
linguistic style. Our study lays the groundwork for a greater understanding of
empathy{\^a}s role in facilitating interactions on social media.},
 address = {Osaka, Japan},
 author = {Litvak, Marina and Otterbacher, Jahna and Ang, Chee Siang and Atkins, David},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4314},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {128--137},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Social and linguistic behavior and its correlation to trait empathy},
 year = {2016}
}

@inproceedings{W16-4315,
 abstract = {This paper outlines a pilot study on multi-dimensional and multilingual
sentiment analysis of social media content. We use parallel corpora of movie
subtitles as a proxy for colloquial language in social media channels and a
multilingual emotion lexicon for fine-grained sentiment analyses. Parallel data
sets make it possible to study the preservation of sentiments and emotions in
translation and our assessment reveals that the lexical approach shows great
inter-language agreement. However, our manual evaluation also suggests that the
use of purely lexical methods is limited and further studies are necessary to
pinpoint the cross-lingual differences and to develop better sentiment
classifiers.},
 address = {Osaka, Japan},
 author = {\"{O}hman, Emily and Honkela, Timo and Tiedemann, J\"{o}rg},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4315},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {138--142},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The Challenges of Multi-dimensional Sentiment Analysis Across Languages},
 year = {2016}
}

@inproceedings{W16-4316,
 abstract = {In this paper, we address the issue of automatic prediction of readers{\^a} mood
from newspaper ar- ticles and comments. As online newspapers are becoming more
and more similar to social media platforms, users can provide affective
feedback, such as mood and emotion. We have exploited the self-reported
annotation of mood categories obtained from the metadata of the Italian online
newspaper corriere.it to design and evaluate a system for predicting five
different mood cate- gories from news articles and comments: indignation, disappointment, worry, satisfaction, and amusement. The outcome of our
experiments shows that overall, bag-of-word-ngrams perform better compared to
all other feature sets; however, stylometric features perform better for the
mood score prediction of articles. Our study shows that self-reported
annotations can be used to design automatic mood prediction systems.},
 address = {Osaka, Japan},
 author = {Alam, Firoj and Celli, Fabio and Stepanov, Evgeny A. and Ghosh, Arindam and Riccardi, Giuseppe},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4316},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {143--152},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The Social Mood of News: Self-reported Annotations to Design Automatic Mood Detection Systems},
 year = {2016}
}

@inproceedings{W16-4317,
 abstract = {Most work in NLP analysing microblogs focuses on textual content thus
neglecting temporal and spatial information. We present a new interdisciplinary
method for emotion classification that combines linguistic, temporal, and
spatial information into a single metric. We create a graph of labeled and
unlabeled tweets that encodes the relations between neighboring tweets with
respect to their emotion labels. Graph-based semi-supervised learning labels
all tweets with an emotion.},
 address = {Osaka, Japan},
 author = {Summa, Anja and Resch, Bernd and Strube, Michael},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4317},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {153--162},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Microblog Emotion Classification by Computing Similarity in Text, Time, and Space},
 year = {2016}
}

@inproceedings{W16-4318,
 abstract = {We explore a domain-agnostic approach for analyzing speech with the goal of
opinion prediction. We represent the speech signal by mel-frequency cepstral
coefficients and apply long short-term memory neural networks to automatically
learn temporal regularities in speech. In contrast to previous work, our
approach does not require complex feature engineering and works without textual
transcripts. As a consequence, it can easily be applied on various speech
analysis tasks for different languages and the results show that it can
nevertheless be competitive to the state-of-the-art in opinion prediction. In a
detailed error analysis for opinion mining we find that our approach performs
well in identifying speaker-specific characteristics, but should be combined
with additional information if subtle differences in the linguistic content
need to be identified.},
 address = {Osaka, Japan},
 author = {Santos, Pedro Bispo and Beinborn, Lisa and Gurevych, Iryna},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4318},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {163--172},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A domain-agnostic approach for opinion prediction on speech},
 year = {2016}
}

@inproceedings{W16-4319,
 abstract = {Considering the importance of public speech skills, a system which makes a
prediction on where audiences laugh in a talk can be helpful to a person who
prepares for a talk. We investigated a possibility that a state-of-the-art
humor
recognition system can be used in detecting sentences inducing laughters in
talks. In this study, we used TED talks and laughters in the talks as data. Our
results showed that the state-of-the-art system needs to be improved in order
to
be used in a practical application. In addition, our analysis showed that
classifying humorous sentences in talks is very challenging due to close
distance between humorous and non-humorous sentences.},
 address = {Osaka, Japan},
 author = {Lee, Chong Min and Yoon, Su-Youn and Chen, Lei},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4319},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {173--181},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Can We Make Computers Laugh at Talks?},
 year = {2016}
}

@inproceedings{W16-4320,
 abstract = {Major depressive disorder, a debilitating and burdensome disease experienced by
individuals
worldwide, can be defined by several depressive symptoms (e.g., anhedonia
(inability to feel
pleasure), depressed mood, difficulty concentrating, etc.). Individuals often
discuss their experiences with depression symptoms on public social media
platforms like Twitter, providing
a potentially useful data source for monitoring population-level mental health
risk factors. In a
step towards developing an automated method to estimate the prevalence of
symptoms associated with major depressive disorder over time in the United
States using Twitter, we developed classifiers for discerning whether a Twitter
tweet represents no evidence of depression or evidence of depression. If there
was evidence of depression, we then classified whether the tweet contained a
depressive symptom and if so, which of three subtypes: depressed mood, disturbed sleep, or fatigue or loss of energy. We observed that the most
accurate classifiers could predict classes with high-to-moderate F1-score
performances for no evidence of depression (85), evidence of depression (52), and depressive symptoms (49). We report moderate F1-scores for depressive
symptoms ranging from 75 (fatigue or loss of energy) to 43 (disturbed sleep) to
35 (depressed mood). Our work demonstrates baseline approaches for
automatically encoding Twitter data with granular depressive symptoms
associated with major depressive disorder.},
 address = {Osaka, Japan},
 author = {Mowery, Danielle L and Park, Albert and Bryan, Craig and Conway, Mike},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4320},
 booktitle = {Proceedings of the Workshop on Computational Modeling of People's Opinions, Personality, and Emotions in Social Media (PEOPLES)},
 month = {December},
 pages = {182--191},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Towards Automatically Classifying Depressive Symptoms from Twitter Data for Population Health},
 year = {2016}
}

@inproceedings{W16-4401,
 abstract = {This paper proposes a new idea that uses Wikipedia categories as answer types
and defines candidate sets inside Wikipedia.  The focus of a given question is
searched in the hierarchy of Wikipedia main pages.  Our searching strategy
combines head-noun matching and synonym matching provided in semantic
resources.  The set of answer candidates is determined by the entry hierarchy
in Wikipedia and the hyponymy hierarchy in WordNet.  The experimental results
show that the approach can find candidate sets in a smaller size but achieve
better performance especially for ARTIFACT and ORGANIZATION types, where the
performance is better than state-of-the-art Chinese factoid QA systems.},
 address = {Osaka, Japan},
 author = {Chen, Po-Chun and Zhuang, Meng-Jie and Lin, Chuan-Jie},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4401},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {1--10},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Using Wikipedia and Semantic Resources to Find Answer Types and Appropriate Answer Candidate Sets in Question Answering},
 year = {2016}
}

@inproceedings{W16-4402,
 abstract = {Commonsense knowledge is essential for fully understanding language in many
situations. We acquire large-scale commonsense knowledge from humans using a
game with a purpose (GWAP) developed on a smartphone spoken dialogue system. We
transform the manual knowledge acquisition process into an enjoyable quiz game
and have collected over 150,000 unique commonsense facts by gathering the data
of more than 70,000 players over eight months. In this paper, we present a
simple method for maintaining the quality of acquired knowledge and an
empirical analysis of the knowledge acquisition process. To the best of our
knowledge, this is the first work to collect large-scale knowledge via a GWAP
on a widely-used spoken dialogue system.},
 address = {Osaka, Japan},
 author = {Otani, Naoki and Kawahara, Daisuke and Kurohashi, Sadao and Kaji, Nobuhiro and Sassano, Manabu},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4402},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {11--20},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Large-Scale Acquisition of Commonsense Knowledge via a Quiz Game on a Dialogue System},
 year = {2016}
}

@inproceedings{W16-4403,
 abstract = {This paper describes a hierarchical neural network we propose for sentence
classification to extract product information from product documents. The
network classifies each sentence in a document into attribute and condition
classes on the basis of word sequences and sentence sequences in the document.
Experimental results showed the method using the proposed network significantly
outperformed baseline methods by taking semantic representation of word and
sentence sequential data into account. We also evaluated the network with two
different product domains (insurance and tourism domains) and found that it was
effective for both the domains.},
 address = {Osaka, Japan},
 author = {Homma, Yukinori and Sadamitsu, Kugatsu and Nishida, Kyosuke and Higashinaka, Ryuichiro and Asano, Hisako and Matsuo, Yoshihiro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4403},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {21--29},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Hierarchical Neural Network for Information Extraction of Product Attribute and Condition Sentences},
 year = {2016}
}

@inproceedings{W16-4404,
 abstract = {Question answering is always an attractive and challenging task in natural
language processing area. There are some open domain question answering
systems, such as IBM Waston, which take the unstructured text data as input, in
some ways of humanlike thinking process and a mode of artificial intelligence.
At the conference on Natural Language Processing and Chinese Computing~(NLPCC)
2016, China Computer Federation hosted a shared task evaluation about Open
Domain Question Answering. We achieve the 2nd place at the document-based
subtask. In this paper, we present our solution, which consists of feature
engineering in lexical and semantic aspects and model training methods. As the
result of the evaluation shows, our solution provides a valuable and brief
model which could be used in modelling question answering or sentence semantic
relevance. We hope our solution would contribute to this vast and significant
task with some heuristic thinking.},
 address = {Osaka, Japan},
 author = {Shi, Jing and Xu, Jiaming and Yao, Yiqun and Zheng, Suncong and Xu, Bo},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4404},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {30--38},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Combining Lexical and Semantic-based Features for Answer Sentence Selection},
 year = {2016}
}

@inproceedings{W16-4405,
 abstract = {An Entity-based approach to Answering recurrent and non-recurrent
questions with Past Answers
Abstract
Community question answering (CQA) systems such as Yahoo! Answers allow
registered-users to ask and answer questions in various question categories.
However, a significant percentage of asked questions in Yahoo! Answers are
unanswered. In this paper, we propose to reduce this percentage by reusing
answers to past resolved questions from the site. Specifically, we propose
to satisfy unanswered questions in entity rich categories by searching for and
reusing the best answers to past resolved questions with shared needs. For
unanswered questions that do not have a past resolved question with a shared
need, we propose to use the best answer to a past resolved question with
similar needs. Our experiments on a Yahoo! Answers dataset shows that our
approach retrieves most of the past resolved questions that have shared and
similar needs to unanswered questions.},
 address = {Osaka, Japan},
 author = {Andy, Anietie and Rwebangira, Mugizi and Sekine, Satoshi},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4405},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {39--43},
 publisher = {The COLING 2016 Organizing Committee},
 title = {An Entity-Based approach to Answering Recurrent and Non-Recurrent Questions with Past Answers},
 year = {2016}
}

@inproceedings{W16-4406,
 abstract = {In an era where highly accurate Question Answering (QA) systems are being built
using complex Natural Language Processing (NLP) and Information Retrieval (IR)
algorithms, presenting the acquired answer to the user akin to a human answer
is also crucial. In this paper we present an answer presentation strategy by
embedding the answer in a sentence which is developed by incorporating the
linguistic structure of the source question extracted through typed dependency
parsing. The evaluation using human participants proved that the methodology is
human-competitive and can result in linguistically correct sentences for more
that 70\% of the test dataset acquired from QALD question dataset.},
 address = {Osaka, Japan},
 author = {Perera, Rivindu and Nand, Parma},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4406},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {44--48},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Answer Presentation in Question Answering over Linked Data using Typed Dependency Subtree Patterns},
 year = {2016}
}

@inproceedings{W16-4407,
 abstract = {Question answering (QA) systems need to provide exact answers for the questions
that are posed to the system. However, this can only be achieved through a
precise processing of the question. During this procedure, one important step
is the detection of the expected type of answer that the system should provide
by  extracting the headword of the questions and identifying its semantic type.
We have annotated the headword and assigned UMLS semantic types to 643
factoid/list questions from the BioASQ training data. We present statistics on
the corpus and a preliminary evaluation in baseline experiments. We also
discuss the challenges on both the manual annotation and the automatic
detection of the headwords and the semantic types. We believe that this is a
valuable resource for both training and evaluation of biomedical QA systems.
The corpus is available at: https://github.com/mariananeves/BioMedLAT.},
 address = {Osaka, Japan},
 author = {Neves, Mariana and Kraus, Milena},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4407},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {49--58},
 publisher = {The COLING 2016 Organizing Committee},
 title = {BioMedLAT Corpus: Annotation of the Lexical Answer Type for Biomedical Questions},
 year = {2016}
}

@inproceedings{W16-4408,
 abstract = {The paper describes topic shifting in dialogues with a robot that provides
information from Wiki-pedia. The work focuses on a double topical construction
of dialogue coherence which refers to discourse coherence on two levels: the
evolution of dialogue topics via the interaction between the user and the robot
system, and the creation of discourse topics via the content of the Wiki-pedia
article itself. The user selects topics that are of interest to her, and the
system builds a list of potential topics, anticipated to be the next topic, by
the links in the article and by the keywords extracted from the article. The
described system deals with Wikipedia articles, but could easily be adapted to
other digital information providing systems.},
 address = {Osaka, Japan},
 author = {Jokinen, Kristiina and Wilcock, Graham},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4408},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {59--66},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Double Topic Shifts in Open Domain Conversations: Natural Language Interface for a Wikipedia-based Robot Application},
 year = {2016}
}

@inproceedings{W16-4409,
 address = {Osaka, Japan},
 author = {Choi, GyuHyeon and Nam, Sangha and Choi, Dongho and CHOI, KEY-SUN},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4409},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {67--71},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Filling a Knowledge Graph with a Crowd},
 year = {2016}
}

@inproceedings{W16-4410,
 abstract = {Wikipedia has become a reference knowledge source for scores of NLP
applications. One of its invaluable features lies in its multilingual nature, where articles on a same entity or concept can have from one to more than 200
different versions. The interlinking of language versions in Wikipedia has
undergone a major renewal with the advent of Wikidata, a unified scheme to
identify entities and their properties using unique numbers.
However, as the interlinking is still manually carried out by thousands of
editors across the globe, errors may creep in the assignment of entities. In
this paper, we describe an optimization technique to match automatically
language versions of articles, and hence entities, that is only based on bags
of words and anchors. We created a dataset of all the articles on persons we
extracted from Wikipedia in six languages:  English, French, German, Russian, Spanish, and Swedish. We report a correct match of at least 94.3\% on each
pair.},
 address = {Osaka, Japan},
 author = {Klang, Marcus and Nugues, Pierre},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4410},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {72--76},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Pairing Wikipedia Articles Across Languages},
 year = {2016}
}

@inproceedings{W16-4411,
 abstract = {In this paper, we present an open information extraction system so-called SRDF
that generates lexical knowledge graphs from unstructured texts. In semantic
web, knowledge is expressed in the RDF triple form but the natural language
text consist of multiple relations between arguments. For this reason, we
combine open information extraction with the reification for the full text
extraction to preserve meaning of sentence in our knowledge graph. And also our
knowledge graph is designed to adapt for many existing semantic web
applications. At the end of this paper, we introduce the result of the
experiment and a Korean template generation module developed using SRDF.},
 address = {Osaka, Japan},
 author = {Nam, Sangha and Choi, GyuHyeon and Hahm, Younggyun and CHOI, KEY-SUN},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4411},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {77--81},
 publisher = {The COLING 2016 Organizing Committee},
 title = {SRDF: Extracting Lexical Knowledge Graph for Preserving Sentence Meaning},
 year = {2016}
}

@inproceedings{W16-4412,
 abstract = {Natural language questions are interpreted to a sequence of patterns to be
matched with instances of patterns in a knowledge base (KB) for answering. A
natural language (NL) question answering (QA) system utilizes meaningful
patterns matching the syntac-tic/lexical features between the NL questions and
KB. In the most of KBs, there are only binary relations in triple form to
represent relation between two entities or entity and a value using the domain
specific ontology. However, the binary relation representation is not enough to
cover complex information in questions, and the ontology vocabulary sometimes
does not cover the lexical meaning in questions. Complex meaning needs a
knowledge representation to link the binary relation-type triples in KB. In
this paper, we propose a frame semantics-based semantic parsing approach as
KB-independent question pre-processing. We will propose requirements of
question interpretation in the KBQA perspective, and a query form
representation based on our proposed format QAF (Ques-tion Answering with the
Frame Semantics), which is supposed to cover the requirements. In QAF, frame
semantics roles as a model to represent complex information in questions and to
disambiguate the lexical meaning in questions to match with the ontology
vocabu-lary. Our system takes a question as an input and outputs QAF-query by
the process which assigns semantic information in the question to its
corresponding frame semantic structure using the semantic parsing rules.},
 address = {Osaka, Japan},
 author = {Hahm, Younggyun and Nam, Sangha and CHOI, KEY-SUN},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4412},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {82--90},
 publisher = {The COLING 2016 Organizing Committee},
 title = {QAF: Frame Semantics-based Question Interpretation},
 year = {2016}
}

@inproceedings{W16-4413,
 abstract = {Answering yes--no questions is more difficult than simply retrieving ranked
search results. To answer yes--no questions, especially when the correct
answer is no, one must find an objectionable keyword that makes the question's
answer no. Existing systems, such as factoid-based ones, cannot answer yes--no
questions very well because of insufficient handling of such objectionable
keywords. We suggest an algorithm that answers yes--no questions by assigning
an importance to objectionable keywords. Concretely speaking, we suggest a
penalized scoring method that finds and makes lower score for parts of
documents that include such objectionable keywords. We check a keyword
distribution for each part of a document such as a paragraph, calculating the
keyword density as a basic score. Then we use an objectionable keyword penalty
when a keyword does not appear in a target part but appears in other parts of
the document. Our algorithm is robust for open domain problems because it
requires no training. We achieved 4.45 point better results in F1 scores than
the best score of the NTCIR-10 RITE2 shared task, also obtained the best score
in 2014 mock university examination challenge of the Todai Robot project.},
 address = {Osaka, Japan},
 author = {Kano, Yoshinobu},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4413},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {91--96},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Answering Yes-No Questions by Penalty Scoring in History Subjects of University Entrance Examinations},
 year = {2016}
}

@inproceedings{W16-4414,
 abstract = {Nowadays, a question answering (QA) system is used in various areas such a quiz
show, personal assistant, home device, and so on. The OKBQA framework supports
developing a QA system in an intuitive and collaborative ways. To support
collaborative development, the framework should be equipped with some
functions, e.g., flexible system configuration, debugging supports, intuitive
user interface, and so on while considering different developing groups of
different domains. This paper presents OKBQA controller, a dedicated workflow
manager for OKBQA framework, to boost collaborative development of a QA system.},
 address = {Osaka, Japan},
 author = {Kim, Jiseong and Choi, GyuHyeon and CHOI, KEY-SUN},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4414},
 booktitle = {Proceedings of the Open Knowledge Base and Question Answering Workshop (OKBQA 2016)},
 month = {December},
 pages = {97--101},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Dedicated Workflow Management for OKBQA Framework},
 year = {2016}
}

@inproceedings{W16-4501,
 abstract = {fast align is a simple and fast word alignment tool which is widely used in
state-of-the-art machine translation systems. It yields comparable results in
the end-to-end translation experiments of various language pairs. However, fast
align does not perform as well as GIZA++ when applied to language pairs with
distinct word orders, like English and Japanese. In this paper, given the
lexical translation table output by fast align, we propose to realign words
using the hierarchical sub-sentential alignment approach. Experimental results
show that simple additional processing improves the performance of word
alignment, which is measured by counting alignment matches in comparison with
fast align. We also report the result of final machine translation in both
English-Japanese and Japanese-English. We show our best system provided
significant improvements over the baseline as measured by BLEU and RIBES.},
 address = {Osaka, Japan},
 author = {Wang, Hao and Lepage, Yves},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4501},
 booktitle = {Proceedings of the Sixth Workshop on Hybrid Approaches to Translation (HyTra6)},
 month = {December},
 pages = {1--7},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Combining fast\_align with Hierarchical Sub-sentential Alignment for Better Word Alignments},
 year = {2016}
}

@inproceedings{W16-4502,
 abstract = {This paper presents the comparison of how using different neural network based
language modeling tools for selecting the best candidate fragments affects the
final output translation quality in a hybrid multi-system machine translation
setup. Experiments were conducted by comparing perplexity and BLEU scores on
common test cases using the same training data set. A 12-gram statistical
language model was selected as a baseline to oppose three neural network based
models of different characteristics. The models were integrated in a hybrid
system that depends on the perplexity score of a sentence fragment to produce
the best fitting translations. The results show a correlation between language
model perplexity and BLEU scores as well as overall improvements in BLEU.},
 address = {Osaka, Japan},
 author = {Rikters, Mat\={\i}ss},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4502},
 booktitle = {Proceedings of the Sixth Workshop on Hybrid Approaches to Translation (HyTra6)},
 month = {December},
 pages = {8--15},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Neural Network Language Models for Candidate Scoring in Hybrid Multi-System Machine Translation},
 year = {2016}
}

@inproceedings{W16-4503,
 abstract = {We present a novel method of comparable corpora construction. Unlike the
traditional methods which heavily rely on linguistic features, our method only
takes image similarity into consid-eration. We use an image-image search engine
to obtain similar images, together with the cap-tions in source language and
target language. On the basis, we utilize captions of similar imag-es to
construct sentence-level bilingual corpora. Experiments on 10,371 target
captions show that our method achieves a precision of 0.85 in the top search
results.},
 address = {Osaka, Japan},
 author = {Hong, Yu and Yao, Liang and Liu, Mengyi and Zhang, Tongtao and Zhou, Wenxuan and Yao, Jianmin and Ji, Heng},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4503},
 booktitle = {Proceedings of the Sixth Workshop on Hybrid Approaches to Translation (HyTra6)},
 month = {December},
 pages = {16--25},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Image-Image Search for Comparable Corpora Construction},
 year = {2016}
}

@inproceedings{W16-4504,
 abstract = {We present an algorithm for predicting translation equivalents between
two languages, based on the corresponding WordNets. The assumption is
that all synsets of one of the languages are linked
to the corresponding synsets in the other language. In theory, given
the exact sense of a word in a context it must be possible to translate
it as any of the words in the linked
synset. In practice, however, this does not work well since
automatic and accurate sense disambiguation is difficult. Instead it
is possible to define a more robust translation relation between the lexemes
of the two languages. As far as we know the Finnish WordNet is the only
one that includes that relation. Our algorithm can be used to predict
the relation for other languages as well. This is useful for instance
in hybrid machine translation systems which are usually more dependent
on high-quality translation dictionaries.},
 address = {Osaka, Japan},
 author = {Angelov, Krasimir and Lobanov, Gleb},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4504},
 booktitle = {Proceedings of the Sixth Workshop on Hybrid Approaches to Translation (HyTra6)},
 month = {December},
 pages = {26--32},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Predicting Translation Equivalents in Linked WordNets},
 year = {2016}
}

@inproceedings{W16-4505,
 abstract = {Traditional machine translation evaluation metrics such as BLEU and WER have
been widely used, but these metrics have poor correlations with human
judgements because they badly represent word similarity and impose strict
identity matching. In this paper, we propose some modifications to the
traditional measures based on word embeddings for these two metrics. The
evaluation results show that our modifications significantly improve their
correlation with human judgements.},
 address = {Osaka, Japan},
 author = {Wang, Haozhou and Merlo, Paola},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4505},
 booktitle = {Proceedings of the Sixth Workshop on Hybrid Approaches to Translation (HyTra6)},
 month = {December},
 pages = {33--41},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Modifications of Machine Translation Evaluation Metrics by Using Word Embeddings},
 year = {2016}
}

@inproceedings{W16-4506,
 abstract = {We describe experiments in Machine Translation using word sense disambiguation
(WSD) information. This work focuses on WSD in verbs, based on two different
approaches -- verbal patterns based on corpus pattern analysis and verbal word
senses from valency frames. We evaluate several options of using verb senses in
the source-language sentences as an additional factor for the Moses statistical
machine translation system. Our results show a statistically significant
translation quality improvement in terms of the BLEU metric for the valency
frames approach, but in manual evaluation, both WSD methods bring improvements.},
 address = {Osaka, Japan},
 author = {Sudarikov, Roman and Du\v{s}ek, Ond\v{r}ej and Holub, Martin and Bojar, Ond\v{r}ej and Kr\'{i}\v{z}, Vincent},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4506},
 booktitle = {Proceedings of the Sixth Workshop on Hybrid Approaches to Translation (HyTra6)},
 month = {December},
 pages = {42--50},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Verb sense disambiguation in Machine Translation},
 year = {2016}
}

@inproceedings{W16-4507,
 abstract = {We introduce a new statistical machine translation approach specifically geared
to learning translation from low resource languages, that exploits monolingual
English semantic parsing to bias inversion transduction grammar (ITG)
induction. We show that in contrast to conventional statistical machine
translation (SMT) training methods, which rely heavily on phrase memorization, our approach focuses on learning bilingual correlations that help translating
low resource languages, by using the output language semantic structure to
further narrow down ITG constraints. This approach is motivated by previous
research which has shown that injecting a semantic frame based objective
function while training SMT models improves the translation quality. We show
that including a monolingual semantic objective function during the learning of
the translation model leads towards a semantically driven alignment which is
more efficient than simply tuning loglinear mixture weights against a semantic
frame based evaluation metric in the final stage of statistical machine
translation training. We test our approach with three different language pairs
and demonstrate that our model biases the learning towards more semantically
correct alignments. Both GIZA++ and ITG based techniques fail to capture
meaningful bilingual constituents, which is required when trying to learn
translation models for low resource languages. In contrast, our proposed model
not only improve translation by injecting a monolingual objective function to
learn bilingual correlations during early training of the translation model, but also helps to learn more meaningful correlations with a relatively small
data set, leading to a better alignment compared to either conventional ITG or
traditional GIZA++ based approaches.},
 address = {Osaka, Japan},
 author = {Beloucif, Meriem and Saers, Markus and Wu, Dekai},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4507},
 booktitle = {Proceedings of the Sixth Workshop on Hybrid Approaches to Translation (HyTra6)},
 month = {December},
 pages = {51--60},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Improving word alignment for low resource languages using English monolingual SRL},
 year = {2016}
}

@inproceedings{W16-4508,
 abstract = {We defend that bilingual lexicons automatically extracted from parallel
corpora, whose entries have been meanwhile validated by linguists and
classified as correct or incorrect, should constitute a specific parallel
corpora.
And, in this paper, we propose to use word-to-word translations to learn
morph-units (comprising of bilingual stems and suffixes) from those bilingual
lexicons for two language pairs L1-L2 and L1-L3 to induce a bilingual lexicon
for the language pair L2-L3, apart from also learning morph-units for this
other language pair.
The applicability of bilingual morph-units in L1-L2 and L1-L3 is examined from
the perspective of pivot-based lexicon induction for language pair L2-L3 with
L1 as bridge. While the lexicon is derived by transitivity, the correspondences
are identified based on previously learnt bilingual stems and suffixes rather
than surface translation forms. The induced pairs are validated using a binary
classifier trained on morphological and similarity-based features using an
existing, automatically acquired, manually validated bilingual translation
lexicon for language pair L2-L3. In this paper, we discuss the use of English
(EN)-French (FR) and English (EN)-Portuguese (PT) lexicon of word-to-word
translations in generating word-to-word translations for the language pair
FR-PT with EN as pivot language. Generated translations are filtered out first
using an SVM-based FR-PT classifier and then are manually validated.},
 address = {Osaka, Japan},
 author = {mahesh, kavitha and Pereira Lopes, Gabriel and Gomes, Lu\'{i}s},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4508},
 booktitle = {Proceedings of the Sixth Workshop on Hybrid Approaches to Translation (HyTra6)},
 month = {December},
 pages = {61--71},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Using Bilingual Segments in Generating Word-to-word Translations},
 year = {2016}
}

@inproceedings{W16-4601,
 abstract = {This paper presents the results of the shared tasks from the 3rd workshop on
Asian translation (WAT2016) including J <-> E, J <-> C scientific paper
translation subtasks, C <-> J, K <-> J,  E <-> J patent translation subtasks, I
<-> E newswire subtasks and H <-> E, H <-> J mixed domain subtasks. For the
WAT2016, 15 institutions participated in the shared tasks. About 500
translation results have been submitted to the automatic evaluation server, and
selected submissions were manually evaluated.},
 address = {Osaka, Japan},
 author = {Nakazawa, Toshiaki and Ding, Chenchen and MINO, Hideya and Goto, Isao and Neubig, Graham and Kurohashi, Sadao},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4601},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {1--46},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Overview of the 3rd Workshop on Asian Translation},
 year = {2016}
}

@inproceedings{W16-4602,
 abstract = {Neural machine translation (NMT), a new approach to machine
translation, has achieved promising results comparable to those of
traditional approaches such as statistical machine translation
(SMT). Despite its recent success, NMT cannot handle a larger
vocabulary because training complexity and decoding complexity
proportionally increase with the number of target words. This problem
becomes even more serious when translating patent documents, which
contain many technical terms that are observed infrequently.  In NMTs, words that are out of vocabulary are represented by a single unknown
token.  In this paper, we propose a method that enables NMT to
translate patent sentences comprising a large vocabulary of technical
terms. We train an NMT system on bilingual data wherein technical terms
are replaced with technical term tokens; this allows it to translate
most of the source sentences except technical terms. Further, we use it
as a decoder to translate source sentences with technical term tokens
and replace the tokens with technical term translations using SMT. We
also use it to rerank the 1,000-best SMT translations on the basis of
the average of the SMT score and that of the NMT rescoring of the
translated sentences with technical term tokens. Our experiments on
Japanese-Chinese patent sentences show that the proposed NMT system
achieves a substantial improvement of up to 3.1 BLEU points and 2.3
RIBES points over traditional SMT systems and an improvement of
approximately 0.6 BLEU points and 0.8 RIBES points over an equivalent
NMT system without our proposed technique.},
 address = {Osaka, Japan},
 author = {Long, Zi and Utsuro, Takehito and Mitsuhashi, Tomoharu and Yamamoto, Mikio},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4602},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {47--57},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Translation of Patent Sentences with a Large Vocabulary of Technical Terms Using Neural Machine Translation},
 year = {2016}
}

@inproceedings{W16-4603,
 abstract = {Concomitant with the globalization of food culture, demand for the recipes of
specialty dishes
has been increasing. The recent growth in recipe sharing websites and food
blogs
has resulted in
numerous recipe texts being available for diverse foods in various languages.
However, little
work has been done on machine translation of recipe texts. In this paper, we
address the task
of translating recipes and investigate the advantages and disadvantages of
traditional phrase-
based statistical machine translation and more recent neural machine
translation. Specifically, we translate Japanese recipes into English, analyze errors in the translated
recipes, and discuss
available room for improvements.},
 address = {Osaka, Japan},
 author = {Sato, Takayuki and Harashima, Jun and Komachi, Mamoru},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4603},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {58--67},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Japanese-English Machine Translation of Recipe Texts},
 year = {2016}
}

@inproceedings{W16-4604,
 abstract = {This paper describes the IIT Bombay{\^a}s submission as a part of the shared task
in WAT 2016 for English--Indonesian language pair. The results reported here
are for both the direction of the language pair. Among the various approaches
experimented, Operation Sequence Model (OSM) and Neural Language Model have
been submitted for WAT. The OSM approach integrates translation and reordering
process resulting in relatively improved translation. Similarly the neural
experiment integrates Neural Language Model with Statistical Machine
Translation (SMT) as a feature for translation. The Neural Probabilistic
Language Model (NPLM) gave relatively high BLEU points for Indonesian to
English translation system while the Neural Network Joint Model (NNJM)
performed better for English to Indonesian direction of  translation system.
The results indicate improvement over the baseline Phrase-based SMT by 0.61
BLEU points for English-Indonesian system and 0.55 BLEU points for
Indonesian-English translation system.},
 address = {Osaka, Japan},
 author = {Singh, Sandhya and Kunchukuttan, Anoop and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4604},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {68--74},
 publisher = {The COLING 2016 Organizing Committee},
 title = {IIT Bombay{\^a}s English-Indonesian submission at WAT: Integrating Neural Language Models with SMT},
 year = {2016}
}

@inproceedings{W16-4605,
 abstract = {This paper describes our UT-KAY system that participated in the Workshop on
Asian Translation 2016. Based on an Attention-based Neural Machine Translation
(ANMT) model, we build our system by incorporating a domain adaptation method
for multiple domains and an attention-based unknown word replacement method. In
experiments, we verify that the attention-based unknown word replacement method
is effective in improving translation scores in Chinese-to-Japanese machine
translation. We further show results of manual analysis on the replaced unknown
words.},
 address = {Osaka, Japan},
 author = {Hashimoto, Kazuma and Eriguchi, Akiko and Tsuruoka, Yoshimasa},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4605},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {75--83},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Domain Adaptation and Attention-Based Unknown Word Replacement in Chinese-to-Japanese Neural Machine Translation},
 year = {2016}
}

@inproceedings{W16-4606,
 abstract = {When translating formal documents, capturing the sentence structure specific to
the sublanguage is extremely necessary to obtain high-quality translations.
This paper proposes a novel global reordering method with particular focus on
long-distance reordering for capturing the global sentence structure of a
sublanguage. The proposed method learns global reordering models from a
non-annotated parallel corpus and works in conjunction with conventional
syntactic reordering. Experimental results on the patent abstract sublanguage
show substantial gains of more than 25 points in the RIBES metric and
comparable BLEU scores both for Japanese-to-English and English-to-Japanese
translations.},
 address = {Osaka, Japan},
 author = {Fuji, Masaru and Utiyama, Masao and Sumita, Eiichiro and Matsumoto, Yuji},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4606},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {84--93},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Global Pre-ordering for Improving Sublanguage Translation},
 year = {2016}
}

@inproceedings{W16-4607,
 abstract = {This paper presents an improved lexicalized reordering model for phrase-based
statistical machine translation using a deep neural network.
Lexicalized reordering suffers from reordering ambiguity, data sparseness and
noises in a phrase table.
Previous neural reordering model is successful to solve the first and second
problems but fails to address the third one.
Therefore,  we propose new features using phrase translation and word alignment
to construct phrase vectors to handle inherently noisy phrase translation
pairs.
The experimental results show that our proposed method improves the accuracy of
phrase reordering.
We confirm that the proposed method works well with phrase pairs including NULL
alignments.},
 address = {Osaka, Japan},
 author = {Kanouchi, Shin and Sudoh, Katsuhito and Komachi, Mamoru},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4607},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {94--103},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Neural Reordering Model Considering Phrase Translation and Word Alignment for Phrase-based Translation},
 year = {2016}
}

@inproceedings{W16-4608,
 abstract = {This paper presents our machine translation system that developed for the
WAT2016 evalua-tion tasks of ja-en, ja-zh, en-ja, zh-ja, JPCja-en, JPCja-zh, JPCen-ja, JPCzh-ja. We build our system based on encoder--decoder framework by
integrating recurrent neural network (RNN) and gate recurrent unit (GRU), and
we also adopt an attention mechanism for solving the problem of information
loss. Additionally, we propose a simple translation-specific approach to
resolve the unknown word translation problem. Experimental results show that
our system performs better than the baseline statistical machine translation
(SMT) systems in each task. Moreover, it shows that our proposed approach of
unknown word translation performs effec-tively improvement of translation
results.},
 address = {Osaka, Japan},
 author = {Li, Shaotong and Xu, JinAn and Chen, Yufeng and Zhang, Yujie},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4608},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {104--110},
 publisher = {The COLING 2016 Organizing Committee},
 title = {System Description of bjtu\_nlp Neural Machine Translation System},
 year = {2016}
}

@inproceedings{W16-4609,
 abstract = {System architecture, experimental settings and experimental results of the
group for the WAT2016 tasks are described. We participate in six tasks: en-ja, zh-ja, JPCzh-ja, JPCko-ja, HINDENen-hi and HINDENhi-ja. Although the basic
architecture of our sys-tems is PBSMT with reordering, several techniques are
conducted. Especially, the system for the HINDENhi-ja task with pivoting by
English uses the reordering technique. Be-cause Hindi and Japanese are both OV
type languages and English is a VO type language, we can use reordering
technique to the pivot language. We can improve BLEU score from 7.47 to 7.66 by
the reordering technique for the sentence level pivoting of this task.},
 address = {Osaka, Japan},
 author = {Ehara, Terumasa},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4609},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {111--118},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Translation systems and experimental results of the EHR group for WAT2016 tasks},
 year = {2016}
}

@inproceedings{W16-4610,
 abstract = {This year, the Nara Institute of Science and Technology (NAIST)/Carnegie Mellon
University (CMU) submission to the Japanese-English translation track of the
2016 Workshop on Asian Translation was based on attentional neural machine
translation (NMT) models. In addition to the standard NMT model, we make a
number of improvements, most notably the use of discrete translation lexicons
to improve probability estimates, and the use of minimum risk training to
optimize the MT system for BLEU score. As a result, our system achieved the
highest translation evaluation scores for the task.},
 address = {Osaka, Japan},
 author = {Neubig, Graham},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4610},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {119--125},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Lexicons and Minimum Risk Training for Neural Machine Translation: NAIST-CMU at WAT2016},
 year = {2016}
}

@inproceedings{W16-4611,
 abstract = {This paper describes the NICT-2 translation system for the 3rd Workshop on
Asian Translation.  The proposed system employs a domain adaptation method
based on feature augmentation.              We regarded the Japan Patent Office
Corpus as a
mixture of four domain corpora and improved the translation quality of each
domain.  In addition, we incorporated language models constructed from Google
n-grams as external knowledge. Our domain adaptation method can naturally
incorporate such external knowledge that contributes to translation quality.},
 address = {Osaka, Japan},
 author = {Imamura, Kenji and Sumita, Eiichiro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4611},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {126--132},
 publisher = {The COLING 2016 Organizing Committee},
 title = {NICT-2 Translation System for WAT2016: Applying Domain Adaptation to Phrase-based Statistical Machine Translation},
 year = {2016}
}

@inproceedings{W16-4612,
 abstract = {We participate in scientific paper subtask (ASPEC-EJ/CJ) and patent subtask
(JPC-EJ/CJ/KJ) with phrase-based SMT systems which are trained with its own
patent corpora.  Using larger corpora than those prepared by the workshop
organizer, we achieved higher BLEU scores than most participants in EJ and CJ
translations of patent subtask, but in crowdsourcing evaluation, our EJ
translation, which is best in all automatic evaluations, received a very poor
score.                    In scientific paper subtask, our translations are given
lower
scores
than most translations that are produced by translation engines trained with
the in-domain corpora.                    But our scores are higher than those of
general-purpose
RBMTs and online services.  Considering the result of crowdsourcing evaluation, it shows a possibility that CJ SMT system trained with a large patent corpus
translates non-patent technical documents at a practical level.},
 address = {Osaka, Japan},
 author = {Kinoshita, Satoshi and Oshio, Tadaaki and Mitsuhashi, Tomoharu and Ehara, Terumasa},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4612},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {133--138},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Translation Using JAPIO Patent Corpora: JAPIO at WAT2016},
 year = {2016}
}

@inproceedings{W16-4613,
 abstract = {Simultaneous interpretation is a very challenging application of machine
translation in which the input is a stream of words from a speech recognition
engine. The key problem is how to segment the stream in an online manner into
units suitable for translation. The segmentation process proceeds by
calculating  a confidence score for each word that indicates the soundness of
placing a sentence boundary after it, and then heuristics are employed to
determine the position of the boundaries. Multiple variants of the confidence
scoring method and segmentation heuristics were studied. Experimental results
show that the best performing strategy is not only efficient in terms of
average latency per word, but also achieved end-to-end translation quality
close to an offline baseline, and close to oracle segmentation.},
 address = {Osaka, Japan},
 author = {Wang, Xiaolin and Finch, Andrew and Utiyama, Masao and Sumita, Eiichiro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4613},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {139--148},
 publisher = {The COLING 2016 Organizing Committee},
 title = {An Efficient and Effective Online Sentence Segmenter for Simultaneous Interpretation},
 year = {2016}
}

@inproceedings{W16-4614,
 abstract = {This paper illustrates the similarity between Thai and Laotian, and between
Malay and Indonesian, based on an investigation on raw parallel data from Asian
Language Treebank. The cross-lingual similarity is investigated and
demonstrated on metrics of correspondence and order of tokens, based on several
standard statistical machine translation techniques. The similarity shown in
this study suggests a possibility on harmonious annotation and processing of
the language pairs in future development.},
 address = {Osaka, Japan},
 author = {Ding, Chenchen and Utiyama, Masao and Sumita, Eiichiro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4614},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {149--156},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Similar Southeast Asian Languages: Corpus-Based Case Study on Thai-Laotian and Malay-Indonesian},
 year = {2016}
}

@inproceedings{W16-4615,
 abstract = {We propose a method for integrating Japanese empty category detection into the
preordering process of Japanese-to-English statistical machine translation.
First, we apply machine-learning-based empty category detection to estimate
the position and the type of empty categories in the constituent tree of the
source sentence.
Then, we apply discriminative preordering to the augmented constituent tree in
which empty categories are treated as if they are normal lexical symbols.
We find that it is effective to filter empty categories based on the
confidence of estimation.
Our experiments show that, for the IWSLT dataset consisting of short travel
conversations, the insertion of empty categories alone improves the BLEU score
from 33.2 to 34.3 and the RIBES score from 76.3 to 78.7, which imply that
reordering has improved
For the KFTT dataset consisting of Wikipedia sentences, the proposed
preordering method considering empty categories improves the BLEU score from
19.9 to 20.2 and the RIBES score from 66.2 to 66.3, which shows both
translation and reordering have improved slightly.},
 address = {Osaka, Japan},
 author = {Takeno, Shunsuke and Nagata, Masaaki and Yamamoto, Kazuhide},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4615},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {157--165},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Integrating empty category detection into preordering Machine Translation},
 year = {2016}
}

@inproceedings{W16-4616,
 abstract = {We describe here our approaches and results on the WAT 2016 shared translation
tasks. We tried to use both an example-based machine translation (MT) system
and a neural MT system. We report very good translation results, especially
when using neural MT for Chinese-to-Japanese translation.},
 address = {Osaka, Japan},
 author = {Cromieres, Fabien and Chu, Chenhui and Nakazawa, Toshiaki and Kurohashi, Sadao},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4616},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {166--174},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Kyoto University Participation to WAT 2016},
 year = {2016}
}

@inproceedings{W16-4617,
 abstract = {This paper reports our systems (UT-AKY) submitted in the 3rd Workshop of Asian
Translation 2016 (WAT'16) and their results in the English-to-Japanese
translation task.  Our model is based on the tree-to-sequence Attention-based
NMT (ANMT) model proposed by Eriguchi et al. (2016).  We submitted two ANMT
systems: one with a word-based decoder and the other with a character-based
decoder.  Experimenting on the English-to-Japanese translation task, we have
confirmed that the character-based decoder can cover almost the full vocabulary
in the target language and generate translations much faster than the
word-based model.},
 address = {Osaka, Japan},
 author = {Eriguchi, Akiko and Hashimoto, Kazuma and Tsuruoka, Yoshimasa},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4617},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {175--183},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Character-based Decoding in Tree-to-Sequence Attention-based Neural Machine Translation},
 year = {2016}
}

@inproceedings{W16-4618,
 abstract = {This paper describes the SENSE machine translation system participation in the
Third Workshop for Asian Translation (WAT2016). We share our best practices to
build a fast and light phrase-based machine translation (PBMT) models that have
comparable results to the baseline systems provided by the organizers. As
Neural Machine Translation (NMT) overtakes PBMT as the state-of-the-art, deep
learning and new MT practitioners might not be familiar with the PBMT paradigm
and we hope that this paper will help them build a PBMT baseline system quickly
and easily.},
 address = {Osaka, Japan},
 author = {Tan, Liling},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4618},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {184--193},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Faster and Lighter Phrase-based Machine Translation Baseline},
 year = {2016}
}

@inproceedings{W16-4619,
 abstract = {Unlike European languages, many Asian languages like Chinese and Japanese do
not have typographic boundaries in written system. Word segmentation
(tokenization) that break sentences down into individual words (tokens) is
normally treated as the first step for machine translation (MT). For Chinese
and Japanese, different rules and segmentation tools lead different
segmentation results in different level of granularity between Chinese and
Japanese. To improve the translation accuracy, we adjust and balance the
granularity of segmentation results around terms for Chinese--Japanese patent
corpus for training translation model. In this paper, we describe a statistical
machine translation (SMT) system which is built on re-tokenized
Chinese--Japanese patent training corpus using extracted bilingual multi-word
terms.},
 address = {Osaka, Japan},
 author = {Yang, Wei and Lepage, Yves},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4619},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {194--202},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Improving Patent Translation using Bilingual Term Extraction and Re-tokenization for Chinese--Japanese},
 year = {2016}
}

@inproceedings{W16-4620,
 abstract = {In machine translation, we must consider the difference in expression between
languages. For example, the active/passive voice may change in Japanese-English
translation. The same verb in Japanese may be translated into different voices
at each translation because the voice of a generated sentence cannot be
determined using only the information of the Japanese sentence. Machine
translation systems should consider the information structure to improve the
coherence of the output by using several topicalization techniques such as
passivization.
Therefore, this paper reports on our attempt to control the voice of the
sentence generated by an encoder-decoder model. To control the voice of the
generated sentence, we added the voice information of the target sentence to
the source sentence during the training. We then generated sentences with a
specified voice by appending the voice information to the source sentence. We
observed experimentally whether the voice could be controlled. The results
showed that, we could control the voice of the generated sentence with 85.0%
accuracy on average. In the evaluation of Japanese-English translation, we
obtained a 0.73-point improvement in BLEU score by using gold voice labels.},
 address = {Osaka, Japan},
 author = {Yamagishi, Hayahide and Kanouchi, Shin and Sato, Takayuki and Komachi, Mamoru},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4620},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {203--210},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Controlling the Voice of a Sentence in Japanese-to-English Neural Machine Translation},
 year = {2016}
}

@inproceedings{W16-4621,
 abstract = {This paper presents our Chinese-to-Japanese patent machine translation system
for WAT 2016 (Group ID: ntt) that uses syntactic pre-ordering over Chinese
dependency structures. Chinese words are reordered by a learning-to-rank model
based on pairwise classification to obtain word order close to Japanese. In
this year{\^a}s system, two different machine translation methods are compared:
traditional phrase-based statistical machine translation and recent
sequence-to-sequence neural machine translation with an attention mechanism.
Our pre-ordering showed a significant improvement over the phrase-based
baseline, but, in contrast, it degraded the neural machine translation
baseline.},
 address = {Osaka, Japan},
 author = {Sudoh, Katsuhito and Nagata, Masaaki},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4621},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {211--215},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Chinese-to-Japanese Patent Machine Translation based on Syntactic Pre-ordering for WAT 2016},
 year = {2016}
}

@inproceedings{W16-4622,
 abstract = {In this paper we describe the system that we develop as part of our
participation in WAT 2016. We develop a system based on hierarchical
phrase-based SMT for English to Hindi language pair. We perform re-ordering and
augment bilingual dictionary to improve the performance. As a baseline we use a
phrase-based SMT model. The MT models are fine-tuned on the development set, and the best configurations are used to report the evaluation on the test set.
Experiments show the BLEU of 13.71 on the benchmark test data. This is better
compared to the official baseline BLEU score of 10.79.},
 address = {Osaka, Japan},
 author = {Sen, Sukanta and Banik, Debajyoty and Ekbal, Asif and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4622},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {216--222},
 publisher = {The COLING 2016 Organizing Committee},
 title = {IITP English-Hindi Machine Translation System at WAT 2016},
 year = {2016}
}

@inproceedings{W16-4623,
 abstract = {To enhance Neural Machine Translation models, several obvious ways such as
enlarging the hidden size of recurrent layers and stacking multiple layers of
RNN can be considered. Surprisingly, we observe that using naively stacked RNNs
in the decoder slows down the training and leads to degradation in performance.
In this paper, We demonstrate that applying residual connections in the depth
of stacked RNNs can help the optimization, which is referred to as residual
stacking. In empirical evaluation, residual stacking of decoder RNNs gives
superior results compared to other methods of enhancing the model with a fixed
parameter budget. Our submitted systems in WAT2016 are based on a NMT model
ensemble with residual stacking in the decoder. To further improve the
performance, we also attempt various methods of system combination in our
experiments.},
 address = {Osaka, Japan},
 author = {Shu, Raphael and Miura, Akiva},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4623},
 booktitle = {Proceedings of the 3rd Workshop on Asian Translation (WAT2016)},
 month = {December},
 pages = {223--229},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Residual Stacking of RNNs for Neural Machine Translation},
 year = {2016}
}

@inproceedings{W16-4701,
 abstract = {Cancer (a.k.a neoplasms in a broader sense) is one of the leading causes of
death worldwide and its incidence is expected to exacerbate. To respond to the
critical need from the society, there have been rigorous attempts for the
cancer research community to develop treatment for cancer. Accordingly, we
observe a surge in the sheer volume of research products and outcomes in
relation to neoplasms.
In this talk, we introduce the notion of entitymetrics to provide a new lens
for understanding the impact, trend, and diffusion of knowledge associated with
neoplasms research. To this end, we collected over two million records from
PubMed, the most popular search engine in the medical domain. Coupled with text
mining techniques including named entity recognition, sentence boundary
detection, string approximate matching, entitymetrics enables us to analyze
knowledge diffusion, impact, and trend at various knowledge entity units, such
as bio-entity, organization, and country.
At the end of the talk, the future applications and possible directions of
entitymetrics will be discussed.},
 address = {Osaka, Japan},
 author = {Song, Min},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4701},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {1},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Analyzing Impact, Trend, and Diffusion of Knowledge associated with Neoplasms Research},
 year = {2016}
}

@inproceedings{W16-4702,
 abstract = {The present paper explores a novel method that integrates efficient distributed
representations with terminology extraction. We show that the information from
a small number of observed instances can be combined with local and global word
embeddings to remarkably improve the term extraction results on unigram terms.
To do so we pass the terms extracted by other tools to a filter made of the
local-global embeddings and a classifier which in turn decides whether or not a
term candidate is a term. The filter can also be used as a hub to merge
different term extraction tools into a single higher-performing system. We
compare filters that use the skip-gram architecture and filters that employ the
CBOW architecture for the task at hand.
Author{4}{Affiliation}},
 address = {Osaka, Japan},
 author = {Amjadian, Ehsan and Inkpen, Diana and Paribakht, Tahereh and Faez, Farahnaz},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4702},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {2--11},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Local-Global Vectors to Improve Unigram Terminology Extraction},
 year = {2016}
}

@inproceedings{W16-4703,
 abstract = {In the paper, we address the problem of recognition of non-domain phrases in
terminology lists obtained with an automatic term extraction tool. We focus on
identification of multi-word phrases that are general terms and discourse
function expressions. We tested several methods based on domain corpora
comparison and a method based on contexts of phrases identified in a large
corpus of general language. We compared the results of the methods to manual
annotation. The results show that the task is quite hard as the inter-annotator
agreement is low. Several tested methods achieved similar overall results, although the phrase ordering varied between methods. The most successful method
with the precision about 0.75 at the half of the tested list was the context
based method using a modified contextual diversity coefficient.},
 address = {Osaka, Japan},
 author = {Mykowiecka, Agnieszka and Marciniak, Malgorzata and Rychlik, Piotr},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4703},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {12--20},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Recognition of non-domain phrases in automatically extracted lists of terms},
 year = {2016}
}

@inproceedings{W16-4704,
 abstract = {This article presents a domain-driven algorithm for the task of term sense
disambiguation (TSD).  TSD aims at automatically choosing which term record
from a term bank best represents the meaning of a term occurring in a
particular context.  In a translation environment, finding the contextually
appropriate term record is necessary to access the proper equivalent to be used
in the target language text. The term bank TERMIUM Plus, recently published as
an open access repository, is chosen as a domain-rich resource for testing our
TSD algorithm, using English and French as source and target languages.  We
devise an experiment using over 1300 English terms found in scientific
articles, and show that our domain-driven TSD algorithm is able to bring the
best term record, and therefore the best French equivalent, at the average rank
of 1.69 compared to a baseline random rank of 3.51.},
 address = {Osaka, Japan},
 author = {Barriere, Caroline and M\'{e}nard, Pierre Andr\'{e} and Azoulay, Daphn\'{e}e},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4704},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {21--29},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Contextual term equivalent search using domain-driven disambiguation},
 year = {2016}
}

@inproceedings{W16-4705,
 abstract = {In this paper, we propose a method of augmenting existing bilingual
terminologies. Our method belongs to a "generate and validate" framework rather
than extraction from corpora.
Although many studies have proposed methods to find term translations or to
augment terminology within a "generate and validate" framework, few has taken
full advantage of the systematic nature of terminologies.
A terminology of a domain represents the conceptual system of the domain fairly
systematically, and we contend that making use of the systematicity fully will
greatly contribute to the effective augmentation of terminologies. This paper
proposes and evaluates a novel method to generate bilingual term candidates by
using existing terminologies and delving into their systematicity. Experiments
have shown that our method can generate
much better term candidate pairs than the existing method and give improved
performance for terminology augmentation.},
 address = {Osaka, Japan},
 author = {Iwai, Miki and Takeuchi, Koichi and Kageura, Kyo and Ishibashi, Kazuya},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4705},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {30--40},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Method of Augmenting Bilingual Terminology by Taking Advantage of the Conceptual Systematicity of Terminologies},
 year = {2016}
}

@inproceedings{W16-4706,
 abstract = {The extraction of data exemplifying relations between terms can make use, at
least to a large extent, of techniques that are similar to those used in
standard hybrid term candidate extraction, namely basic corpus analysis tools
(e.g. tagging, lemmatization, parsing), as well as morphological analysis of
complex words (compounds and derived items). In this article, we discuss the
use of such techniques for the extraction of raw material for a description of
relations between terms, and we provide internal evaluation data for the
devices developed.
We claim that user-generated content is a rich source of term variation through
paraphrasing and reformulation, and that these provide relational data at the
same time as term variants. Germanic languages with their rich word formation
morphology may be particularly good candidates for the approach advocated here.},
 address = {Osaka, Japan},
 author = {Roesiger, Ina and Bettinger, Julia and Sch\"{a}fer, Johannes and Dorna, Michael and Heid, Ulrich},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4706},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {41--51},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Acquisition of semantic relations between terms: how far can we get with standard NLP tools?},
 year = {2016}
}

@inproceedings{W16-4707,
 abstract = {We investigate how both model-related factors and application-related factors
affect the accuracy of distributional semantic models (DSMs) in the context of
specialized lexicography, and how these factors interact. This holistic
approach to the evaluation of DSMs provides valuable guidelines for the use of
these models and insight into the kind of semantic information they capture.},
 address = {Osaka, Japan},
 author = {Bernier-Colborne, Gabriel and Drouin, Patrick},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4707},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {52--61},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Evaluation of distributional semantic models: a holistic approach},
 year = {2016}
}

@inproceedings{W16-4708,
 abstract = {We propose and evaluate a method for identifying co-hyponym lexical units in a
terminological resource. The principles of term recognition and distributional
semantics are combined to extract terms from a similar category of concept.
Given a set of candidate terms, random projections are employed to represent
them as low-dimensional vectors. These vectors are derived automatically from
the frequency of the co-occurrences of the candidate terms and words that
appear within windows of text in their proximity (context-windows). In a
$k$-nearest neighbours framework, these vectors are classified using a small
set of manually annotated terms which exemplify concept categories. We then
investigate the interplay between the size of the corpus that is used for
collecting the co-occurrences and a number of factors that play roles in the
performance of the proposed method: the configuration of context-windows for
collecting co-occurrences, the selection of neighbourhood size ($k$), and the
choice of similarity metric.},
 address = {Osaka, Japan},
 author = {QasemiZadeh, Behrang},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4708},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {62--72},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Study on the Interplay Between the Corpus Size and Parameters of a Distributional Model for Term Classification},
 year = {2016}
}

@inproceedings{W16-4709,
 abstract = {Despite advances in computer technology, terminologists still tend to rely on
manual work to extract all the semantic information that they need for the
description of specialized concepts. In this paper we propose the creation of
new word sketches in Sketch Engine for the extraction of semantic relations.
Following a pattern-based approach, new sketch grammars are devel-oped in order
to extract some of the most common semantic relations used in the field of
ter-minology: generic-specific, part-whole, location, cause and function.},
 address = {Osaka, Japan},
 author = {Le\'{o}n-Ara\'{u}z, Pilar and San Mart\'{i}n, Antonio and Faber, Pamela},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4709},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {73--82},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Pattern-based Word Sketches for the Extraction of Semantic Relations},
 year = {2016}
}

@inproceedings{W16-4710,
 abstract = {This paper presents the construction and evaluation of Japanese and English
controlled bilingual terminologies that are particularly intended for
controlled authoring and machine translation with special reference to the
Japanese municipal domain. Our terminologies are constructed by extracting
terms from municipal website texts, and the term variations are controlled by
defining preferred and proscribed terms for both the source Japanese and the
target English. To assess the coverage of the terms/concepts in the municipal
domain and validate the quality of the control, we employ a quantitative
extrapolation method that estimates the potential vocabulary size. Using
Large-Number-of-Rare-Event (LNRE) modelling, we compare two parameters: (1)
uncontrolled and controlled and (2) Japanese and English. The results show that
our terminologies currently cover about 45--65% of the terms and 50--65% of
the concepts in the municipal domain, and are well controlled. The detailed
analysis of growth patterns of terminologies also provides insight into the
extent to which we can enlarge the terminologies within the realistic range.},
 address = {Osaka, Japan},
 author = {Miyata, Rei and Kageura, Kyo},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4710},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {83--93},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Constructing and Evaluating Controlled Bilingual Terminologies},
 year = {2016}
}

@inproceedings{W16-4711,
 abstract = {By its own nature, the Natural Language Processing (NLP) community is a priori
the best equipped to study the evolution of its own publications, but works in
this direction are rare and only recently have we seen a few attempts at
charting the field. In this paper, we use the algorithms, resources, standards, tools and common practices of the NLP field to build a list of terms
characteristic of ongoing research, by mining a large corpus of scientific
publications, aiming at the largest possible exhaustivity and covering the
largest possible time span. Study of the evolution of this term list through
time reveals interesting insights on the dynamics of field and the availability
of the term database and of the corpus (for a large part) make possible many
further comparative studies in addition to providing a test field for a new
graphic interface designed to  perform visual  time analytics of large sized
thesauri.},
 address = {Osaka, Japan},
 author = {Francopoulo, Gil and Mariani, Joseph and Paroubek, Patrick and Vernier, Fr\'{e}d\'{e}ric},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4711},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {94--103},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Providing and Analyzing NLP Terms for our Community},
 year = {2016}
}

@inproceedings{W16-4712,
 abstract = {Annotating medical text such as clinical notes with human phenotype descriptors
is an important task that can, for example, assist in building patient
profiles. To automatically annotate text one usually needs a dictionary of
predefined terms. However, do to the variety of human expressiveness, current
state-of-the art phenotype concept recognizers and automatic annotators
struggle with specific domain issues and challenges. In this paper we present
results of an-notating gold standard corpus with a dictionary containing
lexical variants for the Human Phenotype Ontology terms. The main purpose of
the dictionary is to improve the recall of phenotype concept recognition
systems. We compare the method with four other approaches and present results.},
 address = {Osaka, Japan},
 author = {Kocbek, Simon and Fujiwara, Toyofumi and Kim, Jin-Dong and Takagi, Toshihisa and Groza, Tudor},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4712},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {104--109},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Evaluating a dictionary of human phenotype terms focusing on rare diseases},
 year = {2016}
}

@inproceedings{W16-4713,
 abstract = {We propose a semi-automatic method for the acquisition of specialised
ontological and terminological knowledge. An ontology and a terminology are
automatically built from domain experts' annotations. The ontology formalizes
the common and shared conceptual vocabulary of those experts. Its associated
terminology defines a glossary linking annotated terms to their semantic
categories. These two resources evolve incrementally and are used for an
automatic annotation of a new corpus at each iteration. The annotated corpus
concerns the evaluation of French higher education and science institutions.},
 address = {Osaka, Japan},
 author = {Sadoun, Driss},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4713},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {110--120},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A semi automatic annotation approach for ontological and terminological knowledge acquisition},
 year = {2016}
}

@inproceedings{W16-4714,
 abstract = {With many hospitals digitalizing clinical records it has opened opportunities
for researchers in NLP, Machine Learning to apply techniques for extracting
meaning and make actionable insights. There has been previous attempts in
mapping free text to medical nomenclature like UMLS, SNOMED. However, in this
paper, we had analyzed diagnosis in clinical reports using ICD10 to achieve a
lightweight, real-time predictions by introducing concepts like WordInfo, root
word identification. We were able to achieve 68.3% accuracy over clinical
records collected from qualified clinicians. Our study would further help the
healthcare institutes in organizing their clinical reports based on ICD10
mappings and derive numerous insights to achieve operational efficiency and
better medical care.},
 address = {Osaka, Japan},
 author = {Krishna, Santosh Sai and Hans, Manoj},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4714},
 booktitle = {Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)},
 month = {December},
 pages = {121--125},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Understanding Medical free text: A Terminology driven approach},
 year = {2016}
}

@inproceedings{W16-4801,
 abstract = {We present the results of the third edition of the Discriminating between
Similar Languages (DSL) shared task, which was organized as part of the
VarDial'2016 workshop at COLING'2016. The challenge offered two subtasks:
subtask 1 focused on the identification of very similar languages and language
varieties in newswire texts, whereas subtask 2 dealt with Arabic dialect
identification in speech transcripts. A total of 37 teams registered to
participate in the task, 24 teams submitted test results, and 20 teams also
wrote system description papers.
High-order character n-grams were the most successful feature, and the best
classification approaches included traditional supervised learning methods such
as SVM, logistic regression, and language models, while deep learning
approaches did not perform very well.},
 address = {Osaka, Japan},
 author = {Malmasi, Shervin and Zampieri, Marcos and Ljube\v{s}i\'{c}, Nikola and Nakov, Preslav and Ali, Ahmed and Tiedemann, J\"{o}rg},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4801},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {1--14},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Discriminating between Similar Languages and Arabic Dialect Identification: A Report on the Third DSL Shared Task},
 year = {2016}
}

@inproceedings{W16-4802,
 abstract = {This paper describes the systems we experimented with for participating in
the discriminating between similar languages (DSL) shared task 2016.  We
submitted results of a single system based on support vector machines (SVM)
with linear kernel and using character ngram features, which obtained the
first rank at the closed training track for test set A.  Besides the linear
SVM, we also report additional experiments with a number of deep learning
architectures. Despite our intuition that non-linear deep learning methods
should be advantageous, linear models seems to fare better in this task, at
least with the amount of data and the amount of effort we spent on tuning
these models.},
 address = {Osaka, Japan},
 author = {\c{C}\"{o}ltekin, \c{C}a\u{g}r{\"A}$\pm$ and Rama, Taraka},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4802},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {15--24},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Discriminating Similar Languages with Linear SVMs and Neural Networks},
 year = {2016}
}

@inproceedings{W16-4803,
 abstract = {Computational approaches for dialectometry employed Levenshtein distance to
compute an aggregate similarity between two dialects belonging to a single
language group. In this paper, we apply a sequence-to-sequence autoencoder to
learn a deep representation for words that can be used for meaningful
comparison across dialects. In contrast to the alignment-based methods, our
method does not require explicit alignments. We apply our architectures to
three different datasets and show that the learned representations indicate
highly similar results with the analyses based on Levenshtein distance and
capture the traditional dialectal differences shown by dialectologists.},
 address = {Osaka, Japan},
 author = {Rama, Taraka and \c{C}\"{o}ltekin, \c{C}a\u{g}r{\"A}$\pm$},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4803},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {25--32},
 publisher = {The COLING 2016 Organizing Committee},
 title = {LSTM Autoencoders for Dialect Analysis},
 year = {2016}
}

@inproceedings{W16-4804,
 abstract = {This paper describes the GW/LT3 contribution to the 2016 VarDial shared task on
the identification of similar languages (task 1) and Arabic dialects (task 2).
For both tasks, we
experimented with Logistic Regression and Neural Network classifiers in
isolation.
Additionally, we implemented a cascaded classifier that consists of coarse and
fine-grained classifiers (task 1) and a classifier ensemble with majority
voting for task 2. The submitted systems obtained state-of-the art performance
and ranked first for the evaluation on social media data (test sets B1 and B2
for task 1), with a maximum weighted F1 score of 91.94%.},
 address = {Osaka, Japan},
 author = {Zirikly, Ayah and Desmet, Bart and Diab, Mona},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4804},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {33--41},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The GW/LT3 VarDial 2016 Shared Task System for Dialects and Similar Languages Detection},
 year = {2016}
}

@inproceedings{W16-4805,
 abstract = {We recently witnessed an exponential growth in dialectal Arabic usage in both
textual data and speech recordings especially in social media. Processing such
media is of great utility for all kinds of applications ranging from
information extraction to social media analytics for political and commercial
purposes to building decision support systems. Compared to other languages, Arabic, especially the informal variety, poses a significant challenge to
natural language processing algorithms since it comprises multiple dialects, linguistic code switching, and a lack of standardized orthographies, to top its
relatively complex morphology. Inherently, the problem of processing Arabic in
the context of social media is the problem of how to handle resource poor
languages. In this talk I will go over some of our insights to some of these
problems and show how there is a silver lining where we can generalize some of
our solutions to other low resource language contexts.},
 address = {Osaka, Japan},
 author = {Diab, Mona},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4805},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {42},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Processing Dialectal Arabic: Exploiting Variability and Similarity to Overcome Challenges and Discover Opportunities},
 year = {2016}
}

@inproceedings{W16-4806,
 abstract = {Machine translation between closely related languages is less challenging and
exibits a smaller number of translation errors than translation between distant
languages, but there are still obstacles which should be addressed in order to
improve such systems.
This work explores the obstacles for machine translation systems between
closely related South Slavic languages, namely Croatian, Serbian and Slovenian.
Statistical systems for all language pairs and translation directions are
trained using parallel texts from different domains, however mainly on spoken
language i.e. subtitles. For translation between Serbian and Croatian, a
rule-based system is also explored. It is shown that for all language pairs and
translation systems, the main obstacles are differences between structural
properties.},
 address = {Osaka, Japan},
 author = {Popovi\'{c}, Maja and Arcan, Mihael and Klubi\v{c}ka, Filip},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4806},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {43--52},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Language Related Issues for Machine Translation between Closely Related South Slavic Languages},
 year = {2016}
}

@inproceedings{W16-4807,
 abstract = {The identification of the language of text/speech input is the first step to be
able to properly do any language-dependent natural language processing. The
task is called Automatic Language Identification (ALI). Being a well-studied
field since early 1960{\^a}s, various methods have been applied to many standard
languages. The ALI standard methods require datasets for training and use
character/word-based n-gram models. However, social media and new technologies
have contributed to the rise of informal and minority languages on the Web. The
state-of-the-art auto- matic language identifiers fail to properly identify
many of them. Romanized Arabic (RA) and Romanized Berber (RB) are cases of
these informal languages which are under-resourced. The goal of this paper is
twofold: detect RA and RB, at a document level, as separate languages and
distinguish between them as they coexist in North Africa. We consider the task
as a classification problem and use supervised machine learning to solve it.
For both languages, character-based 5-grams combined with additional lexicons
score the best, F-score of 99.75% and 97.77% for RB and RA respectively.},
 address = {Osaka, Japan},
 author = {Adouane, Wafia and Semmar, Nasredine and Johansson, Richard},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4807},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {53--61},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Romanized Berber and Romanized Arabic Automatic Language Identification Using Machine Learning},
 year = {2016}
}

@inproceedings{W16-4808,
 abstract = {One of the purposes of the VarDial workshop series is to encourage research
into NLP methods that treat human languages as a continuum, by designing
models that exploit the similarities between languages and variants.
In my work, I am using a continuous vector representation of languages that
allows modeling and exploring the language continuum in a very direct way.
The basic tool for this is a character-based recurrent neural network language
model conditioned on language vectors whose values are learned during training.
By feeding the model Bible translations in a thousand languages, not only does
the learned vector space capture language similarity, but by interpolating
between the learned vectors it is possible to generate text in unattested
intermediate forms between the training languages.},
 address = {Osaka, Japan},
 author = {\"{O}stling, Robert},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4808},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {62},
 publisher = {The COLING 2016 Organizing Committee},
 title = {How Many Languages Can a Language Model Model?},
 year = {2016}
}

@inproceedings{W16-4809,
 abstract = {Automatic Language Identification (ALI) is the detection of the natural
language of an input text by a machine. It is the first necessary step to do
any language-dependent natural language pro- cessing task. Various methods have
been successfully applied to a wide range of languages, and the
state-of-the-art automatic language identifiers are mainly based on character
n-gram models trained on huge corpora. However, there are many languages which
are not yet automatically pro- cessed, for instance minority and informal
languages. Many of these languages are only spoken and do not exist in a
written format. Social media platforms and new technologies have facili- tated
the emergence of written format for these spoken languages based on
pronunciation. The latter are not well represented on the Web, commonly
referred to as under-resourced languages, and the current available ALI tools
fail to properly recognize them. In this paper, we revisit the problem of ALI
with the focus on Arabicized Berber and dialectal Arabic short texts. We intro-
duce new resources and evaluate the existing methods. The results show that
machine learning models combined with lexicons are well suited for detecting
Arabicized Berber and different Arabic varieties and distinguishing between
them, giving a macro-average F-score of 92.94%.},
 address = {Osaka, Japan},
 author = {Adouane, Wafia and Semmar, Nasredine and Johansson, Richard and Bobicev, Victoria},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4809},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {63--72},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Automatic Detection of Arabicized Berber and Arabic Varieties},
 year = {2016}
}

@inproceedings{W16-4810,
 abstract = {We present an approach for automatic verification and augmentation of
multilingual lexica. We exploit existing parallel and monolingual corpora to
extract multilingual correspondents via tri-angulation. We demonstrate the
efficacy of our approach on two publicly available resources: Tharwa, a
three-way lexicon comprising Dialectal Arabic, Modern Standard Arabic and
English lemmas among other information (Diab et al., 2014); and BabelNet, a
multilingual thesaurus comprising over 276 languages including Arabic variant
entries (Navigli and Ponzetto, 2012). Our automated approach yields an F1-score
of 71.71% in generating correct multilingual corre- spondents against gold
Tharwa, and 54.46% against gold BabelNet without any human interven- tion.},
 address = {Osaka, Japan},
 author = {Aminian, Maryam and Al-Badrashiny, Mohamed and Diab, Mona},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4810},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {73--81},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Automatic Verification and Augmentation of Multilingual Lexicons},
 year = {2016}
}

@inproceedings{W16-4811,
 abstract = {A common and effective way to train translation systems between related
languages is to consider sub-word level basic units. However, this increases
the length of the sentences resulting in increased decoding time. The increase
in length is also impacted by the specific choice of data format for
representing the sentences as subwords. In a phrase-based SMT framework, we
investigate different choices of decoder parameters as well as data format and
their impact on decoding time and translation accuracy. We suggest best options
for these settings that significantly improve decoding time with little impact
on the translation accuracy.},
 address = {Osaka, Japan},
 author = {Kunchukuttan, Anoop and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4811},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {82--88},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Faster Decoding for Subword Level Phrase-based SMT between Related Languages},
 year = {2016}
}

@inproceedings{W16-4812,
 abstract = {In this study we apply classification methods for detecting subdialectal
differences in Sorani Kurdish texts produced in different regions, namely Iran
and Iraq. As Sorani is a low-resource language, no corpus including texts from
different regions was readily available. To this end, we identified data
sources that could be leveraged for this task to create a dataset of 200,000
sentences. Using surface features, we attempted to classify Sorani subdialects, showing that sentences from news sources in Iraq and Iran are distinguishable
with 96% accuracy. This is the first preliminary study for a dialect that has
not been widely studied in computational linguistics, evidencing the possible
existence of distinct subdialects.},
 address = {Osaka, Japan},
 author = {Malmasi, Shervin},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4812},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {89--96},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Subdialectal Differences in Sorani Kurdish},
 year = {2016}
}

@inproceedings{W16-4813,
 abstract = {Massive Open Online Courses have been growing rapidly in size and impact. Yet
the language barrier constitutes a major growth impediment in reaching out all
people and educating all citizens. A vast majority of educational material is
available only in English, and state-of-the-art machine translation  systems
still have not been tailored for this peculiar genre. In addition, a mere
collection of appropriate in-domain training material is a challenging task. In
this work, we investigate statistical machine translation of lecture subtitles
from English into Croatian, which is  morphologically rich and generally weakly
supported, especially for the educational domain. We show that results
comparable with publicly available systems trained on much larger data can be
achieved if a small in-domain training set is used in combination with
additional in-domain corpus originating from the closely related Serbian
language.},
 address = {Osaka, Japan},
 author = {Popovi\'{c}, Maja and Cholakov, Kostadin and Kordoni, Valia and Ljube\v{s}i\'{c}, Nikola},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4813},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {97--105},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Enlarging Scarce In-domain English-Croatian Corpus for SMT of MOOCs Using Serbian},
 year = {2016}
}

@inproceedings{W16-4814,
 abstract = {In this paper we describe a system developed to identify a set of four regional
Arabic dialects (Egyptian, Gulf, Levantine, North African) and Modern Standard
Arabic (MSA) in a transcribed speech corpus. We competed under the team name
MAZA in the Arabic Dialect Identification sub-task of the 2016 Discriminating
between Similar Languages (DSL) shared task. Our system
achieved an F1-score of 0.51 in the closed training track, ranking first among
the 18 teams that participated in the sub-task. Our system utilizes a
classifier ensemble with a set of linear models as base classifiers. We
experimented with three different ensemble fusion strategies, with the
mean probability approach providing the best performance.},
 address = {Osaka, Japan},
 author = {Malmasi, Shervin and Zampieri, Marcos},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4814},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {106--113},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Arabic Dialect Identification in Speech Transcripts},
 year = {2016}
}

@inproceedings{W16-4815,
 abstract = {In this paper we investigate two approaches to discrimination of similar
languages: Expectation--maximization algorithm for estimating conditional
probability P(word|language) and byte level language models similar to
compression-based language modelling methods.
The accuracy of these methods reached respectively 86.6\,\% and 88.3\,\% on set
A of the DSL Shared task 2016 competition.},
 address = {Osaka, Japan},
 author = {Herman, Ond\v{r}ej and Suchomel, Vit and Baisa, V\'{i}t and Rychl\'{y}, Pavel},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4815},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {114--118},
 publisher = {The COLING 2016 Organizing Committee},
 title = {DSL Shared Task 2016: Perfect Is The Enemy of Good Language Discrimination Through Expectation--Maximization and Chunk-based Language Model},
 year = {2016}
}

@inproceedings{W16-4816,
 abstract = {We report on our system for the shared task on discriminating between similar
languages (DSL 2016).
The system uses only byte representations in a deep residual network (ResNet).
The system, named ResIdent, is trained only on the data released with the task
(closed training).
We obtain 84.88% accuracy on subtask A, 68.80% accuracy on subtask B1, and
69.80% accuracy on subtask B2.
A large difference in accuracy on development data can be observed with
relatively minor changes in our network's architecture and hyperparameters.
We therefore expect fine-tuning of these parameters to yield higher accuracies.},
 address = {Osaka, Japan},
 author = {Bjerva, Johannes},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4816},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {119--125},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Byte-based Language Identification with Deep Convolutional Networks},
 year = {2016}
}

@inproceedings{W16-4817,
 abstract = {We describe several systems for identifying short samples of Arabic dialects.
The systems were prepared for the shared task of the 2016 DSL
Workshop.
Our best system, an SVM using character tri-gram features, achieved an accuracy on the test data for the task of 0.4279, compared to
a baseline of 0.20 for chance guesses or 0.2279 if we had always chosen the
same most frequent class in the test set. This compares with the results
of the team with the best weighted F1 score, which was
an accuracy of 0.5117.
The team entries seem to fall into cohorts, with
all the teams in a cohort within a
standard-deviation of each other, and our three entries are in the third
cohort, which is about seven standard deviations from the top.},
 address = {Osaka, Japan},
 author = {Hanani, Abualsoud and Qaroush, Aziz and Taylor, Stephen},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4817},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {126--134},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Classifying ASR Transcriptions According to Arabic Dialect},
 year = {2016}
}

@inproceedings{W16-4818,
 abstract = {The most common approach in text mining classification tasks is to rely on
features like words, part-of-speech tags, stems, or some other high-level
linguistic features. Unlike the common approach, we present a method that uses
only character p-grams (also known as n-grams) as features for the Arabic
Dialect Identification (ADI)
Closed Shared Task of the DSL 2016 Challenge. The proposed approach combines
several string kernels using multiple kernel learning. In the learning stage, we try both Kernel Discriminant Analysis (KDA) and Kernel Ridge Regression
(KRR), and we choose KDA as it gives better results in a 10-fold
cross-validation carried out on the training set. Our approach is shallow and
simple, but the empirical results obtained in the ADI Shared Task prove that it
achieves very good results. Indeed, we ranked on the second place with an
accuracy of 50.91% and a weighted F1 score of 51.31%. We also present improved
results in this paper, which we obtained after the competition ended. Simply by
adding more regularization into our model to make it more suitable for test
data that comes from a different distribution than training data, we obtain an
accuracy of 51.82% and a weighted F1 score of 52.18%. Furthermore, the proposed
approach has an important advantage in that it is language independent and
linguistic theory neutral, as it does not require any NLP tools.},
 address = {Osaka, Japan},
 author = {Ionescu, Radu Tudor and Popescu, Marius},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4818},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {135--144},
 publisher = {The COLING 2016 Organizing Committee},
 title = {UnibucKernel: An Approach for Arabic Dialect Identification Based on Multiple String Kernels},
 year = {2016}
}

@inproceedings{W16-4819,
 abstract = {Discriminating between closely-related language varieties is considered a
challenging and important task. This paper describes our submission to the DSL
2016 shared-task, which included two sub-tasks: one on discriminating similar
languages and one on identifying Arabic dialects. We developed a
character-level neural network for this task. Given a sequence of characters, our model embeds each character in vector space, runs the sequence through
multiple convolutions with different filter widths, and pools the convolutional
representations to obtain a hidden vector representation of the text that is
used for predicting the language or dialect. We primarily focused on the Arabic
dialect identification task and obtained an F1 score of 0.4834, ranking 6th out
of 18 participants. We also analyze errors made by our system on the Arabic
data in some detail, and point to challenges such an approach is faced with.},
 address = {Osaka, Japan},
 author = {Belinkov, Yonatan and Glass, James},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4819},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {145--152},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Character-level Convolutional Neural Network for Distinguishing Similar Languages and Dialects},
 year = {2016}
}

@inproceedings{W16-4820,
 abstract = {In this paper we describe the Helsinki language identification method, HeLI, and the resources we created for and used in the 3rd edition of the
Discriminating between Similar Languages (DSL) shared task, which was organized
as part of the VarDial 2016 workshop. The shared task comprised of a total of 8
tracks, of which we participated in 7. The shared task had a record number of
participants, with 17 teams providing results for the closed track of the test
set A. Our system reached the 2nd position in 4 tracks (A closed and open, B1
open and B2 open) and in this paper we are focusing on the methods and data
used for those tracks. We describe our word-based backoff method in
mathematical notation. We also describe how we selected the corpus we used in
the open tracks.},
 address = {Osaka, Japan},
 author = {Jauhiainen, Tommi and Lind\'{e}n, Krister and Jauhiainen, Heidi},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4820},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {153--162},
 publisher = {The COLING 2016 Organizing Committee},
 title = {HeLI, a Word-Based Backoff Method for Language Identification},
 year = {2016}
}

@inproceedings{W16-4821,
 abstract = {This paper presents the system built by ASIREM team for the Discriminating
between Similar Languages (DSL) Shared task 2016. It describes the system which
uses character-based and word-based n-grams separately. ASIREM participated in
both sub-tasks (sub-task 1 and sub- task 2) and in both open and closed tracks.
For the sub-task 1 which deals with Discriminating between similar languages
and national language varieties, the system achieved an accuracy of 87.79% on
the closed track, ending up ninth (the best results being 89.38%). In sub-task
2, which deals with Arabic dialect identification, the system achieved its best
performance using character-based n-grams (49.67% accuracy), ranking fourth in
the closed track (the best result being 51.16%), and an accuracy of 53.18%, ranking first in the open track.},
 address = {Osaka, Japan},
 author = {Adouane, Wafia and Semmar, Nasredine and Johansson, Richard},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4821},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {163--169},
 publisher = {The COLING 2016 Organizing Committee},
 title = {ASIREM Participation at the Discriminating Similar Languages Shared Task 2016},
 year = {2016}
}

@inproceedings{W16-4822,
 abstract = {This article describes the systems submitted by the Citius\_Ixa\_Imaxin team to
the Discriminating Similar Languages Shared Task 2016. The systems are based on
two different strategies: classification with ranked dictionaries and Naive
Bayes classifiers. The results of the evaluation show that ranking dictionaries
are more sound and stable across different domains while basic bayesian models
perform reasonably well on in-domain datasets, but their performance drops when
they are applied on out-of-domain texts.},
 address = {Osaka, Japan},
 author = {Gamallo, Pablo and Alegria, I\~{n}aki and Pichel, Jos\'{e} Ramom and Agirrezabal, Manex},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4822},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {170--177},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Comparing Two Basic Methods for Discriminating Between Similar Languages and Varieties},
 year = {2016}
}

@inproceedings{W16-4823,
 abstract = {We describe the systems entered by the National Research Council in the 2016
shared task on discriminating similar languages. Like previous years, we relied
on character ngram features, and a mixture of discriminative and generative
statistical classifiers. We mostly investigated the influence of the amount of
data on the performance, in the open task, and compared the two- stage approach
(predicting language/group, then variant) to a flat approach. Results suggest
that ngrams are still state-of-the-art for language and variant identification, and that additional data has a small but decisive impact.},
 address = {Osaka, Japan},
 author = {Goutte, Cyril and L\'{e}ger, Serge},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4823},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {178--184},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Advances in Ngram-based Discrimination of Similar Languages},
 year = {2016}
}

@inproceedings{W16-4824,
 abstract = {In this paper, we describe a system (CGLI) for discriminating similar
languages, varieties and dialects using convolutional neural networks (CNNs)
and
long short-term memory (LSTM) neural networks. We have participated in the
Arabic dialect identification sub-task of DSL 2016 shared task for
distinguishing different Arabic language texts under closed submission track.
Our proposed approach is language independent and works for discriminating any
given set of languages, varieties, and dialects. We have obtained 43.29%
weighted-F1 accuracy in this sub-task using CNN approach using default network
parameters.},
 address = {Osaka, Japan},
 author = {Guggilla, Chinnappa},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4824},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {185--194},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Discrimination between Similar Languages, Varieties and Dialects using CNN- and LSTM-based Deep Neural Networks},
 year = {2016}
}

@inproceedings{W16-4825,
 abstract = {The DSL 2016 shared task continued previous evaluations from 2014 and 2015 that
facilitated the study of automated language and dialect identification. This
paper describes results for this year{\^a}s shared task and from several related
experiments conducted at the Johns Hopkins University Human Language Technology
Center of Excellence (JHU HLTCOE). Previously the HLTCOE has explored the use
of compression-inspired language modeling for language and dialect
identification, using news, Wikipedia, blog post, and Twitter corpora. The
technique we have relied upon is based on prediction by partial matching (PPM), a state of the art text compression technique. Due to the close relationship
between adaptive compression and language modeling, such compression techniques
can also be applied to multi-way text classification problems, and previous
studies have examined tasks such as authorship attribution, email spam
detection, and topical classification. We applied our approach to the
multi-class decision that considered each dialect or language as a possibility
for the given shared task input line. Results for test-set A were in accord
with our expectations, however results for test-sets B and C appear to be
markedly worse. We had not anticipated the inclusion of multiple communications
in differing languages in test- set B (social media) input lines, and had not
expected the test-set C (dialectal Arabic) data to be represented phonetically
instead of in native orthography.},
 address = {Osaka, Japan},
 author = {McNamee, Paul},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4825},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {195--203},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Language and Dialect Discrimination Using Compression-Inspired Language Models},
 year = {2016}
}

@inproceedings{W16-4826,
 abstract = {This paper describes an Arabic dialect identification system which we developed
for the Discriminating Similar Languages (DSL) 2016 shared task. We classified
Arabic dialects by using Waikato Environment for Knowledge Analysis (WEKA) data
analytic tool which contains many alternative filters and classifiers for
machine learning. We experimented with several classifiers and the best
accuracy was achieved using the Sequential Minimal Optimization (SMO) algorithm
for training and testing process set to three different feature-sets for each
testing process. Our approach achieved an accuracy equal to 42.85% which is
considerably worse in comparison to the evaluation scores on the training set
of 80-90% and with training set {\^a}60:40{\^a} percentage split which achieved
accuracy around 50%. We observed that Buckwalter transcripts from the Saarland
Automatic Speech Recognition (ASR) system are given without short vowels, though the Buckwalter system has notation for these. We elaborate such
observations, describe our methods and analyse the training dataset.},
 address = {Osaka, Japan},
 author = {Alshutayri, Areej and Atwell, Eric and Alosaimy, Abdulrahman and Dickins, James and Ingleby, Michael and Watson, Janet},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4826},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {204--211},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Arabic Language WEKA-Based Dialect Classifier for Arabic Automatic Speech Recognition Transcripts},
 year = {2016}
}

@inproceedings{W16-4827,
 abstract = {In this study conducted on the occasion of the Discriminating between Similar
Languages shared task, I introduce an additional decision factor focusing on
the token and subtoken level. The motivation behind this submission is to test
whether a morphologically-informed criterion can add linguistically relevant
information to global categorization and thus improve performance. The
contributions of this paper are (1) a description of the unsupervised, low-resource method; (2) an evaluation and analysis of its raw performance; and
(3) an assessment of its impact within a model comprising common indicators
used in language identification. I present and discuss the systems used in the
task A, a 12-way language identification task comprising varieties of five main
language groups. Additionally I introduce a new off-the-shelf Naive Bayes
classifier using a contrastive word and subword n-gram model ("Bayesline")
which outperforms the best submissions.},
 address = {Osaka, Japan},
 author = {Barbaresi, Adrien},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4827},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {212--220},
 publisher = {The COLING 2016 Organizing Committee},
 title = {An Unsupervised Morphological Criterion for Discriminating Similar Languages},
 year = {2016}
}

@inproceedings{W16-4828,
 abstract = {The paper describes the QCRI submissions to the task of automatic Arabic
dialect classification into 5 Arabic variants, namely Egyptian, Gulf, Levantine,  North-African, and Modern Standard Arabic (MSA). The training data
is relatively small and is automatically generated from an ASR system. To avoid
over-fitting on such small data, we carefully selected and designed the
features to capture the morphological essence of the different dialects. We
submitted four runs to the Arabic sub-task. For all runs, we used a combined
feature vector of character bi-grams, tri-grams, 4-grams, and 5-grams. We tried
several machine-learning algorithms, namely Logistic Regression, Naive Bayes, Neural Networks, and Support Vector Machines (SVM) with linear and string
kernels. However, our submitted runs used SVM with a linear kernel. In the
closed submission, we got the best accuracy of 0.5136 and the third best
weighted F1 score, with a difference less than 0.002 from the highest score.},
 address = {Osaka, Japan},
 author = {Eldesouki, Mohamed and Dalvi, Fahim and Sajjad, Hassan and Darwish, Kareem},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4828},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {221--226},
 publisher = {The COLING 2016 Organizing Committee},
 title = {QCRI $@$ DSL 2016: Spoken Arabic Dialect Identification Using Textual Features},
 year = {2016}
}

@inproceedings{W16-4829,
 abstract = {This paper describes an analysis of our submissions to the Dialect Detection
Shared Task 2016. We proposed three different systems that involved simplistic
features, to name: a Naive-bayes system, a Support Vector Machines-based system
and a Tree Kernel-based system. These systems underperform when compared to
other submissions in this shared task, since the best one achieved an accuracy
of $\sim$0.834.},
 address = {Osaka, Japan},
 author = {Franco-Penya, Hector-Hugo and Mamani Sanchez, Liliana},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4829},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {227--234},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Tuning Bayes Baseline for Dialect Detection},
 year = {2016}
}

@inproceedings{W16-4830,
 abstract = {In this paper we describe the submission of the UniBuc-NLP team for the
Discriminating between Similar Languages Shared Task, DSL 2016. We present and
analyze the results we obtained in the closed track of sub-task 1
(Similar languages and language varieties) and sub-task 2
(Arabic dialects). For sub-task 1 we used a logistic regression
classifier with tf-idf feature weighting and for sub-task 2 a character-based
string kernel with an SVM classifier. Our results show that good accuracy
scores can be obtained with limited feature and model engineering. While
certain limitations are to be acknowledged, our approach worked surprisingly
well for out-of-domain, social media data, with 0.898 accuracy (3rd place) for
dataset B1 and 0.838 accuracy (4th place) for dataset B2.},
 address = {Osaka, Japan},
 author = {Nisioi, Sergiu and Ciobanu, Alina Maria and Dinu, Liviu P.},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4830},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {235--242},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Vanilla Classifiers for Distinguishing between Similar Languages},
 year = {2016}
}

@inproceedings{W16-4831,
 abstract = {This paper describes our submission to the 2016 Discriminating Similar
Languages (DSL) Shared Task. We participated in the closed Sub-task 1 with two
separate machine learning techniques. The first approach is a character based
Convolution Neural Network with an LSTM layer (CLSTM), which achieved an
accuracy of 78.45\% with minimal tuning.  The second approach is a
character-based n-gram model of size 7. It achieved an accuracy of 88.45\%
which is close to the accuracy of 89.38\% achieved by the best submission.},
 address = {Osaka, Japan},
 author = {Cianflone, Andre and Kosseim, Leila},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4831},
 booktitle = {Proceedings of the Third Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial3)},
 month = {December},
 pages = {243--250},
 publisher = {The COLING 2016 Organizing Committee},
 title = {N-gram and Neural Language Models for Discriminating Similar Languages},
 year = {2016}
}

@inproceedings{W16-4901,
 abstract = {Learning functional expressions is one of the difficulties for language
learners, since functional expressions tend to have multiple meanings and
complicated usages in various situations. In this paper, we report an
experiment of simplifying example sentences of Japanese functional expressions
especially for Chinese-speaking learners. For this purpose, we developed
{\^a}Japanese Functional Expressions List{\^a} and {\^a}Simple Japanese Replacement
List{\^a}. To evaluate the method, we conduct a small-scale experiment with
Chinese-speaking learners on the
effectiveness of the simplified example sentences. The experimental results
indicate that simplified sentences are helpful in learning Japanese functional
expressions.},
 address = {Osaka, Japan},
 author = {Liu, Jun and Matsumoto, Yuji},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4901},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {1--5},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Simplification of Example Sentences for Learners of Japanese Functional Expressions},
 year = {2016}
}

@inproceedings{W16-4902,
 abstract = {In learning Asian languages, learners encounter the problem of character types
that are different from those in their first language, for instance, between
Chinese characters and the Latin alphabet. This problem also affects listening
because learners reconstruct letters from speech sounds. Hence, special
attention should be paid to listening practice for learners of Asian languages.
However, to our knowledge, few studies have evaluated the ease of listening
comprehension (listenability) in Asian languages. Therefore, as a pilot study
of listenability in Asian languages, we developed a measurement method for
learners of English in order to examine the discriminability of linguistic and
learner features. The results showed that the accuracy of our method
outperformed a simple majority vote, which suggests that a combination of
linguistic and learner features should be used to measure listenability in
Asian languages as well as in English.},
 address = {Osaka, Japan},
 author = {Kotani, Katsunori and Yoshimi, Takehiko},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4902},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {6--10},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Effectiveness of Linguistic and Learner Features to Listenability Measurement Using a Decision Tree Classifier},
 year = {2016}
}

@inproceedings{W16-4903,
 abstract = {We propose a new approach for extracting argument structure from natural
language texts that contain an underlying argument. Our approach comprises of
two phases: Score Assignment and Structure Prediction. The Score Assignment
phase trains models to classify relations between argument units (Support, Attack or Neutral). To that end, different training strategies have been
explored. We identify different linguistic and lexical features for training
the classifiers. Through ablation study, we observe that our novel use of
word-embedding features is most effective for this task. The Structure
Prediction phase makes use of the scores from the Score Assignment phase to
arrive at the optimal structure. We perform experiments on three argumentation
datasets, namely, AraucariaDB, Debatepedia and Wikipedia. We also propose two
baselines and observe that the proposed approach outperforms baseline systems
for the final task of Structure Prediction.},
 address = {Osaka, Japan},
 author = {Pathak, Arkanath and Goyal, Pawan and Bhowmick, Plaban},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4903},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {11--19},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Two-Phase Approach Towards Identifying Argument Structure in Natural Language},
 year = {2016}
}

@inproceedings{W16-4904,
 abstract = {We address the problem of automatic short answer grading, evaluating a
collection of approaches
inspired by recent advances in distributional text representations. In
addition, we propose an unsupervised
approach for determining text similarity using one-to-many alignment of word
vectors.
We evaluate the proposed technique across two datasets from different domains, namely, computer science and English reading comprehension, that additionally vary
between highschool
level and undergraduate students. Experiments demonstrate that the proposed
technique
often outperforms other compositional distributional semantics approaches as
well as vector
space methods such as latent semantic analysis. When combined with a scoring
scheme, the
proposed technique provides a powerful tool for tackling the complex problem of
short answer
grading. We also discuss a number of other key points worthy of consideration
in preparing
viable, easy-to-deploy automatic short-answer grading systems for the
real-world.},
 address = {Osaka, Japan},
 author = {Adams, Oliver and Roy, Shourya and Krishnapuram, Raghuram},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4904},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {20--29},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Distributed Vector Representations for Unsupervised Automatic Short Answer Grading},
 year = {2016}
}

@inproceedings{W16-4905,
 abstract = {Word embeddings are now ubiquitous forms of word representation in
natural language processing.  There have been applications of
word embeddings for monolingual word sense disambiguation (WSD) in English, but few comparisons have been done.  This paper attempts to bridge
that gap by examining popular embeddings for the task of monolingual
English WSD.  Our simplified method leads to comparable
state-of-the-art performance without expensive retraining.
Cross-Lingual WSD -- where the word senses of a word in a source
language come from a separate target translation language --
can also assist in language learning; for example, when providing
translations of target vocabulary for learners.  Thus we have also
applied word embeddings to the novel task of cross-lingual WSD for
Chinese and provide a public dataset for further benchmarking.
We have also experimented with using word embeddings for LSTM networks
and found surprisingly that a basic LSTM network does not work well.
We discuss the ramifications of this outcome.},
 address = {Osaka, Japan},
 author = {Kang, Hong Jin and Chen, Tao and Chandrasekaran, Muthu Kumar and Kan, Min-Yen},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4905},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {30--39},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Comparison of Word Embeddings for English and Cross-Lingual Chinese Word Sense Disambiguation},
 year = {2016}
}

@inproceedings{W16-4906,
 abstract = {This paper presents the NLP-TEA 2016 shared task for Chinese grammatical error
diagnosis which seeks to identify grammatical error types and their range of
occurrence within sentences written by learners of Chinese as foreign language.
We describe the task definition, data preparation, performance metrics, and
evaluation results. Of the 15 teams registered for this shared task, 9 teams
developed the system and submitted a total of 36 runs. We expected this
evaluation campaign could lead to the development of more advanced NLP
techniques for educational applications, especially for Chinese error
detection. All data sets with gold standards and scoring scripts are made
publicly available to researchers.},
 address = {Osaka, Japan},
 author = {Lee, Lung-Hao and RAO, Gaoqi and Yu, Liang-Chih and XUN, Endong and Zhang, Baolin and Chang, Li-Ping},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4906},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {40--48},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Overview of NLP-TEA 2016 Shared Task for Chinese Grammatical Error Diagnosis},
 year = {2016}
}

@inproceedings{W16-4907,
 abstract = {Grammatical error diagnosis is an important task in natural language
processing. This paper introduces our Chinese Grammatical Error Diagnosis
(CGED) system in the NLP-TEA-3 shared task for CGED. The CGED system can
diagnose four types of grammatical errors which are redundant words (R), missing words (M), bad word selection (S) and disordered words (W). We treat
the CGED task as a sequence labeling task and describe three models, including
a CRF-based model, an LSTM-based model and an ensemble model using stacking. We
also show in details how we build and train the models. Evaluation includes
three levels, which are detection level, identification level and position
level. On the CGED-HSK dataset of NLP-TEA-3 shared task, our system presents
the best F1-scores in all the three levels and also the best recall in the last
two levels.},
 address = {Osaka, Japan},
 author = {Zheng, Bo and Che, Wanxiang and Guo, Jiang and Liu, Ting},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4907},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {49--56},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Chinese Grammatical Error Diagnosis with Long Short-Term Memory Networks},
 year = {2016}
}

@inproceedings{W16-4908,
 abstract = {In the process of learning and using Chinese, foreigners may have grammatical
errors due to negative migration of their native languages. Currently, the
computer-oriented automatic detection method of grammatical errors is not
mature enough. Based on the evaluating task ----CGED2016, we select and analyze
the classification model and design feature extraction method to obtain
grammatical errors in-cluding Mission(M), Disorder(W), Selection (S) and
Redundant (R) automatically. The experiment re-sults based on the dynamic
corpus of HSK show that the Chinese grammatical error automatic detection
method, which uses CRF as classification model and n-gram as feature extraction
method. It is simple and efficient whichplay a positive effect on the research
of Chinese grammatical error automatic detection and also a supporting and
guiding role in the teaching of Chinese as a foreign language.},
 address = {Osaka, Japan},
 author = {Liu, Yajun and Han, Yingjie and Zhuo, Liyan and Zan, Hongying},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4908},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {57--62},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Automatic Grammatical Error Detection for Chinese based on Conditional Random Field},
 year = {2016}
}

@inproceedings{W16-4909,
 abstract = {This paper describe the CYUT-III system on grammar error detection in the 2016
NLP-TEA Chinese Grammar Error Detection shared task CGED. In this task a system
has to detect four types of errors, in-cluding redundant word error, missing
word error, word selection error and word ordering error. Based on the
conditional random fields (CRF) model, our system is a linear tagger that can
detect the errors in learners{\^a} essays. Since the system performance depends
on the features heavily, in this paper, we are going to report how to integrate
the collocation feature into the CRF model. Our system presents the best
detection accuracy and Identification accuracy on the TOCFL dataset, which is
in traditional Chi-nese. The same system also works well on the simplified
Chinese HSK dataset.},
 address = {Osaka, Japan},
 author = {PO-LIN, CHEN and Wu, Shih-Hung and Chen, Liang-Pu and yang, ping-che},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4909},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {63--72},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CYUT-III System at Chinese Grammatical Error Diagnosis Task},
 year = {2016}
}

@inproceedings{W16-4910,
 abstract = {This paper discusses how to adapt two new word embedding features to build a
more efficient Chinese Grammatical Error Diagnosis (CGED) systems to assist
Chinese foreign learners (CFLs) in improving their written essays. The major
idea is to apply word order sensitive Word2Vec approaches including (1)
structured skip-gram and (2) continuous window (CWindow) models, because they
are more suitable for solving syntax-based problems. The proposed new features
were evaluated on the Test of Chinese as a Foreign Language (TOCFL) learner
database provided by NLP-TEA-3\&CGED shared task. Experimental results showed
that the new features did work better than the traditional word order
insensitive Word2Vec approaches. Moreover, according to the official evaluation
results, our system achieved the lowest (0.1362) false positive (FA) and the
highest precision rates in all three measurements.},
 address = {Osaka, Japan},
 author = {Chou, Wei-Chieh and Lin, Chin-Kui and Liao, Yuan-Fu and Wang, Yih-Ru},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4910},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {73--81},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Word Order Sensitive Embedding Features/Conditional Random Field-based Chinese Grammatical Error Detection},
 year = {2016}
}

@inproceedings{W16-4911,
 abstract = {We offer a fluctuation smoothing computational approach for unsupervised
automatic short answer
grading (ASAG) techniques in the educational ecosystem. A major drawback of the
existing
techniques is the significant effect that variations in model answers could
have on their
performances. The proposed fluctuation smoothing approach, based on classical
sequential pattern
mining, exploits lexical overlap in students{\^a} answers to any typical
question. We empirically
demonstrate using multiple datasets that the proposed approach improves the
overall performance
and significantly reduces (up to 63%) variation in performance (standard
deviation) of unsupervised
ASAG techniques. We bring in additional benchmarks such as (a) paraphrasing of
model
answers and (b) using answers by k top performing students as model answers, to
amplify the
benefits of the proposed approach.},
 address = {Osaka, Japan},
 author = {Roy, Shourya and Dandapat, Sandipan and Narahari, Y.},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4911},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {82--91},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Fluctuation Smoothing Approach for Unsupervised Automatic Short Answer Grading},
 year = {2016}
}

@inproceedings{W16-4912,
 abstract = {This paper introduces Japanese lexical simplification.

Japanese
lexical
simplification is the task of replacing difficult words in a given sentence to
produce a new sentence with simple words without changing the original meaning
of the sentence.  We purpose a method of supervised regression learning to
estimate difficulty ordering of words with statistical features obtained from
two types of Japanese corpora.                                            For the
similarity of
words, we use
a
Japanese
thesaurus and dependency-based word embeddings.  Evaluation of the proposed
method is performed by comparing the difficulty ordering of the words.},
 address = {Osaka, Japan},
 author = {Hading, Muhaimin and Matsumoto, Yuji and Sakamoto, Maki},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4912},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {92--96},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Japanese Lexical Simplification for Non-Native Speakers},
 year = {2016}
}

@inproceedings{W16-4913,
 abstract = {Due to the huge population that speaks Spanish and Chinese, these languages
occupy an important position in the language learning studies. Although there
are some automatic translation systems that benefit the learning of both
languages, there is enough space to create resources in order to help language
learners. As a quick and effective resource that can give large amount language
information, corpus-based learning is becoming more and more popular. In this
paper we enrich a Spanish-Chinese parallel corpus automatically with part
of-speech (POS) information and manually with discourse segmentation (following
the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988)). Two search
tools allow the Spanish-Chinese language learners to carry out different
queries based on tokens and lemmas. The parallel corpus and the research tools
are available to the academic community. We propose some examples to illustrate
how learners can use the corpus to learn Spanish and Chinese.},
 address = {Osaka, Japan},
 author = {Cao, Shuyuan and da Cunha, Iria and Iruskieta, Mikel},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4913},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {97--106},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Corpus-based Approach for Spanish-Chinese Language Learning},
 year = {2016}
}

@inproceedings{W16-4914,
 abstract = {We present a novel approach to Computer Assisted Language Learning (CALL), using deep syntactic parsers and semantic based machine translation (MT) in
diagnosing and providing explicit feedback on language learners{\^a} errors. We
are currently developing a proof of concept system showing how semantic-based
machine translation can, in conjunction with robust computational grammars, be
used to interact with students, better understand their language errors, and
help students correct their grammar through a series of useful feedback
messages and guided language drills. Ultimately, we aim to prove the viability
of a new integrated rule-based MT approach to disambiguate students{\^a} intended
meaning in a CALL system. This is a necessary step to provide accurate coaching
on how to correct ungrammatical input, and it will allow us to overcome a
current bottleneck in the  field {\^a} an exponential burst of ambiguity caused
by ambiguous lexical items (Flickinger, 2010). From the users{\^a} interaction
with the system, we will also produce a richly annotated Learner Corpus, annotated automatically with both syntactic and semantic information.},
 address = {Osaka, Japan},
 author = {Morgado da Costa, Lu\'{i}s and Bond, Francis and He, Xiaoling},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4914},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {107--116},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Syntactic Well-Formedness Diagnosis and Error-Based Coaching in Computer Assisted Language Learning using Machine Translation},
 year = {2016}
}

@inproceedings{W16-4915,
 abstract = {This paper describes a corpus of nearly 10K French-Chinese aligned segments, produced by post-editing machine translated computer science courseware. This
corpus was built from 2013 to 2016 within the PROJECT\_NAME project, by native
Chinese students. The quality, as judged by native speakers, is ad-equate for
understanding (far better than by reading only the original French) and for
getting better marks. This corpus is annotated at segment-level by a
self-assessed quality score. It has been directly used as supplemental training
data to build a statistical machine translation system dedicated to that
sublanguage, and can be used to extract the specific bilingual terminology. To
our knowledge, it is the first corpus of this kind to be released.},
 address = {Osaka, Japan},
 author = {Kalitvianski, Ruslan and Wang, Lingxiao and Bellynck, Val\'{e}rie and Boitet, Christian},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4915},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {117--121},
 publisher = {The COLING 2016 Organizing Committee},
 title = {An Aligned French-Chinese corpus of 10K segments from university educational material},
 year = {2016}
}

@inproceedings{W16-4916,
 abstract = {Much research in education has been done on the study of different language
teaching methods. However, there has been little investigation using
computational analysis to compare such methods in terms of readability or
complexity progression. In this paper, we make use of existing readability
scoring techniques and our own classifiers to analyze the textbooks used in two
very different teaching methods for English as a Second Language -- the
grammar-based and the communicative methods. Our analysis indicates that the
grammar-based curriculum shows a more coherent readability progression compared
to the communicative curriculum. This finding corroborates with the
expectations about the differences between these two methods and validates our
approach{\^a}s value in comparing different teaching methods quantitatively.},
 address = {Osaka, Japan},
 author = {Zalmout, Nasser and Saddiki, Hind and Habash, Nizar},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4916},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {122--130},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Analysis of Foreign Language Teaching Methods: An Automatic Readability Approach},
 year = {2016}
}

@inproceedings{W16-4917,
 abstract = {Grammatical error diagnosis is an essential part in a language-learning
tutoring system.  Based on the data sets of Chinese grammar error detection
tasks, we proposed a system which measures the likelihood of correction
candidates generated by deleting or inserting characters or words, moving
substrings to different positions, substituting prepositions with other
prepositions, or substituting words with their synonyms or similar strings.
Sentence likelihood is measured based on the frequencies of substrings from the
space-removed version of Google n-grams.  The evaluation on the training set
shows that Missing-related and Selection-related candidate generation methods
have promising performance.  Our final system achieved a precision of 30.28%
and a recall of 62.85% in the identification level evaluated on the test set.},
 address = {Osaka, Japan},
 author = {Chen, Shao-Heng and Tsai, Yu-Lin and Lin, Chuan-Jie},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4917},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {131--139},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Generating and Scoring Correction Candidates in Chinese Grammatical Error Diagnosis},
 year = {2016}
}

@inproceedings{W16-4918,
 abstract = {Mandarin is not simple language for foreigner. Even using Mandarin as the
mother tongue, they have to spend more time to learn when they were child. The
following issues are the reason why causes learning problem. First, the word is
envolved by Hieroglyphic. So a character can express meanings independently, but become a word has another semantic. Second, the Mandarin's grammars have
flexible rule and special usage. Therefore, the common grammatical errors can
classify to missing, redundant, selection and disorder. In this paper, we
proposed the structure of the Recurrent Neural Networks using Long Short-term
memory (RNN-LSTM). It can detect the error type from the foreign learner
writing. The features based on the word vector and part-of-speech vector. In
the test data found that our method in the detection level of recall better
than the others, even as high as 0.9755. That is because we give the
possibility of greater choice in detecting errors.},
 address = {Osaka, Japan},
 author = {Yeh, Jui-Feng and Hsu, Tsung-Wei and Yeh, Chan-Kun},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4918},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {140--147},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Grammatical Error Detection Based on Machine Learning for Mandarin as Second Language Learning},
 year = {2016}
}

@inproceedings{W16-4919,
 abstract = {Grammatical Error Diagnosis for Chinese has always been a challenge for both
foreign learners and NLP researchers, for the variousity of grammar and the
flexibility of expression. In this paper, we present a model based on
Bidirectional Long Short-Term Memory(Bi-LSTM) neural networks, which treats the
task as a sequence labeling problem, so as to detect Chinese grammatical
errors, to identify the error types and to locate the error positions. In the
corpora of this year's shared task, there can be multiple errors in a single
offset of a sentence, to address which, we simutaneously train three Bi-LSTM
models sharing word embeddings which label Missing, Redundant and Selection
errors respectively. We regard word ordering error as a special kind of word
selection error which is longer during training phase, and then separate them
by length during testing phase.
In NLP-TEA 3 shared task for Chinese Grammatical Error Diagnosis(CGED), Our
system achieved relatively high F1 for all the three levels in the traditional
Chinese track and for the detection level in the Simpified Chinese track.},
 address = {Osaka, Japan},
 author = {Huang, Shen and WANG, Houfeng},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4919},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {148--154},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Bi-LSTM Neural Networks for Chinese Grammatical Error Diagnosis},
 year = {2016}
}

@inproceedings{W16-4920,
 abstract = {Abstract
Automatic grammatical error detection for Chinese has been a big challenge for
NLP researchers. Due to the formal and strict grammar rules in Chinese, it is
hard for foreign students to master Chinese. A computer-assisted learning tool
which can automatically detect and correct Chinese grammatical errors is
necessary for those foreign students. Some of the previous works have sought to
identify Chinese grammatical errors using template- and learning-based methods.
In contrast, this study introduced convolutional neural network (CNN) and
long-short term memory (LSTM) for the shared task of Chinese Grammatical Error
Diagnosis (CGED). Different from traditional word-based embedding, single word
embedding was used as input of CNN and LSTM. The proposed single word embedding
can capture both semantic and syntactic information to detect those four type
grammatical error. In experimental evaluation, the recall and f1-score of our
submitted results Run1 of the TOCFL testing data ranked the fourth place in all
submissions in detection-level.},
 address = {Osaka, Japan},
 author = {Yang, Jinnan and Peng, Bo and Wang, Jin and Zhang, Jixian and Zhang, Xuejie},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-4920},
 booktitle = {Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA2016)},
 month = {December},
 pages = {155--161},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Chinese Grammatical Error Diagnosis Using Single Word Embedding},
 year = {2016}
}

@inproceedings{W16-5001,
 abstract = {Topic Models have been reported to be beneficial for aspect-based sentiment
analysis. This paper reports the first topic model for sarcasm detection, to
the best of our knowledge. Designed on the basis of the intuition that
sarcastic tweets are likely to have a mixture of words of both sentiments as
against tweets with literal sentiment (either positive or negative), our
hierarchical topic model discovers sarcasm-prevalent topics and topic-level
sentiment. Using a dataset of tweets labeled using hashtags, the model
estimates topic-level, and sentiment-level distributions. Our evaluation shows
that topics such as `work', `gun laws', `weather' are sarcasm-prevalent topics.
Our model is also able to discover the mixture of sentiment-bearing words that
exist in a text of a given sentiment-related label. Finally, we apply our model
to predict sarcasm in tweets. We outperform two prior work based on statistical
classifiers with specific features, by around 25%.},
 address = {Osaka, Japan},
 author = {Joshi, Aditya and Jain, Prayas and Bhattacharyya, Pushpak and Carman, Mark},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5001},
 booktitle = {Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM)},
 month = {December},
 pages = {1--10},
 publisher = {The COLING 2016 Organizing Committee},
 title = {{\^a}Who would have thought of that!{\^a}: A Hierarchical Topic Model for Extraction of Sarcasm-prevalent Topics and Sarcasm Detection},
 year = {2016}
}

@inproceedings{W16-5002,
 abstract = {In this paper, we aim at identifying uncertainty cues in Hungarian social media
texts. We present our machine learning based uncertainty detector which is
based on a rich features set including lexical, morphological, syntactic, semantic and discourse-based features, and we evaluate our system on a small
set of manually annotated social media texts. We also carry out cross-domain
and domain adaptation experiments using an annotated corpus of standard
Hungarian texts and show that domain differences significantly affect machine
learning. Furthermore, we argue that differences among uncertainty cue types
may also affect the efficiency of uncertainty detection.},
 address = {Osaka, Japan},
 author = {Vincze, Veronika},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5002},
 booktitle = {Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM)},
 month = {December},
 pages = {11--21},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Detecting Uncertainty Cues in Hungarian Social Media Texts},
 year = {2016}
}

@inproceedings{W16-5003,
 abstract = {There has been extensive work on detecting the level of committed belief
(also known as ``factuality'') that an author is expressing towards the
propositions in his or her utterances.  Previous work on English has
revealed that this can be done as a sequence tagging task.  In this
paper, we investigate the same task for Chinese and Spanish, two very
different languages from English and from each other.},
 address = {Osaka, Japan},
 author = {Colomer, Juan Pablo and Lai, Keyu and Rambow, Owen},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5003},
 booktitle = {Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM)},
 month = {December},
 pages = {22--30},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Detecting Level of Belief in Chinese and Spanish},
 year = {2016}
}

@inproceedings{W16-5004,
 abstract = {The utilization of social media material in journalistic workflows is
increasing, demanding automated methods for the identification of mis- and
disinformation. Since textual contradiction across social media posts can be a
signal of rumorousness, we seek to model how claims in Twitter posts are being
textually contradicted. We identify two different contexts in which
contradiction emerges: its broader form can be observed across independently
posted tweets and its more specific form in threaded conversations. We define
how the two scenarios differ in terms of central elements of argumentation:
claims and conversation structure. We design and evaluate models for the two
scenarios uniformly as 3-way Recognizing Textual Entailment tasks in order to
represent claims and conversation structure implicitly in a generic inference
model, while previous studies used explicit or no representation of these
properties. To address noisy text, our classifiers use simple similarity
features derived from the string and part-of-speech level. Corpus statistics
reveal distribution differences for these features in contradictory as opposed
to non-contradictory tweet relations, and the classifiers yield state of the
art performance.},
 address = {Osaka, Japan},
 author = {Lendvai, Piroska and Reichel, Uwe},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5004},
 booktitle = {Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM)},
 month = {December},
 pages = {31--40},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Contradiction Detection for Rumorous Claims},
 year = {2016}
}

@inproceedings{W16-5005,
 abstract = {Negation and modality are two important grammatical phenomena that have
attracted recent research attention as they can contribute to
extra-propositional meaning aspects, among with factuality, attribution, irony
and sarcasm. These aspects go beyond analysis such as semantic role labeling, and modeling them is important as a step towards a higher level of language
understanding, which is needed for practical applications such as sentiment
analysis. In this talk, I will go beyond English, and I will discuss how
negation and modality are expressed in other languages. I will also go beyond
sentiment analysis and I will present some challenges that the two phenomena
pose for machine translation (MT). In particular, I will demonstrate how
contemporary MT systems fail on them, and I will discuss some possible
solutions.},
 address = {Osaka, Japan},
 author = {Nakov, Preslav},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5005},
 booktitle = {Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM)},
 month = {December},
 pages = {41},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Negation and Modality in Machine Translation},
 year = {2016}
}

@inproceedings{W16-5006,
 abstract = {This paper presents the main sources of disagreement found during the
annotation of the Spanish SFU Review Corpus with negation (SFU ReviewSP -NEG).
Negation detection is a challenge in most of the task related to NLP, so the
availability of corpora annotated with this phenomenon is essential in order to
advance in tasks related to this area. A thorough analysis of the problems
found during the annotation could help in the study of this phenomenon.},
 address = {Osaka, Japan},
 author = {Jim\'{e}nez-Zafra, Salud Mar\'{i}a and Martin, Maite and Urena Lopez, L. Alfonso and Marti, Toni and Taul\'{e}, Mariona},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5006},
 booktitle = {Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM)},
 month = {December},
 pages = {42--48},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Problematic Cases in the Annotation of Negation in Spanish},
 year = {2016}
}

@inproceedings{W16-5007,
 abstract = {This paper discusses the need for a dictionary of affixal negations and regular
antonyms to facilitate their automatic detection in text. Without such a
dictionary, affixal negations are very difficult to detect. In addition, we
show that the set of affixal negations is not homogeneous, and that different
NLP tasks may require different subsets. A dictionary can store the subtypes of
affixal negations, making it possible to select a certain subset or to make
inferences on the basis of these subtypes. We take a first step towards
creating a negation dictionary by annotating all direct antonym pairs inWordNet
using an existing typology of affixal negations. By highlighting some of the
issues that were encountered in this annotation experiment, we hope to provide
some insights into the necessary steps of building a negation dictionary.},
 address = {Osaka, Japan},
 author = {van Son, Chantal and van Miltenburg, Emiel and Morante, Roser},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5007},
 booktitle = {Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM)},
 month = {December},
 pages = {49--56},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Building a Dictionary of Affixal Negations},
 year = {2016}
}

@inproceedings{W16-5101,
 abstract = {Methods based on deep learning approaches have recently achieved
state-of-the-art performance in a range of machine learning tasks and are
increasingly applied to natural language processing (NLP). Despite strong
results in various established NLP tasks involving general domain texts, there
is only limited work applying these models to biomedical NLP. In this paper, we
consider a Convolutional Neural Network (CNN) approach to biomedical text
classification. Evaluation using a recently introduced cancer domain dataset
involving the categorization of documents according to the well-established
hallmarks of cancer shows that a basic CNN model can achieve a level of
performance competitive with a Support Vector Machine (SVM) trained using
complex manually engineered features optimized to the task. We further show
that simple modifications to the CNN hyperparameters, initialization, and
training process allow the model to notably outperform the SVM, establishing a
new state of the art result at this task. We make all of the resources and
tools introduced in this study available under open licenses from
https://cambridgeltl.github.io/cancer-hallmark-cnn/ .},
 address = {Osaka, Japan},
 author = {Baker, Simon and Korhonen, Anna and Pyysalo, Sampo},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5101},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {1--9},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Cancer Hallmark Text Classification Using Convolutional Neural Networks},
 year = {2016}
}

@inproceedings{W16-5102,
 abstract = {End-to-end neural network models for named entity recognition (NER) have shown
to achieve effective performances on general domain datasets (e.g.\ newswire), without requiring additional hand-crafted features. However, in biomedical
domain, recent studies have shown that hand-engineered features (e.g.\
orthographic features) should be used to attain effective performance, due to
the complexity of biomedical terminology (e.g.\ the use of acronyms and complex
gene names). In this work, we propose a novel approach that allows a neural
network model based on a long short-term memory (LSTM) to automatically learn
orthographic features and incorporate them into a model for biomedical NER.
Importantly, our bi-directional LSTM model learns and leverages orthographic
features on an end-to-end basis. We evaluate our approach by comparing against
existing neural network models for NER using three well-established biomedical
datasets. Our experimental results show that the proposed approach consistently
outperforms these strong baselines across all of the three datasets.},
 address = {Osaka, Japan},
 author = {Limsopatham, Nut and Collier, Nigel},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5102},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {10--19},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Learning Orthographic Features in Bi-directional LSTM for Biomedical Named Entity Recognition},
 year = {2016}
}

@inproceedings{W16-5103,
 abstract = {This paper proposes several network construction methods for collections of
scarce scientific literature data. We define scarcity as lacking in value and
in volume. Instead of using the paper's metadata to construct several kinds of
scientific networks, we use the full texts of the articles and automatically
extract the entities needed to construct the networks. Specifically, we present
seven kinds of networks using the proposed construction methods: co-occurrence
networks for author, keyword, and biological entities, and citation networks
for author, keyword, biological, and topic entities. We show two case studies
that applies our proposed methods: CADASIL, a rare yet the most common form of
hereditary stroke disorder, and Metformin, the first-line medication to the
type 2 diabetes treatment. We apply our proposed method to four different
applications for evaluation: finding prolific authors, finding important
bio-entities, finding meaningful keywords, and discovering influential topics.
The results show that the co-occurrence and citation networks constructed using
the proposed method outperforms the traditional-based networks. We also compare
our proposed networks to traditional citation networks constructed using enough
data and infer that even with the same amount of enough data, our methods
perform comparably or better than the traditional methods.},
 address = {Osaka, Japan},
 author = {Amplayo, Reinald Kim and Song, Min},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5103},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {20--29},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Building Content-driven Entity Networks for Scarce Scientific Literature using Content Information},
 year = {2016}
}

@inproceedings{W16-5104,
 abstract = {We propose an approach for named entity recognition in medical data, using a
character-based
deep bidirectional recurrent neural network. Such models can learn features and
patterns based
on the character sequence, and are not limited to a fixed vocabulary. This
makes them very well
suited for the NER task in the medical domain. Our experimental evaluation
shows promising
results, with a 60% improvement in F 1 score over the baseline, and our system
generalizes well
between different datasets.},
 address = {Osaka, Japan},
 author = {Almgren, Simon and Pavlov, Sean and Mogren, Olof},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5104},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {30--39},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Named Entity Recognition in Swedish Health Records with Character-Based Deep Bidirectional LSTMs},
 year = {2016}
}

@inproceedings{W16-5105,
 abstract = {The increasing amount of biomedical information that is available for
researchers and clinicians makes it harder to quickly find the right
information. Automatic summarization of multiple texts can provide summaries
specific to the user{\^a}s information needs. In this paper we look into the use
named-entity recognition for graph-based summarization. We extend the LexRank
algorithm with information about named entities and present EntityRank, a
multi-document graph-based summarization algorithm that is solely based on
named entities. We evaluate our system on a datasets of 1009 human written
summaries provided by BioASQ and on 1974 gene summaries, fetched from the
Entrez Gene database. The results show that the addition of named-entity
information increases the performance of graph-based summarizers and that the
EntityRank significantly outperforms the other methods with regard to the ROUGE
measures.},
 address = {Osaka, Japan},
 author = {Schulze, Frederik and Neves, Mariana},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5105},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {40--49},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Entity-Supported Summarization of Biomedical Abstracts},
 year = {2016}
}

@inproceedings{W16-5106,
 abstract = {Electronic health records show great variability since the same concept is
often expressed with different terms,  either scientific  latin forms, common
or lay variants and even vernacular naming. Deep learning enables
distributional representation of  terms in a vector-space, and therefore, related terms tend to be close in the vector space. Accordingly, embedding
words through these vectors opens the way towards accounting for semantic
relatedness through classical algebraic operations.
In this work we propose a simple though efficient unsupervised characterization
of Adverse Drug Reactions (ADRs). This approach exploits the embedding
representation of the terms involved in candidate ADR events, that is, drug-disease entity pairs. In brief, the ADRs are represented as vectors that
link the drug  with the disease in their context through a recursive additive
model.
We discovered that a low-dimensional representation that makes use of the
modulus and argument of the embedded representation of the ADR event shows
correlation with the manually annotated class. Thus, it can be derived that
this characterization results in to be beneficial  for further classification
tasks as predictive features.},
 address = {Osaka, Japan},
 author = {P\'{e}rez, Alicia and Casillas, Arantza and Gojenola, Koldo},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5106},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {50--59},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Fully unsupervised low-dimensional representation of adverse drug reaction events through distributional semantics},
 year = {2016}
}

@inproceedings{W16-5107,
 abstract = {Very few datasets have been released for the evaluation of diagnosis coding
with the International Classification of Diseases, and only one so far in a
language other than English. This paper describes a large-scale dataset
prepared from French death certificates, and the problems which needed to be
solved to turn it into a dataset suitable for the application of machine
learning and natural language processing methods of ICD-10 coding. The dataset
includes the free-text statements written by medical doctors, the associated
meta-data, the human coder-assigned codes for each statement, as well as the
statement segments which supported the coder{\^a}s decision for each code. The
dataset comprises 93,694 death certificates totalling 276,103 statements and
377,677 ICD-10 code assignments (3,457 unique codes). It was made available for
an international automated coding shared task, which attracted five
participating teams. An extended version of the dataset will be used in a new
edition of the shared task.},
 address = {Osaka, Japan},
 author = {Lavergne, Thomas and Neveol, Aurelie and Robert, Aude and Grouin, Cyril and Rey, Gr\'{e}goire and Zweigenbaum, Pierre},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5107},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {60--69},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Dataset for ICD-10 Coding of Death Certificates: Creation and Usage},
 year = {2016}
}

@inproceedings{W16-5108,
 abstract = {The development of text mining techniques for biomedical research literature
has received increased attention in recent times. However, most of these
techniques focus on prose, while much important biomedical data reside in
tables. In this paper, we present a corpus created to serve as a gold standard
for the development and evaluation of techniques for the automatic extraction
of information from biomedical tables. We describe the guidelines used for
corpus annotation and the manner in which they were developed. The high
inter-annotator agreement achieved on the corpus, and the generic nature of our
annotation approach, suggest that the developed guidelines can serve as a
general framework for table annotation in biomedical and other scientific
domains. The annotated corpus and the guidelines are available at
http://www.csse.monash.edu.au/research/umnl/data/index.shtml.},
 address = {Osaka, Japan},
 author = {Shmanina, Tatyana and Zukerman, Ingrid and Cheam, Ai Lee and Bochynek, Thomas and Cavedon, Lawrence},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5108},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {70--79},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Corpus of Tables in Full-Text Biomedical Research Publications},
 year = {2016}
}

@inproceedings{W16-5109,
 abstract = {In some plain text documents, end-of-line marks may or may not mark the
boundary of a text unit (e.g., of a paragraph).  This vexing problem is likely
to impact subsequent natural language processing components, but is seldom
addressed in the literature.  We propose a method which uses no manual
annotation to classify whether end-of-lines must actually be seen as simple
spaces (soft line breaks) or as true text unit boundaries. This method, which
includes self-training and co-training steps based on token and line length
features, achieves 0.943 F-measure on a corpus of short e-books with controlled
format, F=0.904 on a random sample of 24 clinical texts with soft line breaks, and F=0.898 on a larger set of mixed clinical texts which may or may not
contain soft line breaks, a fairly high value for a method with no manual
annotation.},
 address = {Osaka, Japan},
 author = {Zweigenbaum, Pierre and Grouin, Cyril and Lavergne, Thomas},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5109},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {80--88},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Supervised classification of end-of-lines in clinical text with no manual annotation},
 year = {2016}
}

@inproceedings{W16-5110,
 abstract = {This paper describes a Natural language processing system developed for
automatic identification of explicit connectives, its sense and arguments.
Prior work has shown that the difference in usage of connectives across corpora
affects the cross domain connective identification task negatively. Hence the
development of domain specific discourse parser has become indispensable. Here, we present a corpus annotated with discourse relations on Medline abstracts.
Kappa score is calculated to check the annotation quality of our corpus. The
previous works on discourse analysis in bio-medical data have concentrated only
on the                          identification of connectives and hence we have
developed
an
end-end
parser for connective and argument identification using Conditional Random
Fields algorithm. The type and sub-type of the connective sense is also
identified. The results obtained are encouraging.},
 address = {Osaka, Japan},
 author = {Gopalan, Sindhuja and Lalitha Devi, Sobha},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5110},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {89--98},
 publisher = {The COLING 2016 Organizing Committee},
 title = {BioDCA Identifier: A System for Automatic Identification of Discourse Connective and Arguments from Biomedical Text},
 year = {2016}
}

@inproceedings{W16-5111,
 abstract = {Social media has emerged into a crucial resource for obtaining population-based
signals for various public health monitoring and surveillance tasks, such as
pharmacovigilance. There is an abundance of knowledge hidden within social
media data, and the volume is growing. Drug-related chatter on social media can
include user-generated information that can provide insights into public health
problems such as abuse, adverse reactions, long-term effects, and multi-drug
interactions. Our objective in this paper is to present to the biomedical
natural language processing, data science, and public health communities data
sets (annotated and unannotated), tools and resources that we have collected
and created from social media. The data we present was collected from Twitter
using the generic and brand names of drugs as keywords, along with their common
misspellings. Following the collection of the data, annotation guidelines were
created over several iterations, which detail important aspects of social media
data annotation and can be used by future researchers for developing similar
data sets. The annotation guidelines were followed to prepare data sets for
text classification, information extraction and normalization. In this paper, we discuss the preparation of these guidelines, outline the data sets prepared, and present an overview of our state-of-the-art systems for data collection, supervised classification, and information extraction. In addition to the
development of supervised systems for classification and extraction, we
developed and released unlabeled data and language models. We discuss the
potential uses of these language models in data mining and the large volumes of
unlabeled data from which they were generated. We believe that the summaries
and repositories we present here of our data, annotation guidelines, models, and tools will be beneficial to the research community as a single-point entry
for all these resources, and will promote further research in this area.},
 address = {Osaka, Japan},
 author = {Sarker, Abeed and Gonzalez, Graciela},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5111},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {99--107},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Data, tools and resources for mining social media drug chatter},
 year = {2016}
}

@inproceedings{W16-5112,
 abstract = {Electronic Health Records (EHRs) are increasingly available in modern health
care institutions either through the direct creation of electronic documents in
hospitals' health information systems, or through the digitization of
historical paper records. Each EHR creation method yields the need for
sophisticated text reuse detection tools in order to prepare the EHR
collections for efficient secondary use relying on Natural Language Processing
methods. Herein, we address the detection of two types of text reuse in French
EHRs: 1) the detection of updated versions of the same document and 2) the
detection of document duplicates that still bear surface differences due to OCR
or de-identification processing. We present a robust text reuse detection
method to automatically identify redundant document pairs in two French EHR
corpora that achieves an overall macro F-measure of 0.68 and 0.60, respectively
and correctly identifies all redundant document pairs of interest.},
 address = {Osaka, Japan},
 author = {D'hondt, Eva and Grouin, Cyril and Neveol, Aurelie and Stamatatos, Efstathios and Zweigenbaum, Pierre},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5112},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {108--114},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Detection of Text Reuse in French Medical Corpora},
 year = {2016}
}

@inproceedings{W16-5113,
 abstract = {An important subtask in clinical text mining tries to identify whether a
clinical finding is expressed as present, absent or unsure in a text. This work
presents a system for detecting mentions of clinical findings that are negated
or just speculated. The system has been applied to two different types of
German clinical texts: clinical notes and discharge summaries. Our approach is
built on top of NegEx, a well known algorithm for identifying non-factive
mentions of medical findings. In this work, we adjust a previous adaptation of
NegEx to German and evaluate the system on our data to detect negation and
speculation. The results are compared to a baseline algorithm and are analyzed
for both types of clinical documents. Our system achieves an F1-Score above 0.9
on both types of reports.},
 address = {Osaka, Japan},
 author = {Cotik, Viviana and Roller, Roland and Xu, Feiyu and Uszkoreit, Hans and Budde, Klemens and Schmidt, Danilo},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5113},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {115--124},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Negation Detection in Clinical Reports Written in German},
 year = {2016}
}

@inproceedings{W16-5114,
 abstract = {Effective knowledge resources are critical for developing successful clinical
decision support systems that alleviate the cognitive load on physicians in
patient care. In this paper, we describe two new methods for building a
knowledge resource of disease to medication associations. These methods use
fundamentally different content and are based on advanced natural language
processing and machine learning techniques. One method uses distributional
semantics on large medical text, and the other uses data mining on a large
number of patient records. The methods are evaluated using 25,379 unique
disease-medication pairs extracted from 100 de-identified longitudinal patient
records of a large multi-provider hospital system. We measured recall (R), precision (P), and F scores for positive and negative association prediction, along with coverage and accuracy. While individual methods performed well, a
combined stacked classifier achieved the best performance, indicating the
limitations and unique value of each resource and method. In predicting
positive associations, the stacked combination significantly outperformed the
baseline (a distant semi-supervised method on large medical text), achieving F
scores of 0.75 versus 0.55 on the pairs seen in the patient records, and F
scores of 0.69 and 0.35 on unique pairs.},
 address = {Osaka, Japan},
 author = {Dandala, Bharath and Devarakonda, Murthy and Bornea, Mihaela and Nielson, Christopher},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5114},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {125--133},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Scoring Disease-Medication Associations using Advanced NLP, Machine Learning, and Multiple Content Sources},
 year = {2016}
}

@inproceedings{W16-5115,
 abstract = {Author name disambiguation (AND) in publication and citation resources is a
well-known problem. Often, information about email address and other details in
the affiliation is missing. In cases where such information is not available, identifying the authorship of publications becomes very challenging.
Consequently, there have been attempts to resolve such cases by utilizing
external resources as references. However, such external resources are
heterogeneous and are not always reliable regarding the correctness of
information.  To solve the AND task, especially when information about an
author is not complete we suggest the use of new features such as journal
descriptors (JD) and semantic types (ST). The evaluation of different feature
models shows that their inclusion has an impact equivalent to that of other
important features such as email address. Using such features we show that our
system outperforms the state of the art.},
 address = {Osaka, Japan},
 author = {Vishnyakova, Dina and Rodriguez-Esteban, Raul and Ozol, Khan and Rinaldi, Fabio},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5115},
 booktitle = {Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM2016)},
 month = {December},
 pages = {134--142},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Author Name Disambiguation in MEDLINE Based on Journal Descriptors and Semantic Types},
 year = {2016}
}

@inproceedings{W16-5201,
 abstract = {We present Kathaa, an Open Source web-based Visual Programming Framework for
Natural Language Processing (NLP) Systems. Kathaa supports the design, execution and analysis of complex NLP systems by visually connecting NLP
components from an easily extensible Module Library. It models NLP systems an
edge-labeled Directed Acyclic MultiGraph, and lets the user use publicly
co-created modules in their own NLP applications irrespective of their
technical proficiency in Natural Language Processing. Kathaa exposes an
intuitive web based Interface for the users to interact with and modify complex
NLP Systems; and a precise Module definition API to allow easy integration of
new state of the art NLP components. Kathaa enables researchers to publish
their services in a standardized format to enable the masses to use their
services out of the box. The vision of this work is to pave the way for a
system like Kathaa, to be the Lego blocks of NLP Research and Applications. As
a practical use case we use Kathaa to visually implement the Sampark
Hindi-Panjabi Machine Translation Pipeline and the Sampark Hindi-Urdu Machine
Translation Pipeline, to demonstrate the fact that Kathaa can handle really
complex NLP systems while still being intuitive for the end user.},
 address = {Osaka, Japan},
 author = {Mohanty, Sharada and Wani, Nehal J and Srivastava, Manish and Sharma, Dipti},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5201},
 booktitle = {Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies (WLSI/OIAF4HLT2016)},
 month = {December},
 pages = {1--10},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Kathaa : NLP Systems as Edge-Labeled Directed Acyclic MultiGraphs},
 year = {2016}
}

@inproceedings{W16-5202,
 abstract = {The US National Science Foundation (NSF) SI2-funded LAPPS/Galaxy project has
developed an open-source platform for enabling complex analyses while hiding
complexities associated with underlying infrastructure, that can be accessed
through a web interface, deployed on any Unix system, or run from the cloud. It
provides sophisticated tool integration and history capabili- ties, a workflow
system for building automated multi-step analyses, state-of-the-art evaluation
capabilities, and facilities for sharing and publishing analyses. This paper
describes the current facilities available in LAPPS/Galaxy and outlines the
project{\^a}s ongoing activities to enhance the framework.},
 address = {Osaka, Japan},
 author = {Ide, Nancy and Suderman, Keith and Nyberg, Eric and Pustejovsky, James and Verhagen, Marc},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5202},
 booktitle = {Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies (WLSI/OIAF4HLT2016)},
 month = {December},
 pages = {11--18},
 publisher = {The COLING 2016 Organizing Committee},
 title = {LAPPS/Galaxy: Current State and Next Steps},
 year = {2016}
}

@inproceedings{W16-5203,
 abstract = {Most tools for natural language processing today are based on machine learning
and come with pre-trained models. In addition, third-parties provide
pre-trained models for popular NLP tools. The predictive power and accuracy of
these tools depends on the quality of these models. Downstream researchers
often base their results on pre-trained models instead of training their own.
Consequently, pre-trained models are an essential resource to our community.
However, to be best of our knowledge, no systematic study of pre-trained models
has been conducted so far.
This paper reports on the analysis of 274 pre-models for six NLP tools and four
potential causes of problems: encoding, tokenization, normalization and change
over time. The analysis is implemented in the open source tool Model
Investigator. Our work 1) allows model consumers to better assess whether a
model is suitable for their task, 2) enables tool and model creators to
sanity-check their models before distributing them, and 3) enables improvements
in tool interoperability by performing automatic adjustments of normalization
or other pre-processing based on the models used.},
 address = {Osaka, Japan},
 author = {Eckart de Castilho, Richard},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5203},
 booktitle = {Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies (WLSI/OIAF4HLT2016)},
 month = {December},
 pages = {19--27},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Automatic Analysis of Flaws in Pre-Trained NLP Models},
 year = {2016}
}

@inproceedings{W16-5204,
 abstract = {In this research, we introduce and implement a method that combines human
inputters and machine translators. When the languages of the participants vary
widely, the cost of simultaneous translation becomes very high. However, the
results of simply applying machine translation to speech text do not have the
quality that is needed for real use.
Thus, we propose a method that people who understand the language of the
speaker cooperate with a machine translation service in support of
multilingualization by the co-creation of value.
We implement a system with this method and apply it to actual presentations.
While the quality of direct machine translations is 1.84 (fluency) and 2.89
(adequacy), the system has corresponding values of 3.76 and 3.85.},
 address = {Osaka, Japan},
 author = {Nakaguchi, Takao and Otani, Masayuki and Takasaki, Toshiyuki and Ishida, Toru},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5204},
 booktitle = {Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies (WLSI/OIAF4HLT2016)},
 month = {December},
 pages = {28--35},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Combining Human Inputters and Language Services to provide Multi-language support system for International Symposiums},
 year = {2016}
}

@inproceedings{W16-5205,
 abstract = {Complaint classification aims at using information to deliver greater insights
to enhance user experience after purchasing the products or services.
Categorized information can help us quickly collect emerging problems in order
to provide a support needed. Indeed, the response to the complaint without the
delay will grant users highest satisfaction. In this paper, we aim to deliver a
novel approach which can clarify the complaints precisely with the aim to
classify each complaint into nine predefined classes i.e. acces-sibility, company brand, competitors, facilities, process, product feature, staff
quality, timing respec-tively and others. Given the idea that one word usually
conveys ambiguity and it has to be interpreted by its context, the word
embedding technique is used to provide word features while applying deep
learning techniques for classifying a type of complaints. The dataset we use
contains 8,439 complaints of one company.},
 address = {Osaka, Japan},
 author = {assawinjaipetch, panuwat and Shirai, Kiyoaki and Sornlertlamvanich, Virach and Marukata, Sanparith},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5205},
 booktitle = {Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies (WLSI/OIAF4HLT2016)},
 month = {December},
 pages = {36--43},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Recurrent Neural Network with Word Embedding for Complaint Classification},
 year = {2016}
}

@inproceedings{W16-5206,
 abstract = {The Universal Dependencies (UD) Project seeks to build a cross-lingual studies
of treebanks, linguistic structures and parsing. Its goal is to create a set of
multilingual harmonized treebanks that are designed according to a universal
annotation scheme. In this paper, we report on the conversion of the Uyghur
dependency treebank to a UD version of the treebank which we term the Uyghur
Universal Dependency Treebank (UyDT). We present the mapping of the Uyghur
dependency treebank{\^a}s labelling scheme to the UD scheme, along with a clear
description of the structural changes required in this conversion.},
 address = {Osaka, Japan},
 author = {eli, marhaba and Mushajiang, Weinila and Yibulayin, Tuergen and Abiderexiti, Kahaerjiang and Liu, Yan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5206},
 booktitle = {Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies (WLSI/OIAF4HLT2016)},
 month = {December},
 pages = {44--50},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Universal dependencies for Uyghur},
 year = {2016}
}

@inproceedings{W16-5207,
 abstract = {In this paper we describe a non-expert setup for Vietnamese speech recognition
system using Kaldi toolkit. We collected a speech corpus over fifteen hours
from about fifty Vietnamese native speakers and using it to test the
feasibility
of our setup. The essential linguistic components for the Automatic Speech
Recognition (ASR) system was prepared basing on the written form of the
language instead of expertise knowledge on linguistic and phonology as commonly
seen in rich resource languages like English. The modeling of tones by
integrating them into the phoneme and using the phonetic decision tree is also
discussed. Experimental results showed this setup for ASR systems does yield
competitive results while still have potentials for further improvements.},
 address = {Osaka, Japan},
 author = {Luong, Hieu-Thi and Vu, Hai-Quan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5207},
 booktitle = {Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies (WLSI/OIAF4HLT2016)},
 month = {December},
 pages = {51--55},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A non-expert Kaldi recipe for Vietnamese Speech Recognition System},
 year = {2016}
}

@inproceedings{W16-5208,
 abstract = {Annotated corpora are crucial language resources, and pre-annotation is an
usual way to reduce the cost of corpus construction. Ensemble based
pre-annotation approach combines multiple existing named entity taggers and
categorizes annotations into normal annotations with high confidence and
candidate annotations with low confidence, to reduce the human annotation time.
In this paper, we manually annotate three English datasets under various
pre-annotation conditions, report the effects of ensemble based pre-annotation, and analyze the experimental results. In order to verify the effectiveness of
ensemble based pre-annotation in other languages, such as Chinese, three
Chinese datasets are also tested. The experimental results show that the
ensemble based pre-annotation approach significantly reduces the number of
annotations which human annotators have to add, and outperforms the baseline
approaches in reduction of human annotation time without loss in annotation
performance (in terms of F1-measure), on both English and Chinese datasets.},
 address = {Osaka, Japan},
 author = {Lu, Tingming and Zhu, Man and Gao, Zhiqiang and Gui, Yaocheng},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5208},
 booktitle = {Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies (WLSI/OIAF4HLT2016)},
 month = {December},
 pages = {56--60},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Evaluating Ensemble Based Pre-annotation on Named Entity Corpus Construction in English and Chinese},
 year = {2016}
}

@inproceedings{W16-5209,
 abstract = {Fragmentation and recombination is a key to create customized language
environments for supporting various intercultural activities. Fragmentation
provides various language resource components for the customized language
environments and recombination builds each language environment according to
user's request by combining these components. To realize this fragmentation and
recombination process, existing language resources (both data and programs)
should be shared as language services and combined beyond mismatch of their
service interfaces. To address this issue, standardization is inevitable:
standardized interfaces are necessary for language services as well as data
format required for language resources. Therefore, we have constructed a
hierarchy of language services based on inheritance of service interfaces, which is called language service ontology. This ontology allows users to create
a new customized language service that is compatible with existing ones.
Moreover, we have developed a dynamic service binding technology that
instantiates various executable customized services from an abstract workflow
according to user's request. By using the ontology and service binding
together, users can bind the instantiated language service to another abstract
workflow for a new customized one.},
 address = {Osaka, Japan},
 author = {Murakami, Yohei and Nakaguchi, Takao and Lin, Donghui and Ishida, Toru},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5209},
 booktitle = {Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies (WLSI/OIAF4HLT2016)},
 month = {December},
 pages = {61--69},
 publisher = {The COLING 2016 Organizing Committee},
 title = {An Ontology for Language Service Composability},
 year = {2016}
}

@inproceedings{W16-5210,
 abstract = {Different types of users require different functions in NLP software. It is
difficult for a single platform to cover all types of users. When a framework
aims to provide more interoperability, users are required to learn more
concepts; users' application designs are restricted to be compliant with the
framework. While an interoperability framework is useful in certain cases, some
types of users will not select the framework due to the learning cost and
design restrictions. We suggest a rather simple framework for the
interoperability aiming at developers. Reusing an existing NLP platform
Kachako, we created an API
oriented NLP system. This system loosely couples rich high-end functions, including annotation visualizations, statistical evaluations, an-notation
searching, etc. This API do not require users much learning cost, providing
customization ability for power users while also allowing easy users to employ
many GUI functions.},
 address = {Osaka, Japan},
 author = {Kano, Yoshinobu},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5210},
 booktitle = {Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies (WLSI/OIAF4HLT2016)},
 month = {December},
 pages = {70--75},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Between Platform and APIs: Kachako API for Developers},
 year = {2016}
}

@inproceedings{W16-5301,
 abstract = {Distributional Semantic Models (DSMs) have recently received increased
attention, together with the rise of neural architectures for scalable training
of dense vector embeddings. While some of the literature even includes terms
like 'vectors' and 'dimensionality' in the definition of DSMs, there are some
good reasons why we should consider alternative formulations of distributional
models. As an instance, I present a scalable graph-based solution to
distributional semantics. The model belongs to the family of 'count-based'
DSMs, keeps its representation sparse and explicit, and thus fully
interpretable.
I will highlight some important differences between sparse graph-based and
dense vector approaches to DSMs: while dense vector-based models are
computationally easier to handle and provide a nice uniform representation that
can be compared and combined in many ways, they lack interpretability, provenance and robustness. On the other hand, graph-based sparse models have a
more straightforward interpretation, handle sense distinctions more naturally
and can straightforwardly be linked to knowledge bases, while lacking the
ability to compare arbitrary lexical units and a compositionality operation.
Since both representations have their merits, I opt for exploring their
combination in the outlook.},
 address = {Osaka, Japan},
 author = {Biemann, Chris},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5301},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {1--7},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Vectors or Graphs? On Differences of Representations for Distributional Semantic Models},
 year = {2016}
}

@inproceedings{W16-5302,
 abstract = {Notwithstanding the success of the notion of construction, the computational
tradition still lacks a way to represent the semantic content of these
linguistic entities. Here we present a simple corpus-based model implementing
the idea that the meaning of a syntactic construction is intimately related to
the semantics of its typical verbs. It is a two-step process, that starts by
identifying the typical verbs occurring with a given syntactic construction and
building their distributional vectors. We then calculated the weighted centroid
of these vectors in order to derive the distributional signature of a
construction. In order to assess the goodness of our approach, we replicated
the priming effect described by Johnson and Golberg (2013) as a function of the
semantic distance between a construction and its prototypical verbs. Additional
support for our view comes from a regression analysis showing that our
distributional information can be used to model behavioral data collected with
a crowdsourced elicitation experiment.},
 address = {Osaka, Japan},
 author = {Lebani, Gianluca and Lenci, Alessandro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5302},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {8--18},
 publisher = {The COLING 2016 Organizing Committee},
 title = {"Beware the Jabberwock, dear reader!" Testing the distributional reality of construction semantics},
 year = {2016}
}

@inproceedings{W16-5303,
 abstract = {Regular polysemy was extensively investigated in lexical semantics, but this
phenomenon has been very little studied in distributional semantics. We propose
a model for regular polysemy detection that is based on sense vectors and
allows to work directly with senses in semantic vector space. Our method is
able to detect polysemous words that have the same regular sense alternation as
in a given example (a word with two automatically induced senses that represent
one polysemy pattern, such as ANIMAL / FOOD). The method works equally well for
nouns, verbs and adjectives and achieves average recall of 0.55 and average
precision of 0.59 for ten different polysemy patterns.},
 address = {Osaka, Japan},
 author = {Lopukhina, Anastasiya and Lopukhin, Konstantin},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5303},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {19--23},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Regular polysemy: from sense vectors to sense patterns},
 year = {2016}
}

@inproceedings{W16-5304,
 abstract = {Recognizing various semantic relations between terms is beneficial for many NLP
tasks. While path-based and distributional information sources are considered
complementary for this task, the superior results the latter showed recently
suggested that the former{\^a}s contribution might have become obsolete. We
follow the recent success of an integrated neural method for hypernymy
detection (Shwartz et al., 2016) and extend it to recognize multiple relations.
The empirical results show that this method is effective in the multiclass
setting as well. We further show that the path-based information source always
contributes to the classification, and analyze the cases in which it mostly
complements the distributional information.},
 address = {Osaka, Japan},
 author = {Shwartz, Vered and Dagan, Ido},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5304},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {24--29},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Path-based vs. Distributional Information in Recognizing Lexical Semantic Relations},
 year = {2016}
}

@inproceedings{W16-5305,
 abstract = {The identification of semantic relations between terms within texts is a
fundamental task in Natural Language Processing which can support applications
requiring a lightweight semantic interpretation model. Currently, semantic
relation classification concentrates on relations which are evaluated over
open-domain data. This work provides a critique on the set of abstract
relations
used for semantic relation classification with regard to their ability to
express relationships between terms which are found in a domain-specific
corpora. Based on this analysis, this work proposes an alternative semantic
relation model based on reusing and extending the set of abstract relations
present in the DOLCE ontology. The resulting set of relations is well grounded, allows to capture a wide range of relations and could thus be used as a
foundation for automatic
classification of semantic relations.},
 address = {Osaka, Japan},
 author = {Santos, Vivian and Huerliman, Manuela and Davis, Brian and Handschuh, Siegfried and Freitas, Andr\'{e}},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5305},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {30--39},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Semantic Relation Classification: Task Formalisation and Refinement},
 year = {2016}
}

@inproceedings{W16-5306,
 abstract = {The interaction between roots and patterns in Arabic has intrigued
lexicographers and morphologists for centuries. While roots provide the
consonantal building blocks, patterns provide the syllabic vocalic moulds.
While roots provide abstract semantic classes, patterns realize these classes
in specific instances. In this way both roots and patterns are indispensable
for understanding the derivational, morphological and, to some extent, the
cognitive aspects of the Arabic language. In this paper we perform
lemmatization (a high-level lexical processing) without relying on a lookup
dictionary. We use a hybrid approach that consists of a machine learning
classifier to predict the lemma pattern for a given stem, and mapping rules to
convert stems to their respective lemmas with the vocalization defined by the
pattern.},
 address = {Osaka, Japan},
 author = {Attia, Mohammed and Zirikly, Ayah and Diab, Mona},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5306},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {40--50},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The Power of Language Music: Arabic Lemmatization through Patterns},
 year = {2016}
}

@inproceedings{W16-5307,
 abstract = {In this paper we present a clean, yet effective, model for word sense
disambiguation.
Our approach leverage a bidirectional long short-term memory network which is
shared between all words. This enables the model to share statistical strength
and to scale well with vocabulary size.
The model is trained end-to-end, directly from the raw text to sense labels, and makes effective use of word order.
We evaluate our approach on two standard datasets, using identical
hyperparameter settings, which are in turn tuned on a third set of held out
data.
We employ no external resources (e.g. knowledge graphs, part-of-speech tagging, etc), language specific features, or hand crafted rules, but still achieve
statistically equivalent results to the best state-of-the-art systems, that
employ no such limitations.},
 address = {Osaka, Japan},
 author = {K\r{a}geb\"{a}ck, Mikael and Salomonsson, Hans},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5307},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {51--56},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Word Sense Disambiguation using a Bidirectional LSTM},
 year = {2016}
}

@inproceedings{W16-5308,
 abstract = {Language production is largely a matter of words which, in the case of access
problems, can be searched for in an external resource (lexicon, thesaurus). In
this kind of dialogue the user provides the momentarily available knowledge
concerning the target and the system responds with the best guess(es) it can
make given this input.
As tip-of-the-tongue (ToT)-studies have shown, people always have some
knowledge concerning the target (meaning fragments, number of syllables, ...)
even if its complete form is eluding them. We will show here how to tap on this
knowledge to build a resource likely to help authors (speakers/writers) to
overcome the ToT-problem.
Yet, before doing so we need a better understanding of the various kinds of
knowledge people have when looking for a word. To this end, we asked
crowdworkers to provide some cues to describe a given target and to specify
then how each one of them relates to the target, in the hope that this could
help others to find the elusive word. Next, we checked how well a given search
strategy worked when being applied to differently built lexical networks. The
results showed quite dramatic differences, which is not really surprising.
After all, different networks are built for different purposes; hence each one
of them is more or less suited for a given task. What was more surprising
though is the fact that the relational information given by the users did not
allow us to find the elusive word in WordNet better than without it.},
 address = {Osaka, Japan},
 author = {Zock, Michael and Biemann, Chris},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5308},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {57--68},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Towards a resource based on users' knowledge to overcome the Tip of the Tongue problem.},
 year = {2016}
}

@inproceedings{W16-5309,
 abstract = {The shared task of the 5th Workshop on Cognitive Aspects of the Lexicon
(CogALex-V) aims at providing a common benchmark for testing current
corpus-based methods for the identification of lexical semantic relations
(synonymy, antonymy, hypernymy, part-whole meronymy) and at gaining a better
understanding of their respective strengths and weaknesses. The shared task
uses a challenging dataset extracted from EVALution 1.0, which contains word
pairs holding the above-mentioned relations as well as semantically unrelated
control items (random). The task is split into two subtasks: (i) identification
of related word pairs vs. unrelated ones; (ii) classification of the word pairs
according to their semantic relation. This paper describes the subtasks, the
dataset, the evaluation metrics, the seven participating systems and their
results. The best performing system in subtask 1 is GHHH (F1 = 0.790), while
the best system in subtask 2 is LexNet (F1 = 0.445). The dataset and the task
description are available at
https://sites.google.com/site/cogalex2016/home/shared-task.},
 address = {Osaka, Japan},
 author = {Santus, Enrico and Gladkova, Anna and Evert, Stefan and Lenci, Alessandro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5309},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {69--79},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The CogALex-V Shared Task on the Corpus-Based Identification of Semantic Relations},
 year = {2016}
}

@inproceedings{W16-5310,
 abstract = {We present a submission to the CogALex 2016 shared task on the corpus-based
identification of semantic relations, using LexNET (Shwartz and Dagan, 2016), an integrated path-based and distributional method for semantic relation
classification.
The reported results in the shared task bring this submission to the third
place on subtask 1 (word relatedness), and the first place on subtask 2
(semantic relation classification), demonstrating the utility of integrating
the complementary path-based and distributional information sources in
recognizing concrete semantic relations.
Combined with a common similarity measure, LexNET performs fairly good on the
word relatedness task (subtask 1).
The relatively low performance of LexNET and all other systems on subtask 2, however, confirms the difficulty of the semantic relation classification task, and stresses the need to develop additional methods for this task.},
 address = {Osaka, Japan},
 author = {Shwartz, Vered and Dagan, Ido},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5310},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {80--85},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CogALex-V Shared Task: LexNET - Integrated Path-based and Distributional Method for the Identification of Semantic Relations},
 year = {2016}
}

@inproceedings{W16-5311,
 abstract = {This paper describes our system submission to the CogALex-2016 Shared Task on
Corpus-Based Identification of Semantic Relations. Our system won first place
for Task-1 and second place for Task-2. The evaluation results of our system on
the test set is 88.1% (79.0% for TRUE only) f-measure for Task-1 on detecting
semantic similarity, and 76.0% (42.3% when excluding RANDOM) for Task-2 on
identifying finer-grained semantic relations. In our experiments, we try word
analogy, linear regression, and multi-task Convolutional Neural Networks (CNNs)
with word embeddings from publicly available word vectors. We found that linear
regression performs better in the binary classification (Task-1), while CNNs
have better performance in the multi-class semantic classification (Task-2).
We assume that word analogy is more suited for deterministic answers rather
than handling the ambiguity of one-to-many and many-to-many relationships. We
also show that classifier performance could benefit from balancing the
distribution of labels in the training data.},
 address = {Osaka, Japan},
 author = {Attia, Mohammed and Maharjan, Suraj and Samih, Younes and Kallmeyer, Laura and Solorio, Thamar},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5311},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {86--91},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CogALex-V Shared Task: GHHH - Detecting Semantic Relations via Word Embeddings},
 year = {2016}
}

@inproceedings{W16-5312,
 abstract = {This contribution provides a strong baseline result for the CogALex-V shared
task using a traditional ``count''-type DSM (placed in rank 2 out of 7 in
subtask 1 and rank 3 out of 6 in subtask 2).  Parameter tuning experiments
reveal some surprising effects and suggest that the use of random word pairs as
negative examples may be problematic, guiding the parameter optimization in an
undesirable direction.},
 address = {Osaka, Japan},
 author = {Evert, Stefan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5312},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {92--97},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CogALex-V Shared Task: Mach5 -- A traditional DSM approach to semantic relatedness},
 year = {2016}
}

@inproceedings{W16-5313,
 abstract = {In this paper, we describe ROOT 18, a classifier using the scores of several
unsupervised distributional measures as features to discriminate between
semantically related and unrelated words, and then to classify the related
pairs according to their semantic relation (i.e. synonymy, antonymy, hypernymy, part-whole meronymy). Our classifier participated in the CogALex-V Shared Task, showing a solid performance on the first subtask, but a poor performance on the
second subtask. The low scores reported on the second subtask suggest that
distributional measures are not sufficient to discriminate between multiple
semantic relations at once.},
 address = {Osaka, Japan},
 author = {Chersoni, Emmanuele and Rambelli, Giulia and Santus, Enrico},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5313},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {98--103},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CogALex-V Shared Task: ROOT18},
 year = {2016}
}

@inproceedings{W16-5314,
 abstract = {In this paper, we describe a system (CGSRC) for classifying four semantic
relations: synonym, hypernym, antonym and meronym using convolutional neural
networks (CNN). We have participated in CogALex-V semantic shared task of
corpus-based identification of semantic relations. Proposed approach using
CNN-based deep neural networks leveraging pre-compiled word2vec distributional
neural embeddings achieved 43.15\% weighted-F1 accuracy on subtask-1 (checking
existence of a relation between two terms) and 25.24\% weighted-F1 accuracy on
subtask-2 (classifying relation types).},
 address = {Osaka, Japan},
 author = {Guggilla, Chinnappa},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5314},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {104--109},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CogALex-V Shared Task: CGSRC - Classifying Semantic Relations using Convolutional Neural Networks},
 year = {2016}
}

@inproceedings{W16-5315,
 abstract = {Automatic discovery of semantically-related words is one of the most important
NLP tasks, and has great impact on the theoretical psycholinguistic modeling of
the mental lexicon. In this shared task, we employ the word embeddings model to
testify two thoughts explicitly or implicitly assumed by the NLP community:
(1). Word embedding models can reflect syntagmatic similarities in usage
between words to distances in projected vector space. (2). Word embedding
models can reflect paradigmatic relationships between words.},
 address = {Osaka, Japan},
 author = {Luce, Kanan and Yu, Jiaxing and HSIEH, Shu-Kai},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5315},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {110--113},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CogALex-V Shared Task: LOPE},
 year = {2016}
}

@inproceedings{W16-5316,
 abstract = {The CogALex-V Shared Task provides two datasets  that consists of pairs of
words along with a classification of their semantic relation. The dataset for
the first task distinguishes only between related and unrelated, while the
second data set distinguishes several types of semantic relations. A number of
recent papers propose to construct a feature vector that represents a pair of
words by applying a pairwise simple operation to all elements of the feature
vector. Subsequently, the pairs can be classified by training any
classification algorithm on these vectors. In the present paper we apply this
method to the provided datasets. We see that the results are not better than
from the given simple baseline. We conclude that the results of the
investigated method are strongly depended on the type of data to which it is
applied.},
 address = {Osaka, Japan},
 author = {Wartena, Christian and Aga, Rosa Tsegaye},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5316},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {114--118},
 publisher = {The COLING 2016 Organizing Committee},
 title = {CogALex-V Shared Task: HsH-Supervised -- Supervised similarity learning using entry wise product of context vectors},
 year = {2016}
}

@inproceedings{W16-5317,
 abstract = {This paper deals with a seldom studied object/oblique alternation phenomenon in
Japanese, which. We call this the bump alternation. This phenomenon, first
discussed by Sadanobu (1990), is similar to the English with/against
alternation. For example, compare hit the wall with the bat
[=immobile-as-direct-object frame] to hit the bat against the wall
[=mobile-as-direct-object frame]). However, in the Japanese version, the case
frame remains constant. Although we fundamentally question Sadanobu{\^a}s
acceptability judgment, we also claim that the causation type (i.e., whether
the event is an instance of onset or extended causation; Talmy, 1988; 2000)
could make an improvement. An extended causative interpretation could improve
the acceptability of the otherwise awkward immobile-as-direct-object frame. We
examined this claim through a rating study, and the results showed an
interaction between the Causation type (extended/onset) and the Object type
(mobile/immobile) in the direction we predicted. We propose that a perspective
shift on what is moving causes the {\^a}extended causation{\^a} advantage.},
 address = {Osaka, Japan},
 author = {Aoki, Natsuno and Nakatani, Kentaro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5317},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {119--124},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Study of the Bump Alternation in Japanese from the Perspective of Extended/Onset Causation},
 year = {2016}
}

@inproceedings{W16-5318,
 abstract = {German particle verbs represent a frequent type of multi-word-expression that
forms a highly productive paradigm in the lexicon. Similarly to other
multi-word expressions, particle verbs exhibit various levels of
compositionality. One of the major obstacles for the study of compositionality
is the lack of representative gold standards of human ratings. In order to
address this bottleneck, this paper presents such a gold standard data set
containing 400 randomly selected German particle verbs. It is balanced across
several particle types and three frequency bands, and accomplished by human
ratings on the degree of semantic compositionality.},
 address = {Osaka, Japan},
 author = {Bott, Stefan and Khvtisavrishvili, Nana and Kisselew, Max and Schulte im Walde, Sabine},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5318},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {125--133},
 publisher = {The COLING 2016 Organizing Committee},
 title = {GhoSt-PV: A Representative Gold Standard of German Particle Verbs},
 year = {2016}
}

@inproceedings{W16-5319,
 abstract = {This paper presents a method to discover possible terminological relationships
from tweets. We match the histories of terms (frequency patterns). Similar
history indicates a possible relationship between terms. For example, if two
terms (t1, t2) appeared frequently in Twitter at particular days, and there is
a {\^a}similarity{\^a} in the frequencies over a period of time, then t1 and t2 can
be related. Maintaining standard terminological repository with updated
relationships can be difficult; especially in a dynamic domain such as social
media where thousands of new terms (neology) are coined every day.  So we
propose to construct a raw repository of lexical units with unconfirmed
relationships. We have experimented our method on time-sensitive Arabic terms
used by the online Arabic community of Twitter. We draw relationships between
these terms by matching their similar frequency patterns (timelines). We use
dynamic time warping as a similarity measure. For evaluation, we have selected
630 possible terms (we call them preterms) and we matched the similarity of
these terms over a period of 30 days. Around 270 correct relationships were
discovered with a precision of 0.61. These relationships were extracted without
considering the textual context of the term.},
 address = {Osaka, Japan},
 author = {Daoud, Mohammad and Daoud, Daoud},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5319},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {134--144},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Discovering Potential Terminological Relationships from Twitter{\^a}s Timed Content},
 year = {2016}
}

@inproceedings{W16-5320,
 abstract = {A lexical function represents a type of relation that exists between lexical
units (words or expressions) in any language. For example, the antonymy is a
type of relation that is represented by the lexical function Anti: Anti(big) =
small. Those relations include both paradigmatic relations, i.e. vertical
relations, such as synonymy, antonymy and meronymy and syntagmatic relations, i.e. horizontal relations, such as objective qualification (legitimate demand), subjective qualification (fruitful analysis), positive evaluation (good review)
and support verbs (pay a visit, subject to an interrogation). In this paper, we
present the Lexical Functions Ontology Model (lexfom) to represent lexical
functions and the relation among lexical units. Lexfom is divided in four
modules: lexical function representation (lfrep), lexical function family
(lffam), lexical function semantic perspective (lfsem) and lexical function
relations (lfrel). Moreover, we show how it combines to Lexical Model for
Ontologies (lemon), for the transformation of lexical networks into the
semantic web formats. So far, we have implemented 100 simple and 500 complex
lexical functions, and encoded about 8,000 syntagmatic and 46,000 paradigmatic
relations, for the French language.},
 address = {Osaka, Japan},
 author = {Fonseca, Alexsandro and Sadat, Fatiha and Lareau, Fran\c{c}ois},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5320},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {145--155},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Lexfom: a lexical functions ontology model},
 year = {2016}
}

@inproceedings{W16-5321,
 abstract = {The objectives of the work described in this paper are: 1. To list the
differences between a general language resource (namely FrameNet) and a
domain-specific resource; 2. To devise solutions to merge their contents in
order to increase the coverage of the general resource. Both resources are
based on Frame Semantics (Fillmore 1985; Fillmore and Baker 2010) and this
raises specific challenges since the theoretical framework and the methodology
derived from it provide for both a lexical description and a conceptual
representation. We propose a series of strategies that handle both lexical and
conceptual (frame) differences and implemented them in the specialized
resource. We also show that most differences can be handled in a
straightforward manner. However, some more domain specific differences (such as
frames defined exclusively for the specialized domain or relations between
these frames) are likely to be much more difficult to take into account since
some are domain-specific.},
 address = {Osaka, Japan},
 author = {L' Homme, Marie-Claude and Subirats, Carlos and Robichaud, Beno\^{i}t},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5321},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {156--165},
 publisher = {The COLING 2016 Organizing Committee},
 title = {A Proposal for combining {\^a}general{\^a} and specialized frames},
 year = {2016}
}

@inproceedings{W16-5322,
 abstract = {The present paper investigates the phenomenon of antonym canonicity by
providing new behavioural and distributional evidence on Italian adjectives.
Previous studies have showed that some pairs of antonyms are perceived to be
better examples of opposition than others, and are so considered representative
of the whole category (e.g., Deese, 1964; Murphy, 2003; Paradis et al., 2009).
Our goal is to further investigate why such canonical pairs (Murphy, 2003)
exist and how they come to be associated. In the literature, two different
approaches have dealt with this issue. The lexical-categorical approach
(Charles and Miller, 1989; Justeson and Katz, 1991) finds the cause of
canonicity in the high co-occurrence frequency of the two adjectives. The
cognitive-prototype approach (Paradis et al., 2009; Jones et al., 2012) instead
claims that two adjectives form a canonical pair because they are aligned along
a simple and salient dimension. Our empirical evidence, while supporting the
latter view, shows that the paradigmatic distributional properties of
adjectives can also contribute to explain the phenomenon of canonicity, providing a corpus-based correlate of the cognitive notion of salience.},
 address = {Osaka, Japan},
 author = {Pastena, Andreana and Lenci, Alessandro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5322},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {166--175},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Antonymy and Canonicity: Experimental and Distributional Evidence},
 year = {2016}
}

@inproceedings{W16-5323,
 abstract = {Understanding the semantic relationships between terms is a fundamental task in
natural language processing applications. While structured resources that can
express those relationships in a formal way, such as ontologies, are still
scarce, a large number of linguistic resources gathering dictionary definitions
is becoming available, but understanding the semantic structure of natural
language definitions is fundamental to make them useful in semantic
interpretation tasks. Based on an analysis of a subset of WordNet{\^a}s glosses, we propose a set of semantic roles that compose the semantic structure of a
dictionary definition, and show how they are related to the definition{\^a}s
syntactic configuration, identifying patterns that can be used in the
development of information extraction frameworks and semantic models.},
 address = {Osaka, Japan},
 author = {Silva, Vivian and Handschuh, Siegfried and Freitas, Andr\'{e}},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5323},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {176--184},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Categorization of Semantic Roles for Dictionary Definitions},
 year = {2016}
}

@inproceedings{W16-5324,
 abstract = {Although quantifiers/classifiers expressions occur frequently in everyday
communications or written documents, there is no description for them in
classical bilingual paper dictionaries, nor in machine-readable dictionaries.
The paper describes a corpus and  dictionary development for
quantifiers/classifiers, and their usage in the framework of French-Japanese
machine translation (MT). They often cause problems of lexical ambiguity and of
set phrase recognition during analysis, in particular for a long-distance
language pair like French and Japanese.
For the development of a dictionary aiming at ambiguity resolution for
expressions including quantifiers and classifiers which may be ambiguous with
common nouns, we have annotated our corpus with UWs (interlingual lexemes) of
UNL (Universal Networking Language) found on the UNL-jp dictionary. The
extraction of potential classifiers/quantifiers from corpus is

made by
UNLexplorer web service.
Keywords : classifiers, quantifiers, phraseology study, corpus annotation, UNL
(Universal Networking Language), UWs dictionary, Tori Bank, French-Japanese
machine translation (MT).},
 address = {Osaka, Japan},
 author = {Tomokiyo, Mutsuko and Boitet, Christian},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5324},
 booktitle = {Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V)},
 month = {December},
 pages = {185--192},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Corpus and dictionary development for classifiers/quantifiers towards a French-Japanese machine translation},
 year = {2016}
}

@inproceedings{W16-5401,
 abstract = {In this paper, we extend an existing annotation scheme ISO-Space for annotating
necessary spatial information for the task placing an specified object at a
specified location with a specified direction according to a natural language
instruction. We call such task the spatial placement problem. Our extension
particularly focuses on describing the object direction, when the object is
placed on the 2D plane. We conducted an annotation experiment in which a corpus
of 20 situated dialogues were annotated. The annotation result showed the
number of newly introduced tags by our proposal is not negligible. We also
implemented an analyser that automatically assigns the proposed tags to the
corpus and evaluated its performance. The result showed that the performance
for entity tag was quite high ranging from 0.68 to 0.99 in F-measure, but not
the case for relation tags, i.e. less than 0.4 in F-measure.},
 address = {Osaka, Japan},
 author = {Gotou, Daiki and Nishikawa, Hitoshi and Tokunaga, Takenobu},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5401},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {1--9},
 publisher = {The COLING 2016 Organizing Committee},
 title = {An extension of ISO-Space for annotating object direction},
 year = {2016}
}

@inproceedings{W16-5402,
 abstract = {This paper proposes a methodology for building a specialized Japanese data set
for recognizing temporal relations and discourse relations.
In addition to temporal and discourse relations, multi-layered situational
relations
that distinguish generic and specific states belonging to different layers in a
discourse are annotated.
Our methodology has been applied to 170 text fragments taken from Wikinews
articles in Japanese.
The validity of our methodology is evaluated and analyzed
in terms of degree of annotator agreement and frequency of errors.},
 address = {Osaka, Japan},
 author = {Kaneko, Kimi and Sugawara, Saku and Mineshima, Koji and Bekki, Daisuke},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5402},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {10--19},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Annotation and Analysis of Discourse Relations, Temporal Relations and Multi-Layered Situational Relations in Japanese Texts},
 year = {2016}
}

@inproceedings{W16-5403,
 abstract = {This article proposes a Universal Dependency Annotation Scheme for Mandarin
Chinese, including  POS tags and dependency analysis. We identify cases of
idiosyncrasy of Mandarin Chinese that are difficult to fit into the current
schema which has mainly been based on the descriptions of various Indo-European
languages. We discuss differences between our scheme and those of the Stanford
Chinese Dependencies and the Chinese Dependency Treebank.},
 address = {Osaka, Japan},
 author = {Leung, Herman and Poiret, Rafa\"{e}l and Wong, Tak-sum and Chen, Xinying and Gerdes, Kim and Lee, John},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5403},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {20--29},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Developing Universal Dependencies for Mandarin Chinese},
 year = {2016}
}

@inproceedings{W16-5404,
 abstract = {The approach which formulates the automatic text summarization as a maximum
coverage problem with knapsack constraint over a set of textual units and a set
of weighted conceptual units is promising. However, it is quite important and
difficult to determine the appropriate granularity of conceptual units for this
formulation. In order to resolve this problem, we are examining to use
components of presentation slides as conceptual units to generate a summary of
lecture utterances, instead of other possible conceptual units like base noun
phrases or important nouns. This paper explains our developing corpus designed
to evaluate our proposing approach, which consists of presentation slides and
lecture utterances aligned to presentation slide components.},
 address = {Osaka, Japan},
 author = {Minamiguchi, Ryo and Tsuchiya, Masatoshi},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5404},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {30--37},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Developing Corpus of Lecture Utterances Aligned to Slide Components},
 year = {2016}
}

@inproceedings{W16-5405,
 abstract = {This paper presents VSoLSCSum, a Vietnamese linked sentence-comment dataset, which was manually created to treat the lack of standard corpora for social
context summarization in
Vietnamese. The dataset was collected through the keywords of 141 Web documents
in 12 special events, which were mentioned on Vietnamese Web pages. Social
users were asked to involve in creating standard summaries and the label of
each sentence or comment. The inter-agreement calculated by Cohen's Kappa among
raters after validating is 0.685. To illustrate the potential use of our
dataset, a learning to rank method was trained by using a set of local and
social features. Experimental results indicate that the summary model trained
on our dataset outperforms state-of-the-art baselines in both ROUGE-1 and
ROUGE-2 in social context summarization.},
 address = {Osaka, Japan},
 author = {Nguyen, Minh-Tien and Lai, Dac Viet and Do, Phong-Khac and Tran, Duc-Vu and Nguyen, Minh-Le},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5405},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {38--48},
 publisher = {The COLING 2016 Organizing Committee},
 title = {VSoLSCSum: Building a Vietnamese Sentence-Comment Dataset for Social Context Summarization},
 year = {2016}
}

@inproceedings{W16-5406,
 abstract = {Paratactic syntactic structures are difficult to represent in syntactic
dependency tree structures.
As such, we propose an annotation schema for syntactic dependency annotation of
Japanese, in which coordinate structures are split from and overlaid on bunsetsu-based
(base phrase unit)
dependency. The schema represents nested coordinate structures, non-constituent
conjuncts, and
forward sharing as the set of regions. The annotation was performed on the core
data of {\^a}Balanced
Corpus of Contemporary Written Japanese{\^a}, which comprised about one million
words and 1980
samples from six registers, such as newspapers, books, magazines, and web
texts.},
 address = {Osaka, Japan},
 author = {Asahara, Masayuki and Matsumoto, Yuji},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5406},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {49--58},
 publisher = {The COLING 2016 Organizing Committee},
 title = {BCCWJ-DepPara: A Syntactic Annotation Treebank on the {\^a}Balanced Corpus of Contemporary Written Japanese{\^a}},
 year = {2016}
}

@inproceedings{W16-5407,
 abstract = {Treebanks are curial for natural language processing (NLP). In this paper, we
present our work for annotating a Chinese treebank in scientific domain (SCTB), to address the problem of the lack of Chinese treebanks in this domain. Chinese
analysis and machine translation experiments conducted using this treebank
indicate that the annotated treebank can significantly improve the performance
on both tasks. This treebank is released to promote Chinese NLP research in
scientific domain.},
 address = {Osaka, Japan},
 author = {Chu, Chenhui and Nakazawa, Toshiaki and Kawahara, Daisuke and Kurohashi, Sadao},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5407},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {59--67},
 publisher = {The COLING 2016 Organizing Committee},
 title = {SCTB: A Chinese Treebank in Scientific Domain},
 year = {2016}
}

@inproceedings{W16-5408,
 abstract = {This paper introduces the NIFTY-Serve corpus, a large data archive collected
from Japanese discussion forums that operated via a Bulletin Board System (BBS)
between 1987 and 2006. This corpus can be used in Artificial Intelligence
researches such as Natural Language Processing, Community Analysis, and so on.
The NIFTY-Serve corpus differs from data on WWW in three ways; (1) essentially
spam- and duplication-free because of strict data collection procedures, (2)
historic user-generated data before WWW, and (3) a complete data set because
the service now shut down. We also introduce some examples of use of the
corpus.},
 address = {Osaka, Japan},
 author = {Iwakura, Tomoya and Takahashi, Tetsuro and Ohtani, Akihiro and Matsui, Kunio},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5408},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {68--72},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Big Community Data before World Wide Web Era},
 year = {2016}
}

@inproceedings{W16-5409,
 abstract = {This paper describes various Indonesian language resources that Agency for the
Assessment and Application of Technology (BPPT) has developed and collected
since mid 80{\^a}s when we joined MMTS (Multilingual Machine Translation System), an international project coordinated by CICC-Japan to develop a machine
translation system for five Asian languages (Bahasa Indonesia, Malay, Thai, Japanese, and Chinese). Since then, we have been actively doing many types of
research in the field of statistical machine translation, speech recognition, and speech synthesis which requires many text and speech corpus. Most recent
cooperation within ASEAN-IVO is the development of Indonesian ALT (Asian
Language Treebank) has added new NLP tools.},
 address = {Osaka, Japan},
 author = {Gunarso, Gunarso and Riza, Hammam},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5409},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {73--77},
 publisher = {The COLING 2016 Organizing Committee},
 title = {An Overview of BPPT's Indonesian Language Resources},
 year = {2016}
}

@inproceedings{W16-5410,
 abstract = {This paper describes a Japanese political corpus created for interdisciplinary
political research.
The corpus contains the local assembly minutes of 47 prefectures from April
2011 to March 2015.
This four-year period coincides with the term of office for assembly members in
most autonomies.
We analyze statistical data, such as the number of speakers, characters, and
words, to clarify the characteristics of local assembly minutes.
In addition, we identify problems associated with the different web services
used by the autonomies to make the minutes available to the public.},
 address = {Osaka, Japan},
 author = {Kimura, Yasutomo and Takamaru, Keiichi and Tanaka, Takuma and Kobayashi, Akio and Sakaji, Hiroki and Uchida, Yuzu and Ototake, Hokuto and Masuyama, Shigeru},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5410},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {78--85},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Creating Japanese Political Corpus from Local Assembly Minutes of 47 prefectures},
 year = {2016}
}

@inproceedings{W16-5411,
 abstract = {Many NLP tasks involve sentence-level annotation yet the relevant information
is not encoded at sentence level but at some relevant parts of the sentence.
Such tasks include but are not limited to: sentiment expression annotation, product feature annotation, and template annotation for Q\&A systems. However, annotation of the full corpus sentence by sentence is resource intensive. In
this paper, we propose an approach that iteratively extracts frequent parts of
sentences for annotating, and compresses the set of sentences after each round
of annotation. Our approach can also be used in preparing training sentences
for binary classification (domain-related vs. noise, subjectivity vs.
objectivity, etc.), assuming that sentence-type annotation can be predicted by
annotation of the most relevant sub-sentences. Two experiments are performed to
test our proposal and evaluated in terms of time saved and agreement of
annotation.},
 address = {Osaka, Japan},
 author = {Xu, Ge and Yang, Xiaoyan and Huang, Chu-Ren},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5411},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {86--94},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Selective Annotation of Sentence Parts: Identification of Relevant Sub-sentential Units},
 year = {2016}
}

@inproceedings{W16-5412,
 abstract = {Summarization of multi-party conversation is one of the important tasks in
natural language processing.
In this paper, we explain a Japanese corpus and a topic segmentation task.
To the best of our knowledge, the corpus is the first Japanese corpus annotated
for summarization tasks and freely available to anyone.
We call it ``the Kyutech corpus.''
The task of the corpus is a decision-making task with four participants and it
contains utterances with time information, topic segmentation and reference
summaries.
As a case study for the corpus, we describe a method combined with LCSeg and
TopicTiling for a topic segmentation task.
We discuss the effectiveness and the problems of the combined method through
the experiment with the Kyutech corpus.},
 address = {Osaka, Japan},
 author = {Yamamura, Takashi and Shimada, Kazutaka and Kawahara, Shintaro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5412},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {95--104},
 publisher = {The COLING 2016 Organizing Committee},
 title = {The Kyutech corpus and topic segmentation using a combined method},
 year = {2016}
}

@inproceedings{W16-5413,
 abstract = {In this paper we present two methods for automatic common sense knowledge
evaluation for Japanese entries in ConceptNet ontology. Our proposed methods
utilize text-mining approach: one with relation clue words and WordNet
synonyms, and one without. Both methods were tested with a blog corpus. The
system based on our proposed methods reached relatively high precision score
for three relations (MadeOf, UsedFor, AtLocation), which is comparable with
previous research using commercial search engines and simpler input. We analyze
errors and discuss problems of common sense evaluation, both manual and
automatic and propose ideas for further improvements.},
 address = {Osaka, Japan},
 author = {Shudo, Seiya and Rzepka, Rafal and Araki, Kenji},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5413},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {105--112},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Automatic Evaluation of Commonsense Knowledge for Refining Japanese ConceptNet},
 year = {2016}
}

@inproceedings{W16-5414,
 abstract = {Although MWE are relatively morphologically and syntactically fixed
expressions, several types
of flexibility can be observed in MWE, verbal MWE in particular. Identifying
the degree of
morphological and syntactic flexibility of MWE is very important for many
Lexicographic and
NLP tasks. Adding MWE variants/tokens to a dictionary resource requires
characterizing the
flexibility among other morphosyntactic features. Carrying out the task
manually faces several
challenges since it is a very laborious task time and effort wise, as well as
it will suffer from
coverage limitation. The problem is exacerbated in rich morphological languages
where the
average word in Arabic could have 12 possible inflection forms. Accordingly, in
this paper we
introduce a semi-automatic Arabic multiwords expressions resource (SAMER). We
propose an
automated method that identifies the morphological and syntactic flexibility of
Arabic Verbal
Multiword Expressions (AVMWE). All observed morphological variants and
syntactic pattern
alternations of an AVMWE are automatically acquired using large scale corpora.
We look for three
morphosyntactic aspects of AVMWE types investigating derivational and
inflectional variations
and syntactic templates, namely: 1) inflectional variation (inflectional
paradigm) and calculating
degree of flexibility; 2) derivational productivity; and 3) identifying and
classifying the different
syntactic types. We build a comprehensive list of AVMWE. Every token in the
AVMWE list is
lemmatized and tagged with POS information. We then search Arabic Gigaword and
All ATBs
for all possible flexible matches. For each AVMWE type we generate: a) a
statistically ranked list
of MWE-lexeme inflections and syntactic pattern alternations; b) An abstract
syntactic template;
and c) The most frequent form. Our technique is validated using a Golden MWE
annotated list.
The results shows that the quality of the generated resource is 80.04%.},
 address = {Osaka, Japan},
 author = {Al-Badrashiny, Mohamed and Hawwari, Abdelati and Ghoneim, Mahmoud and Diab, Mona},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5414},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {113--122},
 publisher = {The COLING 2016 Organizing Committee},
 title = {SAMER: A Semi-Automatically Created Lexical Resource for Arabic Verbal Multiword Expressions Tokens Paradigm and their Morphosyntactic Features},
 year = {2016}
}

@inproceedings{W16-5415,
 abstract = {This paper describes our attempt to build a sentiment analysis system for
Indonesian tweets. With this system, we can study and identify sentiments and
opinions in a text or document computationally. We used four thousand manually
labeled tweets collected in February and March 2016 to build the model. Because
of the variety of content in tweets, we analyze tweets into eight groups in
total, including pos(itive), neg(ative), and neu(tral). Finally, we obtained
73.2% accuracy with Long Short Term Memory (LSTM) without normalizer.},
 address = {Osaka, Japan},
 author = {Le, Tuan Anh and Moeljadi, David and Miura, Yasuhide and Ohkuma, Tomoko},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5415},
 booktitle = {Proceedings of the 12th Workshop on Asian Language Resources (ALR12)},
 month = {December},
 pages = {123--131},
 publisher = {The COLING 2016 Organizing Committee},
 title = {Sentiment Analysis for Low Resource Languages: A Study on Informal Indonesian Tweets},
 year = {2016}
}

@inproceedings{W16-5501,
 address = {Edinburgh, UK},
 author = {Vaudry, Pierre-Luc and Lapalme, Guy},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-5501},
 booktitle = {Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation},
 month = {September},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Assembling Narratives with Associative Threads},
 year = {2016}
}

@inproceedings{W16-5502,
 address = {Edinburgh, UK},
 author = {Kumagai, Kaori and Kobayashi, Ichiro and Mochihashi, Daichi and Asoh, Hideki and Nakamura, Tomoaki and Nagai, Takayuki},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-5502},
 booktitle = {Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation},
 month = {September},
 pages = {11--18},
 publisher = {Association for Computational Linguistics},
 title = {Human-like Natural Language Generation Using Monte Carlo Tree Search},
 year = {2016}
}

@inproceedings{W16-5503,
 address = {Edinburgh, UK},
 author = {Gerv{\'a}s, Pablo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-5503},
 booktitle = {Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation},
 month = {September},
 pages = {19--26},
 publisher = {Association for Computational Linguistics},
 title = {Empirical Determination of Basic Heuristics for Narrative Content Planning},
 year = {2016}
}

@inproceedings{W16-5504,
 address = {Edinburgh, UK},
 author = {Winterstein, Daniel and Corneli, Joseph},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-5504},
 booktitle = {Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation},
 month = {September},
 pages = {27--30},
 publisher = {Association for Computational Linguistics},
 title = {X575: Writing Rengas with Web Services},
 year = {2016}
}

@inproceedings{W16-5505,
 address = {Edinburgh, UK},
 author = {Sato, Satoshi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-5505},
 booktitle = {Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation},
 month = {September},
 pages = {31--35},
 publisher = {Association for Computational Linguistics},
 title = {A Challenge to the Third Hoshi Shinichi Award},
 year = {2016}
}

@inproceedings{W16-5506,
 address = {Edinburgh, UK},
 author = {Pragst, Louisa and Miehle, Juliana and Ultes, Stefan and Minker, Wolfgang},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-5506},
 booktitle = {Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation},
 month = {September},
 pages = {36--40},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Modification of Communication Style in Dialogue Management},
 year = {2016}
}

@inproceedings{W16-5507,
 address = {Edinburgh, UK},
 author = {Concepci{\'o}n, Eugenio and Gerv{\'a}s, Pablo and M{\'e}ndez, Gonzalo},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-5507},
 booktitle = {Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation},
 month = {September},
 pages = {41--50},
 publisher = {Association for Computational Linguistics},
 title = {Mining Knowledge in Storytelling Systems for Narrative Generation},
 year = {2016}
}

@inproceedings{W16-5508,
 address = {Edinburgh, UK},
 author = {McGregor, Stephen and Purver, Matthew and Wiggins, Geraint},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-5508},
 booktitle = {Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation},
 month = {September},
 pages = {51--60},
 publisher = {Association for Computational Linguistics},
 title = {Process Based Evaluation of Computer Generated Poetry},
 year = {2016}
}

@inproceedings{W16-5509,
 address = {Edinburgh, UK},
 author = {Mazzei, Alessandro and Valle, Andrea},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-5509},
 booktitle = {Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation},
 month = {September},
 pages = {61--70},
 publisher = {Association for Computational Linguistics},
 title = {Combinatorics vs Grammar: Archeology of Computational Poetry in Tape Mark I},
 year = {2016}
}

@inproceedings{W16-5601,
 address = {Austin, Texas},
 author = {Joseph, Kenneth and Carley, Kathleen M.},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5601},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Relating semantic similarity and semantic association to how humans label other people},
 year = {2016}
}

@inproceedings{W16-5602,
 address = {Austin, Texas},
 author = {Freitas, Jesse and Ji, Heng},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5602},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {11--16},
 publisher = {Association for Computational Linguistics},
 title = {Identifying News from Tweets},
 year = {2016}
}

@inproceedings{W16-5603,
 address = {Austin, Texas},
 author = {Reddy, Sravana and Knight, Kevin},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5603},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {17--26},
 publisher = {Association for Computational Linguistics},
 title = {Obfuscating Gender in Social Media Writing},
 year = {2016}
}

@inproceedings{W16-5604,
 address = {Austin, Texas},
 author = {Rosenthal, Sara and McKeown, Kathy},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5604},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {27--36},
 publisher = {Association for Computational Linguistics},
 title = {Social Proof: The Impact of Author Traits on Influence Detection},
 year = {2016}
}

@inproceedings{W16-5605,
 address = {Austin, Texas},
 author = {Beieler, John},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5605},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {37--42},
 publisher = {Association for Computational Linguistics},
 title = {Generating Politically-Relevant Event Data},
 year = {2016}
}

@inproceedings{W16-5606,
 address = {Austin, Texas},
 author = {Poulston, Adam and Stevenson, Mark and Bontcheva, Kalina},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5606},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {43--48},
 publisher = {Association for Computational Linguistics},
 title = {User profiling with geo-located posts and demographic data},
 year = {2016}
}

@inproceedings{W16-5607,
 address = {Austin, Texas},
 author = {Nay, John J.},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5607},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {49--54},
 publisher = {Association for Computational Linguistics},
 title = {Gov2Vec: Learning Distributed Representations of Institutions and Their Legal Text},
 year = {2016}
}

@inproceedings{W16-5608,
 address = {Austin, Texas},
 author = {Priante, Anna and Hiemstra, Djoerd and van den Broek, Tijs and Saeed, Aaqib and Ehrenhard, Michel and Need, Ariana},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5608},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {55--65},
 publisher = {Association for Computational Linguistics},
 title = {\#WhoAmI in 160 Characters? Classifying Social Identities Based on Twitter Profile Descriptions},
 year = {2016}
}

@inproceedings{W16-5609,
 address = {Austin, Texas},
 author = {Johnson, Kristen and Goldwasser, Dan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5609},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {66--75},
 publisher = {Association for Computational Linguistics},
 title = {Identifying Stance by Analyzing Political Discourse on Twitter},
 year = {2016}
}

@inproceedings{W16-5610,
 address = {Austin, Texas},
 author = {Wang, Alex and Hamilton, William L. and Leskovec, Jure},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5610},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {76--85},
 publisher = {Association for Computational Linguistics},
 title = {Learning Linguistic Descriptors of User Roles in Online Communities},
 year = {2016}
}

@inproceedings{W16-5611,
 address = {Austin, Texas},
 author = {Kim, Sunghwan Mac and Wan, Stephen and Paris, Cecile and Brian, Jin and Robinson, Bella},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5611},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {86--91},
 publisher = {Association for Computational Linguistics},
 title = {The Effects of Data Collection Methods in Twitter},
 year = {2016}
}

@inproceedings{W16-5612,
 address = {Austin, Texas},
 author = {Rheault, Ludovic},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5612},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {92--101},
 publisher = {Association for Computational Linguistics},
 title = {Expressions of Anxiety in Political Texts},
 year = {2016}
}

@inproceedings{W16-5613,
 address = {Austin, Texas},
 author = {Makarov, Peter and Lorenzini, Jasmine and Kriesi, Hanspeter},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5613},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {102--107},
 publisher = {Association for Computational Linguistics},
 title = {Constructing an Annotated Corpus for Protest Event Mining},
 year = {2016}
}

@inproceedings{W16-5614,
 address = {Austin, Texas},
 author = {Knowles, Rebecca and Carroll, Josh and Dredze, Mark},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5614},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {108--113},
 publisher = {Association for Computational Linguistics},
 title = {Demographer: Extremely Simple Name Demographics},
 year = {2016}
}

@inproceedings{W16-5615,
 address = {Austin, Texas},
 author = {Handler, Abram and Denny, Matthew and Wallach, Hanna and O'Connor, Brendan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5615},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {114--124},
 publisher = {Association for Computational Linguistics},
 title = {Bag of What? Simple Noun Phrase Extraction for Text Analysis},
 year = {2016}
}

@inproceedings{W16-5616,
 address = {Austin, Texas},
 author = {Fraiberger, Samuel},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5616},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {125--131},
 publisher = {Association for Computational Linguistics},
 title = {News Sentiment and Cross-Country Fluctuations},
 year = {2016}
}

@inproceedings{W16-5617,
 address = {Austin, Texas},
 author = {Coppersmith, Glen and Hollingshead, Kristy and Schwartz, H. Andrew and Ireland, Molly and Resnik, Rebecca and Loveys, Kate and Foreman, April and Ingraham, Loring},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5617},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {132--137},
 publisher = {Association for Computational Linguistics},
 title = {The Clinical Panel: Leveraging Psychological Expertise During NLP Research},
 year = {2016}
}

@inproceedings{W16-5618,
 address = {Austin, Texas},
 author = {Waseem, Zeerak},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5618},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {138--142},
 publisher = {Association for Computational Linguistics},
 title = {Are You a Racist or Am I Seeing Things? Annotator Influence on Hate Speech Detection on Twitter},
 year = {2016}
}

@inproceedings{W16-5619,
 address = {Austin, Texas},
 author = {Wilson, Steven and Mihalcea, Rada and Boyd, Ryan and Pennebaker, James},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5619},
 booktitle = {Proceedings of the First Workshop on NLP and Computational Social Science},
 month = {November},
 pages = {143--152},
 publisher = {Association for Computational Linguistics},
 title = {Disentangling Topic Models: A Cross-cultural Analysis of Personal Values through Words},
 year = {2016}
}

@inproceedings{W16-5701,
 address = {Austin, Texas},
 author = {Caswell, David},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5701},
 booktitle = {Proceedings of the 2nd Workshop on Computing News Storylines (CNS 2016)},
 month = {November},
 pages = {1--8},
 publisher = {Association for Computational Linguistics},
 title = {Computable News Ecosystems: Roles for Humans and Machines},
 year = {2016}
}

@inproceedings{W16-5702,
 address = {Austin, Texas},
 author = {Bruggermann, Daniel and Hermey, Yannik and Orth, Carsten and Schneider, Darius and Selzer, Stefan and Spanakis, Gerasimos},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5702},
 booktitle = {Proceedings of the 2nd Workshop on Computing News Storylines (CNS 2016)},
 month = {November},
 pages = {9--19},
 publisher = {Association for Computational Linguistics},
 title = {Storyline detection and tracking using Dynamic Latent Dirichlet Allocation},
 year = {2016}
}

@inproceedings{W16-5703,
 address = {Austin, Texas},
 author = {Poghosyan, Gevorg and Ifrim, Georgiana},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5703},
 booktitle = {Proceedings of the 2nd Workshop on Computing News Storylines (CNS 2016)},
 month = {November},
 pages = {20--29},
 publisher = {Association for Computational Linguistics},
 title = {Real-time News Story Detection and Tracking with Hashtags},
 year = {2016}
}

@inproceedings{W16-5704,
 address = {Austin, Texas},
 author = {Krishnan, Vinodh and Eisenstein, Jacob},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5704},
 booktitle = {Proceedings of the 2nd Workshop on Computing News Storylines (CNS 2016)},
 month = {November},
 pages = {30--35},
 publisher = {Association for Computational Linguistics},
 title = {Nonparametric Bayesian Storyline Detection from Microtexts},
 year = {2016}
}

@inproceedings{W16-5705,
 address = {Austin, Texas},
 author = {Eisenberg, Joshua and Finlayson, Mark},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5705},
 booktitle = {Proceedings of the 2nd Workshop on Computing News Storylines (CNS 2016)},
 month = {November},
 pages = {36--46},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Identification of Narrative Diegesis and Point of View},
 year = {2016}
}

@inproceedings{W16-5706,
 address = {Austin, Texas},
 author = {O'Gorman, Tim and Wright-Bettner, Kristin and Palmer, Martha},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5706},
 booktitle = {Proceedings of the 2nd Workshop on Computing News Storylines (CNS 2016)},
 month = {November},
 pages = {47--56},
 publisher = {Association for Computational Linguistics},
 title = {Richer Event Description: Integrating event coreference with temporal, causal and bridging annotation},
 year = {2016}
}

@inproceedings{W16-5707,
 address = {Austin, Texas},
 author = {Simonson, Dan and Davis, Anthony},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5707},
 booktitle = {Proceedings of the 2nd Workshop on Computing News Storylines (CNS 2016)},
 month = {November},
 pages = {57--66},
 publisher = {Association for Computational Linguistics},
 title = {NASTEA: Investigating Narrative Schemas through Annotated Entities},
 year = {2016}
}

@inproceedings{W16-5708,
 address = {Austin, Texas},
 author = {Caselli, Tommaso and Vossen, Piek},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5708},
 booktitle = {Proceedings of the 2nd Workshop on Computing News Storylines (CNS 2016)},
 month = {November},
 pages = {67--72},
 publisher = {Association for Computational Linguistics},
 title = {The Storyline Annotation and Representation Scheme (StaR): A Proposal},
 year = {2016}
}

@inproceedings{W16-5801,
 address = {Austin, Texas},
 author = {\c{C}etino\u{g}lu, \"{O}zlem and Schulz, Sarah and Vu, Ngoc Thang},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5801},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {1--11},
 publisher = {Association for Computational Linguistics},
 title = {Challenges of Computational Processing of Code-Switching},
 year = {2016}
}

@inproceedings{W16-5802,
 address = {Austin, Texas},
 author = {Guzman, Gualberto A. and Serigos, Jacqueline and Bullock, Barbara E. and Toribio, Almeida Jacqueline},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5802},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {12--20},
 publisher = {Association for Computational Linguistics},
 title = {Simple Tools for Exploring Variation in Code-switching for Linguists},
 year = {2016}
}

@inproceedings{W16-5803,
 address = {Austin, Texas},
 author = {Piergallini, Mario and Shirvani, Rouzbeh and S. Gautam, Gauri and Chouikha, Mohamed},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5803},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {21--29},
 publisher = {Association for Computational Linguistics},
 title = {Word-Level Language Identification and Predicting Codeswitching Points in Swahili-English Language Data},
 year = {2016}
}

@inproceedings{W16-5804,
 address = {Austin, Texas},
 author = {Barman, Utsab and Wagner, Joachim and Foster, Jennifer},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5804},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {30--39},
 publisher = {Association for Computational Linguistics},
 title = {Part-of-speech Tagging of Code-mixed Social Media Content: Pipeline, Stacking and Joint Modelling},
 year = {2016}
}

@inproceedings{W16-5805,
 address = {Austin, Texas},
 author = {Molina, Giovanni and AlGhamdi, Fahad and Ghoneim, Mahmoud and Hawwari, Abdelati and Rey-Villamizar, Nicolas and Diab, Mona and Solorio, Thamar},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5805},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {40--49},
 publisher = {Association for Computational Linguistics},
 title = {Overview for the Second Shared Task on Language Identification in Code-Switched Data},
 year = {2016}
}

@inproceedings{W16-5806,
 address = {Austin, Texas},
 author = {Samih, Younes and Maharjan, Suraj and Attia, Mohammed and Kallmeyer, Laura and Solorio, Thamar},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5806},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {50--59},
 publisher = {Association for Computational Linguistics},
 title = {Multilingual Code-switching Identification via LSTM Recurrent Neural Networks},
 year = {2016}
}

@inproceedings{W16-5807,
 address = {Austin, Texas},
 author = {Jaech, Aaron and Mulcaire, George and Ostendorf, Mari and Smith, Noah A.},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5807},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {60--64},
 publisher = {Association for Computational Linguistics},
 title = {A Neural Model for Language Identification in Code-Switched Tweets},
 year = {2016}
}

@inproceedings{W16-5808,
 address = {Austin, Texas},
 author = {Samih, Younes and Maier, Wolfgang and Kallmeyer, Laura},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5808},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {65--70},
 publisher = {Association for Computational Linguistics},
 title = {SAWT: Sequence Annotation Web Tool},
 year = {2016}
}

@inproceedings{W16-5809,
 address = {Austin, Texas},
 author = {Xia, Meng Xuan and Cheung, Jackie Chi Kit},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5809},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {71--79},
 publisher = {Association for Computational Linguistics},
 title = {Accurate Pinyin-English Codeswitched Language Identification},
 year = {2016}
}

@inproceedings{W16-5810,
 address = {Austin, Texas},
 author = {Chanda, Arunavha and Das, Dipankar and Mazumdar, Chandan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5810},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {80--89},
 publisher = {Association for Computational Linguistics},
 title = {Unraveling the English-Bengali Code-Mixing Phenomenon},
 year = {2016}
}

@inproceedings{W16-5811,
 address = {Austin, Texas},
 author = {Ghosh, Souvick and Ghosh, Satanu and Das, Dipankar},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5811},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {90--97},
 publisher = {Association for Computational Linguistics},
 title = {Part-of-speech Tagging of Code-Mixed Social Media Text},
 year = {2016}
}

@inproceedings{W16-5812,
 address = {Austin, Texas},
 author = {AlGhamdi, Fahad and Molina, Giovanni and Diab, Mona and Solorio, Thamar and Hawwari, Abdelati and Soto, Victor and Hirschberg, Julia},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5812},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {98--107},
 publisher = {Association for Computational Linguistics},
 title = {Part of Speech Tagging for Code Switched Data},
 year = {2016}
}

@inproceedings{W16-5813,
 address = {Austin, Texas},
 author = {Al-Badrashiny, Mohamed and Diab, Mona},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5813},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {108--111},
 publisher = {Association for Computational Linguistics},
 title = {The George Washington University System for the Code-Switching Workshop Shared Task 2016},
 year = {2016}
}

@inproceedings{W16-5814,
 address = {Austin, Texas},
 author = {Chanda, Arunavha and Das, Dipankar and Mazumdar, Chandan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5814},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {112--115},
 publisher = {Association for Computational Linguistics},
 title = {Columbia-Jadavpur submission for EMNLP 2016 Code-Switching Workshop Shared Task: System description},
 year = {2016}
}

@inproceedings{W16-5815,
 address = {Austin, Texas},
 author = {Shirvani, Rouzbeh and Piergallini, Mario and Gautam, Gauri Shankar and Chouikha, Mohamed},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5815},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {116--120},
 publisher = {Association for Computational Linguistics},
 title = {The Howard University System Submission for the Shared Task in Language Identification in Spanish-English Codeswitching},
 year = {2016}
}

@inproceedings{W16-5816,
 address = {Austin, Texas},
 author = {Shrestha, Prajwol},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5816},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {121--126},
 publisher = {Association for Computational Linguistics},
 title = {Codeswitching Detection via Lexical Features in Conditional Random Fields},
 year = {2016}
}

@inproceedings{W16-5817,
 address = {Austin, Texas},
 author = {Sikdar, Utpal Kumar and Gamb\"{a}ck, Bj\"{o}rn},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5817},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {127--131},
 publisher = {Association for Computational Linguistics},
 title = {Language Identification in Code-Switched Text Using Conditional Random Fields and Babelnet},
 year = {2016}
}

@inproceedings{W16-5818,
 address = {Austin, Texas},
 author = {Xia, Meng Xuan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5818},
 booktitle = {Proceedings of the Second Workshop on Computational Approaches to Code Switching},
 month = {November},
 pages = {132--136},
 publisher = {Association for Computational Linguistics},
 title = {Codeswitching language identification using Subword Information Enriched Word Vectors},
 year = {2016}
}

@inproceedings{W16-5901,
 address = {Austin, TX},
 author = {Eisner, Jason},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5901},
 booktitle = {Proceedings of the Workshop on Structured Prediction for NLP},
 month = {November},
 pages = {1--17},
 publisher = {Association for Computational Linguistics},
 title = {Inside-Outside and Forward-Backward Algorithms Are Just Backprop (tutorial paper)},
 year = {2016}
}

@inproceedings{W16-5902,
 address = {Austin, TX},
 author = {liu, zhuang and Huang, Degen and zhang, jing and huang, kaiyu},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5902},
 booktitle = {Proceedings of the Workshop on Structured Prediction for NLP},
 month = {November},
 pages = {18--24},
 publisher = {Association for Computational Linguistics},
 title = {Research on attention memory networks as a model for learning natural language inference},
 year = {2016}
}

@inproceedings{W16-5903,
 address = {Austin, TX},
 author = {Goyal, Naman and Eisenstein, Jacob},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5903},
 booktitle = {Proceedings of the Workshop on Structured Prediction for NLP},
 month = {November},
 pages = {25--34},
 publisher = {Association for Computational Linguistics},
 title = {A Joint Model of Rhetorical Discourse Structure and Summarization},
 year = {2016}
}

@inproceedings{W16-5904,
 address = {Austin, TX},
 author = {Goyal, Kartik and Dyer, Chris},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5904},
 booktitle = {Proceedings of the Workshop on Structured Prediction for NLP},
 month = {November},
 pages = {35--43},
 publisher = {Association for Computational Linguistics},
 title = {Posterior regularization for Joint Modeling of Multiple Structured Prediction Tasks with Soft Constraints},
 year = {2016}
}

@inproceedings{W16-5905,
 address = {Austin, TX},
 author = {Wolfe, Travis and Dredze, Mark and Van Durme, Benjamin},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5905},
 booktitle = {Proceedings of the Workshop on Structured Prediction for NLP},
 month = {November},
 pages = {44--53},
 publisher = {Association for Computational Linguistics},
 title = {A Study of Imitation Learning Methods for Semantic Role Labeling},
 year = {2016}
}

@inproceedings{W16-5906,
 address = {Austin, TX},
 author = {Zhang, Xiao and Pacheco, Mar\'{i}a Leonor and Li, Chang and Goldwasser, Dan},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5906},
 booktitle = {Proceedings of the Workshop on Structured Prediction for NLP},
 month = {November},
 pages = {54--62},
 publisher = {Association for Computational Linguistics},
 title = {Introducing DRAIL -- a Step Towards Declarative Deep Relational Learning},
 year = {2016}
}

@inproceedings{W16-5907,
 address = {Austin, TX},
 author = {Tran, Ke M. and Bisk, Yonatan and Vaswani, Ashish and Marcu, Daniel and Knight, Kevin},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-5907},
 booktitle = {Proceedings of the Workshop on Structured Prediction for NLP},
 month = {November},
 pages = {63--71},
 publisher = {Association for Computational Linguistics},
 title = {Unsupervised Neural Hidden Markov Models},
 year = {2016}
}

@inproceedings{W16-6001,
 address = {Austin, TX},
 author = {Sugawara, Saku and Aizawa, Akiko},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6001},
 booktitle = {Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods},
 month = {November},
 pages = {1--5},
 publisher = {Association for Computational Linguistics},
 title = {An Analysis of Prerequisite Skills for Reading Comprehension},
 year = {2016}
}

@inproceedings{W16-6002,
 address = {Austin, TX},
 author = {Benikova, Darina and Zesch, Torsten},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6002},
 booktitle = {Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods},
 month = {November},
 pages = {6--10},
 publisher = {Association for Computational Linguistics},
 title = {Bridging the gap between computable and expressive event representations in Social Media},
 year = {2016}
}

@inproceedings{W16-6003,
 address = {Austin, TX},
 author = {Pichotta, Karl and Mooney, Raymond},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6003},
 booktitle = {Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods},
 month = {November},
 pages = {11--16},
 publisher = {Association for Computational Linguistics},
 title = {Statistical Script Learning with Recurrent Neural Networks},
 year = {2016}
}

@inproceedings{W16-6004,
 address = {Austin, TX},
 author = {Postma, Marten and Ilievski, Filip and Vossen, Piek and van Erp, Marieke},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6004},
 booktitle = {Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods},
 month = {November},
 pages = {17--21},
 publisher = {Association for Computational Linguistics},
 title = {Moving away from semantic overfitting in disambiguation datasets},
 year = {2016}
}

@inproceedings{W16-6005,
 address = {Austin, TX},
 author = {Rajagopal, Dheeraj and Hovy, Eduard and Mitamura, Teruko},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6005},
 booktitle = {Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods},
 month = {November},
 pages = {22--26},
 publisher = {Association for Computational Linguistics},
 title = {Unsupervised Event Coreference for Abstract Words},
 year = {2016}
}

@inproceedings{W16-6006,
 address = {Austin, TX},
 author = {Bakhshandeh, Omid and Allen, James},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6006},
 booktitle = {Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods},
 month = {November},
 pages = {27--31},
 publisher = {Association for Computational Linguistics},
 title = {Towards Broad-coverage Meaning Representation: The Case of Comparison Structures},
 year = {2016}
}

@inproceedings{W16-6007,
 address = {Austin, TX},
 author = {Zhao, Tiancheng and Lee, Kyusong and Eskenazi, Maxine},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6007},
 booktitle = {Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods},
 month = {November},
 pages = {32--34},
 publisher = {Association for Computational Linguistics},
 title = {DialPort: A General Framework for Aggregating Dialog Systems},
 year = {2016}
}

@inproceedings{W16-6008,
 address = {Austin, TX},
 author = {Church, Ken and Zhu, Weizhong and Pelecanos, Jason},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6008},
 booktitle = {Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods},
 month = {November},
 pages = {35--38},
 publisher = {Association for Computational Linguistics},
 title = {C2D2E2: Using Call Centers to Motivate the Use of Dialog and Diarization in Entity Extraction},
 year = {2016}
}

@inproceedings{W16-6009,
 address = {Austin, TX},
 author = {Do, Quynh Ngoc Thi and Bethard, Steven and Moens, Marie-Francine},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6009},
 booktitle = {Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods},
 month = {November},
 pages = {39--42},
 publisher = {Association for Computational Linguistics},
 title = {Visualizing the Content of a Children{\^a}s Story in a Virtual World: Lessons Learned},
 year = {2016}
}

@inproceedings{W16-6010,
 address = {Austin, TX},
 author = {Kabbara, Jad and Cheung, Jackie Chi Kit},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6010},
 booktitle = {Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods},
 month = {November},
 pages = {43--47},
 publisher = {Association for Computational Linguistics},
 title = {Stylistic Transfer in Natural Language Generation Systems Using Recurrent Neural Networks},
 year = {2016}
}

@inproceedings{W16-6011,
 address = {Austin, TX},
 author = {Lewis, Timothy and Matuszek, Cynthia and Hurst, Amy and Taylor, Matthew},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6011},
 booktitle = {Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods},
 month = {November},
 pages = {48--52},
 publisher = {Association for Computational Linguistics},
 title = {Using Language Groundings for Context-Sensitive Text Prediction},
 year = {2016}
}

@inproceedings{W16-6012,
 address = {Austin, TX},
 author = {Ruder, Sebastian and Ghaffari, Parsa and Breslin, John G.},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6012},
 booktitle = {Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods},
 month = {November},
 pages = {53--57},
 publisher = {Association for Computational Linguistics},
 title = {Towards a continuous modeling of natural language domains},
 year = {2016}
}

@inproceedings{W16-6101,
 address = {Auxtin, TX},
 author = {Chalapathy, Raghavendra and Zare Borzeshi, Ehsan and Piccardi, Massimo},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6101},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {1--5},
 publisher = {Association for Computational Linguistics},
 title = {An Investigation of Recurrent Neural Architectures for Drug Name Recognition},
 year = {2016}
}

@inproceedings{W16-6102,
 address = {Auxtin, TX},
 author = {Spithourakis, Georgios and Petersen, Steffen and Riedel, Sebastian},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6102},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {6--16},
 publisher = {Association for Computational Linguistics},
 title = {Clinical Text Prediction with Numerically Grounded Conditional Language Models},
 year = {2016}
}

@inproceedings{W16-6103,
 address = {Auxtin, TX},
 author = {Cornegruta, Savelie and Bakewell, Robert and Withey, Samuel and Montana, Giovanni},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6103},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {17--27},
 publisher = {Association for Computational Linguistics},
 title = {Modelling Radiological Language with Bidirectional Long Short-Term Memory Networks},
 year = {2016}
}

@inproceedings{W16-6104,
 address = {Auxtin, TX},
 author = {Kokkinakis, Dimitrios and Lundholm Fors, Kristina and Nordlund, Arto},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6104},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {28--36},
 publisher = {Association for Computational Linguistics},
 title = {Data Resource Acquisition from People at Various Stages of Cognitive Decline -- Design and Exploration Considerations},
 year = {2016}
}

@inproceedings{W16-6105,
 address = {Auxtin, TX},
 author = {Rey-Villamizar, Nicolas and Shrestha, Prasha and Sadeque, Farig and Bethard, Steven and Pedersen, Ted and Mukherjee, Arjun and Solorio, Thamar},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6105},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {37--42},
 publisher = {Association for Computational Linguistics},
 title = {Analysis of Anxious Word Usage on Online Health Forums},
 year = {2016}
}

@inproceedings{W16-6106,
 address = {Auxtin, TX},
 author = {Yu, Zhiguo and Cohen, Trevor and Wallace, Byron and Bernstam, Elmer and Johnson, Todd},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6106},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {43--51},
 publisher = {Association for Computational Linguistics},
 title = {Retrofitting Word Vectors of MeSH Terms to Improve Semantic Similarity Measures},
 year = {2016}
}

@inproceedings{W16-6107,
 address = {Auxtin, TX},
 author = {Kirchhoff, Katrin and Turner, Anne M.},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6107},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {52--60},
 publisher = {Association for Computational Linguistics},
 title = {Unsupervised Resolution of Acronyms and Abbreviations in Nursing Notes Using Document-Level Context Models},
 year = {2016}
}

@inproceedings{W16-6108,
 address = {Auxtin, TX},
 author = {D'hondt, Eva and Grouin, Cyril and Grau, Brigitte},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6108},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {61--68},
 publisher = {Association for Computational Linguistics},
 title = {Low-resource OCR error detection and correction in French Clinical Texts},
 year = {2016}
}

@inproceedings{W16-6109,
 address = {Auxtin, TX},
 author = {Munkhdalai, Tsendsuren and Lalor, John and Yu, Hong},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6109},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {69--77},
 publisher = {Association for Computational Linguistics},
 title = {Citation Analysis with Neural Attention Models},
 year = {2016}
}

@inproceedings{W16-6110,
 address = {Auxtin, TX},
 author = {Neveol, Aurelie and Cohen, Kevin and Grouin, Cyril and Robert, Aude},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6110},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {78--84},
 publisher = {Association for Computational Linguistics},
 title = {Replicability of Research in Biomedical Natural Language Processing: a pilot evaluation for a coding task},
 year = {2016}
}

@inproceedings{W16-6111,
 address = {Auxtin, TX},
 author = {Collier, Nigel},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6111},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {85},
 publisher = {Association for Computational Linguistics},
 title = {NLP and Online Health Reports: What do we say and what do we mean?},
 year = {2016}
}

@inproceedings{W16-6112,
 address = {Auxtin, TX},
 author = {Ferracane, Elisa and Marshall, Iain and Wallace, Byron C. and Erk, Katrin},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6112},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {86--95},
 publisher = {Association for Computational Linguistics},
 title = {Leveraging coreference to identify arms in medical abstracts: An experimental study},
 year = {2016}
}

@inproceedings{W16-6113,
 address = {Auxtin, TX},
 author = {Zweigenbaum, Pierre and Lavergne, Thomas},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6113},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {96--105},
 publisher = {Association for Computational Linguistics},
 title = {Hybrid methods for ICD-10 coding of death certificates},
 year = {2016}
}

@inproceedings{W16-6114,
 address = {Auxtin, TX},
 author = {Huang, Chung-Chi and Lu, Zhiyong},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6114},
 booktitle = {Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis},
 month = {November},
 pages = {106--112},
 publisher = {Association for Computational Linguistics},
 title = {Exploring Query Expansion for Entity Searches in PubMed},
 year = {2016}
}

@inproceedings{W16-6201,
 address = {Austin, TX, USA},
 author = {Stowe, Kevin and Paul, Michael J. and Palmer, Martha and Palen, Leysia and Anderson, Kenneth},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6201},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {1--6},
 publisher = {Association for Computational Linguistics},
 title = {Identifying and Categorizing Disaster-Related Tweets},
 year = {2016}
}

@inproceedings{W16-6202,
 address = {Austin, TX, USA},
 author = {Doggett, Erika and Cantarero, Alejandro},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6202},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {7--13},
 publisher = {Association for Computational Linguistics},
 title = {Identifying Eyewitness News-worthy Events on Twitter},
 year = {2016}
}

@inproceedings{W16-6203,
 address = {Austin, TX, USA},
 author = {Sadeque, Farig and Pedersen, Ted and Solorio, Thamar and Shrestha, Prasha and Rey-Villamizar, Nicolas and Bethard, Steven},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6203},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {14--19},
 publisher = {Association for Computational Linguistics},
 title = {Why Do They Leave: Modeling Participation in Online Depression Forums},
 year = {2016}
}

@inproceedings{W16-6204,
 address = {Austin, TX, USA},
 author = {Dredze, Mark and Andrews, Nicholas and DeYoung, Jay},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6204},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {20--25},
 publisher = {Association for Computational Linguistics},
 title = {Twitter at the Grammys: A Social Media Corpus for Entity Linking and Disambiguation},
 year = {2016}
}

@inproceedings{W16-6205,
 address = {Austin, TX, USA},
 author = {Navindgi, Amit and Brun, Caroline and Boulard Masson, C\'{e}cile and Nowson, Scott},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6205},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {26--33},
 publisher = {Association for Computational Linguistics},
 title = {Steps Toward Automatic Understanding of the Function of Affective Language in Support Groups},
 year = {2016}
}

@inproceedings{W16-6206,
 address = {Austin, TX, USA},
 author = {Kim, Sunghwan Mac and Wan, Stephen and Paris, Cecile},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6206},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {34--40},
 publisher = {Association for Computational Linguistics},
 title = {Detecting Social Roles in Twitter},
 year = {2016}
}

@inproceedings{W16-6207,
 address = {Austin, TX, USA},
 author = {Jain, Siddharth},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6207},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {41--47},
 publisher = {Association for Computational Linguistics},
 title = {Identifying Sensible Participants in Online Discussions},
 year = {2016}
}

@inproceedings{W16-6208,
 address = {Austin, TX, USA},
 author = {Eisner, Ben and Rockt\"{a}schel, Tim and Augenstein, Isabelle and Bosnjak, Matko and Riedel, Sebastian},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6208},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {48--54},
 publisher = {Association for Computational Linguistics},
 title = {emoji2vec: Learning Emoji Representations from their Description},
 year = {2016}
}

@inproceedings{W16-6209,
 address = {Austin, TX, USA},
 author = {Fang, Hao and Cheng, Hao and Ostendorf, Mari},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6209},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {55--64},
 publisher = {Association for Computational Linguistics},
 title = {Learning Latent Local Conversation Modes for Predicting Comment Endorsement in Online Discussions},
 year = {2016}
}

@inproceedings{W16-6210,
 address = {Austin, TX, USA},
 author = {Fang, Rui and Nourbakhsh, Armineh and LIU, XIAOMO and Shah, Sameena and Li, Quanzhi},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6210},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {65--73},
 publisher = {Association for Computational Linguistics},
 title = {Witness Identification in Twitter},
 year = {2016}
}

@inproceedings{W16-6211,
 address = {Austin, TX, USA},
 author = {Hsieh, Yu-Lun and Chang, Yung-Chun and Chu, Chun-Han and Hsu, Wen-Lian},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6211},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {74--83},
 publisher = {Association for Computational Linguistics},
 title = {How Do I Look? Publicity Mining From Distributed Keyword Representation of Socially Infused News Articles},
 year = {2016}
}

@inproceedings{W16-6212,
 address = {Austin, TX, USA},
 author = {Jaech, Aaron and Mulcaire, George and Hathi, Shobhit and Ostendorf, Mari and Smith, Noah A.},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6212},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {84--93},
 publisher = {Association for Computational Linguistics},
 title = {Hierarchical Character-Word Models for Language Identification},
 year = {2016}
}

@inproceedings{W16-6213,
 address = {Austin, TX, USA},
 author = {Pappas, Nikolaos and Popescu-Belis, Andrei},
 bdsk-url-1 = {http://aclweb.org/anthology/W16-6213},
 booktitle = {Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media},
 month = {November},
 pages = {94--100},
 publisher = {Association for Computational Linguistics},
 title = {Human versus Machine Attention in Document Classification: A Dataset with Crowdsourced Annotations},
 year = {2016}
}

@inproceedings{W16-6301,
 address = {Varanasi, India},
 author = {Pouliquen, Bruno},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6301},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {1},
 publisher = {NLP Association of India},
 title = {Keynote Lecture 1: Practical Use of Machine Translation in International Organizations},
 year = {2016}
}

@inproceedings{W16-6302,
 address = {Varanasi, India},
 author = {Foley, David and Kalita, Jugal},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6302},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {2--9},
 publisher = {NLP Association of India},
 title = {Integrating WordNet for Multiple Sense Embeddings in Vector Semantics},
 year = {2016}
}

@inproceedings{W16-6303,
 address = {Varanasi, India},
 author = {Banik, Debajyoty and Sen, Sukanta and Ekbal, Asif and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6303},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {10--19},
 publisher = {NLP Association of India},
 title = {Can SMT and RBMT Improve each other's Performance?- An Experiment with English-Hindi Translation},
 year = {2016}
}

@inproceedings{W16-6304,
 address = {Varanasi, India},
 author = {Yee, Kyra and Kalita, Jugal},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6304},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {20--29},
 publisher = {NLP Association of India},
 title = {Composition of Compound Nouns Using Distributional Semantics},
 year = {2016}
}

@inproceedings{W16-6305,
 address = {Varanasi, India},
 author = {Kannan, Abishek and Mohanty, Gaurav and Mamidi, Radhika},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6305},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {30--35},
 publisher = {NLP Association of India},
 title = {Towards Building a SentiWordNet for Tamil},
 year = {2016}
}

@inproceedings{W16-6306,
 address = {Varanasi, India},
 author = {Akarapu, Samaikya and Chowdary, C Ravindranath},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6306},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {36--45},
 publisher = {NLP Association of India},
 title = {Extending AIDA framework by incorporating coreference resolution on detected mentions and pruning based on popularity of an entity},
 year = {2016}
}

@inproceedings{W16-6307,
 address = {Varanasi, India},
 author = {Tripathi, Kumud and Sarkar, Parakrant and Rao, K. Sreenivasa},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6307},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {46--54},
 publisher = {NLP Association of India},
 title = {Sentence Based Discourse Classification for Hindi Story Text-to-Speech (TTS) System},
 year = {2016}
}

@inproceedings{W16-6308,
 address = {Varanasi, India},
 author = {Majumder, Amit and Ekbal, Asif and Naskar, Sudip Kumar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6308},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {55--64},
 publisher = {NLP Association of India},
 title = {Biomolecular Event Extraction using a Stacked Generalization based Classifier},
 year = {2016}
}

@inproceedings{W16-6309,
 address = {Varanasi, India},
 author = {Karmakar, Samir and Ghosh, Soumya Sankar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6309},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {65--70},
 publisher = {NLP Association of India},
 title = {Syntax and Pragmatics of Conversation: A Case of Bangla},
 year = {2016}
}

@inproceedings{W16-6310,
 address = {Varanasi, India},
 author = {Obrebski, Tomasz},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6310},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {71--80},
 publisher = {NLP Association of India},
 title = {Dependency grammars as Haskell programs},
 year = {2016}
}

@inproceedings{W16-6311,
 address = {Varanasi, India},
 author = {Kumar, Subham and Ray, Anwesh Sinha and Kamila, Sabyasachi and Ekbal, Asif and Saha, Sriparna and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6311},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {81--89},
 publisher = {NLP Association of India},
 title = {Improving Document Ranking using Query Expansion and Classification Techniques for Mixed Script Information Retrieval},
 year = {2016}
}

@inproceedings{W16-6312,
 address = {Varanasi, India},
 author = {Yadav, Neha and Chowdary, C Ravindranath},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6312},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {90--98},
 publisher = {NLP Association of India},
 title = {Feature based Sentiment Analysis using a Domain Ontology},
 year = {2016}
}

@inproceedings{W16-6313,
 address = {Varanasi, India},
 author = {Das, Ayan and Saha, Agnivo and Sarkar, Sudeshna},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6313},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {99--108},
 publisher = {NLP Association of India},
 title = {Cross-lingual transfer parser from Hindi to Bengali using delexicalization and chunking},
 year = {2016}
}

@inproceedings{W16-6314,
 address = {Varanasi, India},
 author = {Bick, Eckhard},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6314},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {109--114},
 publisher = {NLP Association of India},
 title = {Constraint Grammar-based conversion of Dependency Treebanks},
 year = {2016}
}

@inproceedings{W16-6315,
 address = {Varanasi, India},
 author = {Sharma, Raksha and Bhingardive, Sudha and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6315},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {115--119},
 publisher = {NLP Association of India},
 title = {Meaning Matters: Senses of Words are More Informative than Words for Cross-domain Sentiment Analysis},
 year = {2016}
}

@inproceedings{W16-6316,
 address = {Varanasi, India},
 author = {Mukherjee, Atreyee and K{\"u}bler, Sandra and Scheutz, Matthias},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6316},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {120--128},
 publisher = {NLP Association of India},
 title = {POS Tagging Experts via Topic Modeling},
 year = {2016}
}

@inproceedings{W16-6317,
 address = {Varanasi, India},
 author = {Karmakar, Samir and Banerjee, Sayantani and Ghosh, Soumya},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6317},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {129--136},
 publisher = {NLP Association of India},
 title = {Graph theoretic interpretation of Bangla traditional grammar},
 year = {2016}
}

@inproceedings{W16-6318,
 address = {Varanasi, India},
 author = {Jadon, Mukesh Kumar and Pareek, Ayush},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6318},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {137--143},
 publisher = {NLP Association of India},
 title = {A method for Automatic Text Summarization using Consensus of Multiple Similarity Measures and Ranking Techniques},
 year = {2016}
}

@inproceedings{W16-6319,
 address = {Varanasi, India},
 author = {Goyal, Lalit and Goyal, Vishal},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6319},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {144--153},
 publisher = {NLP Association of India},
 title = {Automatic Translation of English Text to Indian Sign Language Synthetic Animations},
 year = {2016}
}

@inproceedings{W16-6320,
 address = {Varanasi, India},
 author = {Athavale, Vinayak and Bharadwaj, Shreenivas and Pamecha, Monik and Prabhu, Ameya and Shrivastava, Manish},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6320},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {154--160},
 publisher = {NLP Association of India},
 title = {Towards Deep Learning in Hindi NER: An approach to tackle the Labelled Data Sparsity},
 year = {2016}
}

@inproceedings{W16-6321,
 address = {Varanasi, India},
 author = {Danda, Prathyusha and Srivastava, Brij Mohan Lal and Shrivastava, Manish},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6321},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {161--166},
 publisher = {NLP Association of India},
 title = {Vaidya: A Spoken Dialog System for Health Domain},
 year = {2016}
}

@inproceedings{W16-6322,
 address = {Varanasi, India},
 author = {Reganti, Aishwarya N and Maheshwari, Tushar and Kumar, Upendra and Das, Amitava},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6322},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {167--176},
 publisher = {NLP Association of India},
 title = {Cosmopolitan Mumbai, Orthodox Delhi, Techcity Bangalore:Understanding City Specific Societal Sentiment},
 year = {2016}
}

@inproceedings{W16-6323,
 address = {Varanasi, India},
 author = {Sproat, Richard},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6323},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {177},
 publisher = {NLP Association of India},
 title = {Keynote Lecture 2: Neural (and other Machine Learning) Approaches to Text Normalization},
 year = {2016}
}

@inproceedings{W16-6324,
 address = {Varanasi, India},
 author = {Roy, Shourya and Dandapat, Sandipan and Nagesh, Ajay and Y., Narahari},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6324},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {178--187},
 publisher = {NLP Association of India},
 title = {Wisdom of Students: A Consistent Automatic Short Answer Grading Technique},
 year = {2016}
}

@inproceedings{W16-6325,
 address = {Varanasi, India},
 author = {Shweta, {} and Kumar, Ankit and Ekbal, Asif and Saha, Sriparna and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6325},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {188--197},
 publisher = {NLP Association of India},
 title = {A Recurrent Neural Network Architecture for De-identifying Clinical Records},
 year = {2016}
}

@inproceedings{W16-6326,
 address = {Varanasi, India},
 author = {Sikdar, Utpal Kumar and Gamb{\"a}ck, Bj{\"o}rn},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6326},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {198--207},
 publisher = {NLP Association of India},
 title = {Twitter Named Entity Extraction and Linking Using Differential Evolution},
 year = {2016}
}

@inproceedings{W16-6327,
 address = {Varanasi, India},
 author = {Carlos, Cohan Sujay and Rakshit, Geetanjali},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6327},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {208--218},
 publisher = {NLP Association of India},
 title = {Learning Non-Linear Functions for Text Classification},
 year = {2016}
}

@inproceedings{W16-6328,
 address = {Varanasi, India},
 author = {Das, Debarati and Das, Bhaskarjyoti and Mahesh, Kavi},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6328},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {219--228},
 publisher = {NLP Association of India},
 title = {A Computational Analysis of Mahabharata},
 year = {2016}
}

@inproceedings{W16-6329,
 address = {Varanasi, India},
 author = {Sohoni, Samir Janardan and Kulkarni, Malhar A.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6329},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {229--238},
 publisher = {NLP Association of India},
 title = {Use of Features for Accentuation of gha{\~n}anta Words},
 year = {2016}
}

@inproceedings{W16-6330,
 address = {Varanasi, India},
 author = {Palshikar, Girish K. and Apte, Manoj and Pandita, Deepak and Singh, Vikram},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6330},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {239--248},
 publisher = {NLP Association of India},
 title = {Learning to Identify Subjective Sentences},
 year = {2016}
}

@inproceedings{W16-6331,
 address = {Varanasi, India},
 author = {Gupta, Deepak and Lamba, Ankit and Ekbal, Asif and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6331},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {249--258},
 publisher = {NLP Association of India},
 title = {Opinion Mining in a Code-Mixed Environment: A Case Study with Government Portals},
 year = {2016}
}

@inproceedings{W16-6332,
 address = {Varanasi, India},
 author = {Asnani, Kavita and Pawar, Jyoti D},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6332},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {259--266},
 publisher = {NLP Association of India},
 title = {Use of Semantic Knowledge Base for Enhancement of Coherence of Code-mixed Topic-Based Aspect Clusters},
 year = {2016}
}

@inproceedings{W16-6333,
 address = {Varanasi, India},
 author = {Nongmeikapam, Kishorjit and Bandyopadhyay, Sivaji},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6333},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {267--274},
 publisher = {NLP Association of India},
 title = {Genetic Algorithm (GA) Implementation for Feature Selection in Manipuri POS Tagging},
 year = {2016}
}

@inproceedings{W16-6334,
 address = {Varanasi, India},
 author = {Sinha, Manjira and Dasgupta, Tirthankar and Basu, Anupam},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6334},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {275--284},
 publisher = {NLP Association of India},
 title = {Effect of Syntactic Features in Bangla Sentence Comprehension},
 year = {2016}
}

@inproceedings{W16-6335,
 address = {Varanasi, India},
 author = {Roul, Rajendra Kumar and Rai, Pranav},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6335},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {285--292},
 publisher = {NLP Association of India},
 title = {A New Feature Selection Technique Combined with ELM Feature Space for Text Classification},
 year = {2016}
}

@inproceedings{W16-6336,
 address = {Varanasi, India},
 author = {Ponkiya, Girishkumar and Bhattacharyya, Pushpak and Palshikar, Girish K.},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6336},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {293--298},
 publisher = {NLP Association of India},
 title = {On Why Coarse Class Classification is Bottleneck in Noun Compound Interpretation},
 year = {2016}
}

@inproceedings{W16-6337,
 address = {Varanasi, India},
 author = {Redkar, Hanumant and Singh, Sandhya and Ghag, Nandini and Paranjape, Jai and Joshi, Nilesh and Kulkarni, Malhar and Bhattacharyya, Pushpak},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6337},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {299--304},
 publisher = {NLP Association of India},
 title = {Verbframator:Semi-Automatic Verb Frame Annotator Tool with Special Reference to Marathi},
 year = {2016}
}

@inproceedings{W16-6338,
 address = {Varanasi, India},
 author = {Ramesh, Sree Harsha and Jain, Jayant and S, Sarath K and Sundaresan, Krishna R},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6338},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {305--314},
 publisher = {NLP Association of India},
 title = {Towards Building A Domain Agnostic Natural Language Interface to Real-World Relational Databases},
 year = {2016}
}

@inproceedings{W16-6339,
 address = {Varanasi, India},
 author = {Basu, Joyanta and Basu, Tulika and Khan, Soma and Pal, Madhab and Roy, Rajib and Basu, Tapan Kumar},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6339},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {315--323},
 publisher = {NLP Association of India},
 title = {Experimental Study of Vowels in Nagamese, Ao and Lotha: Languages of Nagaland},
 year = {2016}
}

@inproceedings{W16-6340,
 address = {Varanasi, India},
 author = {Roy, Somnath},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6340},
 booktitle = {Proceedings of the 13th International Conference on Natural Language Processing},
 month = {December},
 pages = {324--330},
 publisher = {NLP Association of India},
 title = {Perception of Phi-Phrase boundaries in Hindi.},
 year = {2016}
}

@inproceedings{W16-6401,
 address = {Praha, Czechia},
 author = {Rudolf Rosa and Martin Popel and Ond{\v{r}}ej Bojar and David Mare{\v{c}}ek and Ond{\v{r}}ej Du{\v{s}}ek},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6401},
 booktitle = {Proceedings of the 2nd Deep Machine Translation Workshop},
 editor = {Jan Haji{\v{c}} and Gertjan van Noord and Ant{\'{o}}nio Branco},
 isbn = {978-80-88132-02-8},
 organization = {{\'{U}}{FAL} {MFF} {UK}},
 pages = {1--10},
 publisher = {{\'{U}}{FAL} {MFF} {UK}},
 title = {Moses {{\&}} Treex Hybrid {MT} Systems Bestiary},
 venue = {University of Lisbon, Faculty of Sciences, Department of Informatics},
 year = {2016}
}

@inproceedings{W16-6402,
 address = {Praha, Czechia},
 author = {Sophie Arnoult and Khalil Sima'an},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6402},
 booktitle = {Proceedings of the 2nd Deep Machine Translation Workshop},
 editor = {Jan Haji{\v{c}} and Gertjan van Noord and Ant{\'{o}}nio Branco},
 isbn = {978-80-88132-02-8},
 organization = {{\'{U}}{FAL} {MFF} {UK}},
 pages = {11--20},
 publisher = {{\'{U}}{FAL} {MFF} {UK}},
 title = {Factoring Adjunction in Hierarchical Phrase-Based {SMT}},
 venue = {University of Lisbon, Faculty of Sciences, Department of Informatics},
 year = {2016}
}

@inproceedings{W16-6403,
 address = {Praha, Czechia},
 author = {Kiril Simov and Petya Osenova},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6403},
 booktitle = {Proceedings of the 2nd Deep Machine Translation Workshop},
 editor = {Jan Haji{\v{c}} and Gertjan van Noord and Ant{\'{o}}nio Branco},
 isbn = {978-80-88132-02-8},
 organization = {{\'{U}}{FAL} {MFF} {UK}},
 pages = {21--28},
 publisher = {{\'{U}}{FAL} {MFF} {UK}},
 title = {A Hybrid Approach for Deep Machine Translation},
 venue = {University of Lisbon, Faculty of Sciences, Department of Informatics},
 year = {2016}
}

@inproceedings{W16-6404,
 address = {Praha, Czechia},
 author = {Eleftherios Avramidis and Vivien Macketanz and Aljoscha Burchardt and Jindrich Helcl and Hans Uszkoreit},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6404},
 booktitle = {Proceedings of the 2nd Deep Machine Translation Workshop},
 editor = {Jan Haji{\v{c}} and Gertjan van Noord and Ant{\'{o}}nio Branco},
 isbn = {978-80-88132-02-8},
 organization = {{\'{U}}{FAL} {MFF} {UK}},
 pages = {29--38},
 publisher = {{\'{U}}{FAL} {MFF} {UK}},
 title = {Deeper Machine Translation and Evaluation for German},
 venue = {University of Lisbon, Faculty of Sciences, Department of Informatics},
 year = {2016}
}

@inproceedings{W16-6405,
 address = {Praha, Czechia},
 author = {Mikel Artetxe and Gorka Labaka and Chakaveh Saedi and Jo{\{{\textasciitilde{}}}{a}}o Rodrigues and Jo{\{{\textasciitilde{}}}{a}}o Silva and Ant{\'{o}}nio Branco and Eneko Agirre},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6405},
 booktitle = {Proceedings of the 2nd Deep Machine Translation Workshop},
 editor = {Jan Haji{\v{c}} and Gertjan van Noord and Ant{\'{o}}nio Branco},
 isbn = {978-80-88132-02-8},
 organization = {{\'{U}}{FAL} {MFF} {UK}},
 pages = {39--46},
 publisher = {{\'{U}}{FAL} {MFF} {UK}},
 title = {Adding syntactic structure to bilingual terminology for improved domain adaptation},
 venue = {University of Lisbon, Faculty of Sciences, Department of Informatics},
 year = {2016}
}

@inproceedings{W16-6406,
 address = {Praha, Czechia},
 author = {Natalia Klyueva and Vladislav Kubo{\v{n}}},
 bdsk-url-1 = {http://www.aclweb.org/anthology/W16-6406},
 booktitle = {Proceedings of the 2nd Deep Machine Translation Workshop},
 editor = {Jan Haji{\v{c}} and Gertjan van Noord and Ant{\'{o}}nio Branco},
 isbn = {978-80-88132-02-8},
 organization = {{\'{U}}{FAL} {MFF} {UK}},
 pages = {47--53},
 publisher = {{\'{U}}{FAL} {MFF} {UK}},
 title = {Incorporation of a valency lexicon into a {TectoMT} pipeline},
 venue = {University of Lisbon, Faculty of Sciences, Department of Informatics},
 year = {2016}
}

@inproceedings{W16-6601,
 address = {Edinburgh, UK},
 author = {Macdonald, Iain and Siddharthan, Advaith},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6601},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {1--10},
 publisher = {Association for Computational Linguistics},
 title = {Summarising News Stories for Children},
 year = {2016}
}

@inproceedings{W16-6602,
 address = {Edinburgh, UK},
 author = {Winer, David and Young, R. Michael},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6602},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {11--20},
 publisher = {Association for Computational Linguistics},
 title = {Discourse-Driven Narrative Generation With Bipartite Planning},
 year = {2016}
}

@inproceedings{W16-6603,
 address = {Edinburgh, UK},
 author = {Pourdamghani, Nima and Knight, Kevin and Hermjakob, Ulf},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6603},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {21--25},
 publisher = {Association for Computational Linguistics},
 title = {Generating English from Abstract Meaning Representations},
 year = {2016}
}

@inproceedings{W16-6604,
 address = {Edinburgh, UK},
 author = {Acharya, Sabita and Di Eugenio, Barbara and D Boyd, Andrew and Dunn Lopez, Karen and Cameron, Richard and M Keenan, Gail},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6604},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {26--30},
 publisher = {Association for Computational Linguistics},
 title = {Generating summaries of hospitalizations: A new metric to assess the complexity of medical terms and their definitions},
 year = {2016}
}

@inproceedings{W16-6605,
 address = {Edinburgh, UK},
 author = {van Deemter, Kees},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6605},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {31--35},
 publisher = {Association for Computational Linguistics},
 title = {Designing Algorithms for Referring with Proper Names},
 year = {2016}
}

@inproceedings{W16-6606,
 address = {Edinburgh, UK},
 author = {Smiley, Charese and Plachouras, Vassilis and Schilder, Frank and Bretz, Hiroko and Leidner, Jochen and Song, Dezhao},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6606},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {36--39},
 publisher = {Association for Computational Linguistics},
 title = {When to Plummet and When to Soar: Corpus Based Verb Selection for Natural Language Generation},
 year = {2016}
}

@inproceedings{W16-6607,
 address = {Edinburgh, UK},
 author = {Choi, Yejin},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6607},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {40},
 publisher = {Association for Computational Linguistics},
 title = {Sketch-to-Text Generation: Toward Contextual, Creative, and Coherent Composition},
 year = {2016}
}

@inproceedings{W16-6608,
 address = {Edinburgh, UK},
 author = {Wubben, Sander and Krahmer, Emiel and van den Bosch, Antal and Verberne, Suzan},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6608},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {41--50},
 publisher = {Association for Computational Linguistics},
 title = {Abstractive Compression of Captions with Attentive Recurrent Neural Networks},
 year = {2016}
}

@inproceedings{W16-6609,
 address = {Edinburgh, UK},
 author = {Mazidi, Karen and Tarau, Paul},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6609},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {51--60},
 publisher = {Association for Computational Linguistics},
 title = {Infusing NLU into Automatic Question Generation},
 year = {2016}
}

@inproceedings{W16-6610,
 address = {Edinburgh, UK},
 author = {Aker, Ahmet and Paramita, Monica and Kurtic, Emina and Funk, Adam and Barker, Emma and Hepple, Mark and Gaizauskas, Rob},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6610},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {61--69},
 publisher = {Association for Computational Linguistics},
 title = {Automatic label generation for news comment clusters},
 year = {2016}
}

@inproceedings{W16-6611,
 address = {Edinburgh, UK},
 author = {Ahn, Emily and Morbini, Fabrizio and Gordon, Andrew},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6611},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {70--73},
 publisher = {Association for Computational Linguistics},
 title = {Improving Fluency in Narrative Text Generation With Grammatical Transformations and Probabilistic Parsing},
 year = {2016}
}

@inproceedings{W16-6612,
 address = {Edinburgh, UK},
 author = {Braun, Nadine and Goudbeek, Martijn and Krahmer, Emiel},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6612},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {74--78},
 publisher = {Association for Computational Linguistics},
 title = {The Multilingual Affective Soccer Corpus (MASC): Compiling a biased parallel corpus on soccer reportage in English, German and Dutch},
 year = {2016}
}

@inproceedings{W16-6613,
 address = {Edinburgh, UK},
 author = {Saint-Dizier, Patrick},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6613},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {79--83},
 publisher = {Association for Computational Linguistics},
 title = {Challenges of Argument Mining: Generating an Argument Synthesis based on the Qualia Structure},
 year = {2016}
}

@inproceedings{W16-6614,
 address = {Edinburgh, UK},
 author = {Byamugisha, Joan and Keet, C. Maria and DeRenzi, Brian},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6614},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {84--88},
 publisher = {Association for Computational Linguistics},
 title = {Tense and Aspect in Runyankore Using a Context-Free Grammar},
 year = {2016}
}

@inproceedings{W16-6615,
 address = {Edinburgh, UK},
 author = {Baltaretu, Adriana and Castro Ferreira, Thiago},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6615},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {89--93},
 publisher = {Association for Computational Linguistics},
 title = {Task demands and individual variation in referring expressions},
 year = {2016}
}

@inproceedings{W16-6616,
 address = {Edinburgh, UK},
 author = {Mohammed, Rania and Perez-Beltrachini, Laura and Gardent, Claire},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6616},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {94--98},
 publisher = {Association for Computational Linguistics},
 title = {Category-Driven Content Selection},
 year = {2016}
}

@inproceedings{W16-6617,
 address = {Edinburgh, UK},
 author = {Lee, Chia-Chen and HSIEH, Shu-Kai},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6617},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {99--103},
 publisher = {Association for Computational Linguistics},
 title = {Evaluative Pattern Extraction for Automated Text Generation},
 year = {2016}
}

@inproceedings{W16-6618,
 address = {Edinburgh, UK},
 author = {Li, Xiao and van Deemter, Kees and Lin, Chenghua},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6618},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {104--108},
 publisher = {Association for Computational Linguistics},
 title = {Statistics-Based Lexical Choice for NLG from Quantitative Information},
 year = {2016}
}

@inproceedings{W16-6619,
 address = {Edinburgh, UK},
 author = {Yu, Yanchao and Eshghi, Arash and Lemon, Oliver},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6619},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {109--110},
 publisher = {Association for Computational Linguistics},
 title = {Incremental Generation of Visually Grounded Language in Situated Dialogue (demonstration system)},
 year = {2016}
}

@inproceedings{W16-6620,
 address = {Edinburgh, UK},
 author = {Narayan, Shashi and Gardent, Claire},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6620},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {111--120},
 publisher = {Association for Computational Linguistics},
 title = {Unsupervised Sentence Simplification Using Deep Semantics},
 year = {2016}
}

@inproceedings{W16-6621,
 address = {Edinburgh, UK},
 author = {Moraes, Priscilla and Mccoy, Kathleen and Carberry, Sandra},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6621},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {121--131},
 publisher = {Association for Computational Linguistics},
 title = {Enabling text readability awareness during the micro planning phase of NLG applications},
 year = {2016}
}

@inproceedings{W16-6622,
 address = {Edinburgh, UK},
 author = {Demberg, Vera},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6622},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {132},
 publisher = {Association for Computational Linguistics},
 title = {How can we adapt generation to the user{\^a}s cognitive load?},
 year = {2016}
}

@inproceedings{W16-6623,
 address = {Edinburgh, UK},
 author = {Jin, Yiping and Le, Phu},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6623},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {133--142},
 publisher = {Association for Computational Linguistics},
 title = {Selecting Domain-Specific Concepts for Question Generation With Lightly-Supervised Methods},
 year = {2016}
}

@inproceedings{W16-6624,
 address = {Edinburgh, UK},
 author = {Mahapatra, Joy and Naskar, Sudip Kumar and Bandyopadhyay, Sivaji},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6624},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {143--152},
 publisher = {Association for Computational Linguistics},
 title = {Statistical Natural Language Generation from Tabular Non-textual Data},
 year = {2016}
}

@inproceedings{W16-6625,
 address = {Edinburgh, UK},
 author = {Narayan, Shashi and Reddy, Siva and Cohen, Shay B.},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6625},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {153--162},
 publisher = {Association for Computational Linguistics},
 title = {Paraphrase Generation from Latent-Variable PCFGs for Semantic Parsing},
 year = {2016}
}

@inproceedings{W16-6626,
 address = {Edinburgh, UK},
 author = {Colin, Emilie and Gardent, Claire and Mrabet, Yassine and Narayan, Shashi and Perez-Beltrachini, Laura},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6626},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {163--167},
 publisher = {Association for Computational Linguistics},
 title = {The WebNLG Challenge: Generating Text from DBPedia Data},
 year = {2016}
}

@inproceedings{W16-6627,
 address = {Edinburgh, UK},
 author = {Novikova, Jekaterina and Rieser, Verena},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6627},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {168--170},
 publisher = {Association for Computational Linguistics},
 title = {The aNALoGuE Challenge: Non Aligned Language GEneration},
 year = {2016}
}

@inproceedings{W16-6628,
 address = {Edinburgh, UK},
 author = {Concepci\'{o}n, Eugenio and M\'{e}ndez, Gonzalo and Gerv\'{a}s, Pablo and Le\'{o}n, Carlos},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6628},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {171--173},
 publisher = {Association for Computational Linguistics},
 title = {A Challenge Proposal for Narrative Generation Using CNLs},
 year = {2016}
}

@inproceedings{W16-6629,
 address = {Edinburgh, UK},
 author = {Keet, C. Maria and Khumalo, Langa},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6629},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {174--183},
 publisher = {Association for Computational Linguistics},
 title = {On the verbalization patterns of part-whole relations in isiZulu},
 year = {2016}
}

@inproceedings{W16-6630,
 address = {Edinburgh, UK},
 author = {Mazzei, Alessandro and Battaglino, Cristina and Bosco, Cristina},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6630},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {184--192},
 publisher = {Association for Computational Linguistics},
 title = {SimpleNLG-IT: adapting SimpleNLG to Italian},
 year = {2016}
}

@inproceedings{W16-6631,
 address = {Edinburgh, UK},
 author = {Wang, Josiah and Gaizauskas, Robert},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6631},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {193--202},
 publisher = {Association for Computational Linguistics},
 title = {Don't Mention the Shoe! A Learning to Rank Approach to Content Selection for Image Description Generation},
 year = {2016}
}

@inproceedings{W16-6632,
 address = {Edinburgh, UK},
 author = {Woo, Simon and Li, Zuyao and Mirkovic, Jelena},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6632},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {203--206},
 publisher = {Association for Computational Linguistics},
 title = {Good Automatic Authentication Question Generation},
 year = {2016}
}

@inproceedings{W16-6633,
 address = {Edinburgh, UK},
 author = {Isard, Amy and Knox, Jeremy},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6633},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {207--211},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Generation of Student Report Cards},
 year = {2016}
}

@inproceedings{W16-6634,
 address = {Edinburgh, UK},
 author = {Godwin, Keith and Piwek, Paul},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6634},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {212--216},
 publisher = {Association for Computational Linguistics},
 title = {Collecting Reliable Human Judgements on Machine-Generated Language: The Case of the QG-STEC Data},
 year = {2016}
}

@inproceedings{W16-6635,
 address = {Edinburgh, UK},
 author = {Chali, Yllias and Golestanirad, Sina},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6635},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {217--221},
 publisher = {Association for Computational Linguistics},
 title = {Ranking Automatically Generated Questions Using Common Human Queries},
 year = {2016}
}

@inproceedings{W16-6636,
 address = {Edinburgh, UK},
 author = {Castro Ferreira, Thiago and Wubben, Sander and Krahmer, Emiel},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6636},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {222--226},
 publisher = {Association for Computational Linguistics},
 title = {Towards proper name generation: a corpus analysis},
 year = {2016}
}

@inproceedings{W16-6637,
 address = {Edinburgh, UK},
 author = {Ghodsi, Aneiss and DeNero, John},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6637},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {227--231},
 publisher = {Association for Computational Linguistics},
 title = {An Analysis of the Ability of Statistical Language Models to Capture the Structural Properties of Language},
 year = {2016}
}

@inproceedings{W16-6638,
 address = {Edinburgh, UK},
 author = {King, David L. and White, Michael},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6638},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {232--236},
 publisher = {Association for Computational Linguistics},
 title = {Enhancing PTB Universal Dependencies for Grammar-Based Surface Realization},
 year = {2016}
}

@inproceedings{W16-6639,
 address = {Edinburgh, UK},
 author = {Belz, Anja and Muscat, Adrian and Birmingham, Brandon and Levacher, Jessie and Pain, Julie and Quinquenel, Adam},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6639},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {237--241},
 publisher = {Association for Computational Linguistics},
 title = {Effect of Data Annotation, Feature Selection and Model Choice on Spatial Description Generation in French},
 year = {2016}
}

@inproceedings{W16-6640,
 address = {Edinburgh, UK},
 author = {Patinho Rodrigues, Hugo and Coheur, Luisa and Nyberg, Eric},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6640},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {242--243},
 publisher = {Association for Computational Linguistics},
 title = {QGASP: a Framework for Question Generation Based on Different Levels of Linguistic Information},
 year = {2016}
}

@inproceedings{W16-6641,
 address = {Edinburgh, UK},
 author = {Duboue, Pablo},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6641},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {244--245},
 publisher = {Association for Computational Linguistics},
 title = {Automatic Reports from Spreadsheets: Data Analysis for the Rest of Us},
 year = {2016}
}

@inproceedings{W16-6642,
 address = {Edinburgh, UK},
 author = {Zarrie{\ss}, Sina and Schlangen, David},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6642},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {246--255},
 publisher = {Association for Computational Linguistics},
 title = {Towards Generating Colour Terms for Referents in Photographs: Prefer the Expected or the Unexpected?},
 year = {2016}
}

@inproceedings{W16-6643,
 address = {Edinburgh, UK},
 author = {de Oliveira, Rodrigo and Sripada, Somayajulu and Reiter, Ehud},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6643},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {256--264},
 publisher = {Association for Computational Linguistics},
 title = {Absolute and Relative Properties in Geographic Referring Expressions},
 year = {2016}
}

@inproceedings{W16-6644,
 address = {Edinburgh, UK},
 author = {Novikova, Jekaterina and Lemon, Oliver and Rieser, Verena},
 bdsk-url-1 = {http://anthology.aclweb.org/W16-6644},
 booktitle = {Proceedings of the 9th International Natural Language Generation conference},
 month = {September 5-8},
 pages = {265--273},
 publisher = {Association for Computational Linguistics},
 title = {Crowd-sourcing NLG Data: Pictures Elicit Better Data.},
 year = {2016}
}

